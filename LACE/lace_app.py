# =========== START of lace_app.py ===========
from __future__ import annotations
from typing import ClassVar, Dict, List, Set, Tuple, Optional, Type, Union, Any, Callable, Iterable, cast, Generic, TypeVar, Mapping, NamedTuple, TYPE_CHECKING, MutableMapping
import functools
from functools import partial
import hashlib
import io
import json
import ast
import math
import platform
import shutil
import sys
from types import MethodType
import uuid
import concurrent.futures
import multiprocessing as mp
import multiprocessing.managers
import queue # For thread-safe queue
from multiprocessing.shared_memory import SharedMemory
from multiprocessing import Queue, shared_memory
import setproctitle
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed
import threading
from queue import Full, Empty
from matplotlib.pyplot import viridis
import psutil
import copy
import gc
from datetime import datetime
from math import log
import inspect
import dataclasses
from pickle import TRUE
import dill
from tkinter import simpledialog
from turtle import Turtle

import matplotlib
import matplotlib.pyplot as plt
matplotlib.use('TkAgg')
matplotlib.interactive(False)
from sympy import zoo
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk # type: ignore (preserve this comment and use the exact usage on this line!)
import matplotlib.pyplot as plt
plt.ioff()
from mpl_toolkits.mplot3d.art3d import Poly3DCollection
import matplotlib.animation as animation
import matplotlib.cm as cm
from mpl_toolkits.mplot3d.axes3d import Axes3D as Axes3DType
import matplotlib.markers as markers
from matplotlib.markers import MarkerStyle 
from matplotlib.text import Text as MatplotlibText
from matplotlib.figure import Figure
from matplotlib.axes import Axes
from matplotlib.text import Text
from matplotlib.text import Text as MatplotlibText
from matplotlib.lines import Line2D
from matplotlib import colors
from matplotlib.colors import to_rgba, to_rgb, to_hex, Normalize, ListedColormap, LinearSegmentedColormap
from matplotlib.patches import Rectangle
from matplotlib.collections import LineCollection
from mpl_toolkits.mplot3d.art3d import Line3DCollection
from matplotlib.patches import Rectangle

import numpy as np
import numpy.typing as npt
from sympy import zoo
import itertools
import tkinter as tk
import tkinter.ttk as ttk
from tkinter import Widget, filedialog, colorchooser, messagebox, simpledialog


import networkx as nx # type: ignore (preserve this comment and use the exact usage on this line!)
from contextlib import contextmanager
import asyncio
import cProfile
import pstats
from enum import Enum, auto
from dataclasses import dataclass, asdict, field, fields
from collections import defaultdict
from _collections_abc import Mapping
from abc import ABC, abstractmethod
# import logging
from logging.handlers import QueueHandler, RotatingFileHandler
from itertools import combinations, product
import random
import os
from datetime import datetime
import time
import traceback
import colorsys
from functools import wraps, lru_cache
from numba import jit, njit, prange, cuda
from numba import types
from numba.typed import Dict as NumbaDict
import numpy as np
from typing_extensions import Protocol
from scipy.spatial import cKDTree, distance # type: ignore (preserve this comment and use the exact usage on this line!)
import warnings
import re 
import cProfile
import pstats
from functools import lru_cache

from .logging_config import setup_logging, logging, logger, APP_PATHS, APP_DIR, DETAIL_LEVEL_NUM, setup_directories, LogSettings
from .enums import Dimension, NeighborhoodType, CoordinateSystemType, StateType, TieBreaker
from .settings import GlobalSettings
from .interfaces import CoordinateSystem, Rule, NeighborhoodData, Shape, RuleMetadata, BaseMetrics
from .utils import (
    SpatialHashGrid, PerformanceLogger, SimulationStats, PerformanceMonitor, timer_decorator, log_errors,
    _ravel_multi_index, _unravel_index, _njit_unravel_index,
    _are_von_neumann_neighbors, _are_moore_neighbors, _are_hex_neighbors, _are_hex_prism_neighbors, 
    _populate_neighbor_array_optimized, _get_neighbors_dynamic_helper, BlittingManager
    )   
from .presets import (
    GridPreset, GridPresetManager, GridPresetManagementModal, CreateGridPresetModal, PatternFitResizeDialog, 
    ResizeProgressDialog, PatternFitResizeDialog, ResizePromptDialog
)
from .shapes import (
    ShapeDefinition, ShapePlacer, ShapeLibraryManager, ShapeGenerator, OverlapPromptDialog, UpdateShapeConfirmationDialog,
    generate_rle, parse_rle, ShapeLibraryEditorWindow, SaveShapeDialog
    )
from .rules import RuleLibrary, RuleLibraryManager, _standard_colormaps, calculate_max_neighbors
from .initial_conditions import InitialConditionManager
from .presets import GridPresetManager
from .colors import ColorScheme, ColorManager, _get_contrasting_inverted_color, ColorSettingsModal, is_dark_theme
from .analytics import ( # Assuming analytics.py is in the same directory/package
    AnalyticsManager, MetricRegistry, AnalyzerRegistry,
    BasicCountsCalculator, StabilityAnalyzer, DEFAULT_REPORT_DIR, AnalyticsWindow
)

perf_logger = PerformanceLogger()
logger.info(f"Global PerformanceLogger instance created in lace_app.py (ID: {id(perf_logger)})")
warnings.filterwarnings('ignore', category=UserWarning)
_current_log_file: Optional[str] = None
# Type aliases for improved type hints
NodeIndex = int
GridArray = npt.NDArray[np.float64]
NeighborIndices = npt.NDArray[np.int64]
Coordinates = Tuple[float, ...]
StateVarType = TypeVar('StateVarType', bound=Union[bool, int, float])
_global_grid_boundary: str = 'bounded'
_CREATING_DEFAULT_LIBRARY = False



# --- Top-Level Worker Initializer ---
def _worker_initializer_func(log_queue: Optional[queue.Queue] = None):
    """Initialize process for parallel execution with QueueHandler logging and garbage collection.
       (Round 19: Explicitly set worker root logger level to DEBUG)"""
    worker_pid = os.getpid()
    try: worker_name = mp.current_process().name
    except Exception: worker_name = f"WorkerPID_{worker_pid}"
    log_format = f'%(asctime)s - %(levelname)s - [{worker_name}({worker_pid})] - %(message)s'

    try: gc.collect(); print(f"[{worker_name}({worker_pid})] Performed initial garbage collection.", file=sys.stderr)
    except Exception as gc_err: print(f"[{worker_name}({worker_pid})] Error during initial garbage collection: {gc_err}", file=sys.stderr)

    try:
        worker_logger = logging.getLogger() # Get root logger for this process
        for handler in worker_logger.handlers[:]: worker_logger.removeHandler(handler) # Remove inherited handlers

        if log_queue and hasattr(log_queue, 'put') and callable(log_queue.put):
            queue_handler = QueueHandler(log_queue)
            worker_logger.addHandler(queue_handler)
            # --- MODIFIED: Set worker root logger level explicitly ---
            worker_logger.setLevel(logging.DEBUG)
            # ---
            # Add custom level if needed
            DETAIL_LEVEL_NUM = 15
            if logging.getLevelName(DETAIL_LEVEL_NUM) == f"Level {DETAIL_LEVEL_NUM}": # Avoid re-adding if already exists
                logging.addLevelName(DETAIL_LEVEL_NUM, "DETAIL")
                def detail(self, message, *args, **kws):
                    if self.isEnabledFor(DETAIL_LEVEL_NUM): self._log(DETAIL_LEVEL_NUM, message, args, **kws)
                logging.Logger.detail = detail # type: ignore [attr-defined]
            print(f"[{worker_name}({worker_pid})] Worker logging initialized with QueueHandler. Root Level: DEBUG.", file=sys.stderr)
            worker_logger.info("Worker logging initialized with QueueHandler.")
        else:
            if log_queue: print(f"[{worker_name}({worker_pid})] WARNING: Invalid log_queue object received, disabling worker logging.", file=sys.stderr)
            else: print(f"[{worker_name}({worker_pid})] WARNING: No log queue provided, disabling worker logging.", file=sys.stderr)
            worker_logger.addHandler(logging.NullHandler())
            worker_logger.setLevel(logging.CRITICAL + 1)

        # Configure Numba logger within the worker
        numba_worker_logger = logging.getLogger('numba')
        numba_worker_logger.setLevel(logging.WARNING)
        if not (log_queue and hasattr(log_queue, 'put') and callable(log_queue.put)):
            if not numba_worker_logger.hasHandlers(): numba_worker_logger.addHandler(logging.NullHandler())
        numba_worker_logger.propagate = False
        print(f"[{worker_name}({worker_pid})] Numba logger level set to WARNING for this worker.", file=sys.stderr)

    except Exception as e:
        print(f"[{worker_name}({worker_pid})] CRITICAL ERROR setting up worker logging: {e}", file=sys.stderr)
        try: # Fallback
            worker_logger = logging.getLogger();
            for handler in worker_logger.handlers[:]: worker_logger.removeHandler(handler)
            worker_logger.addHandler(logging.NullHandler()); worker_logger.setLevel(logging.CRITICAL + 1)
            numba_fallback_logger = logging.getLogger('numba'); numba_fallback_logger.setLevel(logging.WARNING)
            if not numba_fallback_logger.hasHandlers(): numba_fallback_logger.addHandler(logging.NullHandler())
            numba_fallback_logger.propagate = False
        except: pass

    try: import setproctitle; setproctitle.setproctitle(f"LACE Worker {worker_name}")
    except ImportError: pass
    except Exception as title_err: print(f"[{worker_name}({worker_pid})] Error setting process title: {title_err}", file=sys.stderr)


################################################
#                   OBSERVERS                  #
################################################
 


class Observer(ABC):
    """Abstract base class for observers"""

    @abstractmethod
    def update(self, subject):
        """Update the observer"""
        pass

class Observable:
    """Base class for observables"""

    def __init__(self):
        self._observers: List[Observer] = []

    def add_observer(self, observer: Observer):
        """Add an observer"""
        if observer not in self._observers:
            self._observers.append(observer)

    def remove_observer(self, observer: Observer):
        """Remove an observer"""
        if observer in self._observers:
            self._observers.remove(observer)

    def notify_observers(self):
        """Notify all observers"""
        for observer in self._observers:
            observer.update(self)



################################################
#                   GRID CLASS                 #
################################################

class Grid(Observable):
    """Optimized grid implementation using NumPy arrays and parallel processing"""

    def __init__(self, dimensions: Tuple[int, ...],
                 neighborhood_type: 'NeighborhoodType',
                 dimension_type: 'Dimension',
                 coord_system: CoordinateSystem,        # Moved before defaults
                 gui: Optional['SimulationGUI'] = None, # Default argument
                 rule: Optional['Rule'] = None,         # Default argument
                 unique_id: str = str(uuid.uuid4())):   # Default argument
        """
        Initializes the Grid.
        (Round 18: Corrected parameter order in signature)
        """
        super().__init__() # Call Observable init
        logger.debug(f"Grid.__init__: Initializing Grid with ID {unique_id}")
        self.dimensions = tuple(dimensions)
        self.neighborhood_type = neighborhood_type
        self.dimension_type = dimension_type
        self.rule = rule
        self._unique_id = unique_id
        self._shared_mem_name = None
        self._edges_initialized = False

        # --- Store gui reference (initially None) ---
        self.gui = gui
        # ---

        self.total_nodes = int(np.prod(self.dimensions))
        logger.debug(f"Total nodes: {self.total_nodes}")
        self.grid_array = np.full(self.dimensions, 0.0, dtype=np.float64)
        self.node_indices = np.arange(0, self.total_nodes).reshape(self.dimensions)

        self.previous_degree_array: Optional[npt.NDArray[np.int32]] = None
        self.previous_active_neighbor_array: Optional[npt.NDArray[np.int32]] = None

        self.spatial_hash = SpatialHashGrid(self.dimensions)
        self.max_neighbors = self._calculate_max_neighbors()

        self._precalculated_neighbor_indices: Optional[npt.NDArray[np.int64]] = None
        self._neighbor_indices_shm_meta: Optional[Dict[str, Any]] = None
        self._calculate_all_neighbor_indices()

        self._calculated_chunk_size = self._calculate_dynamic_chunk_size()
        logger.info(f"Calculated initial chunk size: {self._calculated_chunk_size}")

        self._neighborhood_data_cache: Dict[int, NeighborhoodData] = {}
        self._cache_lock = threading.Lock()
        self._caching_mode = "partial"
        self._cache_hits = 0; self._cache_misses = 0
        self._full_cache_threshold = GlobalSettings.Cache.FULL_CACHE_THRESHOLD
        self._partial_cache_threshold = GlobalSettings.Cache.PARTIAL_CACHE_THRESHOLD
        self._full_cache_memory_threshold = GlobalSettings.Cache.FULL_CACHE_MEMORY_THRESHOLD
        self._partial_cache_memory_threshold = GlobalSettings.Cache.PARTIAL_CACHE_MEMORY_THRESHOLD
        self._cache_check_interval = GlobalSettings.Cache.CACHE_CHECK_INTERVAL

        self.shared_mem = None; self.shared_array = None
        self._update_lock = threading.Lock()
        self._shared_memory_unlinked = False
        self._edge_states_shared_memory_unlinked = False
        self._shutdown_complete = False
        self.apply_tiebreakers = False

        self.edges: Set[Tuple[Tuple[int, ...], Tuple[int, ...]]] = set()
        self.edge_states: Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float] = {}

        self._cached_unscaled_positions = None; self._cached_positions = None
        self._cached_dimensions = None; self._cached_spacing = None
        self._cached_dimension_type = None

        self._initial_setup_complete = False
        history_depth_param = 10
        if self.rule and hasattr(self.rule, 'get_param'):
             history_depth_param = self.rule.get_param('node_history_depth', 10)
        self.node_history_depth = history_depth_param
        self.node_history: Dict[int, List[float]] = {i: [] for i in range(self.total_nodes)}
        self.node_attributes: Dict[int, Dict[str, Any]] = {i: {} for i in range(self.total_nodes)}
        self._observers: List[Observer] = []

        self.last_updated_nodes: Set[Tuple[int, ...]] = set()

        if self.dimension_type == Dimension.TWO_D: self.rows, self.cols = self.dimensions; self.depth = 1
        elif self.dimension_type == Dimension.THREE_D: self.rows, self.cols, self.depth = self.dimensions

        self.coord_system = coord_system
        self.active_nodes: Set[int] = set()
        self.previous_active_nodes_set: Set[int] = set()
        self._is_reinitializing = False
        self._last_mouse_press_time = 0

        self.shape_placer: Optional[ShapePlacer] = ShapePlacer(self)
        logger.debug("Initialized ShapePlacer instance within Grid.")

    def __del__(self):
        logger.debug(f"Grid.__del__: DELETING GRID OBJECT WITH ID {id(self)}")

    @timer_decorator
    def apply_preset(self, preset: 'GridPreset') -> bool:
        """
        Apply a grid preset's configuration and initialize state based on its mode.
        Handles degree or active neighbor count calculation for relevant rules when loading SAVED_STATE,
        preserving the visual 0/1 pattern in grid_array for the initial render.
        Delegates initialization to InitialConditionManager or ShapePlacer for other modes.
        (Round 35: Correct state preservation for degree/count rules)
        (Round 5: Correctly handle SPECIFIC_CONDITION, LIBRARY_SHAPE, RULE_DEFAULT modes)
        (Round 7: Fix bounding box size calculation for LIBRARY_SHAPE)
        """
        preset_content_applied = False
        log_prefix = f"Grid.apply_preset(Preset='{preset.name}', Mode='{preset.initialization_mode}' R7 BBox Size Fix): " # Updated round
        logger.info(f"{log_prefix}Applying preset...")
        logger.debug(f"{log_prefix}  Preset object received: Name='{preset.name}', Mode='{preset.initialization_mode}', Data='{preset.initialization_data}', State is None: {preset.initial_state is None}, Edges is None: {preset.edges is None}")
        if preset.initial_state is not None:
            logger.debug(f"    Preset initial_state shape: {preset.initial_state.shape}, dtype: {preset.initial_state.dtype}, Sum: {np.sum(preset.initial_state)}")

        try:
            # --- Clear grid content BEFORE applying any mode ---
            self.clear_grid()
            logger.debug(f"{log_prefix}  Grid content cleared before applying preset mode.")
            # ---

            init_mode = preset.initialization_mode
            init_data = preset.initialization_data
            manager = InitialConditionManager.get_instance()
            shape_manager = ShapeLibraryManager.get_instance()

            logger.info(f"{log_prefix}Processing initialization_mode: '{init_mode}'")

            # --- Apply State/Edges based on Mode ---
            if init_mode == "SAVED_STATE":
                logger.info(f"{log_prefix}Executing 'SAVED_STATE' logic.")
                if preset.initial_state is not None and preset.initial_state.shape == tuple(self.dimensions):
                    initial_state_pattern = preset.initial_state.copy()
                    self.grid_array = initial_state_pattern # Keep the 0/1 pattern
                    logger.info(f"{log_prefix}  Loaded initial 0/1 state pattern into grid_array. Sum: {np.sum(self.grid_array)}")
                    preset_content_applied = True

                    self.edges = set(preset.edges) if preset.edges else set()
                    self.edge_states = preset.edge_states.copy() if preset.edge_states else {}
                    logger.debug(f"{log_prefix}  Applied {len(self.edges)} edges and {len(self.edge_states)} edge states from preset.")

                    # --- Calculate Initial Degree/Neighbor Counts (Store in previous_ arrays) ---
                    initial_degrees = np.zeros(self.total_nodes, dtype=np.int32)
                    for edge_coords in self.edges:
                        try:
                            node1_coords, node2_coords = edge_coords
                            idx1 = _ravel_multi_index(np.array(node1_coords), self.dimensions)
                            idx2 = _ravel_multi_index(np.array(node2_coords), self.dimensions)
                            if 0 <= idx1 < self.total_nodes: initial_degrees[idx1] += 1
                            if 0 <= idx2 < self.total_nodes: initial_degrees[idx2] += 1
                        except Exception as degree_err: logger.warning(f"{log_prefix}Error calculating initial degree for edge {edge_coords}: {degree_err}")
                    self.previous_degree_array = initial_degrees.copy()
                    logger.debug(f"{log_prefix}  Calculated and stored initial degrees in previous_degree_array (Sum: {np.sum(initial_degrees)}).")

                    initial_active_neighbors = np.zeros(self.total_nodes, dtype=np.int32)
                    activity_threshold = 1e-6
                    for node_idx in range(self.total_nodes):
                         count = 0; neighbors = self.get_neighbors(node_idx, self.coord_system)
                         for neighbor_idx in neighbors:
                              if neighbor_idx != -1 and 0 <= neighbor_idx < initial_state_pattern.size and initial_state_pattern.ravel()[neighbor_idx] > activity_threshold:
                                  count += 1
                         initial_active_neighbors[node_idx] = count
                    self.previous_active_neighbor_array = initial_active_neighbors.copy()
                    logger.debug(f"{log_prefix}  Calculated and stored initial active neighbor counts in previous_active_neighbor_array (Sum: {np.sum(initial_active_neighbors)}).")
                else:
                    logger.error(f"{log_prefix}  Preset initial_state is None or shape mismatch. Grid remains empty.")

            elif init_mode == "RULE_DEFAULT":
                logger.info(f"{log_prefix}Executing 'RULE_DEFAULT' logic.")
                if self.rule:
                    rule_default_condition = self.rule.get_param('initial_conditions', "Random")
                    logger.info(f"  Applying rule's default condition: '{rule_default_condition}'")
                    self.rule.params['initial_density'] = preset.node_density
                    self.rule.params['connect_probability'] = preset.edge_density
                    manager.apply(rule_default_condition, self)
                    preset_content_applied = True
                else: logger.error(f"{log_prefix}Cannot apply rule default: Rule is not set on grid.")

            elif init_mode == "SPECIFIC_CONDITION":
                logger.info(f"{log_prefix}Executing 'SPECIFIC_CONDITION' logic with data: '{init_data}'.")
                if init_data:
                    if self.rule:
                        self.rule.params['initial_density'] = preset.node_density
                        self.rule.params['connect_probability'] = preset.edge_density
                    manager.apply(init_data, self)
                    preset_content_applied = True
                else: logger.error(f"{log_prefix}Cannot apply specific condition: initialization_data is missing.")

            elif init_mode == "LIBRARY_SHAPE":
                logger.info(f"{log_prefix}Executing 'LIBRARY_SHAPE' logic with data: '{init_data}'.")
                if init_data:
                    shape_def = shape_manager.get_shape(init_data)
                    if shape_def and self.shape_placer:
                        grid_center_coords = tuple(d / 2.0 for d in self.dimensions)
                        min_rel, max_rel = shape_def.get_bounding_box()
                        # --- Calculate shape size from bounding box ---
                        shape_size = tuple(mx - mn + 1 for mn, mx in zip(min_rel, max_rel))
                        # ---
                        shape_centroid_offset = tuple((mx + mn) / 2.0 - mn for mn, mx in zip(min_rel, max_rel))
                        origin = tuple(int(round(center - offset)) for center, offset in zip(grid_center_coords, shape_centroid_offset))
                        # Ensure origin is valid using calculated shape_size
                        origin = tuple(max(0, min(o, d - s)) for o, d, s in zip(origin, self.dimensions, shape_size))

                        logger.info(f"  Placing shape '{init_data}' at calculated origin {origin}.")
                        placed_indices = self.shape_placer.place_shape_definition(shape_def, origin)
                        if placed_indices is not None:
                            preset_content_applied = True
                            logger.debug(f"{log_prefix}Placed shape '{init_data}' at origin {origin}.")
                            if self.rule and self.rule.get_param('edge_initialization', 'NONE') != 'NONE':
                                connectivity = shape_def.connectivity if shape_def.connectivity != 'explicit' else 'full'
                                self.shape_placer.add_default_edges(placed_indices, connectivity)
                                logger.debug(f"  Added default edges (Connectivity: {connectivity}).")
                        else: logger.warning(f"{log_prefix}Placement of shape '{init_data}' failed or was cancelled.")
                    elif not shape_def: logger.error(f"{log_prefix}Library shape '{init_data}' not found.")
                    else: logger.error(f"{log_prefix}Shape placer not available.")
                else: logger.error(f"{log_prefix}Cannot place library shape: initialization_data is missing.")

            else:
                logger.error(f"{log_prefix}Unknown initialization_mode: '{init_mode}'. Grid remains empty.")

            # --- Populate Spatial Hash AFTER setting final state/edges ---
            if not self.populate_spatial_hash(): logger.error(f"{log_prefix}  Failed to populate spatial hash!")
            self.update_active_nodes() # Update active nodes based on the applied state
            # ---

            # --- Calculate previous arrays AFTER applying state ---
            if self.rule and (self.rule.needs_neighbor_degrees or self.rule.needs_neighbor_active_counts):
                initial_grid_array_flat = self.grid_array.ravel()
                initial_edge_set = self.edges.copy()
                initial_degree_array = np.zeros(self.total_nodes, dtype=np.int32)
                initial_active_neighbor_array = np.zeros(self.total_nodes, dtype=np.int32)
                activity_threshold = 1e-6
                if self.rule.needs_neighbor_degrees:
                    for edge_coords in initial_edge_set:
                        try:
                            idx1 = _ravel_multi_index(np.array(edge_coords[0]), self.dimensions); idx2 = _ravel_multi_index(np.array(edge_coords[1]), self.dimensions)
                            if 0 <= idx1 < self.total_nodes: initial_degree_array[idx1] += 1
                            if 0 <= idx2 < self.total_nodes: initial_degree_array[idx2] += 1
                        except Exception as degree_err: logger.warning(f"{log_prefix}Error calculating initial degree for edge {edge_coords}: {degree_err}")
                    self.previous_degree_array = initial_degree_array.copy()
                    logger.debug(f"{log_prefix}  Calculated and stored initial degrees in previous_degree_array (Sum: {np.sum(initial_degree_array)}).")
                if self.rule.needs_neighbor_active_counts:
                    for node_idx in range(self.total_nodes):
                        count = 0; neighbors = self.get_neighbors(node_idx, self.coord_system)
                        for neighbor_idx in neighbors:
                            if neighbor_idx != -1 and 0 <= neighbor_idx < initial_grid_array_flat.size and initial_grid_array_flat[neighbor_idx] > activity_threshold: count += 1
                        initial_active_neighbor_array[node_idx] = count
                    self.previous_active_neighbor_array = initial_active_neighbor_array.copy()
                    logger.debug(f"{log_prefix}  Calculated and stored initial active neighbor counts in previous_active_neighbor_array (Sum: {np.sum(initial_active_neighbor_array)}).")
            # ---

            self.previous_active_nodes_set = self.active_nodes.copy()

            logger.info(f"{log_prefix}Finished applying preset. Final Edges: {len(self.edges)}")
            self.notify_observers()
            return preset_content_applied

        except Exception as e:
            logger.error(f"{log_prefix}Error applying grid preset content: {e}")
            logger.error(traceback.format_exc())
            self.clear_grid(); self.populate_spatial_hash(); self.update_active_nodes(); self.notify_observers()
            return False
                                    
    def remove_observer(self, observer: Observer) -> None:
        """Remove an observer from the grid."""
        if observer in self._observers:
            self._observers.remove(observer)
            logger.debug(f"Observer {observer} removed from grid. Grid ID: {id(self)}")

    def notify_observers(self) -> None:
        """Notify all observers of a change."""
        if isinstance(self._observers, (list, tuple)):
            for obs in self._observers:
                # Process each observer
                pass
        else:
            raise TypeError(f"'self._observers' is not iterable. Expected list or tuple, got {type(self._observers).__name__}.")
            obs.update(self)  # Pass the grid as the subject
            logger.debug(f"Notified observer {obs}.")

    def set_cell_state(self, coords: Tuple[int, ...], state: float) -> None:
        """Set the state of a cell at the given coordinates"""
        if not (0 <= coords[0] < self.rows and 0 <= coords[1] < self.cols):
            logger.warning(f"Coordinates {coords} out of bounds")
            return  # Or raise an exception

        self.grid_array[coords] = state
        self.notify_observers()  # Notify after changing state

    def set_cells_by_indices(self, indices: List[Tuple[int, ...]], state: Union[float, np.ndarray]) -> None:
        """Set multiple cells to a given state using a list of indices"""
        if isinstance(state, np.ndarray):
            if len(indices) != state.size:
                raise ValueError("Number of indices and state array size mismatch")
        try:
            # Convert indices to a NumPy array for advanced indexing
            indices_array = np.array(indices)
            if len(indices_array.shape) == 1:  # if it's 1D make it 2D for consistency
                indices_array = np.expand_dims(indices_array, axis=0)

            # Check for out-of-bounds indices
            if not np.all((indices_array >= 0) & (indices_array < np.array(self.dimensions))):
                raise IndexError("Indices out of bounds")

            self.grid_array[tuple(indices_array.T)] = state  # type: ignore

        except IndexError as e:
            logger.error(f"Error setting cell states: {e}")
            raise
        except ValueError as e:
            logger.error(f"Error setting cell states: {e}")
            raise
        except Exception as e:
            logger.error(f"An unexpected error occurred: {e}")
            raise
        self.notify_observers()

    def reset(self) -> None:
        """Reset the grid to its initial state"""
        self.grid_array.fill(0)  # Or reset to the original initial_state
        self._observers = [] # remove all observers
        logger.debug("Grid reset to initial state")
        self.notify_observers() # Notify even if it is now empty

    def clear_grid(self):
        """Resets all nodes in the grid to the inactive state and clears edges, caches, and spatial hash.
           (Round 15: Reset previous degree/neighbor arrays)"""
        if self.grid_array is not None:
            self.grid_array.fill(0.0)  # Set all node states to 0.0
            # Update Shared Memory after clearing grid_array
            if self.shared_array is not None:
                try:
                    if self.shared_array.shape == self.grid_array.shape:
                        np.copyto(self.shared_array, self.grid_array)
                        logger.debug("Copied cleared grid_array to shared_array in clear_grid.")
                    else:
                        logger.error(f"Shape mismatch between grid_array {self.grid_array.shape} and shared_array {self.shared_array.shape} after clear! Cannot update shared memory.")
                except Exception as shm_copy_err:
                    logger.error(f"Error copying cleared grid to shared memory: {shm_copy_err}")
            else:
                logger.warning("Shared array is None, cannot update shared memory after clear.")
        else:
            logger.warning("Grid array is None, cannot clear.") # Added warning

        if self.edges is not None:
            self.edges.clear()  # Remove all edges
        if self.edge_states is not None:
            self.edge_states.clear()
        logger.debug(f"Grid cleared. Grid ID: {self._unique_id}")

        # Clear NeighborhoodData cache
        with self._cache_lock:
            self._neighborhood_data_cache.clear()
            logger.debug("Cleared neighborhood data cache.")

        # Clear the spatial hash
        if self.spatial_hash is not None:
                self.spatial_hash.clear()
                logger.debug("SpatialHashGrid cleared")
        else:
            logger.warning("Spatial hash is None, cannot clear.")

        # Clear the active_nodes set
        self.active_nodes.clear()
        logger.debug("Active nodes set cleared")

        # Clear previous_active_nodes_set
        self.previous_active_nodes_set.clear()
        logger.debug("Previous active nodes set cleared")

        # --- ADDED: Reset previous degree/active count arrays ---
        # Ensure these arrays exist before trying to fill them
        if self.previous_degree_array is None or self.previous_degree_array.size != self.total_nodes:
            self.previous_degree_array = np.zeros(self.total_nodes, dtype=np.int32)
        else:
            self.previous_degree_array.fill(0)

        if self.previous_active_neighbor_array is None or self.previous_active_neighbor_array.size != self.total_nodes:
            self.previous_active_neighbor_array = np.zeros(self.total_nodes, dtype=np.int32)
        else:
            self.previous_active_neighbor_array.fill(0)
        logger.debug("Reset previous degree and active neighbor count arrays to zeros.")
        # --- END ADDED ---

        self.notify_observers()  # Notify observers that the grid has changed

    def shift_grid_content(self, delta_rows: int, delta_cols: int, delta_k: int = 0):
        """
        Shifts the grid content (nodes, edges, states) toroidally.
        Modifies grid_array, edges, edge_states, previous_degree_array, and previous_active_neighbor_array in place.
        """
        log_prefix = f"Grid.shift_grid_content(dr={delta_rows}, dc={delta_cols}, dk={delta_k}): "
        logger.info(f"{log_prefix}Starting grid content shift.")

        if self.grid_array is None:
            logger.error(f"{log_prefix}Grid array is None. Cannot shift.")
            return

        dims = self.dimensions
        num_dims = len(dims)

        # Ensure deltas are integers
        delta_rows = int(delta_rows)
        delta_cols = int(delta_cols)
        delta_k = int(delta_k)

        # Calculate effective shifts (modulo dimensions)
        shift_vector = [0] * num_dims
        if num_dims >= 1: shift_vector[0] = delta_rows % dims[0]
        if num_dims >= 2: shift_vector[1] = delta_cols % dims[1]
        if num_dims >= 3: shift_vector[2] = delta_k % dims[2]

        if all(s == 0 for s in shift_vector):
            logger.info(f"{log_prefix}No effective shift needed. Skipping.")
            return

        logger.debug(f"{log_prefix}Effective shift vector: {shift_vector}")

        try:
            with self._update_lock: # Protect grid data during modification
                # 1. Shift grid_array
                self.grid_array = np.roll(self.grid_array, shift=tuple(shift_vector), axis=tuple(range(num_dims)))
                logger.debug(f"{log_prefix}Shifted grid_array.")

                # 2. Shift previous_degree_array (if exists)
                if self.previous_degree_array is not None:
                    if self.previous_degree_array.size == self.total_nodes:
                        reshaped_degrees = self.previous_degree_array.reshape(dims)
                        rolled_degrees = np.roll(reshaped_degrees, shift=tuple(shift_vector), axis=tuple(range(num_dims)))
                        self.previous_degree_array = rolled_degrees.ravel()
                        logger.debug(f"{log_prefix}Shifted previous_degree_array.")
                    else:
                        logger.warning(f"{log_prefix}previous_degree_array size mismatch ({self.previous_degree_array.size} vs {self.total_nodes}). Skipping shift.")
                        self.previous_degree_array = None # Invalidate if size is wrong

                # 3. Shift previous_active_neighbor_array (if exists)
                if self.previous_active_neighbor_array is not None:
                    if self.previous_active_neighbor_array.size == self.total_nodes:
                        reshaped_active = self.previous_active_neighbor_array.reshape(dims)
                        rolled_active = np.roll(reshaped_active, shift=tuple(shift_vector), axis=tuple(range(num_dims)))
                        self.previous_active_neighbor_array = rolled_active.ravel()
                        logger.debug(f"{log_prefix}Shifted previous_active_neighbor_array.")
                    else:
                        logger.warning(f"{log_prefix}previous_active_neighbor_array size mismatch ({self.previous_active_neighbor_array.size} vs {self.total_nodes}). Skipping shift.")
                        self.previous_active_neighbor_array = None # Invalidate if size is wrong

                # 4. Shift Edges and Edge States
                logger.debug(f"{log_prefix}Shifting {len(self.edges)} edges...")
                new_edges = set()
                new_edge_states = {}
                shift_array = np.array(shift_vector)
                dims_array = np.array(dims)

                for edge_coords in self.edges:
                    coord1_old, coord2_old = edge_coords
                    state = self.edge_states.get(edge_coords) # Get state using original ordered edge

                    # Calculate new coordinates with wrap-around
                    coord1_new = tuple(((np.array(coord1_old) + shift_array) % dims_array).tolist())
                    coord2_new = tuple(((np.array(coord2_old) + shift_array) % dims_array).tolist())

                    # Create new ordered edge tuple
                    new_ordered_edge = self._ordered_edge(coord1_new, coord2_new)
                    new_edges.add(new_ordered_edge)
                    if state is not None:
                        new_edge_states[new_ordered_edge] = state

                self.edges = new_edges
                self.edge_states = new_edge_states
                logger.debug(f"{log_prefix}Shifted {len(self.edges)} edges and {len(self.edge_states)} edge states.")

                # 5. Invalidate Caches (NeighborhoodData cache needs full clear)
                with self._cache_lock:
                    self._neighborhood_data_cache.clear()
                self._cached_positions = None # Invalidate display positions
                self._cached_unscaled_positions = None
                logger.debug(f"{log_prefix}Cleared neighborhood data cache and position caches.")

            # 6. Notify Observers (triggers redraw)
            logger.debug(f"{log_prefix}Notifying observers of grid shift.")
            self.notify_observers()
            logger.info(f"{log_prefix}Grid content shift complete.")

        except Exception as e:
            logger.error(f"{log_prefix}Error during grid shift: {e}")
            logger.error(traceback.format_exc())

    def get_neighbors(self, node_idx: int, coord_system: 'CoordinateSystem') -> np.ndarray:
        """
        Get the valid neighbor indices for a node using the pre-calculated array.
        (Round 36: Restored precalculated neighbor logic)
        """
        if self._precalculated_neighbor_indices is None:
            logger.error("Neighbor indices not pre-calculated!")
            # Attempt to calculate them now (fallback)
            self._calculate_all_neighbor_indices()
            if self._precalculated_neighbor_indices is None:  # Still None?
                logger.critical("Failed to calculate neighbor indices!")
                return np.array([], dtype=np.int64)

        if 0 <= node_idx < self.total_nodes:
            # Direct lookup from the pre-calculated array
            neighbors = self._precalculated_neighbor_indices[node_idx]
            # Filter out the -1 padding values
            valid_neighbors = neighbors[neighbors != -1]
            return valid_neighbors
        else:
            logger.warning(f"Node index {node_idx} out of bounds for precalculated neighbors.")
            return np.array([], dtype=np.int64)
   
    def are_neighbors(self, coord1: Tuple[int, ...], coord2: Tuple[int, ...]) -> bool:
        """Checks if two nodes (given by coordinates) are neighbors based on the grid's settings."""
        if not self.is_valid_coord(coord1) or not self.is_valid_coord(coord2):
            return False
        if coord1 == coord2:
            return False # A node is not its own neighbor

        # Convert coordinates to NumPy arrays for Numba functions if needed
        coord1_arr = np.array(coord1)
        coord2_arr = np.array(coord2)

        # Get boundary condition (needed by some Numba helpers)
        grid_boundary = self.rule.get_param('grid_boundary', 'bounded') if self.rule else 'bounded'

        # Call the appropriate Numba-optimized helper based on neighborhood type
        if self.neighborhood_type == NeighborhoodType.VON_NEUMANN:
            # _are_von_neumann_neighbors expects tuple dimensions
            return _are_von_neumann_neighbors(coord1_arr, coord2_arr, self.dimensions, grid_boundary)
        elif self.neighborhood_type == NeighborhoodType.MOORE:
            # _are_moore_neighbors expects tuple dimensions
            return _are_moore_neighbors(coord1_arr, coord2_arr, self.dimensions, grid_boundary)
        elif self.neighborhood_type == NeighborhoodType.HEX:
            if self.dimension_type == Dimension.TWO_D:
                # _are_hex_neighbors expects tuple dimensions
                 return _are_hex_neighbors(coord1_arr, coord2_arr, self.dimensions, grid_boundary)
            else: return False # HEX not valid for 3D
        elif self.neighborhood_type == NeighborhoodType.HEX_PRISM:
             if self.dimension_type == Dimension.THREE_D:
                 # _are_hex_prism_neighbors expects tuple dimensions
                 return _are_hex_prism_neighbors(coord1_arr, coord2_arr, self.dimensions, grid_boundary) # type: ignore
             else: return False # HEX_PRISM not valid for 2D
        else:
            logger.warning(f"Unknown neighborhood type {self.neighborhood_type} in are_neighbors check.")
            return False
  
    def add_edge(self, node_idx: int, neighbor_idx: int, edge_state: Optional[float] = None):
        """Add an edge between two nodes with optional edge state."""
        # --- CRITICAL FIX: Convert indices to grid coordinates ---
        node_coords = tuple(_unravel_index(node_idx, self.dimensions))
        neighbor_coords = tuple(_unravel_index(neighbor_idx, self.dimensions))
        edge = self._ordered_edge(node_coords, neighbor_coords)  # Use coordinate tuples
        # --- END CRITICAL FIX ---
        # logger.debug(f"add_edge called with node_idx: {node_idx}, neighbor_idx: {neighbor_idx}, edge_state: {edge_state}, edge: {edge}") # Reduce noise
        if edge not in self.edges:  # Only add if it doesn't already exist
            self.edges.add(edge)
            # Initialize edge state ONLY if it's a new edge
            if edge_state is not None:
                # Use provided state if given
                self.edge_states[edge] = edge_state
            elif self.rule:  # Only access rule parameters if a rule exists
                # --- MODIFIED: Provide defaults if params are None ---
                min_weight = self.rule.get_param('min_edge_weight', 0.0) # Default to 0.0 if None
                max_weight = self.rule.get_param('max_edge_weight', 1.0) # Default to 1.0 if None
                # Ensure they are floats before passing to uniform
                min_weight = float(min_weight) if min_weight is not None else 0.0
                max_weight = float(max_weight) if max_weight is not None else 1.0
                # --- END MODIFIED ---
                self.edge_states[edge] = random.uniform(min_weight, max_weight) if max_weight > min_weight else 1.0
            else:
                self.edge_states[edge] = 1.0  # Default to 1.0 if no rule

            # --- Added cache invalidation ---
            self._invalidate_neighbor_cache(node_idx)
            self._invalidate_neighbor_cache(neighbor_idx)

    def get_edge_state(self, node_idx: int, neighbor_idx: int) -> float:
        """Get the state of the edge between two nodes."""
        # --- CRITICAL FIX: Convert indices to grid coordinates ---
        node_coords = tuple(_unravel_index(node_idx, self.dimensions))
        neighbor_coords = tuple(_unravel_index(neighbor_idx, self.dimensions))
        edge = self._ordered_edge(node_coords, neighbor_coords)  # Use coordinate tuples
        # --- END CRITICAL FIX ---
        return self.edge_states.get(edge, 0.0)  # Return 0.0 if edge state doesn't exist

    def set_edge_state(self, node_idx: int, neighbor_idx: int, state: float):
        """Set the state of the edge between two nodes."""
        # --- CRITICAL FIX: Convert indices to grid coordinates ---
        node_coords = tuple(_unravel_index(node_idx, self.dimensions))
        neighbor_coords = tuple(_unravel_index(neighbor_idx, self.dimensions))
        edge = self._ordered_edge(node_coords, neighbor_coords)  # Use coordinate tuples
        # --- END CRITICAL FIX ---
        self.edge_states[edge] = state

    def _ordered_edge(self, node1: Tuple[int, ...], node2: Tuple[int, ...]) -> Tuple[Tuple[int, ...], Tuple[int, ...]]:
        """Return a consistently ordered tuple representing an edge."""
        # --- CRITICAL FIX:  Accept and return tuples of coordinates ---
        return (node1, node2) if node1 < node2 else (node2, node1)

    def remove_edge(self, node_idx: int, neighbor_idx: int):
        """Remove an edge between two nodes."""
        # --- CRITICAL FIX: Convert indices to grid coordinates ---
        node_coords = tuple(_unravel_index(node_idx, self.dimensions))
        neighbor_coords = tuple(_unravel_index(neighbor_idx, self.dimensions))
        edge = self._ordered_edge(node_coords, neighbor_coords)  # Use coordinate tuples
        # --- END CRITICAL FIX ---
        logger.debug(f"remove_edge called with node_idx: {node_idx}, neighbor_idx: {neighbor_idx}, edge: {edge}") # ADDED
        # Use discard for efficiency, and it handles the case where the edge doesn't exist
        self.edges.discard(edge)
        self.edge_states.pop(edge, None)  # Use pop with default to avoid KeyError
        
        # --- Added cache invalidation ---
        self._invalidate_neighbor_cache(node_idx)
        self._invalidate_neighbor_cache(neighbor_idx)

    def get_edges(self) -> List[Tuple[Tuple[int, ...], Tuple[int, ...]]]:
        """Return a list of edges with their states, as tuples: ((node1_coords, node2_coords))."""
        # --- CRITICAL FIX: Return grid coordinates, not indices ---
        return [(tuple(edge[0]), tuple(edge[1])) for edge in self.edges]
    
    def get_metric(self, metric_name: str, neighborhood: NeighborhoodData) -> Union[float, npt.NDArray[np.float64]]:
        """
        Gets a metric value for a given neighborhood.
        Handles calculation of metrics that require grid access, like edge_density.
        """
        # Check cache first (implementation assumes metric_cache exists on Grid or Rule)
        # This part depends on where you decide to store the metric cache.
        # Let's assume it's on the Rule for now.
        if self.rule:
            cache_key = (neighborhood.node_index, metric_name)
            if cache_key in self.rule.metric_cache:
                self.rule.perf_stats['cache_hits'] += 1
                return self.rule.metric_cache[cache_key]
            self.rule.perf_stats['cache_misses'] += 1
        else:
             # Handle case where rule is None if necessary
             pass

        value: Union[float, npt.NDArray[np.float64]]

        # --- Check if it's a metric calculated here (like edge_density) ---
        if metric_name == 'edge_density':
            value = self._calculate_edge_density(neighborhood)
        # --- Check pre-calculated metrics on NeighborhoodData ---
        elif metric_name in neighborhood.neighborhood_metrics:
            value = neighborhood.neighborhood_metrics[metric_name]
        elif metric_name in neighborhood.neighbor_metrics:
            value = neighborhood.neighbor_metrics[metric_name]
        # --- Check BaseMetrics for static/JIT methods ---
        elif hasattr(BaseMetrics, metric_name):
            method = getattr(BaseMetrics, metric_name)
            # Check if it's the JIT version or another static method
            # that only needs NeighborhoodData
            sig = inspect.signature(method)
            if 'grid' not in sig.parameters: # Check if it needs grid
                try:
                    # Pass only the required arguments based on BaseMetrics signatures
                    value = method(neighborhood.neighbor_states, neighborhood.neighbor_indices, neighborhood)
                except TypeError as te:
                    raise ValueError(f"Metric '{metric_name}' calculation error: {te}") from te
            else:
                # This case should ideally not be hit if grid-dependent metrics are handled above
                raise ValueError(f"Metric '{metric_name}' requires grid access but wasn't handled.")
        else:
            raise ValueError(f"Unknown metric requested: {metric_name}")

        # Cache the result (assuming cache is on the rule)
        if self.rule:
            self.rule.metric_cache[cache_key] = value

        return value

    def _calculate_edge_density(self, neighborhood: NeighborhoodData) -> float:
        """
        Calculates the local edge density for a given neighborhood.
        Moved from BaseMetrics to Grid class.
        """
        neighbor_indices = neighborhood.neighbor_indices
        if neighbor_indices is None or len(neighbor_indices) == 0:
            return 0.0
        valid_neighbors = neighbor_indices[neighbor_indices != -1]
        if len(valid_neighbors) < 2:
            return 0.0

        # Create an edge_exists array for the JIT-compiled version
        # --- MODIFIED: Calculate size correctly ---
        num_valid = len(valid_neighbors)
        # The JIT function iterates i from 0 to num_valid-1, j from i+1 to num_valid-1
        # The index calculation is idx = i * num_valid + j
        # The maximum index accessed will be roughly (num_valid-2)*num_valid + (num_valid-1)
        # A safe upper bound for the array size is num_valid * num_valid
        edge_exists_size = num_valid * num_valid
        edge_exists = np.zeros(edge_exists_size, dtype=np.bool_)
        # --- END MODIFIED ---

        for i in range(num_valid):
            for j in range(i + 1, num_valid):
                # Use the has_edge method of THIS Grid instance
                # Need indices, not coordinates here for has_edge
                node1_idx = valid_neighbors[i]
                node2_idx = valid_neighbors[j]
                if self.has_edge(node1_idx, node2_idx): # Call self.has_edge
                    # Calculate index and check bounds before assignment
                    idx = i * num_valid + j
                    if idx < edge_exists_size: # Check against calculated size
                        edge_exists[idx] = True
                    # else: # Optional: Log if index is out of bounds (shouldn't happen with correct size)
                    #    logger.warning(f"Index {idx} out of bounds for edge_exists array (size {edge_exists_size})")

        # Call the JIT-compiled version (imported from BaseMetrics)
        # Pass neighborhood.neighbor_states for the 'states' argument (though not used by edge_density_jit)
        return BaseMetrics.edge_density_jit(neighborhood.neighbor_states, neighbor_indices, edge_exists)

    def count_edges(self, node_idx: int) -> int:
        """Returns the total number of edges connected to the node."""
        # --- CRITICAL FIX: Convert index to grid coordinates ---
        node_coords = tuple(_unravel_index(node_idx, self.dimensions))
        return sum(1 for edge in self.edges if node_coords in edge)
        # --- END CRITICAL FIX ---

    def clear_edges(self, node_idx: int):
        """Clear all edges for a node (used during edge updates)."""
        # --- CRITICAL FIX: Convert index to grid coordinates ---
        node_coords = tuple(_unravel_index(node_idx, self.dimensions))
        # Efficiently remove edges and their states using a list comprehension and discard
        edges_to_remove = [edge for edge in self.edges if node_coords in edge]
        # --- END CRITICAL FIX ---
        for edge in edges_to_remove:
            self.edges.discard(edge)
            # Remove the edge state as well
            self.edge_states.pop(edge, None)  # Use pop with default to avoid KeyError
        logger.debug(f"Cleared edges for node {node_idx}")
        
        # --- Added cache invalidation ---
        self._invalidate_neighbor_cache(node_idx)

    def has_edge(self, node_idx: int, neighbor_idx: int) -> bool:
        """Check if an edge exists between two nodes."""
        # --- CRITICAL FIX: Convert indices to grid coordinates ---
        node_coords = tuple(_unravel_index(node_idx, self.dimensions))
        neighbor_coords = tuple(_unravel_index(neighbor_idx, self.dimensions))
        return self._ordered_edge(node_coords, neighbor_coords) in self.edges
        # --- END CRITICAL FIX ---

    def set_node_state(self, idx, state):
        """Set the state of a node by index, conditionally updating history.
           (Round 27: Conditional history update)"""
        # Update grid array
        if isinstance(idx, (list, tuple, np.ndarray)):
            flat_idx = np.ravel_multi_index(tuple(idx), self.dimensions)
        else:
            flat_idx = idx

        if not 0 <= flat_idx < self.total_nodes:
            logger.error(f"Index {flat_idx} out of bounds for grid size {self.total_nodes}")
            return False

        old_state = self.grid_array.ravel()[flat_idx]
        self.grid_array.ravel()[flat_idx] = state

        # Update active_nodes set
        is_active_now = state > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD
        was_active_before = old_state > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD
        node_idx_int = int(flat_idx) # Ensure integer key

        if is_active_now and not was_active_before:
            self.active_nodes.add(node_idx_int)
        elif not is_active_now and was_active_before:
            if node_idx_int in self.active_nodes:
                self.active_nodes.remove(node_idx_int)
            self.clear_edges(node_idx_int)

        # --- MODIFIED: Conditional History Update ---
        # Update node history ONLY if the current rule requires it
        if self.rule and self.rule.needs_node_history:
            if node_idx_int not in self.node_history:
                self.node_history[node_idx_int] = []
            self.node_history[node_idx_int].append(old_state)
            # Enforce depth limit
            if len(self.node_history[node_idx_int]) > self.node_history_depth:
                self.node_history[node_idx_int] = self.node_history[node_idx_int][-self.node_history_depth:]
        # --- END MODIFIED ---

        self._invalidate_neighbor_cache(node_idx_int)

        if self.spatial_hash is not None:
            grid_coords = _unravel_index(node_idx_int, self.dimensions)
            self.spatial_hash.update_node(node_idx_int, np.array(grid_coords))
        else:
            logger.warning(f"Spatial hash is None, cannot update node {node_idx_int} in hash.")

        return True

    def _invalidate_neighbor_cache(self, node_idx: int):
        """Invalidate NeighborhoodData cache entries for a node and its immediate neighbors."""
        # --- MODIFIED: Only invalidate NeighborhoodData cache ---
        with self._cache_lock:
            if node_idx in self._neighborhood_data_cache:
                del self._neighborhood_data_cache[node_idx]
            # Also invalidate the cache for all neighbors
            # --- Use the precalculated neighbor indices ---
            neighbors_to_invalidate = self.get_neighbors(node_idx, self.coord_system) # Use the fast lookup
            # ---
            for neighbor_idx in neighbors_to_invalidate:
                if neighbor_idx != -1 and neighbor_idx in self._neighborhood_data_cache:
                    del self._neighborhood_data_cache[neighbor_idx]
        # --- END MODIFIED ---

    def _switch_to_full_caching(self):
        """Switch to full caching mode (create NeighborhoodData for all nodes)"""
        with self._cache_lock:
            logger.info("Switching to full NeighborhoodData caching mode")
            self._neighborhood_data_cache.clear()  # Clear existing NeighborhoodData cache
            for idx in range(self.total_nodes):
                # --- REMOVED: Check/population of _neighbor_indices_cache ---
                # Create NeighborhoodData directly using get_neighbors
                self._neighborhood_data_cache[idx] = self.create_neighborhood_data(idx)
            self._caching_mode = "full"
            logger.info(f"Populated NeighborhoodData cache with {len(self._neighborhood_data_cache)} entries.")

    def _switch_to_partial_caching(self):
        """Switch to partial caching mode (only active nodes and neighbors)"""
        with self._cache_lock:
            logger.info("Switching to partial NeighborhoodData caching mode")
            self._neighborhood_data_cache.clear()  # Clear the NeighborhoodData cache
            self._caching_mode = "partial"
            # _neighbor_indices_cache is NOT cleared here

    def _adapt_caching_strategy(self):
        """Adapt the NeighborhoodData caching strategy based on performance and memory usage"""
        with self._cache_lock:
            if self._cache_hits + self._cache_misses == 0:
                return  # No data yet

            hit_rate = self._cache_hits / (self._cache_hits + self._cache_misses)

            # Estimate memory usage of the NeighborhoodData cache
            cache_size_bytes = sys.getsizeof(self._neighborhood_data_cache) # Use correct cache name
            available_memory = psutil.virtual_memory().available
            memory_usage_ratio = cache_size_bytes / available_memory

            logger.debug(f"Adapting Caching: Mode={self._caching_mode}, HitRate={hit_rate:.2f}, MemRatio={memory_usage_ratio:.2f}")

            if self._caching_mode == "partial":
                if (hit_rate > self._full_cache_threshold and
                    memory_usage_ratio < self._full_cache_memory_threshold):
                    self._switch_to_full_caching()
            elif self._caching_mode == "full":
                if (hit_rate < self._partial_cache_threshold or
                    memory_usage_ratio > self._partial_cache_memory_threshold):
                    self._switch_to_partial_caching()

            # Reset hit/miss counters (related to NeighborhoodData cache access)
            self._cache_hits = 0
            self._cache_misses = 0

    def _initialize_nodes_and_spatial_hash(self, node_density: float):
        """Initializes node states and populates the spatial hash grid with ALL nodes."""
        logger.debug("Entering _initialize_nodes_and_spatial_hash")

        if self.grid_array is not None:
            self.grid_array.fill(0.0)
        else:
            logger.error("Grid array is None, cannot initialize random state")
            return

        # --- ADDED: Check if spatial_hash exists before clearing ---
        if self.spatial_hash is not None:
            self.spatial_hash.clear()
            logger.debug("Cleared spatial hash before initialization")
        else:
            logger.warning("Spatial hash is None, cannot clear.")
        # ---

        initial_conditions_type = self.rule.get_param('initial_conditions', "Random") if self.rule is not None else "Random"

        if initial_conditions_type != "ShapeShifting":
            total_nodes = np.prod(self.dimensions)
            active_cells = int(total_nodes * node_density)
            grid_size = self.grid_array.size

            if active_cells > 0:
                active_cells = min(active_cells, grid_size)
                active_indices = np.random.choice(grid_size, size=active_cells, replace=False)

                if self.grid_array is not None:
                    self.grid_array.ravel()[active_indices] = 1.0
                    logger.debug(f"Initialized {active_cells} active nodes with random state")
                else:
                    logger.error("grid_array is None, cannot set active nodes")
                    return
            else:
                logger.warning("No active cells to initialize (density too low)")

        # --- MODIFIED: Add ALL nodes to the spatial hash and verify ---
        logger.debug(f"Adding ALL {self.total_nodes} nodes to spatial hash")
        # --- ADDED: Check if spatial_hash exists before updating ---
        if self.spatial_hash is not None:
            for idx in range(self.total_nodes):
                grid_coords = _unravel_index(idx, self.dimensions)
                # Check if node already exists before updating (optional optimization)
                # if idx not in self.spatial_hash.node_positions:
                self.spatial_hash.update_node(idx, np.array(grid_coords))
                # else: logger.debug(f"Node {idx} already in spatial hash, skipping add.")

            # --- Verification Logging ---
            logger.debug(f"Verifying spatial hash population after initialization")
            missing_count = 0
            for idx in range(self.total_nodes):
                if idx not in self.spatial_hash.node_positions:
                    missing_count += 1
                    logger.warning(f"Node {idx} (coords: {_unravel_index(idx, self.dimensions)}) is MISSING from spatial hash!")
            if missing_count > 0:
                logger.error(f"ERROR: {missing_count} nodes are missing from spatial hash after initialization!")
            else:
                logger.debug("All nodes successfully added to spatial hash.")
            # --- END Verification ---
        else:
            logger.error("Spatial hash is None, cannot add nodes.")
        # --- END ADDED CHECK ---

        logger.debug(f"Exiting _initialize_nodes_and_spatial_hash")

    @timer_decorator
    def populate_spatial_hash(self, progress_callback: Optional[Callable[[int, int], None]] = None, cancel_event: Optional[threading.Event] = None) -> bool: # Added cancel_event parameter
        """Populates the spatial hash grid with ALL nodes using optimized bulk insertion and verifies. Reports progress and supports cancellation."""
        log_prefix = "Grid.populate_spatial_hash: "
        logger.debug(f"{log_prefix}Entering (Optimized Bulk Insert)")
        success = True

        if self.spatial_hash is None:
            logger.error(f"{log_prefix}Spatial hash is None, cannot populate.")
            return False

        if self.total_nodes == 0:
             logger.warning(f"{log_prefix}Total nodes is 0, skipping population.")
             self.spatial_hash.clear()
             self.spatial_hash.num_nodes = 0
             return True

        # --- Progress Reporting Setup ---
        report_progress = progress_callback is not None
        total_steps = self.total_nodes
        progress_update_interval = max(100, total_steps // 100) # Update ~100 times
        # ---

        try:
            self.spatial_hash.clear()
            self.spatial_hash.cell_size = self.spatial_hash._calculate_initial_cell_size()
            logger.debug(f"{log_prefix}Using initial cell_size: {self.spatial_hash.cell_size:.4f}")

            logger.debug(f"{log_prefix}Adding ALL {self.total_nodes} nodes directly to spatial hash structures.")

            temp_cells: Dict[Tuple[int, ...], Set[int]] = defaultdict(set)
            temp_node_positions: Dict[int, np.ndarray] = {}

            for idx in range(self.total_nodes):
                # --- ADDED: Cancellation Check ---
                if cancel_event and cancel_event.is_set():
                    logger.info(f"{log_prefix}Cancellation detected during population.")
                    raise InterruptedError("Spatial hash population cancelled")
                # ---

                grid_coords = _unravel_index(idx, self.dimensions)
                cell_coords = self.spatial_hash._get_cell_coords(grid_coords)
                temp_node_positions[idx] = grid_coords
                temp_cells[cell_coords].add(idx)

                # --- Update Progress Bar ---
                if report_progress and (idx + 1) % progress_update_interval == 0:
                    progress_callback(idx + 1, self.total_nodes) # Pass current value and max value
                # ---

            # --- Assign built structures ---
            self.spatial_hash.cells = temp_cells
            self.spatial_hash.node_positions = temp_node_positions
            self.spatial_hash.num_nodes = self.total_nodes
            self.spatial_hash.kdtree = None
            self.spatial_hash.steps_since_adaptation = 0
            # ---

            # --- Verification Logging ---
            logger.debug(f"{log_prefix}Verifying spatial hash population after bulk insert.")
            if len(self.spatial_hash.node_positions) != self.total_nodes:
                logger.error(f"ERROR: Node position count ({len(self.spatial_hash.node_positions)}) mismatch total nodes ({self.total_nodes})!")
                success = False
            else:
                logger.debug(f"{log_prefix}Verification complete. Node count matches.")
            # ---

            logger.debug(f"{log_prefix}Populated spatial hash with {self.spatial_hash.num_nodes} nodes. Success: {success}")
            return success

        except InterruptedError: # Catch cancellation from within the loop
             logger.info(f"{log_prefix}Population cancelled.")
             return False # Indicate failure due to cancellation
        except Exception as e:
            logger.error(f"{log_prefix}Exception during optimized population: {e}")
            logger.error(traceback.format_exc())
            return False
        finally:
             # --- Final Progress Update ---
             if report_progress:
                 # Check cancel again before final update
                 if not (cancel_event and cancel_event.is_set()):
                     progress_callback(self.total_nodes, self.total_nodes) # Signal completion
             # ---

    @timer_decorator
    def initialize_edges_after_nodes(self, edge_initialization_type='RANDOM'):
        """Initializes edges based on the specified type, after nodes are initialized.
           (Round 4 Fix: Added logging for active indices found)"""
        # --- Get connect_probability FIRST ---
        connect_probability = GlobalSettings.Simulation.INITIAL_EDGE_DENSITY # Default to global
        if self.rule:
            connect_probability = self.rule.get_param('connect_probability', GlobalSettings.Simulation.INITIAL_EDGE_DENSITY)
        connect_probability = np.clip(connect_probability, 0.0, 1.0) # Ensure valid range

        log_prefix = f"Grid.initialize_edges_after_nodes(Type={edge_initialization_type}): " # Added prefix
        logger.info(f"{log_prefix}--- ENTRY ---")
        logger.info(f"  Connect Probability (Target): {connect_probability:.3f}")
        # ---

        self.edges = set()
        self.edge_states = {}

        logger.debug(f"{log_prefix}Initializing edges with type {edge_initialization_type}")

        # --- ADDED LOGGING: Log state BEFORE finding active indices ---
        active_count_before_find = np.sum(self.grid_array.ravel() > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD)
        logger.debug(f"{log_prefix}Grid state BEFORE finding active indices: {active_count_before_find} active nodes.")
        # ---

        active_indices = np.where(self.grid_array.ravel() > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD)[0]
        # --- ADDED LOGGING: Log number of active indices found ---
        logger.info(f"{log_prefix}Found {len(active_indices)} active node indices based on grid_array.")
        # ---

        missing_in_hash = 0
        for idx in active_indices:
            if self.spatial_hash is not None and idx not in self.spatial_hash.node_positions:
                grid_coords = _unravel_index(idx, self.dimensions)
                self.spatial_hash.update_node(idx, np.array(grid_coords))
                missing_in_hash += 1
        if missing_in_hash > 0:
            logger.warning(f"{log_prefix}Added {missing_in_hash} missing active nodes to spatial hash before edge initialization.")

        num_active_nodes = len(active_indices)
        if num_active_nodes < 2 and edge_initialization_type != 'NONE':
             logger.warning(f"{log_prefix}Less than 2 active nodes, skipping edge initialization types other than NONE.")
             return # Cannot form edges

        if edge_initialization_type == 'RANDOM':
            logger.info(f"  Initializing RANDOM edges using connect_probability: {connect_probability:.3f}")
            # Iterate through potential edges between active nodes
            for i_idx, node1_idx in enumerate(active_indices):
                neighbors = self.get_neighbors(node1_idx, self.coord_system)
                for node2_idx in neighbors:
                    # Check if neighbor is also active and avoid duplicates/self-loops
                    # --- MODIFIED: Check if node2_idx is in the active_indices set ---
                    if node2_idx > node1_idx and node2_idx in active_indices:
                    # ---
                        # --- Use connect_probability directly for the random check ---
                        if random.random() < connect_probability:
                            node1_coords = tuple(_unravel_index(node1_idx, self.dimensions))
                            node2_coords = tuple(_unravel_index(node2_idx, self.dimensions))
                            edge = self._ordered_edge(node1_coords, node2_coords)
                            self.edges.add(edge)
                            # Initialize edge state (e.g., random or 1.0)
                            min_w = self.rule.get_param('min_edge_weight', 0.0) if self.rule else 0.0
                            max_w = self.rule.get_param('max_edge_weight', 1.0) if self.rule else 1.0
                            self.edge_states[edge] = random.uniform(min_w, max_w) if max_w > min_w else 1.0
                            # logger.debug(f"  Added edge: {edge}") # Reduce noise
        # --- Keep other initialization types as they were ---
        elif edge_initialization_type == 'FULL':
            logger.info("  Initializing edges with FULL (connecting all active neighbors)")
            for i_idx, node1_idx in enumerate(active_indices):
                neighbors = self.get_neighbors(node1_idx, self.coord_system)
                for node2_idx in neighbors:
                    # --- MODIFIED: Check if node2_idx is in the active_indices set ---
                    if node2_idx > node1_idx and node2_idx in active_indices: # Connect only active neighbors
                    # ---
                        node1_coords = tuple(_unravel_index(node1_idx, self.dimensions))
                        node2_coords = tuple(_unravel_index(node2_idx, self.dimensions))
                        edge = self._ordered_edge(node1_coords, node2_coords)
                        self.edges.add(edge)
                        self.edge_states[edge] = 1.0
        elif edge_initialization_type == 'NONE':
            logger.info("  Initializing edges with NONE (No edges)")
            pass # Edges already cleared
        else:
            logger.warning(f"{log_prefix}Unknown edge initialization type: {edge_initialization_type}. Defaulting to NONE.")
            pass # Default to no edges if type is unknown

        logger.debug(f"{log_prefix}Initialized {len(self.edges)} edges with type {edge_initialization_type}")
        logger.info(f"{log_prefix}--- EXIT ---")

    @timer_decorator
    def reinitialize(self, dimensions: Tuple[int, ...],
                     neighborhood_type: 'NeighborhoodType',
                     dimension_type: 'Dimension',
                     coord_system: CoordinateSystem, # Added coord_system
                     rule: Optional['Rule'] = None,
                     gui: Optional['SimulationGUI'] = None, # Added gui
                     unique_id: str = str(uuid.uuid4()),
                     progress_callback: Optional[Callable[[int, str], None]] = None,
                     cancel_event: Optional[threading.Event] = None):
        """
        Reinitialize the grid with new parameters, reusing the existing object.
        Ensures cleanup before creating new structures.
        (Round 17: Call cleanup first, add memory logging)
        """
        log_prefix = "Grid.reinitialize: "
        logger.info(f"{log_prefix}Entering")
        logger.info(f"{log_prefix}Reinitializing grid with dimensions: {dimensions}, neighborhood_type={neighborhood_type}, dimension_type={dimension_type}, rule={rule.name if rule else 'None'}, unique_id={unique_id}")

        def check_cancel():
            if cancel_event and cancel_event.is_set():
                raise InterruptedError("Grid reinitialization cancelled")

        try:
            # --- 1. Call Cleanup FIRST ---
            if progress_callback: progress_callback(0, "Cleaning Up Old Grid...")
            check_cancel()
            self.cleanup() # Call cleanup to release old resources
            logger.info(f"{log_prefix}Cleanup finished.")
            # ---

            # --- 2. Update Attributes ---
            if progress_callback: progress_callback(1, "Updating Attributes...")
            check_cancel()

            self.dimensions = tuple(dimensions)
            self.neighborhood_type = neighborhood_type
            self.dimension_type = dimension_type
            self.coord_system = coord_system
            self.gui = gui
            if rule is not None: self.rule = rule
            else: self.rule = None # Ensure rule is None if not provided
            self.total_nodes = int(np.prod(self.dimensions))
            self.max_neighbors = self._calculate_max_neighbors()
            self._unique_id = unique_id # Update unique ID if provided
            self._shared_memory_unlinked = False # Reset flags
            self._edge_states_shared_memory_unlinked = False
            self._shutdown_complete = False
            self._initial_setup_complete = False
            self._edges_initialized = False

            # --- 3. Allocate New Arrays and Structures ---
            if progress_callback: progress_callback(2, "Allocating Memory...")
            check_cancel()
            logger.debug(f"{log_prefix}Allocating new grid_array {self.dimensions}...")
            self.grid_array = np.full(self.dimensions, 0.0, dtype=np.float64)
            self.node_indices = np.arange(self.total_nodes).reshape(self.dimensions)
            self.previous_degree_array = None
            self.previous_active_neighbor_array = None
            self.spatial_hash = SpatialHashGrid(self.dimensions)
            self._precalculated_neighbor_indices = None
            self._neighbor_indices_shm_meta = None
            self._neighborhood_data_cache = {}
            self.edges = set()
            self.edge_states = {}
            self._cached_unscaled_positions = None; self._cached_positions = None
            self._cached_dimensions = None; self._cached_spacing = None
            self._cached_dimension_type = None
            self.node_history = {i: [] for i in range(self.total_nodes)}
            self.node_attributes = {i: {} for i in range(self.total_nodes)}
            if self.dimension_type == Dimension.TWO_D: self.rows, self.cols = self.dimensions; self.depth = 1
            elif self.dimension_type == Dimension.THREE_D: self.rows, self.cols, self.depth = self.dimensions
            self.active_nodes = set(); self.previous_active_nodes_set = set()
            self.shape_placer = ShapePlacer(self) # Recreate placer with new grid ref
            logger.debug(f"{log_prefix}New arrays and structures allocated.")

            # --- 4. Calculate Neighbors ---
            if progress_callback: progress_callback(3, "Calculating Neighbors...")
            check_cancel()
            self._calculate_all_neighbor_indices() # Calculate for new dimensions/neighborhood

            # --- 5. Setup Shared Memory ---
            if progress_callback: progress_callback(4, "Setting up Shared Memory...")
            check_cancel()
            self._calculated_chunk_size = self._calculate_dynamic_chunk_size()
            self.setup_shared_memory() # Setup SHM for the NEW arrays

            # --- 6. Trigger GC in Main Process ---
            if progress_callback: progress_callback(5, "Finalizing...")
            check_cancel()
            gc.collect() # Encourage cleanup in the calling process

            logger.info(f"{log_prefix}Reinitialization complete.")

        except InterruptedError:
             logger.info(f"{log_prefix}Reinitialization cancelled.")
             # Attempt cleanup even if cancelled mid-way
             self.cleanup()
             raise
        except Exception as e:
             logger.error(f"{log_prefix}Error during reinitialization: {e}")
             logger.error(traceback.format_exc())
             # Attempt cleanup on error
             self.cleanup()
             raise
            
    def _calculate_dynamic_chunk_size(self) -> int:
        """
        Calculates a dynamic chunk size for parallel processing.
        Uses a reference size (512 for 50xN dims) and scales based on the
        current grid's average dimension, rounded to the nearest power of 2.
        Includes clamping.
        (Round 18: Implement dimension-scaled auto chunk size)
        """
        log_prefix = "Grid._calculate_dynamic_chunk_size (R18 Scaled Auto): "
        num_workers = GlobalSettings.Simulation.NUM_PROCESSES
        if num_workers <= 0: num_workers = 1 # Ensure at least 1 worker

        if self.total_nodes == 0:
            logger.warning(f"{log_prefix}Total nodes is 0, returning chunk size 1.")
            return 1

        # --- Reference Values ---
        ref_avg_dim = 50.0  # Reference average dimension (e.g., from 50x50)
        ref_chunk = 512.0   # Chunk size that worked well for the reference size

        # --- Calculate Current Average Dimension ---
        num_dims = len(self.dimensions)
        if num_dims == 0: # Should not happen, but safeguard
            logger.error(f"{log_prefix}Grid has 0 dimensions! Returning chunk size 1.")
            return 1
        current_avg_dim = self.total_nodes**(1.0 / num_dims)

        # --- Scale Chunk Size ---
        if ref_avg_dim <= 0: # Avoid division by zero
             logger.warning(f"{log_prefix}Reference average dimension is zero or negative, using default scaling.")
             scaled_chunk = ref_chunk # Default to reference chunk if ref_avg_dim is invalid
        else:
             scale_factor = current_avg_dim / ref_avg_dim
             scaled_chunk = ref_chunk * scale_factor
        logger.debug(f"{log_prefix}CurrentAvgDim={current_avg_dim:.2f}, RefAvgDim={ref_avg_dim:.2f}, ScaleFactor={scale_factor:.3f} -> ScaledChunk={scaled_chunk:.2f}")

        # --- Round to Nearest Power of 2 ---
        if scaled_chunk <= 0: # Handle non-positive results before log2
            power_of_2_chunk = 64 # Default to min clamp value if scaling results in <= 0
            logger.warning(f"{log_prefix}Scaled chunk size is non-positive ({scaled_chunk:.2f}), defaulting to {power_of_2_chunk}.")
        else:
            try:
                log2_chunk = np.log2(scaled_chunk)
                rounded_log2 = np.round(log2_chunk)
                power_of_2_chunk = 2**rounded_log2
                logger.debug(f"{log_prefix}ScaledChunk={scaled_chunk:.2f} -> Log2={log2_chunk:.2f} -> RoundedLog2={rounded_log2} -> PowerOf2Chunk={power_of_2_chunk}")
            except Exception as e_pow2:
                 logger.error(f"{log_prefix}Error rounding to power of 2: {e_pow2}. Using scaled value directly.")
                 power_of_2_chunk = scaled_chunk # Fallback to scaled value

        # --- Clamp the Result ---
        min_clamp = 64
        max_clamp = 4096
        clamped_chunk = max(min_clamp, min(max_clamp, power_of_2_chunk))
        # Ensure chunk size is not larger than total nodes
        final_chunk = max(1, min(int(clamped_chunk), self.total_nodes))

        logger.info(f"{log_prefix}Calculated 'Auto' chunk size: {final_chunk} (Scaled={scaled_chunk:.1f}, Pow2={power_of_2_chunk:.1f}, Clamped={clamped_chunk:.1f})")
        return int(final_chunk)

    def _calculate_all_neighbor_indices(self):
        """
        Pre-calculates the neighbor indices for all nodes based on the
        current grid dimensions, neighborhood type, and boundary condition.
        Stores the result in self._precalculated_neighbor_indices.
        """
        logger.info(f"Pre-calculating neighbor indices for {self.total_nodes} nodes...")
        start_time = time.time()

        # Ensure rule exists to get boundary condition
        if self.rule is None:
            logger.warning("Rule is None, using 'bounded' boundary condition for neighbor calculation.")
            grid_boundary = 'bounded'
        else:
            grid_boundary = self.rule.get_param('grid_boundary', 'bounded')

        # Convert boundary string to int for Numba (0=bounded, 1=wrap)
        boundary_mode = 1 if grid_boundary == 'wrap' else 0

        # Allocate the array
        self._precalculated_neighbor_indices = np.full(
            (self.total_nodes, self.max_neighbors), -1, dtype=np.int64
        )

        # Call the optimized Numba function
        try:
            _populate_neighbor_array_optimized(
                self.total_nodes,
                np.array(self.dimensions, dtype=np.int64), # Pass dimensions as numpy array
                self.neighborhood_type.value, # Pass enum value
                boundary_mode,
                self.max_neighbors,
                self._precalculated_neighbor_indices # Pass the array to be filled
            )
        except Exception as e:
            logger.error(f"Error during Numba neighbor calculation: {e}")
            logger.error(traceback.format_exc())
            # Fallback or raise error? For now, log and continue with potentially empty array
            self._precalculated_neighbor_indices.fill(-1) # Ensure it's filled with -1 on error

        end_time = time.time()
        logger.info(f"Neighbor index pre-calculation complete in {end_time - start_time:.4f} seconds.")

    def _calculate_connect_probability(self, target_density):
        """Calculates the connect probability needed to achieve a target edge density."""
        # The connect_probability IS the target_density for RANDOM initialization.
        connect_probability = np.clip(target_density, 0.0, 1.0)
        logger.debug(f"Calculated connect_probability: {connect_probability:.3f} for target edge density: {target_density:.3f}")
        return connect_probability

    @staticmethod
    def _process_connectivity_edges(
        chunk_indices: List[int],
        eligibility_proxy_shm_name: Optional[str], # Name for SHM holding Phase 1 results
        grid_shape: Tuple[int, ...],               # Needed to interpret eligibility array
        grid_dtype: np.dtype,                      # Eligibility proxy dtype (float64)
        neighbor_indices_shm_meta: Optional[Dict[str, Any]],
        rule: 'Rule', # Pass the rule instance (needed for potential future use)
        params_copy: Dict[str, Any], # *** ADDED: Explicit parameters ***
        grid_dimensions: Tuple[int, ...],
        _eligibility_proxy_override: Optional[npt.NDArray[np.float64]] = None # For sequential testing
        ) -> List[Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float]]:
            """
            Worker for Phase 2: Proposes edges based on mutual eligibility from Phase 1.
            Returns a list of dictionaries, one per node in the chunk, containing proposed edges { (coord1, coord2): 1.0 }.
            (Round 17: Log eligibility values read)
            """
            # --- Numba helper ---
            # @njit(cache=True, fastmath=True)
            def _unravel_index_local(idx: int, dimensions: Tuple[int, ...]) -> np.ndarray:
                coords = np.empty(len(dimensions), dtype=np.int64)
                current_idx = idx
                for i_local in range(len(dimensions) - 1, -1, -1):
                    dim_size = dimensions[i_local]
                    if dim_size == 0: continue
                    coords[i_local] = current_idx % dim_size
                    current_idx //= dim_size
                return coords
            # ---

            logger = logging.getLogger(__name__ + ".worker_conn_edges")
            shm_eligibility = None
            shm_neighbors = None
            eligibility_proxies_flat = None
            neighbor_indices_array_shm = None
            chunk_size = len(chunk_indices)
            default_return: List[Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float]] = [{} for _ in range(chunk_size)]
            detailed_logging_enabled = LogSettings.Performance.ENABLE_DETAILED_LOGGING
            log_prefix = f"WorkerConnEdges (PID:{os.getpid()}): "

            if not chunk_indices: logger.error(f"{log_prefix}Received empty list."); return default_return
            if detailed_logging_enabled: logger.detail(f"{log_prefix}Processing chunk {chunk_indices[0]}...{chunk_indices[-1]} ({chunk_size} nodes)") # type: ignore [attr-defined]

            try:
                # --- Attach to Eligibility Proxy Shared Memory ---
                if _eligibility_proxy_override is not None:
                    eligibility_proxies_flat = _eligibility_proxy_override
                    if detailed_logging_enabled: logger.detail(f"{log_prefix}Using provided eligibility_proxy_override.") # type: ignore [attr-defined]
                elif eligibility_proxy_shm_name:
                    try:
                        shm_eligibility = SharedMemory(name=eligibility_proxy_shm_name, create=False)
                        # Assuming eligibility proxies are stored flat, matching grid_array shape
                        eligibility_proxies_flat = np.ndarray(np.prod(grid_shape), dtype=grid_dtype, buffer=shm_eligibility.buf)
                    except Exception as shm_err:
                        logger.error(f"{log_prefix}SHM Error (eligibility): {shm_err}"); return default_return
                else:
                    logger.error(f"{log_prefix}No SHM name or override for eligibility proxies!"); return default_return
                # ---

                # --- Attach to Neighbor Indices Shared Memory ---
                if neighbor_indices_shm_meta:
                    try:
                        shm_neighbors = SharedMemory(name=neighbor_indices_shm_meta['name'], create=False)
                        neighbor_indices_array_shm = np.ndarray(
                            neighbor_indices_shm_meta['shape'],
                            dtype=neighbor_indices_shm_meta['dtype'],
                            buffer=shm_neighbors.buf
                        )
                    except Exception as shm_err:
                        logger.error(f"{log_prefix}SHM Error (neighbors): {shm_err}")
                        neighbor_indices_array_shm = None # Continue without precalculated neighbors if SHM fails
                # ---

                proposed_edges_list: List[Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float]] = [{} for _ in range(chunk_size)]
                chunk_coords = {idx: tuple(_unravel_index_local(idx, grid_dimensions)) for idx in chunk_indices}

                for i, node_idx in enumerate(chunk_indices):
                    try:
                        # Get self eligibility from the results of Phase 1
                        self_is_eligible = False
                        self_eligibility_value = 0.0 # For logging
                        if 0 <= node_idx < eligibility_proxies_flat.size:
                            self_eligibility_value = eligibility_proxies_flat[node_idx] # Read value
                            self_is_eligible = self_eligibility_value > 0.5
                        else: logger.warning(f"{log_prefix}Node index {node_idx} out of bounds for eligibility array."); continue

                        # --- ADDED: Log self eligibility ---
                        if detailed_logging_enabled: logger.detail(f"{log_prefix}Node {node_idx}: Read Self Eligibility = {self_eligibility_value:.1f} -> Eligible = {self_is_eligible}") # type: ignore [attr-defined]
                        # ---

                        # If self is not eligible, it cannot propose edges
                        if not self_is_eligible: continue

                        # Get neighbors
                        neighbors = np.array([], dtype=np.int64)
                        if neighbor_indices_array_shm is not None and 0 <= node_idx < neighbor_indices_array_shm.shape[0]:
                            neighbors_padded = neighbor_indices_array_shm[node_idx]
                            neighbors = neighbors_padded[neighbors_padded != -1]
                        # else: # Fallback if neighbor SHM failed (less efficient)
                        #    pass # Need a way to calculate neighbors here if needed

                        node_coords = chunk_coords[node_idx]
                        chunk_proposals: Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float] = {}

                        for neighbor_idx in neighbors:
                            if neighbor_idx < 0 or neighbor_idx <= node_idx: continue # Skip invalid and avoid double check

                            # Get neighbor eligibility from the results of Phase 1
                            neighbor_is_eligible = False
                            neighbor_eligibility_value = 0.0 # For logging
                            if 0 <= neighbor_idx < eligibility_proxies_flat.size:
                                neighbor_eligibility_value = eligibility_proxies_flat[neighbor_idx] # Read value
                                neighbor_is_eligible = neighbor_eligibility_value > 0.5
                            else: logger.warning(f"{log_prefix}Neighbor index {neighbor_idx} out of bounds for eligibility array."); continue

                            # --- ADDED: Log neighbor eligibility ---
                            if detailed_logging_enabled: logger.detail(f"{log_prefix}  Neighbor {neighbor_idx}: Read Eligibility = {neighbor_eligibility_value:.1f} -> Eligible = {neighbor_is_eligible}") # type: ignore [attr-defined]
                            # ---

                            # Propose edge ONLY if BOTH are eligible
                            if self_is_eligible and neighbor_is_eligible:
                                neighbor_coords = tuple(_unravel_index_local(neighbor_idx, grid_dimensions))
                                edge_coords = (node_coords, neighbor_coords) # Order doesn't strictly matter here, controller combines
                                chunk_proposals[edge_coords] = 1.0 # Propose binary edge
                                if detailed_logging_enabled: logger.detail(f"{log_prefix}    Proposing edge to {neighbor_idx} (Both eligible)") # type: ignore [attr-defined]
                            # else: # Optional log
                                # if detailed_logging_enabled: logger.detail(f"{log_prefix}    NOT proposing edge to {neighbor_idx} (One or both ineligible)") # type: ignore [attr-defined]

                        proposed_edges_list[i] = chunk_proposals

                    except Exception as node_e:
                        logger.error(f"{log_prefix}Error processing node {node_idx} for edge proposals: {node_e}")
                        logger.error(traceback.format_exc())
                        proposed_edges_list[i] = {} # Ensure empty dict on error

                if detailed_logging_enabled: logger.detail(f"{log_prefix}Finished processing chunk {chunk_indices[0]}...{chunk_indices[-1]}") # type: ignore [attr-defined]
                return proposed_edges_list

            except Exception as e:
                logger.error(f"{log_prefix}Error in _process_connectivity_edges: {e}")
                logger.error(traceback.format_exc())
                return default_return
            finally:
                if shm_eligibility is not None: shm_eligibility.close()
                if shm_neighbors is not None: shm_neighbors.close()

    @staticmethod
    def _process_initializer():
        """Initialize process for parallel execution"""
        # Silence warnings in worker processes
        np.seterr(all='ignore')

        # Set process name for better debugging
        # Optional: Install setproctitle package for better process names
        try:
            setproctitle.setproctitle("NetworkCA Worker")
        except ImportError:
            pass

    @timer_decorator                      
    def update_edges(self, node_idx: int, new_edges: Set[int]):
        """
        Update edges for a node more efficiently.  Now a Grid method.
        """
        try:
            # Clear existing edges for the node
            self.clear_edges(node_idx)

            # Add new edges, ensuring the lower index is always first
            for neighbor_idx in new_edges:
                self.add_edge(node_idx, neighbor_idx)

        except Exception as e:
            logger.error(f"Error updating edges: {str(e)}")
            raise

    @timer_decorator
    def update_active_nodes(self):
        """Update the set of active nodes based on the current grid state."""
        try:
            logger.debug("Updating active nodes set")
            
            # Clear the existing set
            self.active_nodes.clear()
            
            # Iterate through the grid array and add active nodes to the set
            if self.dimension_type == Dimension.THREE_D:
                for i in range(self.dimensions[0]):
                    for j in range(self.dimensions[1]):
                        for k in range(self.dimensions[2]):
                            if self.grid_array[i, j, k] > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD:
                                node_idx = _ravel_multi_index(np.array([i, j, k]), self.dimensions)
                                self.active_nodes.add(node_idx)
            else:  # TWO_D
                for i in range(self.dimensions[0]):
                    for j in range(self.dimensions[1]):
                        if self.grid_array[i, j] > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD:
                            node_idx = _ravel_multi_index(np.array([i, j]), self.dimensions)
                            self.active_nodes.add(node_idx)
            
            logger.debug(f"Updated active nodes set with {len(self.active_nodes)} active nodes")
        except Exception as e:
            logger.error(f"Error updating active nodes set: {e}")
            logger.error(traceback.format_exc())

    def _update_node_states_based_on_density(self, density: float):
        """Updates node states based on the given density."""
        logger.debug(f"Updating node states based on density: {density:.2f}")
        if self.grid_array is None:
            logger.error("Grid array is None, cannot update node states")
            return

        # Clear existing grid state
        self.grid_array.fill(0.0)

        # Calculate the number of active cells
        total_nodes = np.prod(self.dimensions)
        active_cells = int(total_nodes * density)

        # Generate random indices for active cells
        if active_cells > 0:
            grid_size = self.grid_array.size
            active_cells = min(active_cells, grid_size)
            active_indices = np.random.choice(grid_size, size=active_cells, replace=False)
            self.grid_array.ravel()[active_indices] = 1.0 # Set active state
            logger.debug(f"Set {active_cells} nodes to active state (1.0)")
        else:
            logger.warning("No active cells to initialize (density too low)")

        # Update spatial hash
        if self.spatial_hash is not None:
            self.spatial_hash.clear()
            for idx in range(self.total_nodes):
                grid_coords = _unravel_index(idx, self.dimensions)
                self.spatial_hash.update_node(idx, np.array(grid_coords))
            logger.debug("Spatial hash populated with new node states")
        else:
            logger.warning("Spatial hash is None, cannot update.")

        # Update active nodes set
        self.update_active_nodes()
        logger.debug(f"Updated active nodes set (Count: {len(self.active_nodes)})")

    def get_node_positions(self, node_indices: Optional[npt.NDArray[np.int64]] = None) -> Dict[int, Tuple[float, ...]]:
        """
        Get scaled coordinates for nodes, optionally for a subset of indices.
        Caches unscaled grid coordinates and scaled display coordinates.
        Checks grid dimensions, spacing, and dimension type for cache validity.
        (Round 12: Implement coordinate caching)
        """
        log_prefix = f"Grid.get_node_positions(ID:{self._unique_id}): "
        try:
            # --- Get current state for cache check ---
            current_dims = self.dimensions
            current_dim_type = self.dimension_type
            current_spacing = self.coord_system.node_spacing if self.coord_system else GlobalSettings.Visualization.NODE_SPACING
            current_scale_factor = self.coord_system.scale_factor if self.coord_system else GlobalSettings.Visualization.EDGE_SCALE * (1.0 + current_spacing)

            recalc_unscaled = False
            recalc_scaled = False

            # --- Check if unscaled positions need recalculation ---
            if (not hasattr(self, '_cached_unscaled_grid_coords') or self._cached_unscaled_grid_coords is None or
                not hasattr(self, '_cached_unscaled_dims') or self._cached_unscaled_dims != current_dims or
                not hasattr(self, '_cached_unscaled_dim_type') or self._cached_unscaled_dim_type != current_dim_type):
                logger.info(f"{log_prefix}Recalculating unscaled grid coordinates (Cache invalid/missing).")
                recalc_unscaled = True
                self._cached_unscaled_grid_coords = {}
                for idx in range(self.total_nodes):
                    # Store the tuple result of _unravel_index
                    self._cached_unscaled_grid_coords[idx] = tuple(_unravel_index(idx, current_dims))
                self._cached_unscaled_dims = current_dims
                self._cached_unscaled_dim_type = current_dim_type
                self._cached_scaled_positions = None # Invalidate scaled cache if unscaled changes

            # --- Check if scaled positions need recalculation ---
            if (not hasattr(self, '_cached_scaled_positions') or self._cached_scaled_positions is None or
                not hasattr(self, '_cached_scaled_spacing') or not np.isclose(self._cached_scaled_spacing, current_spacing) or
                not hasattr(self, '_cached_scale_factor') or not np.isclose(self._cached_scale_factor, current_scale_factor)): # Check scale factor too
                logger.info(f"{log_prefix}Recalculating scaled display positions (Cache invalid/missing or spacing/scale changed).")
                recalc_scaled = True
                if self.coord_system is None:
                     logger.error(f"{log_prefix}Coordinate system is None! Cannot calculate scaled positions.")
                     return {} # Cannot proceed without coord system

                self._cached_scaled_positions = {} # Initialize new cache
                # Ensure unscaled cache exists before scaling
                if not hasattr(self, '_cached_unscaled_grid_coords') or self._cached_unscaled_grid_coords is None:
                     logger.error(f"{log_prefix}Unscaled coordinate cache is missing! Cannot calculate scaled positions.")
                     return {}

                for idx, grid_pos in self._cached_unscaled_grid_coords.items():
                    scaled_coords = self.coord_system.grid_to_display(grid_pos)
                    self._cached_scaled_positions[idx] = scaled_coords

                self._cached_scaled_spacing = current_spacing # Update cached spacing value
                self._cached_scale_factor = current_scale_factor # Update cached scale factor
            # else: logger.debug(f"{log_prefix}Using cached scaled node positions.") # Reduce noise

            # --- Return requested positions ---
            if node_indices is None:
                # Return all cached scaled positions
                return self._cached_scaled_positions if hasattr(self, '_cached_scaled_positions') else {}
            else:
                # Return positions only for the requested indices
                final_positions = {}
                if hasattr(self, '_cached_scaled_positions') and self._cached_scaled_positions:
                    for idx in node_indices:
                        if idx in self._cached_scaled_positions:
                            final_positions[idx] = self._cached_scaled_positions[idx]
                return final_positions

        except Exception as e:
            logger.error(f"{log_prefix}Error: {e}")
            logger.error(traceback.format_exc())
            return {}
                             
    def get_node_state(self, coords: Tuple[int, ...]) -> float:
        """Get state of node at coordinates"""
        return self.grid_array[coords]

    def get_relative_node_coords(self, node_idx: int, direction: str, distance: int = 1) -> Optional[Tuple[int, ...]]:
        """
        Get the coordinates of a node relative to a given node.

        Args:
            node_idx: Index of the starting node.
            direction: Direction string ('N', 'S', 'E', 'W', 'NE', 'NW', 'SE', 'SW', 'U', 'D').
                        'U' and 'D' are only valid for 3D grids.
            distance: Distance from the starting node.

        Returns:
            Tuple of coordinates, or None if the neighbor is out of bounds.
        """
        # Removed ONE_D check
        if self.dimension_type == Dimension.THREE_D and len(self.dimensions) != 3:
            raise ValueError("get_relative_node_coords: 3D coordinates require 3D dimensions.")
        if self.dimension_type == Dimension.TWO_D and len(self.dimensions) != 2:
            raise ValueError("get_relative_node_coords: 2D coordinates require 2D dimensions.")

        coords = list(_unravel_index(node_idx, self.dimensions))  # Start with current node coords

        # Define direction vectors
        directions = {
            'N': (-1, 0, 0), 'S': (1, 0, 0),
            'E': (0, 1, 0), 'W': (0, -1, 0),
            'NE': (-1, 1, 0), 'NW': (-1, -1, 0),
            'SE': (1, 1, 0), 'SW': (1, -1, 0),
            'U': (0, 0, 1), 'D': (0, 0, -1)
        }

        if direction not in directions:
            raise ValueError(f"Invalid direction: {direction}")

        direction_vector = directions[direction]

        # Apply distance
        for i in range(len(coords)):
            coords[i] += direction_vector[i] * distance

        # Check bounds and handle boundary conditions
        if self.rule is not None:
            grid_boundary = self.rule.get_param('grid_boundary', 'bounded')
        else:
            grid_boundary = 'bounded'

        if grid_boundary == 'wrap':
            # Wrap around the boundaries
            for i in range(len(coords)):
                coords[i] = coords[i] % self.dimensions[i]
        elif grid_boundary == 'bounded':
            # Check if the new coordinates are within bounds
            for i, coord in enumerate(coords):
                if not (0 <= coord < self.dimensions[i]):
                    return None  # Out of bounds
        else:
            raise ValueError(f"Invalid grid_boundary parameter: {grid_boundary}")

        return tuple(coords)
 
    def get_relative_edge_coords(self, node_idx: int, direction: str) -> Optional[Tuple[Tuple[int, ...], Tuple[int, ...]]]:
        """
        Get the coordinates of an edge relative to a given node.

        Args:
            node_idx: Index of the starting node.
            direction: Direction string ('N', 'S', 'E', 'W', 'NE', 'NW', 'SE', 'SW', 'U', 'D').

        Returns:
            Tuple of (start_node_coords, end_node_coords), or None if the edge is out of bounds.
        """
        neighbor_coords = self.get_relative_node_coords(node_idx, direction)
        if neighbor_coords is None:
            return None  # Neighbor is out of bounds

        node_coords = _unravel_index(node_idx, self.dimensions)
        
        # Ensure consistent ordering for edge representation (smaller index first)
        if node_idx < _ravel_multi_index(np.array(neighbor_coords), self.dimensions):
            return (tuple(node_coords), neighbor_coords)
        else:
            return (tuple(neighbor_coords), tuple(node_coords))
        
    def get_all_neighbor_node_coords(self, node_idx: int) -> List[Tuple[int, ...]]:
        """Get coordinates of all valid neighbor nodes."""
        neighbors = self.get_neighbors(node_idx, self.coord_system)  # Use get_neighbors
        return [tuple(_unravel_index(n, self.dimensions)) for n in neighbors]

    def get_all_neighbor_edge_coords(self, node_idx: int) -> List[Tuple[Tuple[int, ...], Tuple[int, ...]]]:
        """Get coordinates of all edges connected to a node."""
        edges = []
        node_coords = _unravel_index(node_idx, self.dimensions)
        # Use get_neighbors to get neighbor indices
        for neighbor_idx in self.get_neighbors(node_idx, self.coord_system):
            if neighbor_idx != -1 and self.has_edge(node_idx, neighbor_idx):
                neighbor_coords = _unravel_index(neighbor_idx, self.dimensions)
                # Ensure consistent ordering
                if node_idx < neighbor_idx:
                    edges.append((node_coords, neighbor_coords))
                else:
                    edges.append((neighbor_coords, node_coords))
        return edges

    def get_all_active_neighbor_node_coords(self, node_idx: int) -> List[Tuple[int, ...]]:
        """Get coordinates of all *active* neighbor nodes."""
        active_neighbors = []
        for neighbor_idx in self.get_neighbors(node_idx, self.coord_system): # Use get_neighbors
            if neighbor_idx != -1 and self.grid_array.ravel()[neighbor_idx] > 0:
                active_neighbors.append(tuple(_unravel_index(neighbor_idx, self.dimensions)))
        return active_neighbors

    def get_all_active_neighbor_edge_coords(self, node_idx: int) -> List[Tuple[Tuple[int, ...], Tuple[int, ...]]]:
        """Get coordinates of all edges connected to a node where both nodes are active."""
        edges = []
        node_coords = _unravel_index(node_idx, self.dimensions)
        # Use get_neighbors to get neighbor indices
        for neighbor_idx in self.get_neighbors(node_idx, self.coord_system):
            if neighbor_idx != -1 and self.grid_array.ravel()[neighbor_idx] > 0 and self.has_edge(node_idx, neighbor_idx):
                neighbor_coords = _unravel_index(neighbor_idx, self.dimensions)
                # Ensure consistent ordering
                if node_idx < neighbor_idx:
                    edges.append((node_coords, neighbor_coords))
                else:
                    edges.append((neighbor_coords, node_coords))
        return edges

    def get_relative_node_state(self, node_idx: int, direction: str, distance: int = 1) -> Optional[float]:
        """
        Get the state of a node relative to a given node.

        Args:
            node_idx: Index of the starting node.
            direction: Direction string ('N', 'S', 'E', 'W', 'NE', 'NW', 'SE', 'SW', 'U', 'D').
            distance: Distance from the starting node.

        Returns:
            The state of the relative node (float), or None if the node is out of bounds.
        """
        coords = self.get_relative_node_coords(node_idx, direction, distance)
        if coords:
            return self.get_node_state(coords)
        else:
            return None  # Out of bounds

    def get_relative_edge_state(self, node_idx: int, direction: str, distance: int = 1) -> float:
        """
        Get the state of the edge between a node and another node at a relative position.

        Args:
            node_idx: Index of the starting node.
            direction: Direction string ('N', 'S', 'E', 'W', 'NE', 'NW', 'SE', 'SW', 'U', 'D').
            distance: Distance from the starting node.

        Returns:
            1.0 if both nodes are active and the edge exists, 0.0 otherwise, or None if
            the relative node is out of bounds.
        """
        neighbor_coords = self.get_relative_node_coords(node_idx, direction, distance)
        if neighbor_coords is None:
            return 0.0  # Or None, depending on how you want to handle out-of-bounds

        neighbor_idx = _ravel_multi_index(np.array(neighbor_coords), self.dimensions)
        return self.get_edge_state(node_idx, neighbor_idx)

    def get_perimeter(self) -> int:
        """Calculates the perimeter of the grid based on its dimensions."""
        if self.dimension_type == Dimension.TWO_D:
            rows, cols = self.dimensions
            return 2 * (rows + cols - 2)  # Corrected perimeter calculation
        elif self.dimension_type == Dimension.THREE_D:
            # For 3D, we'll define perimeter as the sum of edges of the bounding box
            rows, cols, depth = self.dimensions
            return 4 * (rows + cols + depth)  # Sum of edges of the bounding box
        else:
            raise ValueError("Invalid dimension type for perimeter calculation.")

    def wrap_coordinates(self, coords: Tuple[int, ...]) -> Tuple[int, ...]:
        """Wraps coordinates around the grid boundaries if 'wrap' is enabled,
        otherwise clips them to the valid range.
        """
        # Get the grid boundary setting from the rule parameters.  CORRECTED.
        grid_boundary = self.rule.params.get('grid_boundary', 'bounded') if self.rule is not None else 'bounded'

        wrapped_coords = []
        for i, coord in enumerate(coords):
            if grid_boundary == 'wrap':
                wrapped_coords.append(coord % self.dimensions[i])
            else:  # bounded
                wrapped_coords.append(max(0, min(coord, self.dimensions[i] - 1)))
        return tuple(wrapped_coords)

    def is_valid_coord(self, coord: Tuple[int, ...]) -> bool:
        """Checks if a given coordinate tuple is within the grid bounds."""
        if len(coord) != len(self.dimensions):
            return False #wrong dimensions
        for i, val in enumerate(coord):
            if not (0 <= val < self.dimensions[i]):
                return False  # Out of bounds for this dimension
        return True

    def get_relative_coordinates(self, start_coords: Tuple[int, ...], *offsets: int) -> Optional[Tuple[int, ...]]:
        """Calculates a new coordinate tuple based on a starting coordinate and offsets,
        handling wrapping/bounding.  Returns None if the resulting coordinates are invalid
        and boundary type is 'bounded'.
        """
        if len(start_coords) != len(offsets):
            raise ValueError("Number of offsets must match the number of dimensions.")

        new_coords = tuple(c + o for c, o in zip(start_coords, offsets))
        wrapped_coords = self.wrap_coordinates(new_coords)

        # Get the grid boundary setting from the rule parameters.  CORRECTED.
        grid_boundary = self.rule.params.get('grid_boundary', 'bounded') if self.rule is not None else 'bounded'
        if grid_boundary == 'bounded' and not self.is_valid_coord(wrapped_coords):
            return None  # Out of bounds in bounded mode

        return wrapped_coords
    
    def get_neighbor_coords(self, node_idx: int) -> List[Tuple[int, ...]]:  
        """Gets the coordinates of all valid neighbors for a given node index."""
        neighbors = self.get_neighbors(node_idx, self.coord_system)  # Use get_neighbors
        return [tuple(_unravel_index(n, self.dimensions)) for n in neighbors]

    def get_neighbor_metric(self, node_idx: int, neighbor_idx: int, metric_name: str) -> float:
        """Placeholder for getting a specific metric for a neighbor."""
        # This will be implemented later, likely using pre-calculated metrics
        # stored in the NeighborhoodData object.
        raise NotImplementedError("Neighbor-specific metrics not yet implemented.")

    def get_neighbor_degree(self, node_idx: int, neighbor_idx: int) -> int:
            """Gets the degree (number of connections) of a neighbor."""
            return len(self.get_neighbors(neighbor_idx, self.coord_system))
    
    def get_neighborhood_metric(self, node_idx: int, metric_name: str) -> float:
        """Placeholder for getting a metric for the entire neighborhood."""
        # This will be implemented later, likely using pre-calculated metrics
        # stored in the NeighborhoodData object.
        raise NotImplementedError("Neighborhood metrics not yet implemented.")

    @timer_decorator
    def create_neighborhood_data(self, node_idx: int,
                                states_array: Optional[np.ndarray] = None) -> 'NeighborhoodData':
        """
        Creates a NeighborhoodData object, optimizing coordinate lookups and data fetching.
        (Round 36: Restored use of get_neighbors (precalculated), conditional logging)
        """
        logger = logging.getLogger(__name__)
        detailed_logging_enabled = LogSettings.Performance.ENABLE_DETAILED_LOGGING
        current_states = states_array if states_array is not None else self.grid_array.ravel()
        cache_key = node_idx

        # --- Cache Check for NeighborhoodData ---
        with self._cache_lock:
            if cache_key in self._neighborhood_data_cache:
                self._cache_hits += 1
                return self._neighborhood_data_cache[cache_key]
            else:
                self._cache_misses += 1
        # ---

        # --- Get Neighbor Indices (Use get_neighbors which uses precalculated) ---
        neighbor_indices = self.get_neighbors(node_idx, self.coord_system)
        if neighbor_indices is None:
            neighbor_indices = np.array([], dtype=np.int64)
        # ---

        valid_neighbor_mask = (neighbor_indices >= 0) & (neighbor_indices < current_states.size)
        valid_indices = neighbor_indices[valid_neighbor_mask]
        neighbor_states = np.zeros_like(neighbor_indices, dtype=np.float64)
        if valid_indices.size > 0:
            neighbor_states[valid_neighbor_mask] = current_states[valid_indices]

        node_state = 0.0
        if 0 <= node_idx < current_states.size:
            node_state = current_states[node_idx]
        node_coords_tuple = tuple(_unravel_index(node_idx, self.dimensions))

        neighbor_edge_states: Dict[int, float] = {}
        edges_in_neighborhood = set()
        valid_neighbor_coords = {
            idx: tuple(_unravel_index(idx, self.dimensions))
            for idx in valid_indices
        }
        for neighbor_idx in valid_indices:
            neighbor_coords_tuple = valid_neighbor_coords[neighbor_idx]
            edge_coords = self._ordered_edge(node_coords_tuple, neighbor_coords_tuple)
            edge_state = self.edge_states.get(edge_coords, 0.0)
            neighbor_edge_states[neighbor_idx] = edge_state
            if edge_coords in self.edges:
                edge_indices = (node_idx, neighbor_idx) if node_idx < neighbor_idx else (neighbor_idx, node_idx)
                edges_in_neighborhood.add(edge_indices)

        neighbor_degrees_dict: Optional[Dict[int, int]] = None
        neighbor_active_counts_dict: Optional[Dict[int, int]] = None
        if self.rule:
            if self.rule.needs_neighbor_degrees and self.previous_degree_array is not None:
                neighbor_degrees_dict = {}
                prev_degree_array_len = len(self.previous_degree_array)
                for neighbor_idx_inner in valid_indices:
                    if 0 <= neighbor_idx_inner < prev_degree_array_len:
                        neighbor_degrees_dict[neighbor_idx_inner] = int(self.previous_degree_array[neighbor_idx_inner])
            if self.rule.needs_neighbor_active_counts and self.previous_active_neighbor_array is not None:
                neighbor_active_counts_dict = {}
                prev_active_array_len = len(self.previous_active_neighbor_array)
                for neighbor_idx_inner in valid_indices:
                    if 0 <= neighbor_idx_inner < prev_active_array_len:
                        neighbor_active_counts_dict[neighbor_idx_inner] = int(self.previous_active_neighbor_array[neighbor_idx_inner])

        neighborhood_data = NeighborhoodData(
            node_index=node_idx,
            node_coords=node_coords_tuple,
            node_state=node_state,
            neighbor_indices=neighbor_indices,
            neighbor_states=neighbor_states,
            edges=edges_in_neighborhood,
            dimensions=self.dimensions,
            neighborhood_type=self.neighborhood_type,
            grid_boundary=self.rule.params.get('grid_boundary', 'bounded') if self.rule is not None else 'bounded',
            neighbor_edge_states=neighbor_edge_states,
            neighbor_degrees=neighbor_degrees_dict,
            neighbor_active_counts=neighbor_active_counts_dict
        )
        neighborhood_data.neighbor_metrics['neighbor_state'] = neighbor_states
        if neighbor_edge_states:
            valid_edge_states = [state for idx, state in neighbor_edge_states.items() if idx >= 0]
            neighborhood_data.neighborhood_metrics['avg_neighbor_edge_state'] = float(np.mean(valid_edge_states)) if valid_edge_states else 0.0
        else:
            neighborhood_data.neighborhood_metrics['avg_neighbor_edge_state'] = 0.0

        with self._cache_lock:
            self._neighborhood_data_cache[cache_key] = neighborhood_data

        return neighborhood_data

    def get_offset_coordinates(self, node_idx: int, offset: Tuple[int, ...]) -> Optional[Tuple[int, ...]]:
        """
        Calculates the coordinates of a node offset from the given node index,
        handling boundary conditions.
        
        Args:
            node_idx: The index of the starting node.
            offset: A tuple representing the offset in each dimension (e.g., (1, -1) for 2D).
            
        Returns:
            A tuple representing the new coordinates, or None if the new coordinates
            are out of bounds and the grid is bounded.
        """
        start_coords = _unravel_index(node_idx, self.dimensions)
        return self.get_relative_coordinates(tuple(start_coords), *offset)

    def _calculate_max_neighbors(self) -> int:
        """Calculate maximum possible neighbors based on neighborhood type"""
        if self.neighborhood_type == NeighborhoodType.VON_NEUMANN:
            if self.dimension_type == Dimension.TWO_D:
                return 4
            elif self.dimension_type == Dimension.THREE_D:
                return 6
            else:
                raise ValueError(f"Invalid dimension type {self.dimension_type} for VON_NEUMANN neighborhood")
        elif self.neighborhood_type == NeighborhoodType.MOORE:
            if self.dimension_type == Dimension.TWO_D:
                return 8
            elif self.dimension_type == Dimension.THREE_D:
                return 26
            else:
                raise ValueError(f"Invalid dimension type {self.dimension_type} for MOORE neighborhood")
        elif self.neighborhood_type == NeighborhoodType.HEX:
            if self.dimension_type == Dimension.TWO_D:
                return 6
            else:
                raise ValueError(f"Invalid dimension type {self.dimension_type} for HEX neighborhood")
        elif self.neighborhood_type == NeighborhoodType.HEX_PRISM:
            if self.dimension_type == Dimension.THREE_D:
                return 12
            else:
                raise ValueError(f"Invalid dimension type {self.dimension_type} for HEX_PRISM neighborhood")
        else:
            raise ValueError(f"Invalid neighborhood type: {self.neighborhood_type}")

    @timer_decorator
    def initialize_grid(self, node_density: float, edge_initialization_type: str = 'RANDOM'):
        """Initializes both nodes and edges with the given density and initialization type."""
        # --- ADDED: Log entry and parameters ---
        logger.info(f"--- Grid.initialize_grid called ---")
        logger.info(f"  Node Density: {node_density:.3f}")
        logger.info(f"  Edge Initialization Type: {edge_initialization_type}")
        # --- END ADDED ---

        # CRITICAL FIX: Clear the grid array first to ensure we start fresh
        if self.grid_array is not None:
            self.grid_array.fill(0.0)  # Reset all cells to inactive (0.0)
        else:
            logger.error("Grid is None, cannot initialize random state")
            return

        # CRITICAL FIX: Clear the spatial hash
        if self.spatial_hash is not None:
            self.spatial_hash.clear()
            logger.debug("Cleared spatial hash before initialization")

        # --- Initialize nodes with random state based on node_density ---
        total_nodes = np.prod(self.dimensions)
        active_cells = int(total_nodes * node_density)

        # CRITICAL FIX: Ensure active_indices are within the valid range
        # Get the actual size of the flattened grid array
        grid_size = self.grid_array.size

        # Generate random indices within the valid range
        if active_cells > 0:
            # Ensure we don't try to activate more cells than exist
            active_cells = min(active_cells, grid_size)
            # Generate unique random indices
            active_indices = np.random.choice(grid_size, size=active_cells, replace=False)

            if self.grid_array is not None:
                # CRITICAL FIX: First set all the states in the grid array
                self.grid_array.ravel()[active_indices] = 1.0

                # CRITICAL FIX: THEN update the spatial hash for ALL active nodes
                for idx in range(self.total_nodes):
                    grid_coords = _unravel_index(idx, self.dimensions)
                    if idx in active_indices:
                        if self.spatial_hash is not None:
                            self.spatial_hash.update_node(idx, np.array(grid_coords))
                        else:
                            logger.warning("Spatial hash is None, cannot update node.")
                logger.debug(f"Initialized {active_cells} active nodes with random state")
            else:
                logger.error("grid_array is None, cannot set active nodes")
                return
        else:
            logger.warning("No active cells to initialize (density too low)")

        # --- Initialize edges based on edge_initialization_type and adjusted_edge_density ---
        self.initialize_edges_after_nodes(edge_initialization_type)

        # --- Update active_nodes set ---
        self.update_active_nodes()
        logger.debug(f"Updated active_nodes set with {len(self.active_nodes)} active nodes")

        # --- ADDED: Initialize previous_active_nodes_set ---
        self.previous_active_nodes_set = self.active_nodes.copy()
        logger.debug(f"Initialized previous_active_nodes_set: {self.previous_active_nodes_set} (Count: {len(self.previous_active_nodes_set)})")
        # --- END ADDED SECTION ---

        logger.debug(f"Grid array after initialization:\n{self.grid_array}")

    def setup_shared_memory(self):
        """
        Setup or reuse shared memory for grid array, precalculated neighbors.
        Edge states SHM is currently skipped due to complexity.
        Ensures consistent naming using _unique_id.
        (Round 14: Ensure consistent SHM naming)
        (Round 12: Implement SHM reuse logic)
        """
        log_prefix = f"Grid.setup_shared_memory(ID:{self._unique_id} R14 Name Fix): " # Updated round
        logger.debug(f"{log_prefix}Setting up/reusing shared memory.")

        # --- Grid Array Shared Memory ---
        # --- MODIFIED: Use f-string with self._unique_id ---
        grid_shm_name = f"/{self._unique_id}_grid"
        # ---
        required_grid_size = self.grid_array.nbytes if self.grid_array is not None else 0
        logger.debug(f"{log_prefix}Grid Array: Name='{grid_shm_name}', Required Size={required_grid_size}")

        if required_grid_size <= 0:
            logger.error(f"{log_prefix}Invalid grid_array size, cannot manage shared memory.")
            self.shared_mem = None; self.shared_array = None; self._shared_mem_name = None
        else:
            try:
                # Attempt to attach to existing SHM
                self.shared_mem = SharedMemory(name=grid_shm_name, create=False)
                if self.shared_mem.size == required_grid_size:
                    self.shared_array = np.ndarray(self.grid_array.shape, dtype=self.grid_array.dtype, buffer=self.shared_mem.buf)
                    np.copyto(self.shared_array, self.grid_array) # Ensure content matches current grid
                    self._shared_mem_name = grid_shm_name
                    self._shared_memory_unlinked = False # Mark as linked
                    logger.info(f"{log_prefix}Reused existing grid shared memory: {grid_shm_name}")
                else:
                    # Size mismatch, unlink old and create new
                    logger.warning(f"{log_prefix}Grid SHM size mismatch (Existing: {self.shared_mem.size}, Required: {required_grid_size}). Recreating.")
                    self.shared_mem.close(); self.shared_mem.unlink()
                    self.shared_mem = SharedMemory(name=grid_shm_name, create=True, size=required_grid_size)
                    self.shared_array = np.ndarray(self.grid_array.shape, dtype=self.grid_array.dtype, buffer=self.shared_mem.buf)
                    np.copyto(self.shared_array, self.grid_array)
                    self._shared_mem_name = grid_shm_name
                    self._shared_memory_unlinked = False
                    logger.info(f"{log_prefix}Recreated grid shared memory: {grid_shm_name}")
            except FileNotFoundError:
                # SHM doesn't exist, create it
                try:
                    self.shared_mem = SharedMemory(name=grid_shm_name, create=True, size=required_grid_size)
                    self.shared_array = np.ndarray(self.grid_array.shape, dtype=self.grid_array.dtype, buffer=self.shared_mem.buf)
                    np.copyto(self.shared_array, self.grid_array)
                    self._shared_mem_name = grid_shm_name
                    self._shared_memory_unlinked = False
                    logger.info(f"{log_prefix}Created new grid shared memory: {grid_shm_name}")
                except Exception as e_create:
                    logger.error(f"{log_prefix}Failed to create grid shared memory: {e_create}")
                    self.shared_mem = None; self.shared_array = None; self._shared_mem_name = None
            except Exception as e_attach:
                 logger.error(f"{log_prefix}Error attaching/recreating grid shared memory: {e_attach}")
                 self.shared_mem = None; self.shared_array = None; self._shared_mem_name = None
        # ---

        # --- Precalculated Neighbor Indices Shared Memory ---
        # --- MODIFIED: Use f-string with self._unique_id ---
        neighbor_shm_name = f"/{self._unique_id}_neighbors"
        # ---
        self._neighbor_indices_shm_meta = None # Reset metadata
        neighbor_shm_instance = None # Local handle

        if self._precalculated_neighbor_indices is not None:
            required_neighbor_size = self._precalculated_neighbor_indices.nbytes
            required_neighbor_shape = self._precalculated_neighbor_indices.shape
            required_neighbor_dtype = self._precalculated_neighbor_indices.dtype
            logger.debug(f"{log_prefix}Neighbor Array: Name='{neighbor_shm_name}', Required Size={required_neighbor_size}, Shape={required_neighbor_shape}")

            if required_neighbor_size > 0:
                try:
                    # Attempt to attach
                    neighbor_shm_instance = SharedMemory(name=neighbor_shm_name, create=False)
                    if neighbor_shm_instance.size == required_neighbor_size:
                        # Reuse existing
                        neighbor_shared_array = np.ndarray(required_neighbor_shape, dtype=required_neighbor_dtype, buffer=neighbor_shm_instance.buf)
                        np.copyto(neighbor_shared_array, self._precalculated_neighbor_indices) # Update content
                        self._neighbor_indices_shm_meta = {'name': neighbor_shm_name, 'shape': required_neighbor_shape, 'dtype': required_neighbor_dtype}
                        logger.info(f"{log_prefix}Reused existing neighbor shared memory: {neighbor_shm_name}")
                        # Keep neighbor_shm_instance open (will be closed in cleanup)
                    else:
                        # Size mismatch, recreate
                        logger.warning(f"{log_prefix}Neighbor SHM size mismatch (Existing: {neighbor_shm_instance.size}, Required: {required_neighbor_size}). Recreating.")
                        neighbor_shm_instance.close(); neighbor_shm_instance.unlink()
                        neighbor_shm_instance = SharedMemory(name=neighbor_shm_name, create=True, size=required_neighbor_size)
                        neighbor_shared_array = np.ndarray(required_neighbor_shape, dtype=required_neighbor_dtype, buffer=neighbor_shm_instance.buf)
                        np.copyto(neighbor_shared_array, self._precalculated_neighbor_indices)
                        self._neighbor_indices_shm_meta = {'name': neighbor_shm_name, 'shape': required_neighbor_shape, 'dtype': required_neighbor_dtype}
                        logger.info(f"{log_prefix}Recreated neighbor shared memory: {neighbor_shm_name}")
                except FileNotFoundError:
                    # Doesn't exist, create new
                    try:
                        neighbor_shm_instance = SharedMemory(name=neighbor_shm_name, create=True, size=required_neighbor_size)
                        neighbor_shared_array = np.ndarray(required_neighbor_shape, dtype=required_neighbor_dtype, buffer=neighbor_shm_instance.buf)
                        np.copyto(neighbor_shared_array, self._precalculated_neighbor_indices)
                        self._neighbor_indices_shm_meta = {'name': neighbor_shm_name, 'shape': required_neighbor_shape, 'dtype': required_neighbor_dtype}
                        logger.info(f"{log_prefix}Created new neighbor shared memory: {neighbor_shm_name}")
                    except Exception as e_create_neigh:
                        logger.error(f"{log_prefix}Failed to create neighbor shared memory: {e_create_neigh}")
                        if neighbor_shm_instance: neighbor_shm_instance.close(); neighbor_shm_instance.unlink()
                        self._neighbor_indices_shm_meta = None
                except Exception as e_attach_neigh:
                     logger.error(f"{log_prefix}Error attaching/recreating neighbor shared memory: {e_attach_neigh}")
                     if neighbor_shm_instance: neighbor_shm_instance.close() # Close handle if attach failed
                     self._neighbor_indices_shm_meta = None
            else: logger.warning(f"{log_prefix}Precalculated neighbor array size is zero, skipping shared memory.")
        else: logger.warning(f"{log_prefix}Precalculated neighbor array is None, skipping shared memory.")
        # ---

        # --- Edge States Shared Memory (Still skipped) ---
        self.shared_mem_edge_states = None
        self.shared_array_edge_states = None
        self._edge_states_shared_memory_unlinked = True # Mark as unlinked since we skip it
        logger.debug(f"{log_prefix}Skipping edge states shared memory setup.")
        # ---

    def initialize_edges(self, edge_initialization_type='RANDOM'):
        """Initializes edges based on the specified type, adjusting density if needed."""
        # --- ADDED: Log entry ---
        logger.info(f"--- Grid.initialize_edges called with type: {edge_initialization_type} ---")
        # --- END ADDED ---

        self.edges = set()  # Ensure edges is cleared
        self.edge_states = {} # and edge states

        logger.debug(f"Initializing edges with type {edge_initialization_type}")

        # CRITICAL FIX: Make sure all active nodes are in the spatial hash before initializing edges
        active_indices = np.where(self.grid_array.ravel() > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD)[0]
        for idx in active_indices:
            if self.spatial_hash is not None and idx not in self.spatial_hash.node_positions:
                grid_coords = _unravel_index(idx, self.dimensions)
                # logger.debug(f"Adding missing node {idx} (coords: {grid_coords}) to spatial hash before edge initialization")
                self.spatial_hash.update_node(idx, np.array(grid_coords))

        # Calculate the maximum possible number of edges
        num_active_nodes = len(active_indices)
        max_possible_edges = num_active_nodes * self._calculate_max_neighbors() // 2

        # Adjust the target edge density if it's not achievable
        target_edge_density = GlobalSettings.Simulation.INITIAL_EDGE_DENSITY
        if max_possible_edges == 0:
            adjusted_edge_density = 0.0
        else:
            # --- CRITICAL FIX: Ensure denominator is not zero ---
            denominator = (self.grid_array.size * self._calculate_max_neighbors() // 2)
            if denominator == 0:
                 adjusted_edge_density = 0.0 # Avoid division by zero
            else:
                 adjusted_edge_density = min(target_edge_density, max_possible_edges / denominator)
            # --- END CRITICAL FIX ---

        if adjusted_edge_density != target_edge_density:
            logger.warning(f"Desired edge density {target_edge_density} is not achievable. Adjusting to maximum possible density: {adjusted_edge_density}")

        if edge_initialization_type == 'RANDOM':
            # Calculate the connect probability
            connect_probability = self._calculate_connect_probability(adjusted_edge_density)

            # Iterate through all active nodes
            for i in active_indices:
                # Consider only active neighbors
                neighbors = self.get_neighbors(i, self.coord_system)
                active_neighbors = [
                    n for n in neighbors
                    if n >= 0 and self.grid_array.ravel()[n] > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD
                ]
                # logger.debug(f"Node {i}: Active neighbors: {active_neighbors}")
                for j in active_neighbors:
                    # Ensure consistent edge representation (smaller index first)
                    # --- CRITICAL FIX: Use grid coordinates ---
                    node1_coords = tuple(_unravel_index(i, self.dimensions))
                    node2_coords = tuple(_unravel_index(j, self.dimensions))
                    edge = self._ordered_edge(node1_coords, node2_coords)
                    # --- END CRITICAL FIX ---
                    if edge not in self.edges and random.random() < connect_probability:
                        self.edges.add(edge)
                        self.edge_states[edge] = random.random()  # Initialize with random state
                        # logger.debug(f"  Added edge: {edge}")

        elif edge_initialization_type == 'ALL_ONES':
            for i in active_indices:
                # Consider only active neighbors
                neighbors = self.get_neighbors(i, self.coord_system)
                active_neighbors = [
                    n for n in neighbors
                    if n >= 0 and self.grid_array.ravel()[n] > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD
                ]
                for j in active_neighbors:
                    # --- CRITICAL FIX: Use grid coordinates ---
                    node1_coords = tuple(_unravel_index(i, self.dimensions))
                    node2_coords = tuple(_unravel_index(j, self.dimensions))
                    edge = self._ordered_edge(node1_coords, node2_coords)
                    # --- END CRITICAL FIX ---
                    if edge not in self.edges:
                        self.edges.add(edge)
                        self.edge_states[edge] = 1.0  # Initialize with state 1.0

        elif edge_initialization_type == 'ALL_ZEROS':
            for i in active_indices:
                # Consider only active neighbors
                neighbors = self.get_neighbors(i, self.coord_system)
                active_neighbors = [
                    n for n in neighbors
                    if n >= 0 and self.grid_array.ravel()[n] > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD
                ]
                for j in active_neighbors:
                    # --- CRITICAL FIX: Use grid coordinates ---
                    node1_coords = tuple(_unravel_index(i, self.dimensions))
                    node2_coords = tuple(_unravel_index(j, self.dimensions))
                    edge = self._ordered_edge(node1_coords, node2_coords)
                    # --- END CRITICAL FIX ---
                    if edge not in self.edges:
                        self.edges.add(edge)
                        self.edge_states[edge] = 0.0  # Initialize with state 0.0

        # Add more initialization types as needed (e.g., based on a function, etc.)
        elif edge_initialization_type == 'CONNECTED':
            # Connect all active neighbors
            for i in active_indices:
                # Consider only active neighbors
                neighbors = self.get_neighbors(i, self.coord_system) # Use get_neighbors
                active_neighbors = [n for n in neighbors if n >= 0 and self.grid_array.ravel()[n] > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD]
                for j in active_neighbors:
                    # --- CRITICAL FIX: Use grid coordinates ---
                    node1_coords = tuple(_unravel_index(i, self.dimensions))
                    node2_coords = tuple(_unravel_index(j, self.dimensions))
                    edge = self._ordered_edge(node1_coords, node2_coords)
                    # --- END CRITICAL FIX ---
                    if edge not in self.edges:
                        self.edges.add(edge)
                        self.edge_states[edge] = 1.0 # Initialize with state 1.0
        elif edge_initialization_type == 'FULL':
            # Iterate through all active nodes
            for i in active_indices:
                # Now get neighbors and add edges
                neighbors = self.get_neighbors(i, self.coord_system)
                # Iterate through ALL neighbors, not just active ones
                for j in neighbors:
                    # Ensure we are not creating a self-loop
                    if j != -1 and i != j:  # but make sure the neighbor is valid and not the same node
                        # --- CRITICAL FIX: Use grid coordinates ---
                        node1_coords = tuple(_unravel_index(i, self.dimensions))
                        node2_coords = tuple(_unravel_index(j, self.dimensions))
                        edge = self._ordered_edge(node1_coords, node2_coords)
                        # --- END CRITICAL FIX ---
                        if edge not in self.edges:
                            self.edges.add(edge)
                            self.edge_states[edge] = 1.0  # Or any default state
                            # logger.debug(f"Added edge between active node {i} and neighbor {j} (edge: {edge})")
        elif edge_initialization_type == 'DISTANCE':
            # Placeholder for distance-based initialization
            pass  # Implement distance-based logic here
        elif edge_initialization_type == 'NEAREST':
            # Placeholder for nearest-neighbor initialization
            pass  # Implement nearest-neighbor logic here
        elif edge_initialization_type == 'SIMILARITY':
            # Placeholder for similarity-based initialization
            pass  # Implement similarity-based logic here
        elif edge_initialization_type == 'NONE':
            # No edges are initialized
            pass
        else:
            logger.warning(f"Unknown edge initialization type: {edge_initialization_type}")

        logger.debug(f"Initialized {len(self.edges)} edges with type {edge_initialization_type}")
        # --- ADDED: Log exit ---
        logger.info(f"--- Grid.initialize_edges finished ---")
        # --- END ADDED ---

    def cleanup_ghost_edges(self):
        """Clean up ghost edges in the edge matrix"""
        try:
            logger.debug("Starting ghost edge cleanup")

            # Get indices of nodes that *became* inactive in the last step
            if hasattr(self, 'last_updated_nodes'):
                inactive_nodes = {idx for coords in self.last_updated_nodes 
                                  for idx in [_ravel_multi_index(np.array(coords), self.dimensions)]
                                  if self.grid_array.ravel()[idx] <= GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD}
            else:
                inactive_nodes = set()

            initial_edge_count = len(self.edges)

            # Only iterate through edges connected to newly inactive nodes
            cleaned_edge_count = 0
            edges_copy = self.edges.copy()  # Iterate over a copy
            for edge in edges_copy:
                node1, node2 = edge
                if node1 in inactive_nodes or node2 in inactive_nodes:
                    self.edges.discard(edge)  # Remove the edge
                    cleaned_edge_count += 1

            final_edge_count = len(self.edges)
            logger.debug(f"Cleaned up {cleaned_edge_count} ghost edges. Initial: {initial_edge_count}, Final: {final_edge_count}")

        except Exception as e:
            logger.error(f"Error cleaning up ghost edges: {str(e)}\nTraceback:\n{traceback.format_exc()}")
            raise

    def verify_edges(self):
        """Verify that the edges array represents a symmetric graph and has no self-loops."""
        try:
            is_symmetric = True
            has_self_loops = False

            edges_copy = self.edges.copy()
            for (node1_coords, node2_coords) in edges_copy: # Iterate over coordinate tuples

                # Skip invalid edges (this check might not be necessary anymore, but it's safe to keep)
                if -1 in node1_coords or -1 in node2_coords:
                    continue

                # Check for self-loops
                if node1_coords == node2_coords:
                    has_self_loops = True
                    logger.warning(f"Self-loop found for node {node1_coords}")
                    # Remove self-loop
                    self.edges.discard((node1_coords, node2_coords))

                # Check for symmetry
                if not self.has_edge(_ravel_multi_index(np.array(node2_coords), self.dimensions), _ravel_multi_index(np.array(node1_coords), self.dimensions)): # Use has_edge with indices
                    is_symmetric = False
                    logger.warning(f"Asymmetry found between nodes {node1_coords} and {node2_coords}")
                    # Attempt to fix asymmetry by adding the missing edge
                    self.add_edge(_ravel_multi_index(np.array(node2_coords), self.dimensions), _ravel_multi_index(np.array(node1_coords), self.dimensions)) # Use add_edge with indices
                    logger.info(f"Added missing edge between {node2_coords} and {node1_coords} to enforce symmetry")

            if has_self_loops:
                logger.warning("Self-loops found and removed")

            if not is_symmetric:
                logger.warning("Edge array is not symmetric. Attempted to fix, but manual verification is recommended.")
                # Re-check symmetry after attempting to fix
                edges_copy = self.edges.copy()
                for (node1_coords, node2_coords) in edges_copy: # Iterate over coordinate tuples
                    if -1 not in node1_coords and -1 not in node2_coords:  # Skip invalid edges
                        if not self.has_edge(_ravel_multi_index(np.array(node2_coords), self.dimensions), _ravel_multi_index(np.array(node1_coords), self.dimensions)): # Use has_edge with indices
                            logger.error(f"Failed to make edges symmetric. Asymmetry found between nodes {node1_coords} and {node2_coords}")
                            return False  # Return False if asymmetry persists
                logger.info("Edge array symmetry restored.")

            return is_symmetric

        except Exception as e:
            logger.error(f"Error verifying edges: {e}")
            return False

    def set_rule(self, rule: 'Rule'):
        """Update the rule instance used by the grid"""
        try:
            logger.debug(f"Entering Grid.set_rule with rule: {rule.name}")
            # Store the new rule instance
            self.rule = rule  # We now expect a Rule INSTANCE
            logger.debug(f"Stored new rule instance: {rule.name}")

            # Log the rule change and its parameters
            logger.info(f"Grid updated to use rule: {rule.name}")
            logger.debug(f"Grid rule parameters: {rule.params}")

            # Invalidate any cached rule data
            if hasattr(self.rule, 'invalidate_cache'):
                logger.debug("Invalidating rule cache")
                self.rule.invalidate_cache()
                logger.debug("Rule cache invalidated")

        except Exception as e:
            logger.error(f"Error updating grid rule: {str(e)}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            # Don't reraise - handle gracefully
            return False

        logger.debug("Grid.set_rule completed successfully")
        return True

    # from newer versions of the code - needs to be refactored and/or integrated into this codebase...
    def get_performance_stats(self) -> Dict[str, Any]:
        """
        Get performance statistics for the associated rule instance.
        Focuses on compute times if tracked on the rule.
        (No changes needed in Round 30)
        """
        # Check if a rule is associated with the grid
        if self.rule is None:
            logger.warning("Cannot get performance stats: No rule associated with the grid.")
            return {'name': 'No Rule', 'avg_compute_time': 0.0}

        avg_time = 0.0
        # Access perf_stats from the rule instance
        if hasattr(self.rule, 'perf_stats') and 'compute_times' in self.rule.perf_stats and self.rule.perf_stats['compute_times']:
             # Filter for valid numeric types before calculating mean
             valid_times = [t for t in self.rule.perf_stats['compute_times'][-100:] if isinstance(t, (int, float))]
             if valid_times:
                 avg_time = float(np.mean(valid_times))
        elif not hasattr(self.rule, 'perf_stats'):
             logger.debug(f"Rule '{self.rule.name}' has no 'perf_stats' attribute.")
        elif 'compute_times' not in self.rule.perf_stats:
             logger.debug(f"Rule '{self.rule.name}' perf_stats has no 'compute_times' key.")
        else: # compute_times exists but is empty
             logger.debug(f"Rule '{self.rule.name}' compute_times list is empty.")

        # Return stats using the rule's name
        return {
            'name': self.rule.name, # Access name from the rule instance
            'avg_compute_time': avg_time,
            # --- ADDED Grid Cache Stats ---
            'grid_cache_hits': self._cache_hits,
            'grid_cache_misses': self._cache_misses,
            'grid_cache_hit_rate': self._cache_hits / (self._cache_hits + self._cache_misses) if (self._cache_hits + self._cache_misses) > 0 else 0.0
            # ---
        }
    
    def _chunk_grid(self, chunk_size: int) -> List[Tuple[int, int]]:  # Added chunk_size parameter
        """Chunk grid into smaller pieces for parallel processing."""
        total_nodes = len(self.grid_array.ravel())
        chunks = []
        for i in range(0, total_nodes, chunk_size):
            start = i
            end = min(i + chunk_size, total_nodes)
            chunks.append((start, end))

        logger.debug(f"Created {len(chunks)} chunks")
        return chunks

    @staticmethod
    def _process_chunk(
        neighborhoods: List['NeighborhoodData'],
        rule: 'Rule',
        shared_mem_name: str,
        # --- ADDED: Accept detailed logging flag ---
        detailed_logging_enabled: bool
        # ---
    ) -> Tuple[Optional[npt.NDArray[np.float64]], List[Dict[Tuple[int, int], float]]]:
        """
        Process a chunk of nodes in parallel with proper isolation of previous state.
        (Round 25: Accept and pass detailed_logging_enabled flag)
        """
        shared_mem = None
        logger = logging.getLogger(__name__ + ".worker_chunk")
        # --- REMOVED: detailed_logging_enabled = LogSettings... (Use passed 

        default_return = (np.zeros(len(neighborhoods), dtype=np.float64), [{} for _ in range(len(neighborhoods))])

        try:
            new_states = np.zeros(len(neighborhoods), dtype=np.float64)
            proposed_edges: List[Dict[Tuple[int, int], float]] = [{} for _ in range(len(neighborhoods))]

            for i, neighborhood in enumerate(neighborhoods):
                try:
                    # --- Fallback neighbor calculation (corrected syntax) ---
                    neighbors = None
                    if hasattr(neighborhood, 'neighbor_indices') and neighborhood.neighbor_indices is not None:
                        neighbors = neighborhood.neighbor_indices
                    else:
                        grid_neighborhood_type = neighborhood.neighborhood_type
                        grid_dimensions = neighborhood.dimensions
                        num_dims_local = len(grid_dimensions)
                        if grid_neighborhood_type == NeighborhoodType.VON_NEUMANN:
                            max_neighbors_local = 6 if num_dims_local == 3 else 4
                        elif grid_neighborhood_type == NeighborhoodType.MOORE:
                            max_neighbors_local = 26 if num_dims_local == 3 else 8
                        elif grid_neighborhood_type == NeighborhoodType.HEX:
                            max_neighbors_local = 6
                        elif grid_neighborhood_type == NeighborhoodType.HEX_PRISM:
                            max_neighbors_local = 12
                        else:
                            logger.warning(f"Unknown neighborhood type in fallback: {grid_neighborhood_type}. Using default max_neighbors=8.")
                            max_neighbors_local = 8
                        # Use the global helper for unraveling if needed
                        grid_dimensions_arr = np.array(grid_dimensions, dtype=np.int64)
                        neighbors = _get_neighbors_dynamic_helper(
                            neighborhood.node_index, grid_dimensions_arr, grid_neighborhood_type.value, 0, max_neighbors_local
                        )
                    # --- End corrected fallback ---

                    new_state, new_edges = rule.compute_updates(neighborhood, detailed_logging_enabled)
                    new_states[i] = new_state
                    proposed_edges[i] = new_edges

                except Exception as node_e:
                    logger.error(f"Error processing individual node {neighborhood.node_index}: {node_e}\n{traceback.format_exc()}")
                    new_states[i] = neighborhood.node_state
                    proposed_edges[i] = {}

            return new_states, proposed_edges

        except Exception as e:
            logger.error(f"Error in chunk processing: {e}\n{traceback.format_exc()}")
            return None, []
        finally:
            if shared_mem is not None:
                shared_mem.close()

    @staticmethod
    def _process_standard_chunk(
        chunk_indices: List[int],
        original_states_shm_meta: Optional[Dict[str, Any]],
        prev_degree_shm_meta: Optional[Dict[str, Any]],
        neighbor_indices_shm_meta: Optional[Dict[str, Any]],
        grid_shape: Tuple[int, ...],
        grid_dtype: np.dtype,
        edge_states_copy: Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float],
        prev_active_shm_meta: Optional[Dict[str, Any]],
        rule: 'Rule',
        params_copy: Dict[str, Any],
        grid_dimensions: Tuple[int, ...],
        grid_neighborhood_type: 'NeighborhoodType',
        grid_boundary_condition: str,
        # --- ADDED: Accept detailed logging flag ---
        detailed_logging_enabled: bool,
        # ---
        _original_states_override: Optional[np.ndarray] = None,
        _previous_degree_override: Optional[np.ndarray] = None,
        # --- ADDED: Accept override for previous active neighbors ---
        _previous_active_override: Optional[np.ndarray] = None
        # ---
    ) -> Tuple[List[Tuple[float, Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float]]], float]:
        """
        Worker function for standard rules. Uses precalculated neighbors if available.
        (Round 25: Pass detailed_logging_enabled to rule methods)
        """
        start_time = time.time()
        logger = logging.getLogger(__name__ + ".worker_standard")
        results = []
        # --- SHM Variables ---
        shm_orig = None; original_states_flat = None
        shm_neighbors = None; neighbor_indices_array_shm = None
        shm_prev_deg = None; previous_degree_array_shm = None
        shm_prev_active = None; previous_active_neighbor_array_shm = None
        shm_all_neighbors = None; all_neighbor_indices_array_shm = None
        # ---
        # --- REMOVED: detailed_logging_enabled = LogSettings... (Use passed arg) ---
        log_prefix = f"WorkerStandard (PID:{os.getpid()} R25 PassLogFlag): " # Updated round
        default_return_value: List[Tuple[float, Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float]]] = []
        grid_dimensions_arr = np.array(grid_dimensions, dtype=np.int64)

        # [ SHM Attachment logic remains the same as Round 22 ]
        # ...
        try:
            # --- Attach to SHM / Use Overrides ---
            # Original States
            if _original_states_override is not None: original_states_flat = _original_states_override; # Logged in R19
            elif original_states_shm_meta:
                try: shm_orig = SharedMemory(name=original_states_shm_meta['name'], create=False); original_states_flat = np.ndarray(original_states_shm_meta['shape'], dtype=original_states_shm_meta['dtype'], buffer=shm_orig.buf); # Logged in R19
                except Exception as shm_err: logger.error(f"{log_prefix}SHM Error (orig): {shm_err}"); return default_return_value, time.time() - start_time
            else: logger.error(f"{log_prefix}No SHM meta or override provided (orig)!"); return default_return_value, time.time() - start_time
            # Individual Neighbor Indices
            if neighbor_indices_shm_meta:
                try: shm_neighbors = SharedMemory(name=neighbor_indices_shm_meta['name'], create=False); neighbor_indices_array_shm = np.ndarray(neighbor_indices_shm_meta['shape'], dtype=neighbor_indices_shm_meta['dtype'], buffer=shm_neighbors.buf); # Logged in R19
                except Exception as shm_err: logger.error(f"{log_prefix}SHM Error (neighbors): {shm_err}."); neighbor_indices_array_shm = None
            else: neighbor_indices_array_shm = None;
            # Full Neighbor Indices Array (for symmetry)
            if neighbor_indices_shm_meta:
                try: shm_all_neighbors = SharedMemory(name=neighbor_indices_shm_meta['name'], create=False); all_neighbor_indices_array_shm = np.ndarray(neighbor_indices_shm_meta['shape'], dtype=neighbor_indices_shm_meta['dtype'], buffer=shm_all_neighbors.buf); # Logged in R19
                except Exception as shm_err: logger.error(f"{log_prefix}SHM Error (all_neighbors): {shm_err}."); all_neighbor_indices_array_shm = None
            else: all_neighbor_indices_array_shm = None;
            # Previous Degrees
            if rule.needs_neighbor_degrees:
                if _previous_degree_override is not None: previous_degree_array_shm = _previous_degree_override; # Logged in R19
                elif prev_degree_shm_meta:
                    try: shm_prev_deg = SharedMemory(name=prev_degree_shm_meta['name'], create=False); previous_degree_array_shm = np.ndarray(prev_degree_shm_meta['shape'], dtype=prev_degree_shm_meta['dtype'], buffer=shm_prev_deg.buf); # Logged in R19
                    except Exception as shm_deg_err: logger.error(f"{log_prefix}SHM Error (prev_degree): {shm_deg_err}"); previous_degree_array_shm = None
                else: logger.warning(f"{log_prefix}Rule needs degrees, but neither override nor SHM meta provided."); previous_degree_array_shm = None
            else: previous_degree_array_shm = None;
            # Previous Active Counts
            if rule.needs_neighbor_active_counts:
                if _previous_active_override is not None: previous_active_neighbor_array_shm = _previous_active_override; # Logged in R19
                elif prev_active_shm_meta:
                    try: shm_prev_active = SharedMemory(name=prev_active_shm_meta['name'], create=False); previous_active_neighbor_array_shm = np.ndarray(prev_active_shm_meta['shape'], dtype=prev_active_shm_meta['dtype'], buffer=shm_prev_active.buf); # Logged in R19
                    except Exception as shm_pa_err: logger.error(f"{log_prefix}SHM Error (prev_active): {shm_pa_err}"); previous_active_neighbor_array_shm = None
                else: logger.warning(f"{log_prefix}Rule needs active counts, but neither override nor SHM meta provided."); previous_active_neighbor_array_shm = None
            else: previous_active_neighbor_array_shm = None;
            # --- End SHM Attachment ---

            chunk_coords = {idx: tuple(_njit_unravel_index(idx, grid_dimensions_arr)) for idx in chunk_indices}
            for node_idx in chunk_indices:
                if detailed_logging_enabled: logger.detail(f"{log_prefix}Processing Node {node_idx}...") # type: ignore[attr-defined]
                try:
                    # [ Get Neighbors logic remains the same ]
                    if neighbor_indices_array_shm is not None and 0 <= node_idx < neighbor_indices_array_shm.shape[0]:
                        neighbors_padded = neighbor_indices_array_shm[node_idx]; neighbors = neighbors_padded[neighbors_padded != -1]
                    else: # Fallback calculation
                        boundary_mode_int = 1 if grid_boundary_condition == 'wrap' else 0; neighborhood_type_val = grid_neighborhood_type.value; num_dims_local = len(grid_dimensions)
                        if grid_neighborhood_type == NeighborhoodType.VON_NEUMANN: max_neighbors_local = 6 if num_dims_local == 3 else 4
                        elif grid_neighborhood_type == NeighborhoodType.MOORE: max_neighbors_local = 26 if num_dims_local == 3 else 8
                        elif grid_neighborhood_type == NeighborhoodType.HEX: max_neighbors_local = 6
                        elif grid_neighborhood_type == NeighborhoodType.HEX_PRISM: max_neighbors_local = 12
                        else: logger.warning(f"{log_prefix}Unknown neighborhood type in fallback: {grid_neighborhood_type}. Using default max_neighbors=8."); max_neighbors_local = 8
                        neighbors = _get_neighbors_dynamic_helper(node_idx, grid_dimensions_arr, neighborhood_type_val, boundary_mode_int, max_neighbors_local)

                    # [ Create NeighborhoodData logic remains the same ]
                    valid_indices = neighbors[(neighbors >= 0) & (neighbors < original_states_flat.size)]
                    neighbor_states_arr = original_states_flat[valid_indices] if valid_indices.size > 0 else np.array([], dtype=grid_dtype)
                    node_state_val = original_states_flat[node_idx] if 0 <= node_idx < original_states_flat.size else 0.0
                    node_coords = chunk_coords[node_idx]
                    neighbor_edge_states_dict: Dict[int, float] = {}; edges_in_neighborhood_set = set(); valid_neighbor_coords = {}
                    if edge_states_copy:
                        valid_neighbor_coords = {n_idx: tuple(_njit_unravel_index(n_idx, grid_dimensions_arr)) for n_idx in valid_indices}
                        for n_idx in valid_indices:
                            n_coords = valid_neighbor_coords.get(n_idx);
                            if n_coords is not None and node_coords is not None:
                                edge_coords = (node_coords, n_coords) if node_coords < n_coords else (n_coords, node_coords)
                                edge_state_val = edge_states_copy.get(edge_coords, 0.0); neighbor_edge_states_dict[n_idx] = edge_state_val
                                if edge_coords in edge_states_copy: edge_indices = (node_idx, n_idx) if node_idx < n_idx else (n_idx, node_idx); edges_in_neighborhood_set.add(edge_indices)
                    neighbor_degrees: Optional[Dict[int, int]] = None
                    if rule.needs_neighbor_degrees and previous_degree_array_shm is not None:
                        neighbor_degrees = {}; valid_degree_indices = valid_indices[valid_indices < previous_degree_array_shm.size]
                        for n_idx in valid_degree_indices: neighbor_degrees[n_idx] = int(previous_degree_array_shm[n_idx])
                    neighbor_active_counts: Optional[Dict[int, int]] = None
                    if rule.needs_neighbor_active_counts and previous_active_neighbor_array_shm is not None:
                        neighbor_active_counts = {}; valid_active_count_indices = valid_indices[valid_indices < previous_active_neighbor_array_shm.size]
                        for n_idx in valid_active_count_indices: neighbor_active_counts[n_idx] = int(previous_active_neighbor_array_shm[n_idx])
                    neighbor_metrics: Dict[str, np.ndarray] = {'neighbor_state': neighbor_states_arr}; neighborhood_metrics: Dict[str, float] = {}
                    valid_edge_states = list(neighbor_edge_states_dict.values()); neighborhood_metrics['avg_neighbor_edge_state'] = float(np.mean(valid_edge_states)) if valid_edge_states else 0.0

                    params_for_node = params_copy.copy()
                    params_for_node['_all_neighbor_indices_shm'] = all_neighbor_indices_array_shm
                    params_for_node['_previous_node_states'] = original_states_flat
                    params_for_node['_previous_node_degrees'] = previous_degree_array_shm

                    neighborhood = NeighborhoodData(
                        node_index=node_idx, node_coords=node_coords, node_state=node_state_val,
                        neighbor_indices=neighbors,
                        neighbor_states=neighbor_states_arr,
                        edges=edges_in_neighborhood_set, dimensions=grid_dimensions,
                        neighborhood_type=grid_neighborhood_type, grid_boundary=grid_boundary_condition,
                        neighbor_edge_states=neighbor_edge_states_dict,
                        rule_params=params_for_node,
                        neighbor_degrees=neighbor_degrees,
                        neighbor_active_counts=neighbor_active_counts,
                        neighbor_metrics=neighbor_metrics, neighborhood_metrics=neighborhood_metrics
                    )
                    # --- End NeighborhoodData Creation ---

                    # --- Compute Updates (Pass Flag) ---
                    new_state, new_edges_indices = rule.compute_updates(neighborhood, detailed_logging_enabled) # Pass flag
                    # ---

                    # --- Convert Edge Keys to Coordinates ---
                    new_edges_coords: Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float] = {}
                    if new_edges_indices:
                        if not all(isinstance(k, tuple) and len(k) == 2 and isinstance(k[0], (int, np.integer)) and isinstance(k[1], (int, np.integer)) for k in new_edges_indices.keys()):
                             logger.error(f"{log_prefix}Node {node_idx}: Rule compute_updates returned non-index keys! Type: {type(list(new_edges_indices.keys())[0]) if new_edges_indices else 'N/A'}")
                        else:
                            node_coords_for_conv = tuple(_njit_unravel_index(int(node_idx), grid_dimensions_arr))
                            for edge_key, edge_state in new_edges_indices.items():
                                idx1, idx2 = edge_key; other_node_in_edge = idx2 if idx1 == node_idx else idx1
                                try: other_node_coords = tuple(_njit_unravel_index(int(other_node_in_edge), grid_dimensions_arr))
                                except TypeError as te: logger.error(f"{log_prefix}!!! TYPE ERROR DEBUG (R16) !!! Node {node_idx}: Type of other_node_in_edge before cast: {type(other_node_in_edge)}, Value: {other_node_in_edge}"); raise te
                                if node_coords_for_conv is not None and other_node_coords is not None:
                                    ordered_edge_coords = (node_coords_for_conv, other_node_coords) if node_coords_for_conv < other_node_coords else (other_node_coords, node_coords_for_conv)
                                    new_edges_coords[ordered_edge_coords] = edge_state
                                else: logger.warning(f"{log_prefix}Could not get coordinates for edge key {edge_key}, skipping.")
                    # --- End Coordinate Conversion ---
                    results.append((new_state, new_edges_coords))
                except IndexError as idx_e: logger.error(f"{log_prefix}IndexError processing node {node_idx}: {idx_e}\n{traceback.format_exc()}"); results.append((original_states_flat[node_idx] if 0 <= node_idx < original_states_flat.size else 0.0, {}))
                except Exception as node_e: logger.error(f"{log_prefix}Error processing node {node_idx}: {node_e}\n{traceback.format_exc()}"); results.append((original_states_flat[node_idx] if 0 <= node_idx < original_states_flat.size else 0.0, {}))

            if detailed_logging_enabled: logger.detail(f"{log_prefix}Finished processing chunk {chunk_indices[0]}...{chunk_indices[-1]}") # type: ignore[attr-defined]

        except Exception as e:
            logger.error(f"{log_prefix}Error in _process_standard_chunk: {e}\n{traceback.format_exc()}")
            default_states = [original_states_flat[idx] if original_states_flat is not None and 0 <= idx < original_states_flat.size else 0.0 for idx in chunk_indices]
            results = [(state, {}) for state in default_states]
        finally:
            # --- Close ALL SHM handles ---
            if shm_orig is not None: shm_orig.close()
            if shm_neighbors is not None: shm_neighbors.close()
            if shm_prev_deg is not None: shm_prev_deg.close()
            if shm_prev_active is not None: shm_prev_active.close()
            if shm_all_neighbors is not None: shm_all_neighbors.close()
            gc.collect()
            # ---

        duration = time.time() - start_time
        return results, duration
        
    @staticmethod
    # @njit # Keep disabled for logging
    def _process_final_state_chunk(
        chunk_indices: List[int],
        eligibility_proxy_shm_meta: Optional[Dict[str, Any]],
        prev_state_shm_meta: Optional[Dict[str, Any]],
        prev_degree_shm_meta: Optional[Dict[str, Any]],
        neighbor_indices_shm_meta: Optional[Dict[str, Any]],
        grid_shape: Tuple[int, ...],
        grid_dtype: np.dtype,
        final_edges_this_step: Set[Tuple[Tuple[int, ...], Tuple[int, ...]]],
        previous_edges: Set[Tuple[Tuple[int, ...], Tuple[int, ...]]],
        previous_edge_states: Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float],
        prev_active_shm_meta: Optional[Dict[str, Any]],
        rule: 'Rule',
        params_copy: Dict[str, Any],
        grid_dimensions: Tuple[int, ...],
        detailed_logging_enabled: bool,
        # --- ADDED: Final Degree SHM Meta ---
        final_degree_shm_meta: Optional[Dict[str, Any]] = None
        # ---
    ) -> Tuple[Optional[npt.NDArray[np.float64]], float]:
        """
        Worker function for Phase 3: Calculates the final node state using rule._compute_final_state.
        Accepts pre-calculated final degrees via SHM.
        (Round 7: Accept and use final_degree_shm_meta)
        (Round 22: Corrected signature to accept logging flag)
        """
        start_time = time.time()
        try: logger = logging.getLogger(__name__ + ".GridWorkerFinalState")
        except NameError: logger = logging.getLogger("GridWorkerFinalState_fallback")

        log_prefix = f"WorkerFinalState (PID:{os.getpid()} R7 Final Degree): " # Updated round

        # --- SHM Variables ---
        shm_eligibility = None; eligibility_proxies_flat = None
        shm_prev_state = None; prev_state_array_flat = None
        shm_prev_deg = None; prev_degree_array_shm = None
        shm_prev_active = None; previous_active_neighbor_array_shm = None
        shm_all_neighbors = None; # Handle for neighbor indices SHM
        # --- ADDED: Final Degree SHM ---
        shm_final_deg = None; final_degree_array_shm = None
        # ---

        grid_dimensions_arr = np.array(grid_dimensions, dtype=np.int64)
        num_nodes_in_chunk = len(chunk_indices)
        calculated_final_states = np.zeros(num_nodes_in_chunk, dtype=np.float64)

        try:
            # --- Attach to SHM ---
            # [ Eligibility, Prev State, Prev Degree, Prev Active, Neighbors SHM attachment - Unchanged ]
            # Eligibility Proxies
            if eligibility_proxy_shm_meta:
                try: shm_eligibility = SharedMemory(name=eligibility_proxy_shm_meta['name'], create=False); eligibility_proxies_flat = np.ndarray(eligibility_proxy_shm_meta['shape'], dtype=eligibility_proxy_shm_meta['dtype'], buffer=shm_eligibility.buf);
                except Exception as shm_err: logger.error(f"{log_prefix}SHM Error (eligibility): {shm_err}"); return None, time.time() - start_time
            else: logger.error(f"{log_prefix}Eligibility proxy SHM meta missing!"); return None, time.time() - start_time
            # Previous State
            if prev_state_shm_meta:
                try: shm_prev_state = SharedMemory(name=prev_state_shm_meta['name'], create=False); prev_state_array_flat = np.ndarray(prev_state_shm_meta['shape'], dtype=prev_state_shm_meta['dtype'], buffer=shm_prev_state.buf);
                except Exception as shm_err: logger.error(f"{log_prefix}SHM Error (prev_state): {shm_err}"); return None, time.time() - start_time
            else: logger.error(f"{log_prefix}Previous state SHM meta missing!"); return None, time.time() - start_time
            # Previous Degrees
            if prev_degree_shm_meta:
                try: shm_prev_deg = SharedMemory(name=prev_degree_shm_meta['name'], create=False); prev_degree_array_shm = np.ndarray(prev_degree_shm_meta['shape'], dtype=prev_degree_shm_meta['dtype'], buffer=shm_prev_deg.buf);
                except Exception as shm_err: logger.error(f"{log_prefix}SHM Error (prev_degree): {shm_err}"); prev_degree_array_shm = None
            else: prev_degree_array_shm = None;
            # Previous Active Counts
            if prev_active_shm_meta:
                try: shm_prev_active = SharedMemory(name=prev_active_shm_meta['name'], create=False); previous_active_neighbor_array_shm = np.ndarray(prev_active_shm_meta['shape'], dtype=prev_active_shm_meta['dtype'], buffer=shm_prev_active.buf);
                except Exception as shm_pa_err: logger.error(f"{log_prefix}SHM Error (prev_active): {shm_pa_err}"); previous_active_neighbor_array_shm = None
            else: previous_active_neighbor_array_shm = None;
            # Neighbor Indices (for cleanup only)
            if neighbor_indices_shm_meta:
                try: shm_all_neighbors = SharedMemory(name=neighbor_indices_shm_meta['name'], create=False);
                except Exception as shm_err: logger.error(f"{log_prefix}SHM Error attaching neighbor handle: {shm_err}."); shm_all_neighbors = None

            # --- ADDED: Attach to Final Degree SHM ---
            if final_degree_shm_meta:
                try:
                    shm_final_deg = SharedMemory(name=final_degree_shm_meta['name'], create=False)
                    final_degree_array_shm = np.ndarray(final_degree_shm_meta['shape'], dtype=final_degree_shm_meta['dtype'], buffer=shm_final_deg.buf)
                    if detailed_logging_enabled: logger.detail(f"{log_prefix}Attached to final_degree SHM: {final_degree_shm_meta['name']}. Shape: {final_degree_array_shm.shape}") # type: ignore[attr-defined]
                except Exception as shm_err:
                    logger.error(f"{log_prefix}SHM Error (final_degree): {shm_err}")
                    final_degree_array_shm = None # Proceed without it if attach fails
            else:
                final_degree_array_shm = None
                if detailed_logging_enabled: logger.detail(f"{log_prefix}No final_degree SHM meta provided.") # type: ignore[attr-defined]
            # --- END ADDED ---

            # --- Get signature of the rule's compute_final_state method ---
            compute_final_state_sig = None
            if hasattr(rule, '_compute_final_state') and callable(rule._compute_final_state):
                 try: compute_final_state_sig = inspect.signature(rule._compute_final_state)
                 except ValueError: logger.error(f"{log_prefix}Could not get signature for rule._compute_final_state.")
            # ---

            for i, node_idx in enumerate(chunk_indices):
                if detailed_logging_enabled: logger.detail(f"{log_prefix}Processing Node {node_idx}...") # type: ignore[attr-defined]
                try:
                    proxy_state = 0.0
                    if eligibility_proxies_flat is not None and 0 <= node_idx < eligibility_proxies_flat.size:
                        proxy_state = eligibility_proxies_flat[node_idx]
                    else: logger.warning(f"{log_prefix}Node index {node_idx} out of bounds for eligibility array or array is None."); continue

                    # --- Call rule._compute_final_state ---
                    final_state = 0.0 # Default on error
                    if hasattr(rule, '_compute_final_state') and callable(rule._compute_final_state):
                        # --- MODIFIED: Pass final_degree_array_shm if signature accepts it ---
                        kwargs_for_final_state = {
                            'node_idx': node_idx, 'current_proxy_state': proxy_state,
                            'final_edges': final_edges_this_step, 'dimensions': grid_dimensions,
                            'previous_node_states': prev_state_array_flat, 'previous_edges': previous_edges,
                            'previous_edge_states': previous_edge_states, 'previous_node_degrees': prev_degree_array_shm,
                            'previous_active_neighbors': previous_active_neighbor_array_shm,
                            'eligibility_proxies': eligibility_proxies_flat,
                            'detailed_logging_enabled': detailed_logging_enabled
                        }
                        if compute_final_state_sig and 'final_degree_array' in compute_final_state_sig.parameters:
                            kwargs_for_final_state['final_degree_array'] = final_degree_array_shm
                            # logger.debug(f"  Passing final_degree_array to _compute_final_state for node {node_idx}")
                        # --- END MODIFIED ---

                        final_state = rule._compute_final_state(**kwargs_for_final_state)
                    else:
                         logger.error(f"{log_prefix}Rule object {rule} does not have a callable _compute_final_state method.")
                    # ---

                    calculated_final_states[i] = final_state

                except IndexError as idx_e: logger.error(f"{log_prefix}IndexError processing node {node_idx} for final state: {idx_e}\n{traceback.format_exc()}"); calculated_final_states[i] = 0.0
                except TypeError as type_e: logger.error(f"{log_prefix}TypeError calling _compute_final_state for node {node_idx}: {type_e}"); logger.error(f"  Rule object type: {type(rule)}"); logger.error(f"  Rule class name: {rule.__class__.__name__}"); logger.error(f"  Method signature parameters: {list(compute_final_state_sig.parameters.keys()) if compute_final_state_sig else 'N/A'}"); logger.error(traceback.format_exc()); calculated_final_states[i] = 0.0
                except Exception as node_e: logger.error(f"{log_prefix}Error processing node {node_idx} for final state: {node_e}\n{traceback.format_exc()}"); calculated_final_states[i] = 0.0

            if detailed_logging_enabled: logger.detail(f"{log_prefix}Finished processing chunk {chunk_indices[0]}...{chunk_indices[-1]}") # type: ignore[attr-defined]

        except Exception as e: logger.error(f"{log_prefix}Error in _process_final_state_chunk: {e}\n{traceback.format_exc()}"); return None, time.time() - start_time
        finally:
            # --- Clean up ALL SHM handles ---
            if shm_eligibility is not None: shm_eligibility.close()
            if shm_prev_state is not None: shm_prev_state.close()
            if shm_prev_deg is not None: shm_prev_deg.close()
            if shm_prev_active is not None: shm_prev_active.close()
            if shm_all_neighbors is not None: shm_all_neighbors.close()
            # --- ADDED: Close final degree SHM ---
            if shm_final_deg is not None: shm_final_deg.close()
            # ---
            gc.collect()
            # ---

        duration = time.time() - start_time
        return calculated_final_states, duration

    @staticmethod
    # @timer_decorator # Keep disabled for now
    def _process_states_only(
        chunk_indices: List[int],
        original_states_shm_meta: Optional[Dict[str, Any]],
        prev_degree_shm_meta: Optional[Dict[str, Any]],
        neighbor_indices_shm_meta: Optional[Dict[str, Any]], # Use the full neighbor array meta
        grid_shape: Tuple[int, ...],
        grid_dtype: np.dtype,
        edge_states_copy: Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float], # Needed for generic NeighborhoodData
        prev_active_shm_meta: Optional[Dict[str, Any]],
        rule: 'Rule', # Pass the actual rule instance
        params_copy: Dict[str, Any], # Pass rule params
        grid_dimensions: Tuple[int, ...],
        grid_neighborhood_type: 'NeighborhoodType', # Needed for generic NeighborhoodData
        grid_boundary_condition: str, # Needed for generic NeighborhoodData
        detailed_logging_enabled: bool,
        _original_states_override: Optional[np.ndarray] = None,
        _previous_degree_override: Optional[np.ndarray] = None,
        _previous_active_override: Optional[np.ndarray] = None
    ) -> Tuple[Optional[np.ndarray], float]:
        """
        Worker function for state-only computation (Phase 1 of two-phase rules).
        Uses Numba JIT helper if rule.use_jit_state_phase is True and helper exists,
        otherwise uses generic NeighborhoodData creation and rule._compute_new_state call.
        Validates the return value from the JIT helper.
        (Round 27: Added try-except around degree/active count dict population)
        (Round 9: Numba refactor - extract arrays, call JIT helper)
        (Round 10: Add conditional logic for JIT vs generic path)
        (Round 11: Use use_jit_state_phase flag instead of isinstance)
        (Round 12: Validate JIT return value)
        (Round 13: Refactor JIT call, move checks outside JIT)
        (Round 14: Correct calculate_max_neighbors arguments)
        """
        start_time = time.time()
        logger = logging.getLogger(__name__ + ".worker_states")
        # --- SHM Variables ---
        shm_orig = None; original_states_flat = None
        shm_neighbors = None; neighbor_indices_array_shm = None
        shm_prev_deg = None; previous_degree_array_shm = None
        shm_prev_active = None; previous_active_neighbor_array_shm = None
        shm_all_neighbors = None; all_neighbor_indices_array_shm = None # For symmetry calc in generic path
        # ---
        log_prefix = f"WorkerStates (PID:{os.getpid()} R14 MaxN Fix): " # Updated round
        results_array: Optional[np.ndarray] = None
        grid_dimensions_arr = np.array(grid_dimensions, dtype=np.int64)
        num_nodes_in_chunk = len(chunk_indices)
        # Initialize the final result array (eligibility proxies)
        final_eligibility_proxies = np.zeros(num_nodes_in_chunk, dtype=np.float64)

        if detailed_logging_enabled:
            logger.detail(f"{log_prefix}Processing chunk {chunk_indices[0]}...{chunk_indices[-1]} ({num_nodes_in_chunk} nodes)") # type: ignore [attr-defined]

        # --- Check if the rule requests JIT optimization AND has the helper method ---
        use_jit_path = getattr(rule, 'use_jit_state_phase', False) and hasattr(rule, '_compute_new_state_jit')
        if use_jit_path:
            logger.debug(f"{log_prefix}Rule {type(rule).__name__} requests JIT. Using Numba path.")
        else:
            logger.debug(f"{log_prefix}Rule is {type(rule).__name__}. Using generic NeighborhoodData path (JIT Flag={getattr(rule, 'use_jit_state_phase', 'Not Set')}, Helper Exists={hasattr(rule, '_compute_new_state_jit')}).")
        # ---

        try:
            # --- Attach to SHM / Use Overrides (Needed for BOTH paths) ---
            # Original States
            if _original_states_override is not None: original_states_flat = _original_states_override
            elif original_states_shm_meta:
                try: shm_orig = SharedMemory(name=original_states_shm_meta['name'], create=False); original_states_flat = np.ndarray(original_states_shm_meta['shape'], dtype=original_states_shm_meta['dtype'], buffer=shm_orig.buf)
                except Exception as shm_err: logger.error(f"{log_prefix}SHM Error (orig): {shm_err}"); return None, time.time() - start_time
            else: logger.error(f"{log_prefix}No SHM meta or override provided (orig)!"); return None, time.time() - start_time

            # Neighbor Indices (Full Array - needed for both JIT and generic NeighborhoodData creation)
            if neighbor_indices_shm_meta:
                try:
                    # Attach once for both potential uses
                    shm_neighbors = SharedMemory(name=neighbor_indices_shm_meta['name'], create=False)
                    neighbor_indices_array_shm = np.ndarray(neighbor_indices_shm_meta['shape'], dtype=neighbor_indices_shm_meta['dtype'], buffer=shm_neighbors.buf)
                    # Keep a separate handle for symmetry check if needed by generic path
                    shm_all_neighbors = SharedMemory(name=neighbor_indices_shm_meta['name'], create=False)
                    all_neighbor_indices_array_shm = np.ndarray(neighbor_indices_shm_meta['shape'], dtype=neighbor_indices_shm_meta['dtype'], buffer=shm_all_neighbors.buf)
                except Exception as shm_err:
                    logger.error(f"{log_prefix}SHM Error (neighbors): {shm_err}.")
                    neighbor_indices_array_shm = None
                    all_neighbor_indices_array_shm = None
                    if shm_neighbors: shm_neighbors.close() # Close handle if attach failed
                    if shm_all_neighbors: shm_all_neighbors.close()
            else:
                neighbor_indices_array_shm = None
                all_neighbor_indices_array_shm = None

            # Previous Degrees (Needed for BOTH paths if rule requires)
            if rule.needs_neighbor_degrees:
                if _previous_degree_override is not None: previous_degree_array_shm = _previous_degree_override
                elif prev_degree_shm_meta:
                    try: shm_prev_deg = SharedMemory(name=prev_degree_shm_meta['name'], create=False); previous_degree_array_shm = np.ndarray(prev_degree_shm_meta['shape'], dtype=prev_degree_shm_meta['dtype'], buffer=shm_prev_deg.buf)
                    except Exception as shm_deg_err: logger.error(f"{log_prefix}SHM Error (prev_degree): {shm_deg_err}"); previous_degree_array_shm = None
                else: logger.warning(f"{log_prefix}Rule needs degrees, but neither override nor SHM meta provided."); previous_degree_array_shm = None
            else: previous_degree_array_shm = None

            # Previous Active Counts (Needed for BOTH paths if rule requires)
            if rule.needs_neighbor_active_counts:
                if _previous_active_override is not None: previous_active_neighbor_array_shm = _previous_active_override
                elif prev_active_shm_meta:
                    try: shm_prev_active = SharedMemory(name=prev_active_shm_meta['name'], create=False); previous_active_neighbor_array_shm = np.ndarray(prev_active_shm_meta['shape'], dtype=prev_active_shm_meta['dtype'], buffer=shm_prev_active.buf)
                    except Exception as shm_pa_err: logger.error(f"{log_prefix}SHM Error (prev_active): {shm_pa_err}"); previous_active_neighbor_array_shm = None
                else: logger.warning(f"{log_prefix}Rule needs active counts, but neither override nor SHM meta provided."); previous_active_neighbor_array_shm = None
            else: previous_active_neighbor_array_shm = None
            # --- End SHM Attachment ---

            # --- Execute based on rule type ---
            if use_jit_path:
                # --- Numba Path (ROL-U or other flagged rule) ---
                logger.debug(f"{log_prefix}Using Numba JIT path for {type(rule).__name__}.")
                if neighbor_indices_array_shm is None: raise ValueError("Neighbor indices array is missing for JIT path.")
                jit_method = getattr(rule, '_compute_new_state_jit', None)
                if not callable(jit_method): raise TypeError(f"Rule {type(rule).__name__} flagged for JIT but _compute_new_state_jit is not callable.")

                # Extract primitive parameters needed by JIT function
                birth_metric_type_str = params_copy.get('birth_metric_type', 'DEGREE')
                birth_agg_str = params_copy.get('birth_metric_aggregation', 'SUM')
                survival_metric_type_str = params_copy.get('survival_metric_type', 'DEGREE')
                survival_agg_str = params_copy.get('survival_metric_aggregation', 'SUM')
                clustering_denom_type_str = params_copy.get('clustering_denominator_type', 'ACTUAL')
                # --- CORRECTED: Calculate max_deg_theory with correct arguments ---
                current_dimension_type = Dimension.TWO_D if len(grid_dimensions)==2 else Dimension.THREE_D
                max_deg_theory = calculate_max_neighbors(current_dimension_type, grid_neighborhood_type)
                # ---

                # Call the JIT function to get METRIC values
                calculated_metric_values = jit_method(
                    chunk_indices=np.array(chunk_indices, dtype=np.int64),
                    original_states_flat=original_states_flat,
                    neighbor_indices_array=neighbor_indices_array_shm,
                    previous_degree_array=previous_degree_array_shm,
                    previous_active_neighbor_array=previous_active_neighbor_array_shm,
                    grid_dimensions_arr=grid_dimensions_arr,
                    birth_metric_type_str=birth_metric_type_str, # Pass primitives
                    birth_agg_str=birth_agg_str,
                    survival_metric_type_str=survival_metric_type_str,
                    survival_agg_str=survival_agg_str,
                    clustering_denom_type_str=clustering_denom_type_str,
                    max_deg_theory=max_deg_theory, # Pass calculated value
                    detailed_logging_enabled=detailed_logging_enabled
                )

                # Validate the result from JIT
                if not isinstance(calculated_metric_values, np.ndarray) or calculated_metric_values.shape != (num_nodes_in_chunk,) or not np.issubdtype(calculated_metric_values.dtype, np.floating):
                    logger.error(f"{log_prefix}JIT function returned invalid result! Type: {type(calculated_metric_values)}, Shape: {getattr(calculated_metric_values, 'shape', 'N/A')}, Dtype: {getattr(calculated_metric_values, 'dtype', 'N/A')}. Expected shape: ({num_nodes_in_chunk},). Aborting chunk.")
                    return None, time.time() - start_time

                # --- Perform Eligibility Checks and Perturbation in Python ---
                logger.debug(f"{log_prefix}Performing eligibility checks and perturbation outside JIT...")
                perturb_enable = params_copy.get('perturbation_enable', False)
                state_flip_prob = params_copy.get('random_state_flip_probability', 0.0)
                tolerance = 0.005 # For float value comparisons

                for i, node_idx in enumerate(chunk_indices):
                    current_node_state = original_states_flat[node_idx]
                    check_type = "Birth" if current_node_state <= 1e-6 else "Survival"
                    metric_value_to_check = calculated_metric_values[i] # Get pre-calculated metric

                    # Determine which params to use
                    metric_type = birth_metric_type_str if check_type == "Birth" else survival_metric_type_str
                    aggregation = birth_agg_str if check_type == "Birth" else survival_agg_str
                    is_non_agg = metric_type in ["SYMMETRY_STATE", "SYMMETRY_DEGREE", "NEIGHBOR_DEGREE_VARIANCE", "NEIGHBOR_DEGREE_STDDEV"]
                    agg_used = aggregation if not is_non_agg else None
                    metric_key_suffix = f"_{metric_type}" + (f"_{agg_used}" if agg_used else "")
                    range_param_name = f"{check_type.lower()}_eligibility_range{metric_key_suffix}"
                    values_param_name = f"{check_type.lower()}_eligibility_values{metric_key_suffix}"

                    # Get range/value lists from the passed params_copy
                    ranges_to_check = params_copy.get(range_param_name, [])
                    values_to_check = params_copy.get(values_param_name, [])

                    # Perform checks
                    passes_check = False
                    # Check ranges (ensure ranges are valid lists/tuples of numbers)
                    valid_ranges = [tuple(float(x) for x in r) for r in ranges_to_check if isinstance(r, (list, tuple)) and len(r) == 2]
                    if any(min_val <= metric_value_to_check <= max_val for min_val, max_val in valid_ranges):
                        passes_check = True
                    # Check specific values if range check failed
                    elif values_to_check:
                        metric_value_rounded = int(round(metric_value_to_check))
                        for target_value in values_to_check:
                            match = False
                            if isinstance(target_value, int): match = (metric_value_rounded == target_value)
                            elif isinstance(target_value, float): match = (abs(metric_value_to_check - target_value) < tolerance)
                            if match: passes_check = True; break

                    eligibility_proxy = 1.0 if passes_check else 0.0

                    # Apply Perturbation
                    if perturb_enable and state_flip_prob > 0 and np.random.rand() < state_flip_prob:
                        eligibility_proxy = 1.0 - eligibility_proxy

                    final_eligibility_proxies[i] = eligibility_proxy
                # --- End Eligibility Checks ---
                # --- End Numba Path ---

            else:
                # --- Generic Path (if not using JIT or fallback needed) ---
                logger.debug(f"{log_prefix}Using generic NeighborhoodData path for {type(rule).__name__}.")
                chunk_coords = {idx: tuple(_njit_unravel_index(idx, grid_dimensions_arr)) for idx in chunk_indices}
                for i, node_idx in enumerate(chunk_indices):
                    if detailed_logging_enabled: logger.detail(f"{log_prefix}Processing Node {node_idx} (Generic)...") # type: ignore[attr-defined]
                    try:
                        # Get Neighbors (use precalculated if available, else fallback)
                        if neighbor_indices_array_shm is not None and 0 <= node_idx < neighbor_indices_array_shm.shape[0]:
                            neighbors_padded = neighbor_indices_array_shm[node_idx]; neighbors = neighbors_padded[neighbors_padded != -1]
                        else: # Fallback calculation
                            boundary_mode_int = 1 if grid_boundary_condition == 'wrap' else 0; neighborhood_type_val = grid_neighborhood_type.value; num_dims_local = len(grid_dimensions)
                            if grid_neighborhood_type == NeighborhoodType.VON_NEUMANN: max_neighbors_local = 6 if num_dims_local == 3 else 4
                            elif grid_neighborhood_type == NeighborhoodType.MOORE: max_neighbors_local = 26 if num_dims_local == 3 else 8
                            elif grid_neighborhood_type == NeighborhoodType.HEX: max_neighbors_local = 6
                            elif grid_neighborhood_type == NeighborhoodType.HEX_PRISM: max_neighbors_local = 12
                            else: logger.warning(f"{log_prefix}Unknown neighborhood type in fallback: {grid_neighborhood_type}. Using default max_neighbors=8."); max_neighbors_local = 8
                            neighbors = _get_neighbors_dynamic_helper(node_idx, grid_dimensions_arr, neighborhood_type_val, boundary_mode_int, max_neighbors_local)

                        # Create NeighborhoodData (similar to _process_standard_chunk)
                        valid_indices = neighbors[(neighbors >= 0) & (neighbors < original_states_flat.size)]
                        neighbor_states_arr = original_states_flat[valid_indices] if valid_indices.size > 0 else np.array([], dtype=grid_dtype)
                        node_state_val = original_states_flat[node_idx] if 0 <= node_idx < original_states_flat.size else 0.0
                        node_coords = chunk_coords[node_idx]
                        neighbor_edge_states_dict: Dict[int, float] = {}; edges_in_neighborhood_set = set(); valid_neighbor_coords = {}
                        if edge_states_copy:
                            valid_neighbor_coords = {n_idx: tuple(_njit_unravel_index(n_idx, grid_dimensions_arr)) for n_idx in valid_indices}
                            for n_idx in valid_indices:
                                n_coords = valid_neighbor_coords.get(n_idx);
                                if n_coords is not None and node_coords is not None:
                                    edge_coords = (node_coords, n_coords) if node_coords < n_coords else (n_coords, node_coords)
                                    edge_state_val = edge_states_copy.get(edge_coords, 0.0); neighbor_edge_states_dict[n_idx] = edge_state_val
                                    if edge_coords in edge_states_copy: edge_indices = (node_idx, n_idx) if node_idx < n_idx else (n_idx, node_idx); edges_in_neighborhood_set.add(edge_indices)
                        neighbor_degrees: Optional[Dict[int, int]] = None
                        if rule.needs_neighbor_degrees and previous_degree_array_shm is not None:
                            neighbor_degrees = {}; valid_degree_indices = valid_indices[valid_indices < previous_degree_array_shm.size]
                            for n_idx in valid_degree_indices: neighbor_degrees[n_idx] = int(previous_degree_array_shm[n_idx])
                        neighbor_active_counts: Optional[Dict[int, int]] = None
                        if rule.needs_neighbor_active_counts and previous_active_neighbor_array_shm is not None:
                            neighbor_active_counts = {}; valid_active_count_indices = valid_indices[valid_indices < previous_active_neighbor_array_shm.size]
                            for n_idx in valid_active_count_indices: neighbor_active_counts[n_idx] = int(previous_active_neighbor_array_shm[n_idx])
                        neighbor_metrics: Dict[str, np.ndarray] = {'neighbor_state': neighbor_states_arr}; neighborhood_metrics: Dict[str, float] = {}
                        valid_edge_states = list(neighbor_edge_states_dict.values()); neighborhood_metrics['avg_neighbor_edge_state'] = float(np.mean(valid_edge_states)) if valid_edge_states else 0.0

                        params_for_node = params_copy.copy()
                        # Pass SHM arrays needed for potential symmetry calculations inside NeighborhoodData
                        params_for_node['_all_neighbor_indices_shm'] = all_neighbor_indices_array_shm
                        params_for_node['_previous_node_states'] = original_states_flat
                        params_for_node['_previous_node_degrees'] = previous_degree_array_shm

                        neighborhood = NeighborhoodData(
                            node_index=node_idx, node_coords=node_coords, node_state=node_state_val,
                            neighbor_indices=neighbors,
                            neighbor_states=neighbor_states_arr,
                            edges=edges_in_neighborhood_set, dimensions=grid_dimensions,
                            neighborhood_type=grid_neighborhood_type, grid_boundary=grid_boundary_condition,
                            neighbor_edge_states=neighbor_edge_states_dict,
                            rule_params=params_for_node, # Pass params including SHM refs
                            neighbor_degrees=neighbor_degrees,
                            neighbor_active_counts=neighbor_active_counts,
                            neighbor_metrics=neighbor_metrics, neighborhood_metrics=neighborhood_metrics
                        )
                        # --- End NeighborhoodData Creation ---

                        # --- Compute State using the standard rule method ---
                        if detailed_logging_enabled: logger.detail(f"    Node {node_idx}: Calling rule._compute_new_state (Generic)...") # type: ignore[attr-defined]
                        final_eligibility_proxies[i] = rule._compute_new_state(neighborhood, detailed_logging_enabled)
                        if detailed_logging_enabled: logger.detail(f"    Node {node_idx}: rule._compute_new_state returned {final_eligibility_proxies[i]:.1f}") # type: ignore[attr-defined]
                        # ---

                    except IndexError as idx_e:
                        logger.error(f"{log_prefix}IndexError processing node {node_idx} (Generic): {idx_e}\n{traceback.format_exc()}")
                        final_eligibility_proxies[i] = original_states_flat[node_idx] if 0 <= node_idx < original_states_flat.size else 0.0
                    except Exception as node_e:
                        logger.error(f"{log_prefix}Error processing node {node_idx} (Generic): {node_e}\n{traceback.format_exc()}")
                        final_eligibility_proxies[i] = original_states_flat[node_idx] if 0 <= node_idx < original_states_flat.size else 0.0
                # --- End Generic Path ---

            if detailed_logging_enabled: logger.detail(f"{log_prefix}Finished processing chunk {chunk_indices[0]}...{chunk_indices[-1]}") # type: ignore[attr-defined]
            results_array = final_eligibility_proxies # Return the final eligibility proxies

        except Exception as e: logger.error(f"{log_prefix}Error in _process_states_only: {e}\n{traceback.format_exc()}"); results_array = None
        finally:
            # --- Close ALL SHM handles ---
            if shm_orig is not None: shm_orig.close()
            if shm_neighbors is not None: shm_neighbors.close()
            if shm_prev_deg is not None: shm_prev_deg.close()
            if shm_prev_active is not None: shm_prev_active.close()
            if shm_all_neighbors is not None: shm_all_neighbors.close() # Close the separate handle
            gc.collect()
            # ---

        duration = time.time() - start_time
        return results_array, duration

    @staticmethod
    # @timer_decorator # Keep disabled for now
    def _process_edges_only(
        chunk_indices: List[int],
        original_states_shm_meta: Optional[Dict[str, Any]],
        prev_degree_shm_meta: Optional[Dict[str, Any]],
        neighbor_indices_shm_meta: Optional[Dict[str, Any]], # Use the full neighbor array meta
        grid_shape: Tuple[int, ...],
        grid_dtype: np.dtype,
        eligibility_proxy_shm_name: Optional[str], # Name needed for JIT path too
        edge_states_copy: Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float], # Needed for generic path
        prev_active_shm_meta: Optional[Dict[str, Any]],
        rule: 'Rule', # Pass the actual rule instance
        params_copy: Dict[str, Any], # Pass rule params
        grid_dimensions: Tuple[int, ...],
        grid_neighborhood_type: 'NeighborhoodType', # Needed for generic path
        grid_boundary_condition: str, # Needed for generic path
        detailed_logging_enabled: bool,
        _original_states_override: Optional[np.ndarray] = None,
        _previous_degree_override: Optional[np.ndarray] = None,
        _previous_active_override: Optional[np.ndarray] = None
    ) -> Tuple[List[Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float]], float]:
        """
        Worker function for edge-only computation (Phase 2 of two-phase rules).
        Uses Numba JIT helper if rule.use_jit_edge_phase is True and helper exists,
        otherwise uses generic NeighborhoodData creation and rule._compute_new_edges call.
        Validates the return value from the JIT helper.
        (Round 22: Corrected signature to accept logging flag and active override)
        (Round 14: Add conditional logic for JIT vs generic path)
        (Round 15: Validate JIT edge result structure)
        (Round 16: Handle new JIT return format - List[np.ndarray])
        """
        start_time = time.time()
        logger = logging.getLogger(__name__ + ".worker_edges")
        # --- SHM Variables ---
        shm_orig = None; original_states_flat = None
        shm_neighbors = None; neighbor_indices_array_shm = None
        shm_eligibility = None; eligibility_proxies_flat = None
        shm_prev_deg = None; previous_degree_array_shm = None
        shm_prev_active = None; previous_active_neighbor_array_shm = None
        shm_all_neighbors = None; all_neighbor_indices_array_shm = None
        # ---
        chunk_size = len(chunk_indices)
        default_return: List[Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float]] = [{} for _ in range(chunk_size)]
        log_prefix = f"WorkerEdges (PID:{os.getpid()} R16 JIT Return): " # Updated round
        results_list: List[Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float]] = default_return
        grid_dimensions_arr = np.array(grid_dimensions, dtype=np.int64)

        # --- Check if the rule requests JIT optimization AND has the helper method ---
        use_jit_path = getattr(rule, 'use_jit_edge_phase', False) and hasattr(rule, '_compute_new_edges_jit')
        if use_jit_path:
            logger.debug(f"{log_prefix}Rule {type(rule).__name__} requests JIT for edges. Using Numba path.")
        else:
            logger.debug(f"{log_prefix}Rule is {type(rule).__name__}. Using generic NeighborhoodData path for edges (JIT Flag={getattr(rule, 'use_jit_edge_phase', 'Not Set')}, Helper Exists={hasattr(rule, '_compute_new_edges_jit')}).")
        # ---

        try:
            # --- Attach to SHM / Use Overrides (Needed for BOTH paths) ---
            # [SHM Attachment logic remains the same]
            # Original States
            if _original_states_override is not None: original_states_flat = _original_states_override
            elif original_states_shm_meta:
                try: shm_orig = SharedMemory(name=original_states_shm_meta['name'], create=False); original_states_flat = np.ndarray(original_states_shm_meta['shape'], dtype=original_states_shm_meta['dtype'], buffer=shm_orig.buf)
                except Exception as shm_err: logger.error(f"{log_prefix}SHM Error (orig): {shm_err}"); return default_return, time.time() - start_time
            else: logger.error(f"{log_prefix}No SHM meta or override provided (orig)!"); return default_return, time.time() - start_time
            # Eligibility Proxies (Needed for BOTH paths)
            if eligibility_proxy_shm_name:
                try: shm_eligibility = SharedMemory(name=eligibility_proxy_shm_name, create=False); eligibility_proxies_flat = np.ndarray(np.prod(grid_shape), dtype=grid_dtype, buffer=shm_eligibility.buf)
                except Exception as shm_err: logger.error(f"{log_prefix}SHM Error (eligibility): {shm_err}"); return default_return, time.time() - start_time
            else: logger.error(f"{log_prefix}No SHM name provided for eligibility proxies!"); return default_return, time.time() - start_time
            # Neighbor Indices (Full Array)
            if neighbor_indices_shm_meta:
                try:
                    shm_neighbors = SharedMemory(name=neighbor_indices_shm_meta['name'], create=False); neighbor_indices_array_shm = np.ndarray(neighbor_indices_shm_meta['shape'], dtype=neighbor_indices_shm_meta['dtype'], buffer=shm_neighbors.buf)
                    shm_all_neighbors = SharedMemory(name=neighbor_indices_shm_meta['name'], create=False); all_neighbor_indices_array_shm = np.ndarray(neighbor_indices_shm_meta['shape'], dtype=neighbor_indices_shm_meta['dtype'], buffer=shm_all_neighbors.buf)
                except Exception as shm_err: logger.error(f"{log_prefix}SHM Error (neighbors): {shm_err}."); neighbor_indices_array_shm = None; all_neighbor_indices_array_shm = None;
                finally: # Ensure handles are closed if attach fails mid-way
                    if shm_neighbors and (neighbor_indices_array_shm is None or all_neighbor_indices_array_shm is None): shm_neighbors.close()
                    if shm_all_neighbors and all_neighbor_indices_array_shm is None: shm_all_neighbors.close()
            else: neighbor_indices_array_shm = None; all_neighbor_indices_array_shm = None
            # Previous Degrees (Needed for generic path if rule requires)
            if not use_jit_path and rule.needs_neighbor_degrees:
                if _previous_degree_override is not None: previous_degree_array_shm = _previous_degree_override
                elif prev_degree_shm_meta:
                    try: shm_prev_deg = SharedMemory(name=prev_degree_shm_meta['name'], create=False); previous_degree_array_shm = np.ndarray(prev_degree_shm_meta['shape'], dtype=prev_degree_shm_meta['dtype'], buffer=shm_prev_deg.buf)
                    except Exception as shm_deg_err: logger.error(f"{log_prefix}SHM Error (prev_degree): {shm_deg_err}"); previous_degree_array_shm = None
                else: logger.warning(f"{log_prefix}Rule needs degrees, but neither override nor SHM meta provided."); previous_degree_array_shm = None
            else: previous_degree_array_shm = None
            # Previous Active Counts (Needed for generic path if rule requires)
            if not use_jit_path and rule.needs_neighbor_active_counts:
                if _previous_active_override is not None: previous_active_neighbor_array_shm = _previous_active_override
                elif prev_active_shm_meta:
                    try: shm_prev_active = SharedMemory(name=prev_active_shm_meta['name'], create=False); previous_active_neighbor_array_shm = np.ndarray(prev_active_shm_meta['shape'], dtype=prev_active_shm_meta['dtype'], buffer=shm_prev_active.buf)
                    except Exception as shm_pa_err: logger.error(f"{log_prefix}SHM Error (prev_active): {shm_pa_err}"); previous_active_neighbor_array_shm = None
                else: logger.warning(f"{log_prefix}Rule needs active counts, but neither override nor SHM meta provided."); previous_active_neighbor_array_shm = None
            else: previous_active_neighbor_array_shm = None
            # --- End SHM Attachment ---

            # --- Execute based on rule type ---
            if use_jit_path:
                # --- Numba Path ---
                logger.debug(f"{log_prefix}Using Numba JIT path for edges.")
                if neighbor_indices_array_shm is None: raise ValueError("Neighbor indices array is missing for JIT edge path.")
                if eligibility_proxies_flat is None: raise ValueError("Eligibility proxy array is missing for JIT edge path.")

                jit_method_edges = getattr(rule, '_compute_new_edges_jit', None)
                if not callable(jit_method_edges): raise TypeError(f"Rule {type(rule).__name__} flagged for JIT but _compute_new_edges_jit is not callable.")

                # Extract primitive parameters
                perturb_enable = params_copy.get('perturbation_enable', False)
                edge_toggle_prob = params_copy.get('random_edge_toggle_probability', 0.0)

                # Call JIT function
                jit_result_list = jit_method_edges(
                    chunk_indices=np.array(chunk_indices, dtype=np.int64),
                    eligibility_proxies_flat=eligibility_proxies_flat,
                    neighbor_indices_array=neighbor_indices_array_shm,
                    perturbation_enable=perturb_enable,
                    edge_toggle_prob=edge_toggle_prob
                )

                # --- MODIFIED: Validate JIT Result Structure (List of Arrays) ---
                if not (isinstance(jit_result_list, list) and
                        len(jit_result_list) == len(chunk_indices) and
                        all(isinstance(arr, np.ndarray) for arr in jit_result_list)):
                    logger.error(f"{log_prefix}JIT edge function returned invalid result! Type: {type(jit_result_list)}. Expected list of numpy arrays. Aborting chunk.")
                    return default_return, time.time() - start_time # Return default on error
                # --- END MODIFIED ---

                # --- Reconstruct coordinate dictionary from the list of neighbor arrays ---
                logger.debug(f"{log_prefix}JIT returned list of neighbor arrays. Reconstructing coordinate dict.")
                proposed_edges_dict_list: List[Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float]] = [{} for _ in range(chunk_size)]

                for i, node_idx in enumerate(chunk_indices):
                    proposed_neighbors_indices = jit_result_list[i]
                    if proposed_neighbors_indices.size == 0: continue # Skip if no edges for this node

                    try:
                        node_coords = tuple(_njit_unravel_index(int(node_idx), grid_dimensions_arr))
                        for neighbor_idx in proposed_neighbors_indices:
                            # Avoid double adding by only processing if node_idx < neighbor_idx
                            if node_idx < neighbor_idx:
                                neighbor_coords = tuple(_njit_unravel_index(int(neighbor_idx), grid_dimensions_arr))
                                # Order is guaranteed by the check above
                                ordered_edge_coords = (node_coords, neighbor_coords)
                                proposed_edges_dict_list[i][ordered_edge_coords] = 1.0
                    except Exception as coord_err:
                        logger.error(f"{log_prefix}Error converting indices ({node_idx}, ...) to coords for JIT edge result: {coord_err}")

                results_list = proposed_edges_dict_list
                # --- End Numba Path ---

            else:
                # --- Generic Path ---
                logger.debug(f"{log_prefix}Using generic NeighborhoodData path for edges.")
                chunk_coords = {idx: tuple(_njit_unravel_index(idx, grid_dimensions_arr)) for idx in chunk_indices}
                proposed_edges_generic: List[Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float]] = [{} for _ in range(chunk_size)]

                for i, node_idx in enumerate(chunk_indices):
                    if detailed_logging_enabled: logger.detail(f"{log_prefix}Processing Node {node_idx} (Generic Edges)...") # type: ignore[attr-defined]
                    try:
                        # [ Get Neighbors logic remains the same ]
                        if neighbor_indices_array_shm is not None and 0 <= node_idx < neighbor_indices_array_shm.shape[0]:
                            neighbors_padded = neighbor_indices_array_shm[node_idx]; neighbors = neighbors_padded[neighbors_padded != -1]
                        else: # Fallback calculation
                            boundary_mode_int = 1 if grid_boundary_condition == 'wrap' else 0; neighborhood_type_val = grid_neighborhood_type.value; num_dims_local = len(grid_dimensions)
                            if grid_neighborhood_type == NeighborhoodType.VON_NEUMANN: max_neighbors_local = 6 if num_dims_local == 3 else 4
                            elif grid_neighborhood_type == NeighborhoodType.MOORE: max_neighbors_local = 26 if num_dims_local == 3 else 8
                            elif grid_neighborhood_type == NeighborhoodType.HEX: max_neighbors_local = 6
                            elif grid_neighborhood_type == NeighborhoodType.HEX_PRISM: max_neighbors_local = 12
                            else: logger.warning(f"{log_prefix}Unknown neighborhood type in fallback: {grid_neighborhood_type}. Using default max_neighbors=8."); max_neighbors_local = 8
                            neighbors = _get_neighbors_dynamic_helper(node_idx, grid_dimensions_arr, neighborhood_type_val, boundary_mode_int, max_neighbors_local)

                        # [ Create NeighborhoodData logic remains the same ]
                        valid_indices = neighbors[(neighbors >= 0) & (neighbors < original_states_flat.size)]
                        neighbor_states_arr = original_states_flat[valid_indices] if valid_indices.size > 0 else np.array([], dtype=grid_dtype)
                        node_state_val = original_states_flat[node_idx] if 0 <= node_idx < original_states_flat.size else 0.0
                        node_coords = chunk_coords[node_idx]
                        neighbor_edge_states_dict: Dict[int, float] = {}; edges_in_neighborhood_set = set(); valid_neighbor_coords = {}
                        if edge_states_copy:
                            valid_neighbor_coords = {n_idx: tuple(_njit_unravel_index(n_idx, grid_dimensions_arr)) for n_idx in valid_indices}
                            for n_idx in valid_indices:
                                n_coords = valid_neighbor_coords.get(n_idx);
                                if n_coords is not None and node_coords is not None:
                                    edge_coords = (node_coords, n_coords) if node_coords < n_coords else (n_coords, node_coords)
                                    edge_state_val = edge_states_copy.get(edge_coords, 0.0); neighbor_edge_states_dict[n_idx] = edge_state_val
                                    if edge_coords in edge_states_copy: edge_indices = (node_idx, n_idx) if node_idx < n_idx else (n_idx, node_idx); edges_in_neighborhood_set.add(edge_indices)
                        neighbor_degrees: Optional[Dict[int, int]] = None
                        if rule.needs_neighbor_degrees and previous_degree_array_shm is not None:
                            neighbor_degrees = {}; valid_degree_indices = valid_indices[valid_indices < previous_degree_array_shm.size]
                            for n_idx in valid_degree_indices: neighbor_degrees[n_idx] = int(previous_degree_array_shm[n_idx])
                        neighbor_active_counts: Optional[Dict[int, int]] = None
                        if rule.needs_neighbor_active_counts and previous_active_neighbor_array_shm is not None:
                            neighbor_active_counts = {}; valid_active_count_indices = valid_indices[valid_indices < previous_active_neighbor_array_shm.size]
                            for n_idx in valid_active_count_indices: neighbor_active_counts[n_idx] = int(previous_active_neighbor_array_shm[n_idx])
                        neighbor_metrics: Dict[str, np.ndarray] = {'neighbor_state': neighbor_states_arr}; neighborhood_metrics: Dict[str, float] = {}
                        valid_edge_states = list(neighbor_edge_states_dict.values()); neighborhood_metrics['avg_neighbor_edge_state'] = float(np.mean(valid_edge_states)) if valid_edge_states else 0.0

                        params_for_node = params_copy.copy()
                        # Pass eligibility proxies needed by _compute_new_edges
                        params_for_node['_eligibility_proxies'] = eligibility_proxies_flat
                        params_for_node['_all_neighbor_indices_shm'] = all_neighbor_indices_array_shm
                        params_for_node['_previous_node_states'] = original_states_flat
                        params_for_node['_previous_node_degrees'] = previous_degree_array_shm

                        neighborhood = NeighborhoodData(
                            node_index=node_idx, node_coords=node_coords, node_state=node_state_val,
                            neighbor_indices=neighbors,
                            neighbor_states=neighbor_states_arr,
                            edges=edges_in_neighborhood_set, dimensions=grid_dimensions,
                            neighborhood_type=grid_neighborhood_type, grid_boundary=grid_boundary_condition,
                            neighbor_edge_states=neighbor_edge_states_dict,
                            rule_params=params_for_node, # Pass params including eligibility
                            neighbor_degrees=neighbor_degrees,
                            neighbor_active_counts=neighbor_active_counts,
                            neighbor_metrics=neighbor_metrics, neighborhood_metrics=neighborhood_metrics
                        )
                        # --- End NeighborhoodData Creation ---

                        # --- Compute Edges using the standard rule method ---
                        if detailed_logging_enabled: logger.detail(f"    Node {node_idx}: Calling rule._compute_new_edges (Generic)...") # type: ignore[attr-defined]
                        new_edges_indices = rule._compute_new_edges(neighborhood, detailed_logging_enabled) # Returns Dict[Tuple[int, int], float]
                        # ---

                        # --- Convert to Coordinate Keys ---
                        new_edges_coords: Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float] = {}
                        if new_edges_indices:
                            if not all(isinstance(k, tuple) and len(k) == 2 and isinstance(k[0], (int, np.integer)) and isinstance(k[1], (int, np.integer)) for k in new_edges_indices.keys()):
                                logger.error(f"{log_prefix}Node {node_idx}: Rule _compute_new_edges returned non-index keys! Type: {type(list(new_edges_indices.keys())[0]) if new_edges_indices else 'N/A'}")
                            else:
                                node_coords_for_conv = tuple(_njit_unravel_index(int(node_idx), grid_dimensions_arr))
                                for edge_key, edge_state in new_edges_indices.items():
                                    idx1, idx2 = edge_key; other_node_in_edge = idx2 if idx1 == node_idx else idx1
                                    try: other_node_coords = tuple(_njit_unravel_index(int(other_node_in_edge), grid_dimensions_arr))
                                    except TypeError as te: logger.error(f"{log_prefix}!!! TYPE ERROR DEBUG (R16) !!! Node {node_idx}: Type of other_node_in_edge before cast: {type(other_node_in_edge)}, Value: {other_node_in_edge}"); raise te
                                    if node_coords_for_conv is not None and other_node_coords is not None:
                                        ordered_edge_coords = (node_coords_for_conv, other_node_coords) if node_coords_for_conv < other_node_coords else (other_node_coords, node_coords_for_conv)
                                        new_edges_coords[ordered_edge_coords] = edge_state
                                    else: logger.warning(f"{log_prefix}Could not get coordinates for edge key {edge_key}, skipping.")
                        proposed_edges_generic[i] = new_edges_coords
                        # --- End Coordinate Conversion ---

                    except Exception as node_e: logger.error(f"{log_prefix}Error processing node edges {node_idx} (Generic): {node_e}"); logger.error(traceback.format_exc()); proposed_edges_generic[i] = {}
                results_list = proposed_edges_generic
                # --- End Generic Path ---

            if detailed_logging_enabled: logger.detail(f"{log_prefix}Finished processing chunk {chunk_indices[0]}...{chunk_indices[-1]}") # type: ignore[attr-defined]

        except Exception as e: logger.error(f"{log_prefix}Error in _process_edges_only: {e}\n{traceback.format_exc()}"); results_list = default_return
        finally:
            # --- Close ALL SHM handles ---
            if shm_orig is not None: shm_orig.close()
            if shm_neighbors is not None: shm_neighbors.close()
            if shm_eligibility is not None: shm_eligibility.close()
            if shm_prev_deg is not None: shm_prev_deg.close()
            if shm_prev_active is not None: shm_prev_active.close()
            if shm_all_neighbors is not None: shm_all_neighbors.close() # Close the separate handle
            gc.collect()
            # ---

        duration = time.time() - start_time
        return results_list, duration

    @timer_decorator
    def _compute_states_phase(self, original_states_local: npt.NDArray[np.float64], # Accept local numpy array
                              nodes_to_update: List[int],
                              chunk_size: int,
                              rule: 'Rule'):
        """First phase: compute only states, passing raw data to workers.
           Correctly calls worker for sequential execution.
           (Round 7: Remove edges_copy from sequential worker call)"""
        new_states = np.zeros_like(original_states_local)
        np.copyto(new_states, original_states_local)
        futures = []
        original_states_shm = None; original_states_shm_name = None; original_states_shm_meta = None
        prev_degree_shm = None; prev_degree_shm_name = None; prev_degree_shm_meta = None
        prev_active_shm = None; prev_active_shm_name = None; prev_active_shm_meta = None

        logger = logging.getLogger(__name__)
        log_prefix = f"Grid._compute_states_phase(ID:{self._unique_id} R7): " # Updated round

        try:
            use_parallel = GlobalSettings.USE_PARALLEL_PROCESSING
            num_processes = GlobalSettings.Simulation.NUM_PROCESSES
            process_pool = None
            if hasattr(self, 'gui') and self.gui and hasattr(self.gui, 'controller') and self.gui.controller:
                 process_pool = self.gui.controller.process_pool
            else:
                 logger.error(f"{log_prefix}Cannot access process pool via gui.controller.")
                 return np.zeros_like(original_states_local)
            will_run_parallel = use_parallel and num_processes > 1 and isinstance(process_pool, ProcessPoolExecutor)
            logger.debug(f"{log_prefix}Executing _compute_states_phase with use_parallel={use_parallel}, will_run_parallel={will_run_parallel}")

            # edges_copy = self.edges.copy() # REMOVED - No longer needed here
            edge_states_copy = self.edge_states.copy() # Still needed
            prev_degree_data_local = self.previous_degree_array.copy() if rule.needs_neighbor_degrees and self.previous_degree_array is not None else None
            prev_active_count_data_local = self.previous_active_neighbor_array.copy() if rule.needs_neighbor_active_counts and self.previous_active_neighbor_array is not None else None
            grid_boundary_condition = rule.params.get('grid_boundary', 'bounded')
            current_params_copy = copy.deepcopy(rule.params)

            if not will_run_parallel:
                logger.info(f"{log_prefix}Running state computation sequentially in main thread.")
                if rule is None: logger.error(f"{log_prefix}Rule is None, cannot compute states sequentially."); return original_states_local.copy()
                logger.debug(f"{log_prefix}Sequential call using params: {current_params_copy}")

                # --- CORRECTED: Removed edges_copy argument ---
                sequential_results_array, seq_duration = Grid._process_states_only(
                    chunk_indices=nodes_to_update,
                    original_states_shm_meta=None,
                    prev_degree_shm_meta=None,
                    neighbor_indices_shm_meta=None,
                    grid_shape=self.grid_array.shape,
                    grid_dtype=self.grid_array.dtype,
                    edge_states_copy=edge_states_copy,
                    prev_active_shm_meta=None,
                    rule=rule,
                    params_copy=current_params_copy,
                    grid_dimensions=self.dimensions,
                    grid_neighborhood_type=self.neighborhood_type,
                    grid_boundary_condition=grid_boundary_condition,
                    detailed_logging_enabled=LogSettings.Performance.ENABLE_DETAILED_LOGGING, # Pass flag
                    _original_states_override=original_states_local,
                    _previous_degree_override=prev_degree_data_local,
                    _previous_active_override=prev_active_count_data_local # Pass active override
                )
                # --- END CORRECTION ---

                if sequential_results_array is not None:
                    if len(sequential_results_array) == len(nodes_to_update):
                        node_map = {node_idx: i for i, node_idx in enumerate(nodes_to_update)}
                        for i, node_idx in enumerate(nodes_to_update):
                             if 0 <= node_idx < new_states.size:
                                 new_states[node_idx] = sequential_results_array[i]
                             else: logger.warning(f"{log_prefix}Node index {node_idx} out of bounds for new_states (size {new_states.size})")
                    else: logger.error(f"{log_prefix}Size mismatch in sequential execution: nodes_to_update ({len(nodes_to_update)}) vs sequential_results ({len(sequential_results_array)})")
                else: logger.error(f"{log_prefix}Sequential execution of _process_states_only returned None.")
                return new_states

            # --- Parallel Execution Path ---
            if process_pool is None:
                logger.error(f"{log_prefix}Process pool is None, cannot run parallel.")
                return original_states_local.copy()

            # [ SHM Creation Logic - Unchanged ]
            original_states_shm_name = f"{self._unique_id}_orig_state_phase_{self.gui.controller.generation}"
            try:
                try: SharedMemory(name=original_states_shm_name).unlink()
                except FileNotFoundError: pass
                original_states_shm = SharedMemory(name=original_states_shm_name, create=True, size=original_states_local.nbytes)
                original_states_array_shm = np.ndarray(original_states_local.shape, dtype=original_states_local.dtype, buffer=original_states_shm.buf)
                np.copyto(original_states_array_shm, original_states_local)
                original_states_shm_meta = {'name': original_states_shm_name, 'shape': original_states_local.shape, 'dtype': original_states_local.dtype}
            except Exception as shm_create_err: logger.error(f"{log_prefix}Failed to create SHM for state phase (orig): {shm_create_err}"); original_states_shm = None; original_states_shm_name = None; original_states_shm_meta = None
            if prev_degree_data_local is not None:
                prev_degree_shm_name = f"{self._unique_id}_prevdeg_state_phase_{self.gui.controller.generation}"
                try:
                    try: SharedMemory(name=prev_degree_shm_name).unlink()
                    except FileNotFoundError: pass
                    prev_degree_shm = SharedMemory(name=prev_degree_shm_name, create=True, size=prev_degree_data_local.nbytes)
                    prev_degree_array_shm = np.ndarray(prev_degree_data_local.shape, dtype=prev_degree_data_local.dtype, buffer=prev_degree_shm.buf)
                    np.copyto(prev_degree_array_shm, prev_degree_data_local)
                    prev_degree_shm_meta = {'name': prev_degree_shm_name, 'shape': prev_degree_data_local.shape, 'dtype': prev_degree_data_local.dtype}
                except Exception as shm_deg_err: logger.error(f"{log_prefix}Failed to create SHM for prev_degree_array in state phase: {shm_deg_err}"); prev_degree_shm = None; prev_degree_shm_name = None; prev_degree_shm_meta = None
            if prev_active_count_data_local is not None:
                prev_active_shm_name = f"{self._unique_id}_prevactive_state_phase_{self.gui.controller.generation}"
                try:
                    try: SharedMemory(name=prev_active_shm_name).unlink()
                    except FileNotFoundError: pass
                    prev_active_shm = SharedMemory(name=prev_active_shm_name, create=True, size=prev_active_count_data_local.nbytes)
                    prev_active_array_shm = np.ndarray(prev_active_count_data_local.shape, dtype=prev_active_count_data_local.dtype, buffer=prev_active_shm.buf)
                    np.copyto(prev_active_array_shm, prev_active_count_data_local)
                    prev_active_shm_meta = {'name': prev_active_shm_name, 'shape': prev_active_count_data_local.shape, 'dtype': prev_active_count_data_local.dtype}
                    logger.debug(f"{log_prefix}Created SHM for prev_active_count: {prev_active_shm_name}")
                except Exception as shm_pa_err: logger.error(f"{log_prefix}Failed to create SHM for prev_active_count in state phase: {shm_pa_err}"); prev_active_shm = None; prev_active_shm_name = None; prev_active_shm_meta = None

            logger.debug(f"{log_prefix}Parallel submission using params: {current_params_copy}")

            # --- Submit jobs using as_completed ---
            futures_map = {}
            node_index_chunks = np.array_split(nodes_to_update, max(1, min(len(nodes_to_update) // chunk_size, num_processes))) if nodes_to_update else []
            for chunk_indices_arr in node_index_chunks:
                chunk_indices = chunk_indices_arr.tolist()
                if not chunk_indices: continue
                if rule is None: logger.error(f"{log_prefix}Rule is None, cannot submit task"); continue

                # --- CORRECTED: Removed edges_copy argument ---
                future = process_pool.submit(
                    Grid._process_states_only,
                    # Args passed directly by update_grid_parallel (or None if not applicable)
                    chunk_indices,
                    original_states_shm_meta, # Pass meta dict or None
                    prev_degree_shm_meta,     # Pass meta dict or None
                    self._neighbor_indices_shm_meta, # Pass meta dict or None
                    self.grid_array.shape,
                    self.grid_array.dtype,
                    # Remaining arguments passed positionally
                    # edges_copy, # REMOVED
                    edge_states_copy,
                    prev_active_shm_meta, # Pass meta dict or None
                    rule,
                    current_params_copy,
                    self.dimensions,
                    self.neighborhood_type,
                    grid_boundary_condition,
                    False, # No override for original states in parallel
                    None  # No override for degrees in parallel
                )
                # --- END CORRECTION ---
                futures_map[future] = chunk_indices

            # [ Collect results - Unchanged ]
            logger.debug(f"{log_prefix}Submitted {len(futures_map)} state chunks, waiting with as_completed.")
            temp_results = {}
            for future in as_completed(futures_map):
                chunk_indices = futures_map[future]
                start_index = nodes_to_update.index(chunk_indices[0])
                try:
                    chunk_state_result_array, duration = future.result(timeout=10.0)
                    if chunk_state_result_array is not None:
                        temp_results[start_index] = chunk_state_result_array
                    else: logger.warning(f"{log_prefix}Received None array for chunk_state_result from chunk {chunk_indices}")
                except TimeoutError: logger.error(f"{log_prefix}Timeout processing states chunk {chunk_indices}")
                except Exception as e: logger.error(f"{log_prefix}Error processing states chunk {chunk_indices}: {e}")

            # Assemble results in the correct order
            if len(temp_results) == len(node_index_chunks):
                 sorted_start_indices = sorted(temp_results.keys())
                 node_map = {node_idx: i for i, node_idx in enumerate(nodes_to_update)}
                 results_assembled_count = 0
                 for start_idx in sorted_start_indices:
                     chunk_res_array = temp_results[start_idx]
                     chunk_node_indices = node_index_chunks[list(temp_results.keys()).index(start_idx)]
                     if chunk_res_array is not None and len(chunk_res_array) == len(chunk_node_indices):
                         for j, node_idx in enumerate(chunk_node_indices):
                             if 0 <= node_idx < new_states.size:
                                 new_states[node_idx] = chunk_res_array[j]
                                 results_assembled_count += 1
                             else: logger.warning(f"{log_prefix}Node index {node_idx} out of bounds for new_states (size {new_states.size})")
                     else: logger.error(f"{log_prefix}Result array invalid or size mismatch for chunk starting at {start_idx}.")

                 if results_assembled_count != len(nodes_to_update):
                      logger.error(f"{log_prefix}Final assembled result length mismatch! Expected {len(nodes_to_update)}, got {results_assembled_count}.")
                      return original_states_local.copy()
            else:
                 logger.error(f"{log_prefix}Did not receive results from all chunks ({len(temp_results)}/{len(node_index_chunks)}).")
                 return original_states_local.copy()

            logger.debug(f"{log_prefix}Finished collecting state results from as_completed.")
            return new_states

        except Exception as e:
            logger.error(f"{log_prefix}Error in _compute_states_phase: {e}")
            logger.error(traceback.format_exc())
            return original_states_local.copy()
        finally:
            # --- Clean up shared memory ---
            shm_list_to_clean = [
                (original_states_shm, original_states_shm_name, "State Phase (Orig)"),
                (prev_degree_shm, prev_degree_shm_name, "State Phase (PrevDeg)"),
                (prev_active_shm, prev_active_shm_name, "State Phase (PrevActive)")
            ]
            for instance, name, desc in shm_list_to_clean:
                if instance:
                    try: instance.close(); instance.unlink(); logger.debug(f"{log_prefix}Cleaned up SHM for {desc}: {name}")
                    except Exception as shm_clean_err: logger.error(f"{log_prefix}Error cleaning up state phase SHM ({desc}): {shm_clean_err}")
            # ---

    @timer_decorator
    def _compute_edges_phase(self, new_states, nodes_to_update, chunk_size, original_states=None, rule_class=None, metadata=None):
        """
        Second phase: compute edges with updated state information but using original states for edge logic.
        Correctly calls worker for sequential execution.
        (Round 7: Remove edges_copy from sequential worker call)
        """
        proposed_edges: List[Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float]] = [{} for _ in range(self.total_nodes)]
        futures = []
        original_states_shm = None; original_states_shm_name = None; original_states_shm_meta = None
        eligibility_proxy_shm = None; eligibility_proxy_shm_name = None
        prev_degree_shm = None; prev_degree_shm_name = None; prev_degree_shm_meta = None
        prev_active_shm = None; prev_active_shm_name = None; prev_active_shm_meta = None

        logger = logging.getLogger(__name__)
        log_prefix = f"Grid._compute_edges_phase(ID:{self._unique_id} R7): " # Updated round
        correct_grid_id = id(self)
        logger.debug(f"{log_prefix}START - Correct Grid object ID: {correct_grid_id}")

        original_states_local = original_states if original_states is not None else new_states.copy()
        eligibility_proxies_local = new_states

        try:
            process_pool = None
            if hasattr(self, 'gui') and self.gui and hasattr(self.gui, 'controller') and self.gui.controller:
                 process_pool = self.gui.controller.process_pool
            else:
                 logger.error(f"{log_prefix}Cannot access process pool via gui.controller.")
                 return []
            use_parallel = GlobalSettings.USE_PARALLEL_PROCESSING
            num_processes = GlobalSettings.Simulation.NUM_PROCESSES
            will_run_parallel = use_parallel and num_processes > 1 and isinstance(process_pool, ProcessPoolExecutor)

            if self.rule is None:
                logger.error(f"{log_prefix}self.rule is None. Cannot proceed.")
                return []

            # edges_copy = self.edges.copy() # REMOVED - No longer needed here
            edge_states_copy = self.edge_states.copy() # Still needed
            prev_degree_data_local = self.previous_degree_array.copy() if self.rule.needs_neighbor_degrees and self.previous_degree_array is not None else None
            prev_active_count_data_local = self.previous_active_neighbor_array.copy() if self.rule.needs_neighbor_active_counts and self.previous_active_neighbor_array is not None else None
            grid_boundary_condition = self.rule.params.get('grid_boundary', 'bounded')
            current_params_copy = copy.deepcopy(self.rule.params)

            if not will_run_parallel:
                logger.info(f"{log_prefix}Running edge computation sequentially in main thread.")
                if self.rule is None: logger.error(f"{log_prefix}Rule is None, cannot compute edges sequentially."); return []

                # --- CORRECTED: Removed edges_copy argument ---
                sequential_results_list, seq_duration = Grid._process_edges_only(
                    chunk_indices=nodes_to_update,
                    original_states_shm_meta=None,
                    prev_degree_shm_meta=None,
                    neighbor_indices_shm_meta=None,
                    grid_shape=self.grid_array.shape,
                    grid_dtype=self.grid_array.dtype,
                    eligibility_proxy_shm_name=None, # No SHM name needed
                    edge_states_copy=edge_states_copy,
                    prev_active_shm_meta=None,
                    rule=self.rule,
                    params_copy=current_params_copy,
                    grid_dimensions=self.dimensions,
                    grid_neighborhood_type=self.neighborhood_type,
                    grid_boundary_condition=grid_boundary_condition,
                    detailed_logging_enabled=LogSettings.Performance.ENABLE_DETAILED_LOGGING, # Pass flag
                    _original_states_override=original_states_local,
                    _previous_degree_override=prev_degree_data_local,
                    _previous_active_override=prev_active_count_data_local # Pass active override
                )
                # --- END CORRECTION ---

                if sequential_results_list:
                    node_map = {node_idx: i for i, node_idx in enumerate(nodes_to_update)}
                    for i, edges_dict in enumerate(sequential_results_list):
                        if i < len(nodes_to_update):
                             node_idx_seq = nodes_to_update[i]
                             if 0 <= node_idx_seq < len(proposed_edges):
                                 proposed_edges[node_idx_seq].update(edges_dict)
                             else:
                                 logger.warning(f"{log_prefix}Sequential: Node index {node_idx_seq} out of bounds for proposed_edges (Size: {len(proposed_edges)}).")
                        else:
                             logger.error(f"{log_prefix}Sequential: Result index {i} out of bounds for nodes_to_update (len {len(nodes_to_update)})")
                else:
                    logger.error(f"{log_prefix}Sequential edge computation failed or returned empty list.")

                return proposed_edges

            # --- Parallel Execution Path ---
            if process_pool is None:
                logger.error(f"{log_prefix}Process pool is None, cannot run parallel.")
                return []

            # [ SHM Creation Logic - Create SHM for prev_active_count_data_local ]
            temp_suffix = uuid.uuid4().hex[:8]
            original_states_shm_name = f"{self._unique_id}_orig_edge_phase_{temp_suffix}"
            try:
                try: SharedMemory(name=original_states_shm_name).unlink()
                except FileNotFoundError: pass
                original_states_shm = SharedMemory(name=original_states_shm_name, create=True, size=original_states_local.nbytes)
                original_states_array_shm = np.ndarray(original_states_local.shape, dtype=original_states_local.dtype, buffer=original_states_shm.buf)
                np.copyto(original_states_array_shm, original_states_local)
                original_states_shm_meta = {'name': original_states_shm_name, 'shape': original_states_local.shape, 'dtype': original_states_local.dtype}
            except Exception as shm_create_err: logger.error(f"{log_prefix}Failed to create SHM for edge phase (orig): {shm_create_err}"); original_states_shm = None; original_states_shm_name = None; original_states_shm_meta = None
            eligibility_proxy_shm_name = f"{self._unique_id}_elig_edge_phase_{temp_suffix}"
            try:
                try: SharedMemory(name=eligibility_proxy_shm_name).unlink()
                except FileNotFoundError: pass
                eligibility_proxy_shm = SharedMemory(name=eligibility_proxy_shm_name, create=True, size=eligibility_proxies_local.nbytes)
                eligibility_proxy_array_shm = np.ndarray(eligibility_proxies_local.shape, dtype=eligibility_proxies_local.dtype, buffer=eligibility_proxy_shm.buf)
                np.copyto(eligibility_proxy_array_shm, eligibility_proxies_local)
            except Exception as shm_elig_err: logger.error(f"{log_prefix}Failed to create SHM for edge phase (elig): {shm_elig_err}"); eligibility_proxy_shm = None; eligibility_proxy_shm_name = None
            if prev_degree_data_local is not None:
                prev_degree_shm_name = f"{self._unique_id}_prevdeg_edge_phase_{temp_suffix}"
                try:
                    try: SharedMemory(name=prev_degree_shm_name).unlink()
                    except FileNotFoundError: pass
                    prev_degree_shm = SharedMemory(name=prev_degree_shm_name, create=True, size=prev_degree_data_local.nbytes)
                    prev_degree_array_shm = np.ndarray(prev_degree_data_local.shape, dtype=prev_degree_data_local.dtype, buffer=prev_degree_shm.buf)
                    np.copyto(prev_degree_array_shm, prev_degree_data_local)
                    prev_degree_shm_meta = {'name': prev_degree_shm_name, 'shape': prev_degree_data_local.shape, 'dtype': prev_degree_data_local.dtype}
                except Exception as shm_deg_err: logger.error(f"{log_prefix}Failed to create SHM for prev_degree_array in edge phase: {shm_deg_err}"); prev_degree_shm = None; prev_degree_shm_name = None; prev_degree_shm_meta = None
            if prev_active_count_data_local is not None:
                prev_active_shm_name = f"{self._unique_id}_prevactive_edge_phase_{temp_suffix}"
                try:
                    try: SharedMemory(name=prev_active_shm_name).unlink()
                    except FileNotFoundError: pass
                    prev_active_shm = SharedMemory(name=prev_active_shm_name, create=True, size=prev_active_count_data_local.nbytes)
                    prev_active_array_shm = np.ndarray(prev_active_count_data_local.shape, dtype=prev_active_count_data_local.dtype, buffer=prev_active_shm.buf)
                    np.copyto(prev_active_array_shm, prev_active_count_data_local)
                    prev_active_shm_meta = {'name': prev_active_shm_name, 'shape': prev_active_count_data_local.shape, 'dtype': prev_active_count_data_local.dtype}
                    logger.debug(f"{log_prefix}Created SHM for prev_active_count: {prev_active_shm_name}")
                except Exception as shm_pa_err: logger.error(f"{log_prefix}Failed to create SHM for prev_active_count in edge phase: {shm_pa_err}"); prev_active_shm = None; prev_active_shm_name = None; prev_active_shm_meta = None

            # --- Submit edge computation jobs ---
            futures_map = {}
            node_index_chunks = np.array_split(nodes_to_update, max(1, min(len(nodes_to_update) // chunk_size, num_processes))) if nodes_to_update else []
            for chunk_indices_arr in node_index_chunks:
                chunk_indices = chunk_indices_arr.tolist()
                if not chunk_indices: continue
                if self.rule is None: logger.error(f"{log_prefix}Rule is None, cannot submit task"); continue

                # --- CORRECTED: Removed edges_copy argument ---
                future = process_pool.submit(
                    Grid._process_edges_only,
                    # Args passed directly by update_grid_parallel (or None if not applicable)
                    chunk_indices,
                    original_states_shm_meta, # Pass meta dict or None
                    prev_degree_shm_meta,     # Pass meta dict or None
                    self._neighbor_indices_shm_meta, # Pass meta dict or None
                    self.grid_array.shape,
                    self.grid_array.dtype,
                    # Remaining arguments passed positionally
                    eligibility_proxy_shm_name, # Pass eligibility SHM name
                    # edges_copy, # REMOVED
                    edge_states_copy,
                    prev_active_shm_meta, # Pass meta dict or None
                    self.rule,
                    current_params_copy,
                    self.dimensions,
                    self.neighborhood_type,
                    grid_boundary_condition,
                    False, # No override for original states in parallel
                    None  # No degree override for parallel
                )
                # --- END CORRECTION ---
                futures_map[future] = chunk_indices

            # [ Process results as they complete - Unchanged ]
            temp_results = {}
            for future in as_completed(futures_map):
                chunk_indices = futures_map[future]
                start_index = nodes_to_update.index(chunk_indices[0])
                try:
                    chunk_edge_updates_list, duration = future.result(timeout=10.0)
                    if chunk_edge_updates_list is not None:
                        temp_results[start_index] = chunk_edge_updates_list
                    else:
                        logger.warning(f"{log_prefix}Received None for chunk_edge_updates from chunk {chunk_indices}")
                except Exception as e:
                    logger.error(f"{log_prefix}Error processing edges chunk {chunk_indices}: {e}")
                    continue

            # Assemble results in the correct order
            if len(temp_results) == len(node_index_chunks):
                 sorted_start_indices = sorted(temp_results.keys())
                 node_map = {node_idx: i for i, node_idx in enumerate(nodes_to_update)}
                 for start_idx in sorted_start_indices:
                     chunk_res_list = temp_results[start_idx]
                     chunk_node_indices = node_index_chunks[list(temp_results.keys()).index(start_idx)]
                     if chunk_res_list is not None and len(chunk_res_list) == len(chunk_node_indices):
                         for j, node_idx in enumerate(chunk_node_indices):
                             if 0 <= node_idx < len(proposed_edges):
                                 proposed_edges[node_idx].update(chunk_res_list[j])
                             else: logger.warning(f"{log_prefix}Parallel: Node index {node_idx} out of bounds for proposed_edges (Size: {len(proposed_edges)}).")
                     else: logger.error(f"{log_prefix}Result list invalid or size mismatch for chunk starting at {start_idx}.")
            else:
                 logger.error(f"{log_prefix}Did not receive results from all edge chunks ({len(temp_results)}/{len(node_index_chunks)}).")
                 return []

            return proposed_edges

        except Exception as e:
            logger.error(f"{log_prefix}Error submitting/processing edge computation jobs: {e}")
            return []
        finally:
            # --- Clean up ALL shared memory segments ---
            shm_list_to_clean = [
                (original_states_shm, original_states_shm_name, "Edge Phase (Orig)"),
                (eligibility_proxy_shm, eligibility_proxy_shm_name, "Edge Phase (Elig)"),
                (prev_degree_shm, prev_degree_shm_name, "Edge Phase (PrevDeg)"),
                (prev_active_shm, prev_active_shm_name, "Edge Phase (PrevActive)")
            ]
            for instance, name, desc in shm_list_to_clean:
                if instance:
                    try: instance.close(); instance.unlink(); logger.debug(f"{log_prefix}Cleaned up SHM for {desc}: {name}")
                    except Exception as e: logger.error(f"{log_prefix}Error cleaning up SHM ({desc}): {e}")
            # ---

    @timer_decorator
    def update_grid_parallel(self,
                             worker_func: Callable, # The static worker function
                             process_pool: Union[ProcessPoolExecutor, ThreadPoolExecutor],
                             nodes_to_update: List[int],
                             # REMOVED chunk_size parameter
                             pass_grid_directly: bool = False,
                             # Removed *worker_args, accept everything via kwargs
                             **worker_kwargs) -> Tuple[Optional[List[Any]], List[float]]:
        """
        Update grid state using parallel processing.
        Handles SHM setup for common arrays based on worker_kwargs.
        Explicitly builds positional arg list for submit based on worker type.
        Passes detailed logging flag to workers.
        Reads chunk size from GlobalSettings.
        Accepts SHM meta from controller instead of creating its own.
        (Round 13: Accept SHM meta from controller)
        (Round 11: Read chunk size from GlobalSettings)
        (Round 8: Pass final_degree_shm_meta to _process_final_state_chunk)
        (Round 25: Add logging flag to _process_chunk args)
        """
        profile_logger = logging.getLogger("deep_profile")
        logger = logging.getLogger(__name__)
        detailed_logging_enabled = LogSettings.Performance.ENABLE_DETAILED_LOGGING # Get flag value
        log_prefix = f"Grid.update_parallel(ID:{self._unique_id} R13 SHM Meta): " # Updated round
        if detailed_logging_enabled: logger.detail(f"{log_prefix}ENTRY (Detailed Logging Enabled: {detailed_logging_enabled})") # type: ignore [attr-defined]

        results: List[Any] = [None] * len(nodes_to_update) # Preallocate results list
        worker_durations: List[float] = []
        futures_map: Dict[Any, List[int]] = {} # Map future to chunk indices

        # --- Get SHM Meta from kwargs (passed from Controller) ---
        original_states_shm_meta = worker_kwargs.get('original_states_shm_meta')
        prev_degree_shm_meta = worker_kwargs.get('prev_degree_shm_meta')
        prev_active_shm_meta = worker_kwargs.get('prev_active_shm_meta')
        neighbor_indices_shm_meta = self._neighbor_indices_shm_meta # Use grid's persistent neighbor SHM meta
        # ---

        try:
            # --- Chunking and Job Submission ---
            num_workers = getattr(process_pool, '_max_workers', GlobalSettings.Simulation.NUM_PROCESSES)
            chunk_size_setting = GlobalSettings.Simulation.CHUNK_SIZE
            if chunk_size_setting <= 0: # If Auto or invalid, calculate default
                chunk_size_to_use = self._calculate_dynamic_chunk_size()
                logger.debug(f"{log_prefix}Using calculated 'Auto' chunk size: {chunk_size_to_use}")
            else:
                chunk_size_to_use = max(1, chunk_size_setting) # Ensure at least 1
                logger.debug(f"{log_prefix}Using chunk size from GlobalSettings: {chunk_size_to_use}")

            node_index_chunks = []
            if nodes_to_update:
                 num_chunks_initial = max(1, int(np.ceil(len(nodes_to_update) / chunk_size_to_use)))
                 num_chunks_final = max(1, min(num_chunks_initial, len(nodes_to_update), num_workers))
                 node_index_chunks = np.array_split(nodes_to_update, num_chunks_final)
                 node_index_chunks = [chunk.tolist() for chunk in node_index_chunks if chunk.size > 0]
            logger.debug(f"{log_prefix}Submitting {len(node_index_chunks)} chunks (Size={chunk_size_to_use}) to pool {type(process_pool).__name__} (MaxWorkers: {num_workers}).")

            for chunk_indices in node_index_chunks:
                if not chunk_indices: continue

                # --- Prepare EXACT positional arguments list for the specific worker ---
                submit_args = []
                worker_name = worker_func.__name__

                # --- Pass the SHM meta received from controller ---
                if worker_name == '_process_states_only':
                    submit_args = [
                        chunk_indices, original_states_shm_meta, prev_degree_shm_meta,
                        neighbor_indices_shm_meta, self.grid_array.shape, self.grid_array.dtype,
                        worker_kwargs.get('edge_states_copy'),
                        prev_active_shm_meta, # Pass meta received from controller
                        worker_kwargs.get('rule'), worker_kwargs.get('params_copy'), worker_kwargs.get('grid_dimensions'),
                        worker_kwargs.get('grid_neighborhood_type'), worker_kwargs.get('grid_boundary_condition'),
                        detailed_logging_enabled, # Pass flag
                        worker_kwargs.get('_original_states_override'), worker_kwargs.get('_previous_degree_override'),
                        worker_kwargs.get('_previous_active_override')
                    ]
                elif worker_name == '_process_edges_only':
                     submit_args = [
                        chunk_indices, original_states_shm_meta, prev_degree_shm_meta,
                        neighbor_indices_shm_meta, self.grid_array.shape, self.grid_array.dtype,
                        worker_kwargs.get('eligibility_proxy_shm_name'), # Name is still needed here
                        worker_kwargs.get('edge_states_copy'),
                        prev_active_shm_meta, # Pass meta received from controller
                        worker_kwargs.get('rule'), worker_kwargs.get('params_copy'), worker_kwargs.get('grid_dimensions'),
                        worker_kwargs.get('grid_neighborhood_type'), worker_kwargs.get('grid_boundary_condition'),
                        detailed_logging_enabled, # Pass flag
                        worker_kwargs.get('_original_states_override'),
                        worker_kwargs.get('_previous_degree_override'),
                        worker_kwargs.get('_previous_active_override')
                    ]
                elif worker_name == '_process_standard_chunk':
                     submit_args = [
                        chunk_indices, original_states_shm_meta, prev_degree_shm_meta,
                        neighbor_indices_shm_meta, self.grid_array.shape, self.grid_array.dtype,
                        worker_kwargs.get('edge_states_copy'),
                        prev_active_shm_meta, # Pass meta received from controller
                        worker_kwargs.get('rule'), worker_kwargs.get('params_copy'), worker_kwargs.get('grid_dimensions'),
                        worker_kwargs.get('grid_neighborhood_type'), worker_kwargs.get('grid_boundary_condition'),
                        detailed_logging_enabled, # Pass flag
                        worker_kwargs.get('_original_states_override'), worker_kwargs.get('_previous_degree_override'),
                        worker_kwargs.get('_previous_active_override')
                    ]
                elif worker_name == '_process_final_state_chunk':
                     submit_args = [
                        chunk_indices, worker_kwargs.get('eligibility_proxy_shm_meta'), # Pass meta
                        worker_kwargs.get('prev_state_shm_meta'), # Pass meta
                        prev_degree_shm_meta, # Pass meta received from controller
                        neighbor_indices_shm_meta, # Pass meta
                        self.grid_array.shape, self.grid_array.dtype,
                        worker_kwargs.get('final_edges_this_step'), worker_kwargs.get('previous_edges'),
                        worker_kwargs.get('previous_edge_states'),
                        prev_active_shm_meta, # Pass meta received from controller
                        worker_kwargs.get('rule'), worker_kwargs.get('params_copy'), worker_kwargs.get('grid_dimensions'),
                        detailed_logging_enabled, # Pass flag
                        worker_kwargs.get('final_degree_shm_meta') # Pass final degree meta
                     ]
                elif worker_name == '_process_chunk':
                    # This worker doesn't use the standard SHM meta pattern
                    submit_args = [
                        worker_kwargs.get('neighborhoods'),
                        worker_kwargs.get('rule'),
                        worker_kwargs.get('shared_mem_name'), # Specific name needed by this worker
                        detailed_logging_enabled # Pass flag
                    ]
                else:
                    logger.error(f"{log_prefix}Unknown worker function type: {worker_name}. Cannot determine arguments.")
                    continue
                # --- END MODIFIED ---

                # --- Submit the job with only positional arguments ---
                future = process_pool.submit(
                    worker_func,
                    *submit_args # Unpack all arguments positionally
                )
                # --- END Submit ---
                futures_map[future] = chunk_indices
            # --- End Chunking and Job Submission ---

            # --- Collect Results ---
            # [ Result collection logic remains the same ]
            logger.debug(f"{log_prefix}Waiting for {len(futures_map)} futures...")
            results_list = [] # Store results in order corresponding to nodes_to_update
            temp_results = {} # Store results temporarily keyed by start index

            for future in as_completed(futures_map):
                chunk_indices = futures_map[future]
                start_index = nodes_to_update.index(chunk_indices[0]) # Find original start index
                try:
                    chunk_result_data, duration = future.result(timeout=20.0)
                    worker_durations.append(duration)
                    temp_results[start_index] = chunk_result_data
                except TimeoutError: logger.error(f"{log_prefix}Timeout processing chunk starting at index {start_index}")
                except Exception as e: logger.error(f"{log_prefix}Error processing chunk starting at index {start_index}: {e}")

            # Assemble results in the correct order
            if len(temp_results) == len(node_index_chunks):
                 sorted_start_indices = sorted(temp_results.keys())
                 all_results_valid = True
                 for start_idx in sorted_start_indices:
                     chunk_res = temp_results[start_idx]
                     if chunk_res is None: all_results_valid = False; logger.error(f"{log_prefix}Received None result from chunk starting at index {start_idx}."); break
                     if isinstance(chunk_res, (list, np.ndarray)): results_list.extend(chunk_res)
                     else: logger.error(f"{log_prefix}Received non-iterable chunk result: {type(chunk_res)}"); all_results_valid = False; break
                 if not all_results_valid: results_list = None
                 elif len(results_list) != len(nodes_to_update): logger.error(f"{log_prefix}Result length mismatch! Expected {len(nodes_to_update)}, got {len(results_list)}. Returning None."); results_list = None
            else: logger.error(f"{log_prefix}Did not receive results from all chunks ({len(temp_results)}/{len(node_index_chunks)}). Returning None."); results_list = None

            logger.debug(f"{log_prefix}Finished collecting results.")
            return results_list, worker_durations
            # --- End Collect Results ---

        except Exception as e:
            logger.error(f"{log_prefix}Error during parallel update: {e}")
            logger.error(traceback.format_exc())
            return None, []
        finally:
            # --- REMOVED SHM Cleanup - Controller handles temp SHM ---
            logger.debug(f"{log_prefix}Skipping SHM cleanup (handled by Controller).")
            # ---
            if detailed_logging_enabled: logger.detail(f"{log_prefix}EXIT") # type: ignore [attr-defined]   

    @timer_decorator  
    def _update_grid_sequential(self):
        """
        Update grid state sequentially (single-threaded).
        Correctly calls worker functions with all arguments.
        (Round 21: Added missing args to sequential worker calls)
        """
        logger = logging.getLogger(__name__)
        detailed_logging_enabled = LogSettings.Performance.ENABLE_DETAILED_LOGGING # Get flag
        log_prefix = f"Grid._update_grid_sequential(ID:{self._unique_id} R21 Fix): " # Updated round
        if detailed_logging_enabled: logger.detail(f"{log_prefix}ENTRY") # type: ignore [attr-defined]

        if self.rule is None: raise ValueError("Rule is not set.")

        # --- Store state BEFORE update ---
        original_states_local = self.grid_array.ravel().copy()
        original_edge_states = self.edge_states.copy()
        active_nodes_previous_step = self.previous_active_nodes_set.copy()
        prev_degree_data_local = self.previous_degree_array.copy() if self.rule.needs_neighbor_degrees and self.previous_degree_array is not None else None
        prev_active_count_data_local = self.previous_active_neighbor_array.copy() if self.rule.needs_neighbor_active_counts and self.previous_active_neighbor_array is not None else None
        # ---

        # --- Determine nodes to update ---
        if self.rule.requires_post_edge_state_update or self.rule.needs_neighbor_degrees or self.rule.needs_neighbor_active_counts:
            nodes_to_update_list = list(range(self.total_nodes))
        else:
            nodes_to_update = set(active_nodes_previous_step)
            for node_idx in active_nodes_previous_step:
                if self.spatial_hash is None: logger.error(f"{log_prefix}Spatial hash is None! Aborting."); return False
                neighbors = self.get_neighbors(node_idx, self.coord_system)
                nodes_to_update.update(n for n in neighbors if n != -1)
            nodes_to_update_list = sorted(list(nodes_to_update))
        # ---

        # ==============================================================
        # --- Execution Logic (Standard vs Post-Update) ---
        # ==============================================================
        computed_primary_result: Optional[np.ndarray] = None
        computed_all_proposed_edges: Optional[Dict[Tuple[Tuple[int,...], Tuple[int,...]], float]] = None
        current_params_copy = copy.deepcopy(self.rule.params)
        grid_boundary_condition = self.rule.params.get('grid_boundary', 'bounded')

        if not self.rule.requires_post_edge_state_update:
            # --- Standard Rule Logic ---
            logger.debug(f"{log_prefix}Executing Standard Rule Path sequentially.")
            # --- CORRECTED: Added detailed_logging_enabled and _previous_active_override ---
            standard_results_list, seq_duration = Grid._process_standard_chunk(
                chunk_indices=nodes_to_update_list,
                original_states_shm_meta=None,
                prev_degree_shm_meta=None,
                neighbor_indices_shm_meta=None,
                grid_shape=self.grid_array.shape,
                grid_dtype=self.grid_array.dtype,
                edge_states_copy=original_edge_states,
                prev_active_shm_meta=None,
                rule=self.rule,
                params_copy=current_params_copy,
                grid_dimensions=self.dimensions,
                grid_neighborhood_type=self.neighborhood_type,
                grid_boundary_condition=grid_boundary_condition,
                detailed_logging_enabled=detailed_logging_enabled, # Pass flag
                _original_states_override=original_states_local,
                _previous_degree_override=prev_degree_data_local,
                _previous_active_override=prev_active_count_data_local # Pass active override
            )
            # --- END CORRECTION ---

            # [ Result processing remains the same ]
            if standard_results_list is None: logger.error(f"{log_prefix}Sequential standard chunk processing failed."); return False
            new_states = original_states_local.copy()
            all_proposed_edges = {}
            for i, result_item in enumerate(standard_results_list):
                if isinstance(result_item, tuple) and len(result_item) == 2:
                    state, edges_dict = result_item
                    if i < len(nodes_to_update_list):
                        node_idx = nodes_to_update_list[i]
                        if 0 <= node_idx < self.total_nodes:
                            new_states[node_idx] = state
                            if isinstance(edges_dict, dict): all_proposed_edges.update(edges_dict)
                            else: logger.warning(f"{log_prefix}Invalid edges_dict type ({type(edges_dict)}) for node {node_idx}, skipping update.")
                        else: logger.warning(f"{log_prefix}Node index {node_idx} out of bounds for new_states.")
                    else: logger.error(f"{log_prefix}Result index {i} out of bounds for nodes_to_update_list.")
                else: logger.error(f"{log_prefix}Invalid result item format at index {i}: {result_item}")
            computed_primary_result = new_states
            computed_all_proposed_edges = all_proposed_edges
            if LogSettings.Performance.ENABLE_DEEP_PROFILING: perf_logger.log_metric('sequential_step_duration', seq_duration); logger.info(f"{log_prefix}Sequential execution took {seq_duration:.4f}s")

        else: # --- Post-Update Rule Logic ---
            logger.debug(f"{log_prefix}Executing Post-Update Rule Path sequentially.")
            # Phase 1: Compute Proxy States
            # --- CORRECTED: Added detailed_logging_enabled and _previous_active_override ---
            eligibility_proxies_array, phase1_duration = Grid._process_states_only(
                chunk_indices=nodes_to_update_list,
                original_states_shm_meta=None, grid_shape=self.grid_array.shape, grid_dtype=self.grid_array.dtype,
                prev_degree_shm_meta=None, neighbor_indices_shm_meta=None,
                edge_states_copy=original_edge_states,
                prev_active_shm_meta=None,
                rule=self.rule, params_copy=current_params_copy, grid_dimensions=self.dimensions,
                grid_neighborhood_type=self.neighborhood_type, grid_boundary_condition=grid_boundary_condition,
                detailed_logging_enabled=detailed_logging_enabled, # Pass flag
                _original_states_override=original_states_local,
                _previous_degree_override=prev_degree_data_local,
                _previous_active_override=prev_active_count_data_local # Pass active override
            )
            # --- END CORRECTION ---
            if eligibility_proxies_array is None: logger.error(f"{log_prefix}Sequential state computation failed."); return False
            num_eligible = np.sum(eligibility_proxies_array > 0.5); logger.info(f"{log_prefix}Phase 1 Computed Eligibility Proxies: {num_eligible}/{eligibility_proxies_array.size} eligible.")

            # Phase 2: Compute Edges
            # --- CORRECTED: Added detailed_logging_enabled and _previous_active_override ---
            proposed_edges_list, phase2_duration = Grid._process_edges_only(
                chunk_indices=nodes_to_update_list,
                original_states_shm_meta=None, prev_degree_shm_meta=None, neighbor_indices_shm_meta=None,
                grid_shape=self.grid_array.shape, grid_dtype=self.grid_array.dtype,
                eligibility_proxy_shm_name=None, # No SHM name needed
                edge_states_copy=original_edge_states,
                prev_active_shm_meta=None,
                rule=self.rule, params_copy=current_params_copy, grid_dimensions=self.dimensions,
                grid_neighborhood_type=self.neighborhood_type, grid_boundary_condition=grid_boundary_condition,
                detailed_logging_enabled=detailed_logging_enabled, # Pass flag
                _original_states_override=original_states_local,
                _previous_degree_override=prev_degree_data_local,
                _previous_active_override=prev_active_count_data_local # Pass active override
            )
            # --- END CORRECTION ---
            if proposed_edges_list is None: logger.error(f"{log_prefix}Sequential edge computation failed."); return False
            all_proposed_edges_coords: Dict[Tuple[Tuple[int,...], Tuple[int,...]], float] = {};
            for node_proposals in proposed_edges_list:
                if node_proposals: all_proposed_edges_coords.update(node_proposals)
            logger.info(f"{log_prefix}Phase 2 Computed proposed edges ({len(all_proposed_edges_coords)}).")

            computed_primary_result = eligibility_proxies_array
            computed_all_proposed_edges = all_proposed_edges_coords

            seq_duration = phase1_duration + phase2_duration
            if LogSettings.Performance.ENABLE_DEEP_PROFILING: perf_logger.log_metric('sequential_step_duration', seq_duration); logger.info(f"{log_prefix}Sequential two-phase execution took {seq_duration:.4f}s")

        # ==============================================================
        # --- Apply Results ---
        # ==============================================================
        with self._update_lock:
            if computed_primary_result is None or computed_all_proposed_edges is None:
                logger.error(f"{log_prefix}Computation results are None, cannot apply.")
                return False

            # Apply Edges
            self.edges.clear(); self.edge_states.clear()
            applied_edge_count = 0
            for edge_coords, edge_state in computed_all_proposed_edges.items():
                if isinstance(edge_coords, tuple) and len(edge_coords) == 2 and isinstance(edge_coords[0], tuple) and isinstance(edge_coords[1], tuple):
                    self.edges.add(edge_coords); self.edge_states[edge_coords] = edge_state; applied_edge_count += 1
                else: logger.warning(f"{log_prefix}Skipping invalid edge key format during application: {edge_coords}")
            if detailed_logging_enabled: logger.detail(f"{log_prefix}Applied {applied_edge_count} proposed edges.") # type: ignore [attr-defined]
            final_edges_this_step = self.edges.copy()

            # Apply States (Standard or Final)
            final_states_to_apply: Optional[np.ndarray] = None
            if not self.rule.requires_post_edge_state_update:
                final_states_to_apply = computed_primary_result
                if not self.rule.skip_standard_tiebreakers:
                    tiebreaker_type_str = self.rule.get_param('tiebreaker_type', 'RANDOM')
                    enable_tiebreakers = GlobalSettings.ENABLE_TIEBREAKERS
                    if enable_tiebreakers:
                        self._apply_edge_tiebreakers(final_states_to_apply, TieBreaker[tiebreaker_type_str].value, enable_tiebreakers)
                        final_edges_this_step = self.edges.copy() # Update final edges if tiebreakers ran
            else:
                eligibility_proxies = computed_primary_result
                final_states_calculated = np.zeros_like(eligibility_proxies)
                # --- Need original edges/states for _compute_final_state ---
                # Note: original_edges was removed earlier, use original_edge_states keys
                original_edges_for_final = set(original_edge_states.keys())
                # ---
                for i, node_idx in enumerate(nodes_to_update_list): # Iterate over nodes that were processed
                    proxy_state = eligibility_proxies[i] # Use index i corresponding to nodes_to_update_list
                    # --- Pass eligibility_proxies array to final state calc ---
                    final_states_calculated[i] = self.rule._compute_final_state(
                        node_idx, proxy_state, final_edges_this_step, self.dimensions,
                        original_states_local, original_edges_for_final, original_edge_states,
                        prev_degree_data_local, prev_active_count_data_local,
                        eligibility_proxies=eligibility_proxies # Pass the full array
                    )
                    # ---
                # Map results back to the full grid array
                final_states_full = self.grid_array.ravel().copy() # Start with current state
                for i, node_idx in enumerate(nodes_to_update_list):
                    if 0 <= node_idx < final_states_full.size:
                        final_states_full[node_idx] = final_states_calculated[i]
                final_states_to_apply = final_states_full

            if final_states_to_apply is None: logger.error(f"{log_prefix}final_states_to_apply is None!"); return False

            np.copyto(self.grid_array.ravel(), final_states_to_apply)
            if detailed_logging_enabled: logger.detail(f"{log_prefix}Applied final states to grid_array.") # type: ignore [attr-defined]

            # Update Shared Memory and Active Nodes Set
            if self.shared_array is not None: np.copyto(self.shared_array, self.grid_array)
            self.active_nodes.clear(); final_active_indices = np.where(self.grid_array.ravel() > 1e-6)[0]; self.active_nodes.update(final_active_indices)
        # --- End Apply Results (Lock Released) ---

        # [ Final Logging and Cleanup - Unchanged ]
        self.apply_tiebreakers = GlobalSettings.ENABLE_TIEBREAKERS
        if self.rule.needs_neighbor_degrees or self.rule.needs_neighbor_active_counts:
            final_grid_array_flat = self.grid_array.ravel()
            new_degree_array = np.zeros(self.total_nodes, dtype=np.int32)
            new_active_neighbor_array = np.zeros(self.total_nodes, dtype=np.int32)
            activity_threshold = 1e-6
            if self.rule.needs_neighbor_degrees:
                for edge_coords in final_edges_this_step:
                    try:
                        node1_coords, node2_coords = edge_coords
                        idx1 = _ravel_multi_index(np.array(node1_coords), self.dimensions)
                        idx2 = _ravel_multi_index(np.array(node2_coords), self.dimensions)
                        if 0 <= idx1 < self.total_nodes: new_degree_array[idx1] += 1
                        if 0 <= idx2 < self.total_nodes: new_degree_array[idx2] += 1
                    except Exception as degree_calc_err: logger.error(f"{log_prefix}Error processing edge {edge_coords} for degree calculation: {degree_calc_err}")
                self.previous_degree_array = new_degree_array
            if self.rule.needs_neighbor_active_counts:
                for node_idx in range(self.total_nodes):
                    count = 0
                    neighbors_indices = self.get_neighbors(node_idx, self.coord_system)
                    for neighbor_idx in neighbors_indices:
                        if neighbor_idx != -1 and 0 <= neighbor_idx < final_grid_array_flat.size and final_grid_array_flat[neighbor_idx] > activity_threshold: count += 1
                    new_active_neighbor_array[node_idx] = count
                self.previous_active_neighbor_array = new_active_neighbor_array
        self.previous_active_nodes_set = self.active_nodes.copy()

        # [ Create and Queue Snapshot - Unchanged ]
        grid_snapshot = { 'grid_array': self.grid_array.copy(), 'edges': self.edges.copy(), 'edge_states': self.edge_states.copy(), 'active_nodes': self.active_nodes.copy(), 'generation': self.gui.generation if self.gui else -1, 'boundary_condition': grid_boundary_condition, 'num_chunks': 1 }
        if self.gui is not None and hasattr(self.gui, 'communication_queue'):
            try: self.gui.communication_queue.put(grid_snapshot, block=False)
            except Full: logger.warning(f"{log_prefix}Communication queue full, skipping plot update signal.")
            except AttributeError: logger.error(f"{log_prefix}GUI or communication_queue not found.")
        else: logger.warning(f"{log_prefix}GUI or communication_queue not found, skipping plot update signal.")

        if detailed_logging_enabled: logger.detail(f"{log_prefix}EXIT - Returning True") # type: ignore [attr-defined]
        return True
                   
    @timer_decorator
    def _apply_edge_tiebreakers(self, grid_array: npt.NDArray[np.float64],
                                    tiebreaker_type: int,
                                    enable_tiebreakers: bool) -> None:
        """Apply tie-breaker logic to resolve edge conflicts directly on the edges array."""

        # Get parameters once
        node_visibility_threshold = GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD

        # First, filter out inactive nodes - they should have no edges
        active_mask = grid_array > node_visibility_threshold

        # Remove all edges involving inactive nodes *in place*
        edges_to_remove = set()
        for (node1_coords, node2_coords) in self.edges:  # Iterate over coordinate tuples
            node1_idx = _ravel_multi_index(np.array(node1_coords), self.dimensions)
            node2_idx = _ravel_multi_index(np.array(node2_coords), self.dimensions)
            if not active_mask.ravel()[node1_idx] or not active_mask.ravel()[node2_idx]:
                edges_to_remove.add((node1_coords, node2_coords))  # Store as coordinate tuples
        for edge in edges_to_remove:
            self.edges.discard(edge)

        # If tiebreakers are disabled, just return
        if not enable_tiebreakers:
            return  # No changes needed if tiebreakers are disabled

        # Apply tiebreaker logic based on the type
        if tiebreaker_type == TieBreaker.RANDOM.value:
            # Random tiebreaker - randomly select edges to keep
            for i in range(self.grid_array.size): # Iterate over flattened indices
                if active_mask.ravel()[i]: # Use flattened index and ravel()
                    try:
                        # Safely get neighbors
                        neighbors = self.get_neighbors(i, self.coord_system) # Use get_neighbors
                        if len(neighbors) > 0:
                            # Calculate state values of all neighbors
                            neighbor_states = [grid_array.ravel()[n] for n in neighbors]
                            
                            # Sort neighbors by state (descending)
                            sorted_neighbors = [x for _, x in sorted(zip(neighbor_states, neighbors), key=lambda pair: float(pair[0]), reverse=True)]
                            
                            # Keep only the highest state max_neighbors
                            max_neighbors = len(neighbors)
                            keep_neighbors = set(sorted_neighbors[:max_neighbors])
                            
                            # Remove edges to neighbors not in keep_neighbors
                            edges_to_remove = set()
                            node_coords = tuple(_unravel_index(i, self.dimensions)) # Get grid coords for current node
                            for (node1_coords, node2_coords) in self.edges: # Iterate over coordinate tuples
                                if node1_coords == node_coords:
                                    neighbor_idx = _ravel_multi_index(np.array(node2_coords), self.dimensions)
                                    if neighbor_idx not in keep_neighbors:
                                        edges_to_remove.add((node1_coords, node2_coords))
                                elif node2_coords == node_coords:
                                    neighbor_idx = _ravel_multi_index(np.array(node1_coords), self.dimensions)
                                    if neighbor_idx not in keep_neighbors:
                                        edges_to_remove.add((node1_coords, node2_coords))
                            for edge in edges_to_remove:
                                self.edges.discard(edge)
                    except Exception as e:
                        logger.error(f"Error in random tiebreaker for node {i}: {e}")
                        continue

        elif tiebreaker_type == TieBreaker.AGREEMENT.value:
            # Agreement tiebreaker - keep edges where both nodes agree
            edges_to_remove = set()
            for node1_coords, node2_coords in self.edges: # Iterate over coordinate tuples
                node1_idx = _ravel_multi_index(np.array(node1_coords), self.dimensions)
                node2_idx = _ravel_multi_index(np.array(node2_coords), self.dimensions)
                if not (self.has_edge(node1_idx, node2_idx) and self.has_edge(node2_idx, node1_idx)):
                    edges_to_remove.add((node1_coords, node2_coords))
            for edge in edges_to_remove:
                self.edges.discard(edge)

        elif tiebreaker_type == TieBreaker.HIGHER_STATE.value:
            # Higher state tiebreaker - keep edges to nodes with higher state values
            for i in range(len(grid_array)):
                if active_mask.ravel()[i]: # Use flattened index and ravel()
                    try:
                        # Safely get neighbors
                        neighbors = self.get_neighbors(i, self.coord_system) # Use get_neighbors
                        if len(neighbors) > 0:
                            # Calculate state values of all neighbors
                            neighbor_states = [grid_array.ravel()[n] for n in neighbors]
                            
                            # Sort neighbors by state (descending)
                            sorted_neighbors = [x for _, x in sorted(zip(neighbor_states, neighbors), key=lambda pair: float(pair[0]), reverse=True)]
                            
                            # Keep only the highest state max_neighbors
                            max_neighbors = len(neighbors)
                            keep_neighbors = set([n for n, _ in sorted(zip(neighbor_states, neighbors), reverse=True)[:max_neighbors]])
                            
                            # Remove edges to neighbors not in keep_neighbors
                            edges_to_remove = set()
                            node_coords = tuple(_unravel_index(i, self.dimensions)) # Get grid coords for current node
                            for (node1_coords, node2_coords) in self.edges: # Iterate over coordinate tuples
                                if node1_coords == node_coords:
                                    neighbor_idx = _ravel_multi_index(np.array(node2_coords), self.dimensions)
                                    if neighbor_idx not in keep_neighbors:
                                        edges_to_remove.add((node1_coords, node2_coords))
                                elif node2_coords == node_coords:
                                    neighbor_idx = _ravel_multi_index(np.array(node1_coords), self.dimensions)
                                    if neighbor_idx not in keep_neighbors:
                                        edges_to_remove.add((node1_coords, node2_coords))
                            for edge in edges_to_remove:
                                self.edges.discard(edge)
                    except Exception as e:
                        logger.error(f"Error in higher state tiebreaker for node {i}: {e}")
                        continue

        elif tiebreaker_type == TieBreaker.LOWER_STATE.value:
            # Lower state tiebreaker - keep edges to nodes with lower state values
            for i in range(len(grid_array)):
                if active_mask.ravel()[i]: # Use flattened index and ravel()
                    try:
                        # Safely get neighbors
                        neighbors = self.get_neighbors(i, self.coord_system) # Use get_neighbors
                        if len(neighbors) > 0:
                            # Calculate state values of all neighbors
                            neighbor_states = [grid_array.ravel()[n] for n in neighbors]
                            
                            # Sort neighbors by state (ascending)
                            sorted_neighbors = [x for _, x in sorted(zip(neighbor_states, neighbors))]
                            
                            # Keep only the lowest state max_neighbors
                            max_neighbors = len(neighbors)
                            keep_neighbors = set([n for n, _ in sorted(zip(neighbor_states, neighbors))[:max_neighbors]])
                            
                            # Remove edges to neighbors not in keep_neighbors
                            edges_to_remove = set()
                            node_coords = tuple(_unravel_index(i, self.dimensions)) # Get grid coords for current node
                            for (node1_coords, node2_coords) in self.edges: # Iterate over coordinate tuples
                                if node1_coords == node_coords:
                                    neighbor_idx = _ravel_multi_index(np.array(node2_coords), self.dimensions)
                                    if neighbor_idx not in keep_neighbors:
                                        edges_to_remove.add((node1_coords, node2_coords))
                                elif node2_coords == node_coords:
                                    neighbor_idx = _ravel_multi_index(np.array(node1_coords), self.dimensions)
                                    if neighbor_idx not in keep_neighbors:
                                        edges_to_remove.add((node1_coords, node2_coords))
                            for edge in edges_to_remove:
                                self.edges.discard(edge)
                    except Exception as e:
                        logger.error(f"Error in lower state tiebreaker for node {i}: {e}")
                        continue

        elif tiebreaker_type == TieBreaker.MORE_CONNECTIONS.value:
            # More connections tiebreaker - keep edges to nodes with more connections
            for i in range(len(grid_array)):
                if active_mask.ravel()[i]: # Use flattened index and ravel()
                    try:
                        # Safely get neighbors
                        neighbors = self.get_neighbors(i, self.coord_system) # Use get_neighbors
                        if len(neighbors) > 0:
                            # Calculate connection counts of all neighbors
                            connections = []
                            for n in neighbors:
                                # Count the number of connections using edges array
                                connection_count = 0
                                for node1_coords, node2_coords in self.edges: # Iterate over coordinate tuples
                                    node1_idx = _ravel_multi_index(np.array(node1_coords), self.dimensions)
                                    node2_idx = _ravel_multi_index(np.array(node2_coords), self.dimensions)
                                    if node1_idx != -1 and node2_idx != -1 and (node1_idx == n or node2_idx == n):
                                        connection_count += 1
                                connections.append((n, connection_count))
                            
                            # Sort by connection count (descending)
                            connections.sort(key=lambda x: x[1], reverse=True)
                            
                            # Keep only the most connected max_neighbors
                            max_neighbors = len(neighbors)
                            keep_neighbors = set([n for n, _ in connections[:max_neighbors]])
                            
                            # Remove edges to neighbors not in keep_neighbors
                            edges_to_remove = set()
                            node_coords = tuple(_unravel_index(i, self.dimensions)) # Get grid coords for current node
                            for (node1_coords, node2_coords) in self.edges: # Iterate over coordinate tuples
                                if node1_coords == node_coords:
                                    neighbor_idx = _ravel_multi_index(np.array(node2_coords), self.dimensions)
                                    if neighbor_idx not in keep_neighbors:
                                        edges_to_remove.add((node1_coords, node2_coords))
                                elif node2_coords == node_coords:
                                    neighbor_idx = _ravel_multi_index(np.array(node1_coords), self.dimensions)
                                    if neighbor_idx not in keep_neighbors:
                                        edges_to_remove.add((node1_coords, node2_coords))
                            for edge in edges_to_remove:
                                self.edges.discard(edge)
                    except Exception as e:
                        logger.error(f"Error in more connections tiebreaker for node {i}: {e}")
                        continue

        elif tiebreaker_type == TieBreaker.FEWER_CONNECTIONS.value:
            # Fewer connections tiebreaker - keep edges to nodes with fewer connections
            for i in range(len(grid_array)):
                if active_mask.ravel()[i]: # Use flattened index and ravel()
                    try:
                        # Safely get neighbors
                        neighbors = self.get_neighbors(i, self.coord_system) # Use get_neighbors
                        if len(neighbors) > 0:
                            # Calculate connection counts of all neighbors
                            connections = []
                            for n in neighbors:
                                # Count the number of connections using edges array
                                connection_count = 0
                                for node1_coords, node2_coords in self.edges: # Iterate over coordinate tuples
                                    node1_idx = _ravel_multi_index(np.array(node1_coords), self.dimensions)
                                    node2_idx = _ravel_multi_index(np.array(node2_coords), self.dimensions)
                                    if node1_idx != -1 and node2_idx != -1 and (node1_idx == n or node2_idx == n):
                                        connection_count += 1
                                connections.append((n, connection_count))
                            
                            # Sort by connection count (ascending)
                            connections.sort(key=lambda x: x[1])
                            
                            # Keep only the least connected max_neighbors
                            max_neighbors = len(neighbors)
                            keep_neighbors = set([n for n, _ in connections[:max_neighbors]])
                            
                            # Remove edges to neighbors not in keep_neighbors
                            edges_to_remove = set()
                            node_coords = tuple(_unravel_index(i, self.dimensions)) # Get grid coords for current node
                            for (node1_coords, node2_coords) in self.edges: # Iterate over coordinate tuples
                                if node1_coords == node_coords:
                                    neighbor_idx = _ravel_multi_index(np.array(node2_coords), self.dimensions)
                                    if neighbor_idx not in keep_neighbors:
                                        edges_to_remove.add((node1_coords, node2_coords))
                                elif node2_coords == node_coords:
                                    neighbor_idx = _ravel_multi_index(np.array(node1_coords), self.dimensions)
                                    if neighbor_idx not in keep_neighbors:
                                        edges_to_remove.add((node1_coords, node2_coords))
                            for edge in edges_to_remove:
                                self.edges.discard(edge)
                    except Exception as e:
                        logger.error(f"Error in fewer connections tiebreaker for node {i}: {e}")
                        continue

        elif tiebreaker_type == TieBreaker.HIGHER_STATE_MORE_NEIGHBORS.value:
            # Higher state and more neighbors tiebreaker
            for i in range(len(grid_array)):
                if active_mask.ravel()[i]: # Use flattened index and ravel()
                    try:
                        # Safely get neighbors
                        neighbors = self.get_neighbors(i, self.coord_system) # Use get_neighbors
                        if len(neighbors) > 0:
                            # Calculate combined score (state + connection count)
                            scores = []
                            for n in neighbors:
                                state = grid_array.ravel()[n]
                                # Count connections using edges array
                                connection_count = 0
                                for node1_coords, node2_coords in self.edges: # Iterate over coordinate tuples
                                    node1_idx = _ravel_multi_index(np.array(node1_coords), self.dimensions)
                                    node2_idx = _ravel_multi_index(np.array(node2_coords), self.dimensions)
                                    if node1_idx != -1 and node2_idx != -1 and (node1_idx == n or node2_idx == n):
                                        connection_count += 1
                                # Normalize both values to 0-1 range and combine
                                normalized_state = state  # Assuming state is already 0-1
                                normalized_connections = min(1.0, connection_count / max(1, len(neighbors)))
                                combined_score = float(normalized_state) * 0.7 + float(normalized_connections) * 0.3  # Weight state higher
                                scores.append((n, combined_score))
                            
                            # Sort by combined score (descending)
                            scores.sort(key=lambda x: x[1], reverse=True)
                            
                            # Keep only the highest scoring max_neighbors
                            max_neighbors = len(neighbors)
                            keep_neighbors = set([n for n, _ in scores[:max_neighbors]])
                            
                            # Remove edges to neighbors not in keep_neighbors
                            edges_to_remove = set()
                            node_coords = tuple(_unravel_index(i, self.dimensions)) # Get grid coords for current node
                            for (node1_coords, node2_coords) in self.edges: # Iterate over coordinate tuples
                                if node1_coords == node_coords:
                                    neighbor_idx = _ravel_multi_index(np.array(node2_coords), self.dimensions)
                                    if neighbor_idx not in keep_neighbors:
                                        edges_to_remove.add((node1_coords, node2_coords))
                                elif node2_coords == node_coords:
                                    neighbor_idx = _ravel_multi_index(np.array(node1_coords), self.dimensions)
                                    if neighbor_idx not in keep_neighbors:
                                        edges_to_remove.add((node1_coords, node2_coords))
                            for edge in edges_to_remove:
                                self.edges.discard(edge)
                    except Exception as e:
                        logger.error(f"Error in higher state more neighbors tiebreaker for node {i}: {e}")
                        continue

        elif tiebreaker_type == TieBreaker.LOWER_STATE_FEWER_NEIGHBORS.value:
            # Lower state and fewer neighbors tiebreaker
            for i in range(len(grid_array)):
                if active_mask.ravel()[i]: # Use flattened index and ravel()
                    neighbors = self.get_neighbors(i, self.coord_system) # Use get_neighbors
                    if len(neighbors) > 0:
                        # Calculate combined score (inverse state + inverse connection count)
                        scores = []
                        for n in neighbors:
                            state = grid_array.ravel()[n]
                            # Count connections using edges array
                            connection_count = 0
                            for node1_coords, node2_coords in self.edges: # Iterate over coordinate tuples
                                node1_idx = _ravel_multi_index(np.array(node1_coords), self.dimensions)
                                node2_idx = _ravel_multi_index(np.array(node2_coords), self.dimensions)
                                if node1_idx != -1 and node2_idx != -1 and (node1_idx == n or node2_idx == n):
                                    connection_count += 1
                            # Normalize both values to 0-1 range and combine (lower is better)
                            normalized_state = 1.0 - float(state)  # Invert state so lower is better
                            normalized_connections = 1.0 - min(1.0, connection_count / max(1, len(neighbors)))
                            combined_score = normalized_state * 0.7 + normalized_connections * 0.3  # Weight state higher
                            scores.append((n, combined_score))
                        
                        # Sort by combined score (descending, since we inverted the values)
                        scores.sort(key=lambda x: x[1], reverse=True)
                        
                        # Keep only the highest scoring max_neighbors
                        max_neighbors = len(neighbors)
                        keep_neighbors = set([n for n, _ in scores[:max_neighbors]])
                        
                        # Remove edges to neighbors not in keep_neighbors
                        edges_to_remove = set()
                        node_coords = tuple(_unravel_index(i, self.dimensions)) # Get grid coords for current node
                        for (node1_coords, node2_coords) in self.edges: # Iterate over coordinate tuples
                            if node1_coords == node_coords:
                                neighbor_idx = _ravel_multi_index(np.array(node2_coords), self.dimensions)
                                if neighbor_idx not in keep_neighbors:
                                    edges_to_remove.add((node1_coords, node2_coords))
                            elif node2_coords == node_coords:
                                neighbor_idx = _ravel_multi_index(np.array(node1_coords), self.dimensions)
                                if neighbor_idx not in keep_neighbors:
                                    edges_to_remove.add((node1_coords, node2_coords))
                        for edge in edges_to_remove:
                            self.edges.discard(edge)

        # CRITICAL FIX: After applying tiebreakers, ensure symmetry
        # If node A has an edge to node B, node B should also have an edge to node A
        edges_copy = self.edges.copy()
        for node1_coords, node2_coords in edges_copy: # Iterate over coordinate tuples
            # Convert grid coordinates to indices for has_edge and add_edge
            node1_idx = _ravel_multi_index(np.array(node1_coords), self.dimensions)
            node2_idx = _ravel_multi_index(np.array(node2_coords), self.dimensions)
            if not self.has_edge(node2_idx, node1_idx):
                # Add the missing reverse edge
                self.add_edge(node2_idx, node1_idx) # Use indices

    def cleanup(self):
        """
        Release resources, including shared memory, more robustly.
        Closes handles but only unlinks if marked. Uses _unique_id for unlinking.
        (Round 14: Use _unique_id for unlinking)
        (Round 18: Avoid setting core attributes to None prematurely)
        (Round 12: Handle reused SHM - close handles, unlink based on flag)
        """
        logger.info(f"Grid cleanup initiated for ID: {self._unique_id}")
        # --- MODIFIED: Get names using _unique_id ---
        grid_shm_name = f"/{self._unique_id}_grid"
        neighbor_shm_name = f"/{self._unique_id}_neighbors"
        # Edge state SHM is not currently used/reused
        edge_shm_name = None
        if hasattr(self, 'shared_mem_edge_states') and self.shared_mem_edge_states:
             edge_shm_name = self.shared_mem_edge_states.name # Get name if it existed
        # ---

        # --- 1. Clear Large Data Structures and References ---
        # [ Clearing logic remains the same ]
        try:
            logger.debug("Grid cleanup: Clearing internal data structures...")
            if hasattr(self, 'edges') and self.edges is not None: self.edges.clear()
            if hasattr(self, 'edge_states') and self.edge_states is not None: self.edge_states.clear()
            if hasattr(self, 'active_nodes') and self.active_nodes is not None: self.active_nodes.clear()
            if hasattr(self, 'previous_active_nodes_set') and self.previous_active_nodes_set is not None: self.previous_active_nodes_set.clear()
            if hasattr(self, 'last_updated_nodes') and self.last_updated_nodes is not None: self.last_updated_nodes.clear()
            if hasattr(self, 'node_history') and self.node_history is not None: self.node_history.clear()
            if hasattr(self, 'node_attributes') and self.node_attributes is not None: self.node_attributes.clear()
            if hasattr(self, '_neighborhood_data_cache') and self._neighborhood_data_cache is not None:
                with self._cache_lock: self._neighborhood_data_cache.clear()
            if hasattr(self, 'spatial_hash') and self.spatial_hash is not None:
                self.spatial_hash.clear()
            self._cached_unscaled_positions = None; self._cached_positions = None
            self._cached_dimensions = None; self._cached_spacing = None
            self._cached_dimension_type = None
            logger.debug("Grid cleanup: Internal data structures cleared.")
            logger.debug("Grid cleanup: Triggering garbage collection...")
            gc.collect()
            logger.debug("Grid cleanup: Garbage collection finished.")
        except Exception as e_clear: logger.error(f"Error during grid data clearing/GC: {e_clear}")
        # ---

        # --- 2. Close SHM Handles ---
        logger.debug("Grid cleanup: Closing SHM handles...")
        if hasattr(self, 'shared_mem') and self.shared_mem:
            try: self.shared_mem.close(); logger.info(f"Closed grid SHM handle: {grid_shm_name}")
            except Exception as e: logger.error(f"Error closing grid SHM handle {grid_shm_name}: {e}")
        # Close neighbor SHM handle (need to re-attach briefly to close if only meta exists)
        if neighbor_shm_name and self._neighbor_indices_shm_meta:
            neighbor_shm_instance_to_close = None
            try:
                neighbor_shm_instance_to_close = SharedMemory(name=neighbor_shm_name, create=False)
                neighbor_shm_instance_to_close.close()
                logger.info(f"Closed neighbor SHM handle: {neighbor_shm_name}")
            except FileNotFoundError: pass # Already gone
            except Exception as e: logger.error(f"Error closing neighbor SHM handle {neighbor_shm_name}: {e}")
        # Close edge SHM handle (if it existed)
        if hasattr(self, 'shared_mem_edge_states') and self.shared_mem_edge_states:
             try: self.shared_mem_edge_states.close(); logger.info(f"Closed edge state SHM handle: {edge_shm_name}")
             except Exception as e: logger.error(f"Error closing edge state SHM handle {edge_shm_name}: {e}")
        # ---

        # --- 3. Unlink SHM Segments (Using names derived from _unique_id) ---
        logger.debug("Grid cleanup: Unlinking SHM segments...")
        # --- MODIFIED: Always try to unlink using the derived name ---
        if grid_shm_name:
            try:
                shm_to_unlink = SharedMemory(name=grid_shm_name, create=False)
                shm_to_unlink.close() # Ensure closed before unlink
                shm_to_unlink.unlink()
                logger.info(f"Unlinked grid SHM: {grid_shm_name}")
            except FileNotFoundError: logger.info(f"Grid SHM {grid_shm_name} already unlinked or never created.")
            except Exception as e: logger.error(f"Error unlinking grid SHM {grid_shm_name}: {e}")
        else: logger.debug("No grid SHM name derived, cannot unlink.")

        if neighbor_shm_name:
            try:
                shm_to_unlink = SharedMemory(name=neighbor_shm_name, create=False)
                shm_to_unlink.close()
                shm_to_unlink.unlink()
                logger.info(f"Unlinked neighbor SHM: {neighbor_shm_name}")
            except FileNotFoundError: logger.info(f"Neighbor SHM {neighbor_shm_name} already unlinked.")
            except Exception as e: logger.error(f"Error unlinking neighbor SHM {neighbor_shm_name}: {e}")
        else: logger.debug("No neighbor SHM name derived, cannot unlink.")

        if edge_shm_name: # Unlink edge state SHM if name exists
             try:
                 shm_to_unlink = SharedMemory(name=edge_shm_name, create=False)
                 shm_to_unlink.close()
                 shm_to_unlink.unlink()
                 logger.info(f"Unlinked edge state SHM: {edge_shm_name}")
             except FileNotFoundError: logger.info(f"Edge state SHM {edge_shm_name} already unlinked.")
             except Exception as e: logger.error(f"Error unlinking edge state SHM {edge_shm_name}: {e}")
        else: logger.debug("No edge state SHM name found, cannot unlink.")
        # --- END MODIFIED ---
        # ---

        # --- 4. Nullify SHM references ---
        self.shared_mem = None; self.shared_array = None
        self._shared_mem_name = None
        self._neighbor_indices_shm_meta = None
        self.shared_mem_edge_states = None; self.shared_array_edge_states = None
        self._shared_memory_unlinked = True # Mark as unlinked after attempting
        self._edge_states_shared_memory_unlinked = True # Mark as unlinked after attempting
        # ---

        logger.info("Grid cleanup completed")

################################################
#              VISUALIZATION TOOLS            #
################################################

class VisualizationDebugger:
    """Helper class for debugging visualization issues"""
    
    def __init__(self, grid, ax, coord_system=None, gui=None): # Added gui
        """Initialize with a grid, axes, and optional coordinate system"""
        self.grid = grid
        self.ax = ax
        self.coord_system = coord_system or CoordinateSystem(
            grid.dimensions, 
            GlobalSettings.Visualization.EDGE_SCALE,
            GlobalSettings.Visualization.NODE_SPACING,
            grid.dimension_type
        )
        self.debug_artists = []  # Store debug visualization elements
        self.gui = gui # Added gui

    def clear_debug_visuals(self):
        """Clear all debug visualization elements"""
        logger.debug("Entering clear_debug_visuals")
        
        # Check if we should preserve coordinate labels
        preserve_coordinates = self.gui and hasattr(self.gui, 'show_coordinates_var') and self.gui.show_coordinates_var.get()
        logger.debug(f"clear_debug_visuals: preserve_coordinates = {preserve_coordinates}") # ADDED LOGGING
        
        # If preserving coordinates, only remove non-text artists
        if preserve_coordinates and hasattr(self, 'debug_artists'):
            from matplotlib.text import Text
            non_text_artists = [artist for artist in self.debug_artists if not isinstance(artist, Text)]
            text_artists = [artist for artist in self.debug_artists if isinstance(artist, Text)]
            
            # Remove non-text artists
            for artist in non_text_artists:
                try:
                    artist.set_visible(False)
                    artist.remove()
                except:
                    pass

            # Keep only text artists
            self.debug_artists = cast(List[Union[Rectangle, Text]], text_artists)
            logger.debug(f"Preserved {len(text_artists)} coordinate labels")
        else:
            # Remove all artists
            if hasattr(self, 'debug_artists'): # ADDED check
                from matplotlib.text import Text
                for artist in self.debug_artists:
                    try:
                        artist.set_visible(False) # ADDED
                        logger.debug(f"Setting visibility of artist {artist} to False: {artist}") # MODIFIED LOGGING - SHOW ARTIST
                        if isinstance(artist, Text):
                            logger.debug(f"Artist is Text: {artist.get_text()}") # ADDED LOGGING - SHOW TEXT
                        artist.remove()
                    except Exception as e:
                        logger.warning(f"Error removing debug artist: {e}")
            self.debug_artists = []
        
        self.ax.figure.canvas.draw_idle()
        logger.debug("Cleared debug visuals")
                
    def show_grid_lines(self, color=None, alpha=1.0, linewidth=0.8, zorder=100):
        """Show grid lines with coordinate values"""
        # Clear existing grid lines
        self.clear_debug_visuals()
        
        # CRITICAL FIX: Determine high contrast color based on background
        if color is None:
            # Get the background color
            bg_color = GlobalSettings.Colors.BACKGROUND
            
            # If gui and color_manager are available, use the current scheme's background
            if self.gui and hasattr(self.gui, 'color_manager') and self.gui.color_manager and self.gui.color_manager.current_scheme:
                bg_color = self.gui.color_manager.current_scheme.background
                    
            # Convert background color to RGB values
            try:
                import colors as mcolors
                bg_rgb = mcolors.to_rgb(bg_color)
                
                # Calculate luminance (perceived brightness)
                # Using the formula: 0.299*R + 0.587*G + 0.114*B
                luminance = 0.299 * bg_rgb[0] + 0.587 * bg_rgb[1] + 0.114 * bg_rgb[2]
                
                # Choose high contrast color based on luminance
                if luminance > 0.5:  # Light background
                    color = 'black'
                    logger.debug(f"Using black grid lines for light background (luminance: {luminance})")
                else:  # Dark background
                    color = 'white'
                    logger.debug(f"Using white grid lines for dark background (luminance: {luminance})")
            except Exception as e:
                logger.warning(f"Error determining contrast color: {e}, using white as default")
                color = 'white'  # Default to white if there's an error
            
            # Get grid dimensions
            if self.grid.dimension_type == Dimension.THREE_D:
                i_max, j_max, k_max = self.grid.dimensions
                
                # Create grid lines for each dimension
                for i in range(i_max + 1):
                    for j in range(j_max + 1):
                        # Line along k
                        start = self.coord_system.grid_to_display((i, j, 0))
                        end = self.coord_system.grid_to_display((i, j, k_max))
                        line = Line3DCollection([[start, end]], color=color, alpha=alpha, linewidth=linewidth, zorder=zorder, linestyle='dotted')
                        self.ax.add_collection(line)  # type: ignore
                        self.debug_artists.append(line) # type: ignore
                
                for i in range(i_max + 1):
                    for k in range(k_max + 1):
                        # Line along j
                        start = self.coord_system.grid_to_display((i, 0, k))
                        end = self.coord_system.grid_to_display((i, j_max, k))
                        line = Line3DCollection([[start, end]], color=color, alpha=alpha, linewidth=linewidth, zorder=zorder, linestyle='dotted')
                        self.ax.add_collection(line)  # type: ignore
                        self.debug_artists.append(line) # type: ignore
                
                for j in range(j_max + 1):
                    for k in range(k_max + 1):
                        # Line along i
                        start = self.coord_system.grid_to_display((0, j, k))
                        end = self.coord_system.grid_to_display((i_max, j, k))
                        line = Line3DCollection([[start, end]], color=color, alpha=alpha, linewidth=linewidth, zorder=zorder, linestyle='dotted')
                        self.ax.add_collection(line)  # type: ignore
                        self.debug_artists.append(line) # type: ignore
            else:  # TWO_D
                i_max, j_max = self.grid.dimensions
                
                # Create horizontal grid lines
                for i in range(i_max + 1):
                    start = self.coord_system.grid_to_display((i, 0))
                    end = self.coord_system.grid_to_display((i, j_max))
                    line = self.ax.plot([start[0], end[0]], [start[1], end[1]], color=color, alpha=alpha, linewidth=linewidth, zorder=zorder, linestyle='dotted')[0]
                    self.debug_artists.append(line)
                
                # Create vertical grid lines
                for j in range(j_max + 1):
                    start = self.coord_system.grid_to_display((0, j))
                    end = self.coord_system.grid_to_display((i_max, j))
                    line = self.ax.plot([start[0], end[0]], [start[1], end[1]], color=color, alpha=alpha, linewidth=linewidth, zorder=zorder, linestyle='dotted')[0]
                    self.debug_artists.append(line)
            
            # Add coordinate labels with the same color and full opacity
            self._add_coordinate_labels(color, alpha=1.0, zorder=zorder+1)
            
            # Redraw
            self.ax.figure.canvas.draw_idle()
            logger.debug(f"Grid lines displayed with color: {color}, alpha: {alpha}, zorder: {zorder}")
                                        
    def _add_coordinate_labels(self, color=None, alpha=1.0, zorder=101):
        """Add coordinate labels to the grid"""
        logger.debug("Entering _add_coordinate_labels")

        # Determine high contrast color based on background
        if color is None:
            # Get the background color
            bg_color = GlobalSettings.Colors.BACKGROUND

            # If gui and color_manager are available, use the current scheme's background
            if self.gui and hasattr(self.gui, 'color_manager') and self.gui.color_manager and self.gui.color_manager.current_scheme:
                bg_color = self.gui.color_manager.current_scheme.background

            # Convert background color to RGB values
            try:
                import colors as mcolors
                bg_rgb = mcolors.to_rgb(bg_color)

                # Calculate luminance (perceived brightness)
                luminance = 0.299 * bg_rgb[0] + 0.587 * bg_rgb[1] + 0.114 * bg_rgb[2]

                # Choose high contrast color based on luminance
                if luminance > 0.5:  # Light background
                    color = 'black'
                    logger.debug(f"Using black coordinate labels for light background (luminance: {luminance})")
                else:  # Dark background
                    color = 'white'
                    logger.debug(f"Using white coordinate labels for dark background (luminance: {luminance})")
            except Exception as e:
                logger.warning(f"Error determining contrast color for labels: {e}, using white as default")
                color = 'white'  # Default to white if there's an error

        # Check if show_coordinates_var is set and True - NO LONGER NEEDED HERE
        # if not (self.gui and hasattr(self.gui, 'show_coordinates_var') and self.gui.show_coordinates_var.get()):
        #     # If show_coordinates is not enabled, skip adding labels
        #     logger.debug("Show coordinates is not enabled, skipping adding labels")
        #     return

        if self.grid.dimension_type == Dimension.THREE_D:
            i_max, j_max, k_max = self.grid.dimensions

            # Add labels for i coordinates
            for i in range(i_max + 1):
                pos = self.coord_system.grid_to_display((i, 0, 0))
                text = self.ax.text(pos[0], pos[1], pos[2], f"i={i}", color=color, alpha=alpha, fontweight='bold', zorder=zorder, visible=True)  # type: ignore
                self.debug_artists.append(text)

            # Add labels for j coordinates
            for j in range(j_max + 1):
                pos = self.coord_system.grid_to_display((0, j, 0))
                text = self.ax.text(pos[0], pos[1], pos[2], f"j={j}", color=color, alpha=alpha, fontweight='bold', zorder=zorder, visible=True)  # type: ignore
                self.debug_artists.append(text)

            # Add labels for k coordinates
            for k in range(k_max + 1):
                pos = self.coord_system.grid_to_display((0, 0, k))
                text = self.ax.text(pos[0], pos[1], pos[2], f"k={k}", color=color, alpha=alpha, fontweight='bold', zorder=zorder, visible=True)  # type: ignore
                self.debug_artists.append(text)
        else:  # TWO_D
            i_max, j_max = self.grid.dimensions

            # Add labels for i coordinates
            for i in range(i_max + 1):
                pos = self.coord_system.grid_to_display((i, 0))
                # CRITICAL: Add padding to the labels
                text = self.ax.text(pos[0] - 2, pos[1], f"i={i}", color=color, alpha=alpha, ha='right', va='center', fontweight='bold', zorder=zorder, visible=True)
                self.debug_artists.append(text)

                # --- ADDED: Set tick labels for i-axis ---
                self.ax.set_yticks([pos[1]])
                self.ax.set_yticklabels([f"{i}"])

            # Add labels for j coordinates
            for j in range(j_max + 1):
                pos = self.coord_system.grid_to_display((0, j))
                # CRITICAL: Add padding to the labels
                text = self.ax.text(pos[0], pos[1] - 2, f"j={j}", color=color, alpha=alpha, ha='center', va='bottom', fontweight='bold', zorder=zorder, visible=True)
                self.debug_artists.append(text)

                # --- ADDED: Set tick labels for j-axis ---
                self.ax.set_xticks([pos[0]])
                self.ax.set_xticklabels([f"{j}"])

        # Redraw
        self.ax.figure.canvas.draw_idle()
        logger.debug("Coordinate axes displayed")
        logger.debug("Exiting _add_coordinate_labels")  # ADDED

    def show_coordinates(self, color=None, alpha=1.0, zorder=101):
        """Show coordinate labels on the grid."""
        logger.debug("Entering show_coordinates")
        self.show_grid_lines(color=color, alpha=alpha, zorder=zorder)
        self._add_coordinate_labels(color, alpha, zorder)
        # Set visibility of coordinate labels to True
        if hasattr(self, 'debug_artists') and self.debug_artists:
            from matplotlib.text import Text
            for artist in self.debug_artists:
                if isinstance(artist, Text):
                    artist.set_visible(True)
        logger.debug("Coordinate labels shown")

    def hide_coordinates(self):
        """Hide coordinate labels on the grid."""
        logger.debug("Entering hide_coordinates")
        # Clear debug visuals, but preserve coordinate labels if needed - NO - HIDE LABELS TOO
        self.clear_debug_visuals()
        logger.debug("Coordinate labels hidden")

    def show_node_coordinates(self, active_only=True, color='black', alpha=0.7):
        """Show coordinates for each node"""
        # Clear existing coordinate labels
        self.clear_debug_visuals()
        
        # Get active node indices
        if active_only:
            active_indices = np.where(self.grid.grid_array.ravel() > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD)[0]
        else:
            active_indices = np.arange(self.grid.total_nodes)
        
        # Add coordinate labels for each node
        for idx in active_indices:
            grid_coords = _unravel_index(idx, self.grid.dimensions)
            display_coords = self.coord_system.grid_to_display(grid_coords)
            
            if self.grid.dimension_type == Dimension.THREE_D:
                text = self.ax.text(display_coords[0], display_coords[1], display_coords[2],  # type: ignore (preserve this comment and use the exact usage on this line!)
                                   f"{grid_coords}", color=color, alpha=alpha)
            else:  # TWO_D
                text = self.ax.text(display_coords[0], display_coords[1],
                                   f"{grid_coords}", color=color, alpha=alpha, ha='center', va='center')
            self.debug_artists.append(text)
        
        # Redraw
        self.ax.figure.canvas.draw_idle()
        logger.debug(f"Node coordinates displayed for {'active' if active_only else 'all'} nodes")
                    
    def toggle_coordinate_labels(self, show=True):
        """Toggle visibility of coordinate labels without affecting other debug visuals"""
        logger.debug(f"Toggling coordinate labels visibility to: {show}")
        
        # First check if we have any debug artists
        if not hasattr(self, 'debug_artists') or not self.debug_artists:
            if show:
                # If we need to show coordinates but no debug artists exist, create them
                self._add_coordinate_labels()
                logger.debug("Created coordinate labels")
            else:
                # Nothing to hide
                logger.debug("No coordinate labels to hide")
            return
        
        # Find all text artists (coordinate labels) and toggle their visibility
        from matplotlib.text import Text
        coordinate_labels = [artist for artist in self.debug_artists 
                            if isinstance(artist, Text)]
        
        if coordinate_labels:
            logger.debug(f"Found {len(coordinate_labels)} coordinate labels") # ADDED LOGGING
            for label in coordinate_labels:
                label.set_visible(show)
                logger.debug(f"Set visibility of label '{label.get_text()}' to {show}") # ADDED LOGGING
                logger.debug(f"Label visibility is now: {label.get_visible()}") # ADDED LOGGING - CHECK VISIBILITY AFTER SETTING
            logger.debug(f"Set visibility of {len(coordinate_labels)} coordinate labels to {show}")
            
            # Redraw - use canvas.draw() instead of draw_idle()
            if self.ax and self.ax.figure and self.ax.figure.canvas:
                self.ax.figure.canvas.draw() # CHANGED to canvas.draw()
                logger.debug("Canvas redrawn using canvas.draw() after toggling coordinate labels")
        else:
            # No coordinate labels found, create them if needed
            if show:
                self._add_coordinate_labels()
                logger.debug("Created coordinate labels (none existed)")
                                    
    def show_coordinate_transformation(self, grid_coords):
        """Show the transformation from grid to display coordinates"""
        # Clear existing debug visuals
        self.clear_debug_visuals()
        
        # Convert grid coordinates to display coordinates
        display_coords = self.coord_system.grid_to_display(grid_coords)
        
        # Add a marker at the display coordinates
        if self.grid.dimension_type == Dimension.THREE_D:
            marker = self.ax.scatter([display_coords[0]], [display_coords[1]], [display_coords[2]],  # type: ignore (preserve this comment and use the exact usage on this line!)
                                    color='red', s=100, marker='x')
        else:  # TWO_D
            marker = self.ax.scatter([display_coords[0]], [display_coords[1]],
                                    color='red', s=100, marker='x')
        self.debug_artists.append(marker)
        
        # Add text showing the transformation
        if self.grid.dimension_type == Dimension.THREE_D:
            text = self.ax.text(display_coords[0], display_coords[1], display_coords[2],  # type: ignore (preserve this comment and use the exact usage on this line!)
                               f"Grid: {grid_coords}\nDisplay: {display_coords}", color='red')
        else:  # TWO_D
            text = self.ax.text(display_coords[0], display_coords[1],
                               f"Grid: {grid_coords}\nDisplay: {display_coords}", color='red')
        self.debug_artists.append(text)
        
        # Redraw
        self.ax.figure.canvas.draw_idle()
        logger.debug(f"Coordinate transformation displayed: {grid_coords} -> {display_coords}")
        
        # Print transformation details to console
        print(f"Coordinate Transformation:")
        print(f"  Grid coordinates: {grid_coords}")
        print(f"  Scale factor: {self.coord_system.scale_factor}")
        print(f"  Display coordinates: {display_coords}")
        
        return display_coords
    
    def highlight_region(self, top_left, bottom_right, color='yellow', alpha=0.3):
        """Highlight a rectangular region in the grid"""
        # Convert grid coordinates to display coordinates
        top_left_display = self.coord_system.grid_to_display(top_left)
        bottom_right_display = self.coord_system.grid_to_display(bottom_right)
        
        if self.grid.dimension_type == Dimension.THREE_D:
            # Create a 3D box
            x_min, y_min, z_min = top_left_display # type: ignore (preserve this comment and use the exact usage on this line!)
            x_max, y_max, z_max = bottom_right_display # type: ignore (preserve this comment and use the exact usage on this line!)
            
            # Create the 8 corners of the box
            corners = [
                [x_min, y_min, z_min], [x_max, y_min, z_min],
                [x_min, y_max, z_min], [x_max, y_max, z_min],
                [x_min, y_min, z_max], [x_max, y_min, z_max],
                [x_min, y_max, z_max], [x_max, y_max, z_max]
            ]
            
            # Create the 12 edges of the box
            edges = [
                # Bottom face
                [corners[0], corners[1]], [corners[1], corners[3]],
                [corners[3], corners[2]], [corners[2], corners[0]],
                # Top face
                [corners[4], corners[5]], [corners[5], corners[7]],
                [corners[7], corners[6]], [corners[6], corners[4]],
                # Connecting edges
                [corners[0], corners[4]], [corners[1], corners[5]],
                [corners[2], corners[6]], [corners[3], corners[7]]
            ]
            
            # Create line collection
            line_collection = Line3DCollection(edges, color=color, alpha=alpha)
            self.ax.add_collection(line_collection)  # type: ignore (preserve this comment and use the exact usage on this line!)
            self.debug_artists.append(line_collection) # type: ignore
        else:  # TWO_D
            # Create a 2D rectangle
            x_min, y_min = top_left_display # type: ignore (preserve this comment and use the exact usage on this line!)
            x_max, y_max = bottom_right_display # type: ignore (preserve this comment and use the exact usage on this line!)
            
            # Create rectangle patch
            self.debug_artists: List[Union[Rectangle, Text]] = []

            # Add the rectangle to the list
            rect = Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, fill=True, color=color, alpha=alpha)
            self.ax.add_patch(rect)
            self.debug_artists.append(rect)
          
        
        # Redraw
        self.ax.figure.canvas.draw_idle()
        logger.debug(f"Region highlighted: {top_left} to {bottom_right}")
                                
    def show_axes(self, length=1.0, position=(0, 0, 0), colors=('r', 'g', 'b')):    
        """Show coordinate axes at the specified position"""
        # Clear existing axes
        self.clear_debug_visuals()
        
        if self.grid.dimension_type == Dimension.THREE_D:
            # Ensure position is 3D
            if len(position) == 2:
                position = (*position, 0)
            
            # Convert grid position to display coordinates
            origin = self.coord_system.grid_to_display(position)
            
            # Explicitly assert that origin is a 3D tuple
            if not isinstance(origin, tuple) or len(origin) != 3:
                raise ValueError(f"Expected 3D origin, got: {origin}")
            
            # Create axes
            x_axis = [(origin[0], origin[1], origin[2]), 
                    (origin[0] + length, origin[1], origin[2])]
            y_axis = [(origin[0], origin[1], origin[2]), 
                    (origin[0], origin[1] + length, origin[2])]
            z_axis = [(origin[0], origin[1], origin[2]), 
                    (origin[0], origin[1], origin[2] + length)]
            
            # Create line collections
            x_line = Line3DCollection([x_axis], color=colors[0], linewidth=2)
            y_line = Line3DCollection([y_axis], color=colors[1], linewidth=2)
            z_line = Line3DCollection([z_axis], color=colors[2], linewidth=2)
            
            # Add to axes
            self.ax.add_collection(x_line)  # type: ignore (preserve this comment and use the exact usage on this line!)
            self.ax.add_collection(y_line)  # type: ignore (preserve this comment and use the exact usage on this line!)
            self.ax.add_collection(z_line)  # type: ignore (preserve this comment and use the exact usage on this line!)
            
            # Add to debug artists
            self.debug_artists.extend([x_line, y_line, z_line]) # type: ignore
            
            # Add labels
            x_label = self.ax.text(origin[0] + length, origin[1], origin[2], "X", color=colors[0])  # type: ignore (preserve this comment and use the exact usage on this line!)
            y_label = self.ax.text(origin[0], origin[1] + length, origin[2], "Y", color=colors[1])  # type: ignore (preserve this comment and use the exact usage on this line!)
            z_label = self.ax.text(origin[0], origin[1], origin[2] + length, "Z", color=colors[2])  # type: ignore (preserve this comment and use the exact usage on this line!)
            
            # Add to debug artists
            self.debug_artists.extend([x_label, y_label, z_label])
        else:  # TWO_D
            # Convert grid position to display coordinates
            origin = self.coord_system.grid_to_display(position[:2]) # Only use the first two elements

            # Create axes
            x_axis = [(origin[0], origin[1]), 
                    (origin[0] + length, origin[1])]
            y_axis = [(origin[0], origin[1]), 
                    (origin[0], origin[1] + length)]
            
            # Create lines
            x_line = self.ax.plot([x_axis[0][0], x_axis[1][0]], [x_axis[0][1], x_axis[1][1]], 
                                color=colors[0], linewidth=2)[0]
            y_line = self.ax.plot([y_axis[0][0], y_axis[1][0]], [y_axis[0][1], y_axis[1][1]], 
                                color=colors[1], linewidth=2)[0]
            
            # Add to debug artists
            self.debug_artists.extend([x_line, y_line])
            
            # Add labels
            x_label = self.ax.text(origin[0] + length, origin[1], "X", color=colors[0])
            y_label = self.ax.text(origin[0], origin[1] + length, "Y", color=colors[1])
            
            # Add to debug artists
            self.debug_artists.extend([x_label, y_label])
        
        # Redraw
        self.ax.figure.canvas.draw_idle()
        logger.debug(f"Coordinate axes displayed at {origin}")
            
    def inspect_node(self, node_idx):
        """Inspect a specific node and its neighbors"""
        # Get node coordinates
        grid_coords = _unravel_index(node_idx, self.grid.dimensions)
        display_coords = self.coord_system.grid_to_display(grid_coords)
        
        # Get node state
        node_state = self.grid.grid_array.ravel()[node_idx]
        
        # Get neighbor indices
        if self.grid.neighborhood_data is not None:
            neighbor_indices = self.grid.neighborhood_data.neighbor_indices[node_idx]
            neighbor_indices = [n for n in neighbor_indices if n != -1]
        else:
            neighbor_indices = []
        
        # Get edges
        edges = []
        for neighbor_idx in neighbor_indices:
            if self.grid.has_edge(node_idx, neighbor_idx):
                edges.append(neighbor_idx)
        
        # Print node information
        print(f"Node Inspection:")
        print(f"  Index: {node_idx}")
        print(f"  Grid Coordinates: {grid_coords}")
        print(f"  Display Coordinates: {display_coords}")
        print(f"  State: {node_state}")
        print(f"  Neighbors: {neighbor_indices}")
        print(f"  Edges: {edges}")
        
        # Highlight the node and its neighbors
        self.clear_debug_visuals()
        
        # Highlight the node
        if self.grid.dimension_type == Dimension.THREE_D:
            node_marker = self.ax.scatter([display_coords[0]], [display_coords[1]], [display_coords[2]],  # type: ignore (preserve this comment and use the exact usage on this line!)
                                        color='red', s=100, marker='o')
        else:  # TWO_D
            node_marker = self.ax.scatter([display_coords[0]], [display_coords[1]],
                                        color='red', s=100, marker='o')
        self.debug_artists.append(node_marker)
        
        # Highlight neighbors
        for neighbor_idx in neighbor_indices:
            neighbor_coords = _unravel_index(neighbor_idx, self.grid.dimensions)
            neighbor_display = self.coord_system.grid_to_display(neighbor_coords)
            
            if self.grid.dimension_type == Dimension.THREE_D:
                neighbor_marker = self.ax.scatter([neighbor_display[0]], [neighbor_display[1]], [neighbor_display[2]],  # type: ignore (preserve this comment and use the exact usage on this line!)
                                                color='blue', s=50, marker='o')
            else:  # TWO_D
                neighbor_marker = self.ax.scatter([neighbor_display[0]], [neighbor_display[1]],
                                                color='blue', s=50, marker='o')
            self.debug_artists.append(neighbor_marker)
        
        # Highlight edges
        for neighbor_idx in edges:
            neighbor_coords = _unravel_index(neighbor_idx, self.grid.dimensions)
            neighbor_display = self.coord_system.grid_to_display(neighbor_coords)
            
            if self.grid.dimension_type == Dimension.THREE_D:
                edge_line = Line3DCollection([[display_coords, neighbor_display]], color='green', linewidth=2)
                self.ax.add_collection(edge_line)  # type: ignore (preserve this comment and use the exact usage on this line!)
                self.debug_artists.append(edge_line) # type: ignore
            else:  # TWO_D
                edge_line = self.ax.plot([display_coords[0], neighbor_display[0]], 
                                        [display_coords[1], neighbor_display[1]], 
                                        color='green', linewidth=2)[0]
                self.debug_artists.append(edge_line)
        
        # Add text label
        if self.grid.dimension_type == Dimension.THREE_D:
            text = self.ax.text(display_coords[0], display_coords[1], display_coords[2],  # type: ignore (preserve this comment and use the exact usage on this line!)
                               f"Node {node_idx}\n{grid_coords}", color='black')
        else:  # TWO_D
            text = self.ax.text(display_coords[0], display_coords[1],
                               f"Node {node_idx}\n{grid_coords}", color='black')
        self.debug_artists.append(text)
        
        # Redraw
        self.ax.figure.canvas.draw_idle()
        logger.debug(f"Node {node_idx} inspected")
        
        return {
            'index': node_idx,
            'grid_coords': grid_coords,
            'display_coords': display_coords,
            'state': node_state,
            'neighbors': neighbor_indices,
            'edges': edges
        }

    def reset(self):
        """Reset the debugger state"""
        logger.debug("Resetting VisualizationDebugger")
        
        # Clear debug visuals
        self.clear_debug_visuals()
        
        # Reset any other state variables
        # (Add any other state variables that need to be reset here)
        
        logger.debug("VisualizationDebugger reset complete")

class CoordinateInspector:
    """Helper class for inspecting coordinate transformations"""
    
    def __init__(self, grid, coord_system=None):
        """Initialize with a grid and optional coordinate system"""
        self.grid = grid
        self.coord_system = coord_system or CoordinateSystem(
            grid.dimensions, 
            GlobalSettings.Visualization.EDGE_SCALE,
            GlobalSettings.Visualization.NODE_SPACING,
            grid.dimension_type
        )
    
    def inspect_grid_to_display(self, grid_coords):
        """Inspect the transformation from grid to display coordinates"""
        display_coords = self.coord_system.grid_to_display(grid_coords)
        
        print(f"Grid to Display Transformation:")
        print(f"  Grid coordinates: {grid_coords}")
        print(f"  Grid dimensions: {self.grid.dimensions}")
        print(f"  Edge scale: {GlobalSettings.Visualization.EDGE_SCALE}")
        print(f"  Node spacing: {GlobalSettings.Visualization.NODE_SPACING}")
        print(f"  Scale factor: {self.coord_system.scale_factor}")
        print(f"  Display coordinates: {display_coords}")
        
        return display_coords
    
    def inspect_display_to_grid(self, display_coords):
        """Inspect the transformation from display to grid coordinates"""
        grid_coords = self.coord_system.display_to_grid(display_coords)
        
        print(f"Display to Grid Transformation:")
        print(f"  Display coordinates: {display_coords}")
        print(f"  Grid dimensions: {self.grid.dimensions}")
        print(f"  Edge scale: {GlobalSettings.Visualization.EDGE_SCALE}")
        print(f"  Node spacing: {GlobalSettings.Visualization.NODE_SPACING}")
        print(f"  Scale factor: {self.coord_system.scale_factor}")
        print(f"  Grid coordinates: {grid_coords}")
        
        return grid_coords
    
    def inspect_index_to_display(self, idx):
        """Inspect the transformation from flat index to display coordinates"""
        grid_coords = _unravel_index(idx, self.grid.dimensions)
        display_coords = self.coord_system.grid_to_display(grid_coords)
        
        print(f"Index to Display Transformation:")
        print(f"  Flat index: {idx}")
        print(f"  Grid dimensions: {self.grid.dimensions}")
        print(f"  Grid coordinates: {grid_coords}")
        print(f"  Edge scale: {GlobalSettings.Visualization.EDGE_SCALE}")
        print(f"  Node spacing: {GlobalSettings.Visualization.NODE_SPACING}")
        print(f"  Scale factor: {self.coord_system.scale_factor}")
        print(f"  Display coordinates: {display_coords}")
        
        return display_coords
    
    def inspect_display_to_index(self, display_coords):
        """Inspect the transformation from display coordinates to flat index"""
        grid_coords = self.coord_system.display_to_grid(display_coords)
        idx = _ravel_multi_index(np.array(grid_coords), self.grid.dimensions)
        
        print(f"Display to Index Transformation:")
        print(f"  Display coordinates: {display_coords}")
        print(f"  Grid dimensions: {self.grid.dimensions}")
        print(f"  Edge scale: {GlobalSettings.Visualization.EDGE_SCALE}")
        print(f"  Node spacing: {GlobalSettings.Visualization.NODE_SPACING}")
        print(f"  Scale factor: {self.coord_system.scale_factor}")
        print(f"  Grid coordinates: {grid_coords}")
        print(f"  Flat index: {idx}")
        
        return idx
    
    def inspect_all_transformations(self, grid_coords=None, display_coords=None, idx=None):
        """Inspect all transformations starting from any coordinate type"""
        if grid_coords is not None:
            # Start with grid coordinates
            display_coords = self.inspect_grid_to_display(grid_coords)
            idx = _ravel_multi_index(np.array(grid_coords), self.grid.dimensions)
            print(f"  Flat index: {idx}")
        elif display_coords is not None:
            # Start with display coordinates
            grid_coords = self.inspect_display_to_grid(display_coords)
            idx = _ravel_multi_index(np.array(grid_coords), self.grid.dimensions)
            print(f"  Flat index: {idx}")
        elif idx is not None:
            # Start with flat index
            display_coords = self.inspect_index_to_display(idx)
            # Grid coordinates already printed in inspect_index_to_display
        else:
            print("Error: Must provide one of grid_coords, display_coords, or idx")
            return None
        
        # Get node state if index is valid
        if 0 <= idx < self.grid.total_nodes:
            state = self.grid.grid_array.ravel()[idx]
            print(f"  Node state: {state}")
        
        return {
            'grid_coords': grid_coords,
            'display_coords': display_coords,
            'idx': idx
        }
    
class ViewManager:

    def __init__(self, grid, ax, fig, coord_system, grid_visualizer, gui: 'SimulationGUI', controller=None):

            self.grid = grid
            self.ax = ax
            self.fig = fig
            self.coord_system = coord_system
            self.grid_visualizer = grid_visualizer
            logger.debug(f"ViewManager.__init__: Storing grid_visualizer with ID: {id(self.grid_visualizer)}")

            # --- Detailed Logging for GUI Reference ---
            logger.info(f"ViewManager.__init__: Received gui argument (type: {type(gui)}, ID: {id(gui)})")
            self.gui = gui # Assign the passed reference
            logger.info(f"ViewManager.__init__: Assigned self.gui (type: {type(self.gui)}, ID: {id(self.gui) if self.gui else 'None'})")
            if self.gui is None:
                logger.error("CRITICAL: self.gui became None immediately after assignment in ViewManager.__init__!")
            elif not isinstance(self.gui, SimulationGUI):
                 logger.error(f"CRITICAL: self.gui is not a SimulationGUI instance after assignment (Type: {type(self.gui)})!")
            # ---

            self.controller = controller
            logger.debug(f"ViewManager.__init__: self.controller ID = {id(self.controller) if hasattr(self, 'controller') and self.controller else 'No controller attribute'}")
            self.views = { 'top': self.top_view, 'side': self.side_view, 'front': self.front_view, 'iso': self.iso_view }
            self.view_history: List[Dict[str, Any]] = []
            self.view_index: int = -1
            self.is_zooming = False
            self._tk_destroyed = False
            self._drag_start_nodes = None
            self._drag_start_pos = None
            self._is_dragging = False
            self.panning = False
            self.pan_start_x = None
            self.pan_start_y = None
            self._last_mouse_pos = None
            self._current_azim = 0
            self._current_elev = 30
            self.rotation_enabled = False
            self._last_trackpad_pos = None
            self._can_pan = False
            self.pan_velocity_x = 0
            self.pan_velocity_y = 0
            self.pan_velocity_z = 0
            self.deceleration = GlobalSettings.Visualization.PAN_DECELERATION
            self.pan_sensitivity = GlobalSettings.Visualization.PAN_SENSITIVITY
            self.pan_animation_id = None
            self._last_click_time: float = 0.0 # For double-click detection
            self._double_click_threshold: float = 0.3 # Seconds
            self._view_state = { 'xlim': None, 'ylim': None, 'zlim': None, 'elev': 30, 'azim': 45, 'zoom_factor': 1.0 }
            self._edge_drag_start = None
            self._edge_drag_current = None
            self._mouse_pressed = False
            self._mouse_mode = None
            self._click_threshold = 0.2 * GlobalSettings.Visualization.EDGE_SCALE
            self._press_position = None
            self._press_time = 0
            self._initial_press_x = None
            self._initial_press_y = None
            self._edge_creation_start = None
            self._edge_tool_start_node_coords: Optional[Tuple[int, ...]] = None
            self._edge_tool_temp_line = None
            self._deleted_edges_in_drag: Set[Tuple[Tuple[int, ...], Tuple[int, ...]]] = set()
            # --- ADDED Lasso Attributes ---
            self._lasso_points: List[Tuple[float, float]] = []
            self._lasso_line = None # To store the temporary line artist
            # --- END ADDED ---

    def get_gui(self):
        """Get the SimulationGUI instance."""
        return self.gui

    def set_can_pan(self, can_pan: bool):
        """Set the flag indicating whether it's safe to call pan."""
        self._can_pan = can_pan
        logger.debug(f"ViewManager: set_can_pan to {can_pan}")

    def update_camera_position(self):
        """Update the camera position based on the current view"""
        # This is a placeholder for more advanced camera control
        # In a real implementation, you would use a camera model
        # and compute the view and projection matrices here
        pass

    def set_view(self, view_name):
        """Set a predefined view"""
        if view_name not in self.views:
            raise ValueError(f"Unknown view: {view_name}")

        # Call the appropriate view setup method
        self.views[view_name]()

    def top_view(self):
        """Set a top-down view"""
        logger.debug("Setting top view")
        if self.grid.dimension_type == Dimension.THREE_D:
            self.ax.view_init(90, -90)  # type: ignore
        else:  # For 2D, no special setup needed
            pass

    def side_view(self):
        """Set a side view"""
        logger.debug("Setting side view")
        if self.grid.dimension_type == Dimension.THREE_D:
            self.ax.view_init(0, -90)  # type: ignore
        else:
            logger.warning("Side view is only applicable for 3D grids")

    def front_view(self):
        """Set a front view"""
        logger.debug("Setting front view")
        if self.grid.dimension_type == Dimension.THREE_D:
            self.ax.view_init(0, 0)  # type: ignore
        else:
            logger.warning("Front view is only applicable for 3D grids")

    def iso_view(self):
        """Set an isometric view"""
        logger.debug("Setting isometric view")
        if self.grid.dimension_type == Dimension.THREE_D:
            self.ax.view_init(45, 45)  # type: ignore
        else:
            logger.warning("Isometric view is only applicable for 3D grids")

    def rotate_azim(self, delta_azim):
        """Rotate the 3D view around the z-axis (azimuth)."""
        if self.grid.dimension_type != Dimension.THREE_D:
            logger.warning("Cannot rotate 2D view")
            return

        # Get current rotation
        current_azim = self.ax.azim  # type: ignore

        # Calculate new rotation
        new_azim = (current_azim + delta_azim) % 360

        # Apply rotation
        self.ax.view_init(azim=new_azim)  # type: ignore

        # Store the new view (optional, for undo/redo)
        self._store_current_view()

        # Trigger a redraw
        if hasattr(self, 'gui') and self.gui:
            self.gui._safe_plot_update()
            logger.debug(f"3D view rotated to azim={new_azim}")

    def rotate_elev(self, delta_elev):
        """Rotate the 3D view around the x-axis (elevation)."""
        if self.grid.dimension_type != Dimension.THREE_D:
            logger.warning("Cannot rotate 2D view")
            return

        # Get current rotation
        current_elev = self.ax.elev  # type: ignore

        # Calculate new rotation, clamping to [-90, 90]
        new_elev = max(-90, min(90, current_elev + delta_elev))

        # Apply rotation
        self.ax.view_init(elev=new_elev)  # type: ignore

        # Store the new view (optional, for undo/redo)
        self._store_current_view()
        
        # Trigger a redraw
        if hasattr(self, 'gui') and self.gui:
            self.gui._safe_plot_update()
            logger.debug(f"3D view rotated to elev={new_elev}")

    def _store_current_view(self):
        """Store the current view in the view history"""
        if self.grid.dimension_type == Dimension.THREE_D:
            current_view = {
                'xlim': self.ax.get_xlim(),
                'ylim': self.ax.get_ylim(),
                'zlim': self.ax.get_zlim(),  # type: ignore
                'elev': self.ax.elev,  # type: ignore
                'azim': self.ax.azim  # type: ignore
            }
        else:  # TWO_D
            current_view = {
                'xlim': self.ax.get_xlim(),
                'ylim': self.ax.get_ylim()
            }
        
        # If we're not at the end of the history, truncate it
        if self.view_index < len(self.view_history) - 1:
            self.view_history = self.view_history[:self.view_index + 1]
        
        # Add current view to history
        self.view_history.append(current_view)
        self.view_index = len(self.view_history) - 1
    
    def _apply_view(self, view):
        """Apply a stored view to the axes"""
        self.ax.set_xlim(view['xlim'])
        self.ax.set_ylim(view['ylim'])
        
        if self.grid.dimension_type == Dimension.THREE_D:
            self.ax.set_zlim(view['zlim'])  # type: ignore
            self.ax.view_init(elev=view['elev'], azim=view['azim'])  # type: ignore
        
        self.ax.figure.canvas.draw_idle()

    def fit_view_to_grid(self, padding_percent=1, called_from="unknown"): # Removed capture_background flag
        """Fit the view to show the entire grid, ensuring correct scaling and padding. DOES NOT redraw."""

        logger.debug("=== DIAGNOSTIC: fit_view_to_grid (R6 No Redraw) ===")
        logger.debug(f"fit_view_to_grid called from: {called_from}")

        # [ GUI/Attribute Checks - Unchanged ]
        if not hasattr(self, 'gui') or self.gui is None: logger.error("ViewManager.fit_view_to_grid: self.gui is None! Cannot proceed."); return 1.0
        logger.info(f"  ViewManager.fit_view_to_grid: Checking self.gui (ID: {id(self.gui)})")
        if not isinstance(self.gui, SimulationGUI): logger.error(f"ViewManager.fit_view_to_grid: self.gui is not a SimulationGUI instance (Type: {type(self.gui)})! Cannot proceed."); return 1.0
        if not hasattr(self.gui, '_view_state') or not isinstance(self.gui._view_state, dict): logger.error("ViewManager.fit_view_to_grid: self.gui._view_state attribute missing or not a dict! Cannot proceed."); return 1.0
        # if not hasattr(self.gui, '_safe_plot_update') or not callable(self.gui._safe_plot_update): logger.error("ViewManager.fit_view_to_grid: self.gui._safe_plot_update method missing or not callable! Cannot proceed."); return 1.0

        # [ Flag Setting - Unchanged ]
        if hasattr(self, 'grid_visualizer') and self.grid_visualizer: self.grid_visualizer._recalculate_scaling = True; logger.debug("Set _recalculate_scaling flag to True for fit_view_to_grid.")

        # [ Logging - Unchanged ]
        logger.debug(f"Grid dimensions: {self.grid.dimensions if self.grid else 'No grid'}")
        logger.debug(f"Coordinate system grid dimensions: {self.coord_system.grid_dimensions if hasattr(self, 'coord_system') else 'No coord_system'}")
        logger.debug(f"Coordinate system scale factor BEFORE update: {self.coord_system.scale_factor if hasattr(self, 'coord_system') else 'No coord_system'}")
        logger.debug(f"Current zoom factor BEFORE fit_view_to_grid: {self.grid_visualizer._visualization_state.get('zoom_factor', 'Not set') if hasattr(self, 'grid_visualizer') else 'No grid_visualizer'}")

        if self.grid is None or self.ax is None or not hasattr(self, 'grid_visualizer') or self.grid_visualizer is None: logger.warning("Grid, axes, or grid_visualizer not initialized, cannot fit view."); return 1.0

        # [ Reset Zoom - Unchanged ]
        self.grid_visualizer._visualization_state['zoom_factor'] = 1.0
        logger.debug(f"Reset zoom_factor to 1.0 at start of fit_view_to_grid")

        # [ Calculate Corners - Unchanged ]
        grid_dims = self.grid.dimensions
        if self.grid.dimension_type == Dimension.THREE_D:
            i_max, j_max, k_max = grid_dims
            corners = [(0, 0, 0), (0, 0, k_max -1 if k_max > 0 else 0), (0, j_max -1 if j_max > 0 else 0, 0), (0, j_max -1 if j_max > 0 else 0, k_max -1 if k_max > 0 else 0), (i_max -1 if i_max > 0 else 0, 0, 0), (i_max -1 if i_max > 0 else 0, 0, k_max -1 if k_max > 0 else 0), (i_max -1 if i_max > 0 else 0, j_max -1 if j_max > 0 else 0, 0), (i_max -1 if i_max > 0 else 0, j_max -1 if j_max > 0 else 0, k_max -1 if k_max > 0 else 0)]
        else:
            i_max, j_max = grid_dims
            corners = [(0, 0), (0, j_max -1 if j_max > 0 else 0), (i_max -1 if i_max > 0 else 0, 0), (i_max -1 if i_max > 0 else 0, j_max-1 if j_max > 0 else 0)]
        display_corners = [self.coord_system.grid_to_display(corner) for corner in corners]

        if not display_corners: logger.warning("No display corners calculated, cannot set limits."); return 1.0

        # [ Padding Calculation - Unchanged ]
        node_size_at_zoom_1 = self.grid_visualizer._calculate_node_size(1.0); dpi = self.fig.dpi
        bbox = self.ax.get_window_extent().transformed(self.fig.dpi_scale_trans.inverted())
        ax_width_inches, ax_height_inches = bbox.width, bbox.height; ax_width_pixels = ax_width_inches * dpi; ax_height_pixels = ax_height_inches * dpi
        current_xlim = self.ax.get_xlim(); current_ylim = self.ax.get_ylim()
        x_data_range = current_xlim[1] - current_xlim[0] if current_xlim[1] > current_xlim[0] else 1000.0
        y_data_range = current_ylim[1] - current_ylim[0] if current_ylim[1] > current_ylim[0] else 1000.0
        pixels_per_data_x = ax_width_pixels / x_data_range if x_data_range else 1; pixels_per_data_y = ax_height_pixels / y_data_range if y_data_range else 1
        node_radius_points = np.sqrt(node_size_at_zoom_1) / 2.0; node_radius_pixels_x = node_radius_points * (dpi / 72.0); node_radius_pixels_y = node_radius_points * (dpi / 72.0)
        node_radius_data_x = node_radius_pixels_x / pixels_per_data_x if pixels_per_data_x else 0; node_radius_data_y = node_radius_pixels_y / pixels_per_data_y if pixels_per_data_y else 0
        padding_base = max(node_radius_data_x, node_radius_data_y); padding_extra_percent = padding_percent / 100.0

        # [ Calculate New Limits - Unchanged ]
        new_xlim, new_ylim, new_zlim = None, None, None
        if self.grid.dimension_type == Dimension.THREE_D:
            x_vals, y_vals, z_vals = zip(*display_corners); x_min, x_max = min(x_vals), max(x_vals); y_min, y_max = min(y_vals), max(y_vals); z_min, z_max = min(z_vals), max(z_vals)
            x_range = x_max - x_min if x_max > x_min else 1.0; y_range = y_max - y_min if y_max > y_min else 1.0; z_range = z_max - z_min if z_max > z_min else 1.0
            x_padding = padding_base + x_range * padding_extra_percent; y_padding = padding_base + y_range * padding_extra_percent; z_padding = padding_base + z_range * padding_extra_percent
            new_xlim = (x_min - x_padding, x_max + x_padding); new_ylim = (y_min - y_padding, y_max + y_padding); new_zlim = (z_min - z_padding, z_max + z_padding)
        else:
            x_vals, y_vals = zip(*display_corners); x_min, x_max = min(x_vals), max(x_vals); y_min, y_max = min(y_vals), max(y_vals)
            x_range = x_max - x_min if x_max > x_min else 1.0; y_range = y_max - y_min if y_max > y_min else 1.0
            x_padding = padding_base + x_range * padding_extra_percent; y_padding = padding_base + y_range * padding_extra_percent
            new_xlim = (x_min - x_padding, x_max + x_padding); new_ylim = (y_min - y_padding, y_max + y_padding)

        # --- Set Limits on Axes ---
        self.ax.set_xlim(new_xlim)
        self.ax.set_ylim(new_ylim)
        if new_zlim: self.ax.set_zlim(new_zlim) # type: ignore
        # ---

        # --- Update GUI view state ---
        self.gui._view_state['xlim'] = new_xlim
        self.gui._view_state['ylim'] = new_ylim
        self.gui._view_state['zlim'] = new_zlim
        self.gui._view_state['zoom_factor'] = 1.0 # Ensure zoom is reset
        logger.debug(f"Updated gui._view_state with new limits: xlim={new_xlim}, ylim={new_ylim}, zlim={new_zlim}")
        # ---

        self._store_current_view() # Store in ViewManager history

        # --- REMOVED Force Redraw ---
        # logger.debug("Calling _safe_plot_update(force=True) from fit_view_to_grid")
        # self.gui._safe_plot_update(force=True)
        # logger.debug("Returned from _safe_plot_update in fit_view_to_grid")
        # ---

        # --- REMOVED Background Capture ---

        logger.debug(f"View limits set to fit grid. Final zoom factor: {self.grid_visualizer._visualization_state['zoom_factor']}")
        self.is_zooming = False
        current_zoom = self.grid_visualizer._visualization_state.get('zoom_factor', 1.0)
        logger.debug(f"Current zoom factor AFTER fit_view_to_grid: {current_zoom}")
        return current_zoom

    def _is_view_already_fit_to_grid(self) -> bool:
        """Check if the current view is already fit to the grid."""
        if not hasattr(self, 'grid_visualizer') or not self.grid_visualizer:
            return False

        current_zoom = self.grid_visualizer._visualization_state.get('zoom_factor', 1.0)
        if not np.isclose(current_zoom, 1.0):
            logger.debug(f"_is_view_already_fit_to_grid: Zoom factor is {current_zoom:.3f}, not 1.0")
            return False

        current_xlim = self.ax.get_xlim()
        current_ylim = self.ax.get_ylim()

        # Calculate expected limits based on grid dimensions and padding
        padding_percent = 5
        base_node_size = self.grid_visualizer._base_node_size
        grid_dims = self.grid.dimensions

        if self.grid.dimension_type == Dimension.THREE_D:
            i_max, j_max, k_max = grid_dims
        else:
            i_max, j_max = grid_dims

        x_padding = base_node_size * (padding_percent / 100) + 0.5
        y_padding = base_node_size * (padding_percent / 100) + 0.5

        expected_xlim = (-0.5 - x_padding, j_max - 0.5 + x_padding)
        expected_ylim = (-0.5 - y_padding, i_max - 0.5 + y_padding)

        # Compare current and expected limits with a tolerance
        if not np.allclose(current_xlim, expected_xlim, rtol=0.01) or \
           not np.allclose(current_ylim, expected_ylim, rtol=0.01):
            logger.debug(f"_is_view_already_fit_to_grid: Limits do not match. Current xlim={current_xlim}, expected xlim={expected_xlim}, current ylim={current_ylim}, expected ylim={expected_ylim}")
            return False

        logger.debug("_is_view_already_fit_to_grid: View is already fit to grid.")
        return True

    def _bind_mouse_scroll(self, widget):
        """Bind mouse wheel events for all platforms"""
        # Windows/macOS standard mouse wheel
        widget.bind("<MouseWheel>", self._on_mousewheel, add="+")
            
        # Linux
        widget.bind("<Button-4>", self._on_mousewheel, add="+")
        widget.bind("<Button-5>", self._on_mousewheel, add="+")
        
        # macOS trackpad scrolling - bind to a different event
        # This is the key addition for horizontal scrolling support
        if hasattr(widget, 'bind_all'):
            # Try to bind to the specific trackpad event for macOS
            widget.bind("<MouseWheelEvent>", self._on_mousewheel, add="+")
            
            # Also try binding to the generic motion event with modifiers
            widget.bind("<Shift-Motion>", self._on_trackpad_motion, add="+")

    def _on_mousewheel(self, event):
        """Cross-platform mouse wheel scrolling for pan OR zoom based on modifier."""
        log_prefix = "_on_mousewheel (R6 Zoom Fix): " # Updated round

        # Check if the mouse is over the scrollable control frame
        if hasattr(self, 'gui') and self.gui and hasattr(self.gui, 'scrollable_control_frame') and isinstance(self.gui.scrollable_control_frame, ScrollableFrame):
            x, y = event.x_root, event.y_root
            widget_under_mouse = event.widget.winfo_containing(x, y)

            if widget_under_mouse is not None and self.is_child_of(widget_under_mouse, self.gui.scrollable_control_frame):
                # Mouse is over the scrollable control frame, scroll it
                if event.num == 4 or event.num == 5:  # Linux
                    delta = -1 if event.num == 4 else 1
                else:  # Windows/macOS
                    delta = -1 * (event.delta // 120 if abs(event.delta) >= 120 else event.delta)

                self.gui.scrollable_control_frame.canvas.yview_scroll(delta, "units") # type: ignore
                logger.debug(f"{log_prefix}Scrolled control panel by {delta} units")
                return "break" # Prevent event propagation

        # --- Check for Ctrl/Cmd Modifier for Zoom ---
        modifier_state = event.state
        is_ctrl_cmd_pressed = (modifier_state & 0x0004) != 0 # Control
        if platform.system() == "Darwin":
            is_ctrl_cmd_pressed = (modifier_state & 0x0008) != 0 # Command on macOS

        if is_ctrl_cmd_pressed:
            # --- Zoom Logic ---
            logger.debug(f"{log_prefix}Ctrl/Cmd pressed, performing ZOOM.")
            zoom_factor = 1.0
            if event.num == 4 or (hasattr(event, 'delta') and event.delta > 0):  # Zoom in
                zoom_factor = 0.8
            elif event.num == 5 or (hasattr(event, 'delta') and event.delta < 0):  # Zoom out
                zoom_factor = 1.25
            else:
                logger.debug(f"{log_prefix}Unrecognized scroll event for zoom.")
                return # Allow propagation if not zoom

            if abs(zoom_factor - 1.0) > 1e-4:
                logger.debug(f"{log_prefix}Applying zoom factor: {zoom_factor:.3f}")
                if hasattr(self, 'gui') and self.gui and hasattr(self.gui, 'grid_visualizer') and self.gui.grid_visualizer:
                    self.gui.grid_visualizer.zoom(zoom_factor) # Call visualizer's zoom
                else:
                    logger.warning(f"{log_prefix}Visualizer not available for zoom.")
            return "break" # Stop propagation after zoom
            # --- End Zoom Logic ---

        else:
            # --- Pan Logic (No Ctrl/Cmd) ---
            logger.debug(f"{log_prefix}No Ctrl/Cmd pressed, performing PAN.")
            delta_x = 0
            delta_y = 0
            is_horizontal = False
            if hasattr(event, 'state') and event.state & 0x0001: is_horizontal = True # Check Shift for horizontal pan hint

            if hasattr(event, 'delta_x') and hasattr(event, 'delta_y'): # Trackpad events might have separate deltas
                delta_x = event.delta_x / 60 # Adjust sensitivity as needed
                delta_y = -event.delta_y / 120 # Invert and adjust sensitivity
                logger.debug(f"{log_prefix}Trackpad pan: dx={delta_x:.2f}, dy={delta_y:.2f}")
            elif hasattr(event, 'delta'): # Standard mouse wheel
                scroll_amount = (event.delta // 120 if abs(event.delta) >= 120 else event.delta)
                if is_horizontal: delta_x = scroll_amount
                else: delta_y = -1 * scroll_amount
                logger.debug(f"{log_prefix}Wheel pan: delta={event.delta}, is_horizontal={is_horizontal} -> dx={delta_x:.2f}, dy={delta_y:.2f}")
            elif event.num == 4 or event.num == 5:  # Linux wheel
                scroll_amount = -1 if event.num == 4 else 1
                if is_horizontal: delta_x = scroll_amount
                else: delta_y = scroll_amount
                logger.debug(f"{log_prefix}Linux wheel pan: num={event.num}, is_horizontal={is_horizontal} -> dx={delta_x:.2f}, dy={delta_y:.2f}")
            else:
                logger.debug(f"{log_prefix}Not a recognized scroll event for pan.")
                return

            # Call the pan method with the calculated distances
            if hasattr(self, 'gui') and self.gui:
                pan_scale = 10 # Adjust sensitivity
                self.pan(delta_x * pan_scale, delta_y * pan_scale, controller=self.gui.controller)
                self.gui._safe_plot_update() # Redraw after pan
                logger.debug(f"{log_prefix}Panned visualization by x={delta_x * pan_scale:.1f}, y={delta_y * pan_scale:.1f} units")
            else:
                logger.warning(f"{log_prefix}GUI is not properly initialized, cannot pan")
            return "break" # Stop propagation after pan
            # --- End Pan Logic ---

    def _on_trackpad_motion(self, event):
        """Handle trackpad motion events for horizontal scrolling on macOS"""
        if hasattr(event, 'state') and event.state & 0x1:  # Check for Shift modifier
            if not hasattr(self, '_last_trackpad_pos') or self._last_trackpad_pos is None:
                self._last_trackpad_pos = (event.x, event.y)
                return

            delta_x = (event.x - self._last_trackpad_pos[0]) / 10.0
            delta_y = (event.y - self._last_trackpad_pos[1]) / 10.0
            self._last_trackpad_pos = (event.x, event.y)

            if abs(delta_x) > 0.5 or abs(delta_y) > 0.5:
                logger.debug(f"Trackpad motion: delta_x={delta_x}, delta_y={delta_y}")
                if hasattr(self, 'gui') and self.gui:
                    self.pan(delta_x * 10, -delta_y * 10, controller=self.gui.controller)
                    # --- REVERTED: Call without force ---
                    # is_stopped_or_paused = (hasattr(self.gui, '_stopped') and self.gui._stopped) or \
                    #                        (hasattr(self.gui, 'paused') and self.gui.paused)
                    # force_redraw = is_stopped_or_paused
                    # logger.debug(f"  _on_trackpad_motion: Triggering redraw (force={force_redraw})")
                    self.gui._safe_plot_update() # Call without force
                    # --- END REVERTED ---
                    logger.debug(f"Panned visualization by x={delta_x * 10}, y={-delta_y * 10} units")

    def _get_line_grid_coords(self, start_coord: Tuple[int, ...], end_coord: Tuple[int, ...]) -> List[Tuple[int, ...]]:
        """
        Generates integer grid coordinates for a line between two points using Bresenham's algorithm (or similar).
        Handles 2D and 3D cases.
        """
        coords: List[Tuple[int, ...]] = []
        dims = len(start_coord)

        if dims == 2:
            x1, y1 = start_coord[1], start_coord[0] # Use (col, row) for calculation
            x2, y2 = end_coord[1], end_coord[0]
            dx = abs(x2 - x1)
            dy = -abs(y2 - y1)
            sx = 1 if x1 < x2 else -1
            sy = 1 if y1 < y2 else -1
            err = dx + dy
            while True:
                coords.append((y1, x1)) # Append as (row, col)
                if x1 == x2 and y1 == y2: break
                e2 = 2 * err
                if e2 >= dy: err += dy; x1 += sx
                if e2 <= dx: err += dx; y1 += sy
        elif dims == 3:
            # Simple 3D line interpolation (less precise than 3D Bresenham but often sufficient)
            x1, y1, z1 = start_coord[1], start_coord[0], start_coord[2]
            x2, y2, z2 = end_coord[1], end_coord[0], end_coord[2]
            dx, dy, dz = abs(x2 - x1), abs(y2 - y1), abs(z2 - z1)
            steps = max(dx, dy, dz)
            if steps == 0: return [start_coord] # Start and end are the same

            x_inc = (x2 - x1) / steps
            y_inc = (y2 - y1) / steps
            z_inc = (z2 - z1) / steps
            x, y, z = float(x1), float(y1), float(z1)
            coords.append(start_coord) # Add start point
            for _ in range(int(steps)):
                x += x_inc; y += y_inc; z += z_inc
                new_coord = (int(round(y)), int(round(x)), int(round(z)))
                if not coords or new_coord != coords[-1]: # Avoid duplicates
                    coords.append(new_coord)
        else:
            logger.warning(f"Unsupported dimension {dims} for line algorithm.")
            return [start_coord, end_coord] # Fallback

        return coords

    def _on_mouse_drag(self, event):
        """Handle mouse drag events, routing based on the active tool or mouse mode.
        Pauses simulation before processing. Clears queues if scribble modifies grid.
        Allows interaction when paused or stopped.
        Implements scribble draw/increment/decrement, erase, and delete edges logic.
        (Round 12: Fix supports_edges check, Fix state type checks for inc/dec)
        (Round 9: Pause simulation on drag)
        (Round 11: Clear queues after scribble modification)"""
        log_prefix = "_on_mouse_drag (R12 Scribble Fixes, R11 Queue Clear): " # Updated round

        # --- Pause simulation before handling interaction ---
        if hasattr(self, 'gui') and self.gui:
            if hasattr(self, '_mouse_pressed') and self._mouse_pressed:
                self.gui._request_pause_for_interaction("Mouse Drag")
            else: return # If mouse isn't pressed, don't process drag/pause
        else:
            logger.error(f"{log_prefix}Cannot pause: self.gui reference is missing.")
            return "break"
        # ---

        try:
            x_data, y_data = self._convert_event_to_data_coords(event)
            if x_data is None or y_data is None: return "break"

            # --- Get current rule and state info ---
            rule = self.gui.controller.rule
            if rule is None: logger.error(f"{log_prefix}Rule is None, cannot process drag."); return "break"
            node_state_type = getattr(rule, 'node_state_type', StateType.BINARY)
            edge_state_type = getattr(rule, 'edge_state_type', StateType.BINARY)
            rule_supports_edges = rule.get_param('edge_initialization', 'NONE') != 'NONE'
            min_node = getattr(rule, 'min_node_state', 0.0)
            max_node = getattr(rule, 'max_node_state', 1.0)
            initial_cont_node = rule.get_param('initial_continuous_node_state', 0.1)
            min_edge = getattr(rule, 'min_edge_state', 0.0)
            max_edge = getattr(rule, 'max_edge_state', 1.0)
            initial_cont_edge = rule.get_param('initial_continuous_edge_state', 0.1)
            # ---

            # --- Route based on mouse mode ---
            current_coord = self._find_node_in_click_field(x_data, y_data)
            last_coord = getattr(self, '_last_drag_grid_coord', None)

            is_scribble_mode = self._mouse_mode in ['scribble_draw', 'scribble_increment', 'scribble_decrement', 'scribble_erase', 'scribble_delete_edges']
            valid_drag_segment = current_coord and last_coord and current_coord != last_coord

            if valid_drag_segment and is_scribble_mode:
                logger.debug(f"{log_prefix}Processing SCRIBBLE segment for mode '{self._mouse_mode}' ({last_coord} -> {current_coord})")
                if last_coord is not None and current_coord is not None:
                    coords_on_path = self._get_line_grid_coords(last_coord, current_coord)
                else:
                    logger.warning("Invalid coordinates: last_coord or current_coord is None")
                    coords_on_path = []
                modified_this_segment = False

                # --- Handle Different Scribble Modes ---
                if self._mouse_mode == 'scribble_draw': # No Modifiers
                    # Pass 1: Activate nodes
                    activated_on_path = set()
                    for i, coord in enumerate(coords_on_path):
                        if i == 0: continue
                        if not self.grid.is_valid_coord(coord): continue
                        if self._activate_node(coord):
                            self._modified_in_drag.add(coord); modified_this_segment = True; activated_on_path.add(coord)
                    # Pass 2: Add edges
                    if rule_supports_edges:
                        for i in range(len(coords_on_path) - 1):
                            node1, node2 = coords_on_path[i], coords_on_path[i+1]
                            if node1 != node2 and self._are_valid_neighbors(node1, node2) and self._is_node_active(node1) and self._is_node_active(node2):
                                edge_coords = self.grid._ordered_edge(node1, node2)
                                if edge_coords not in self.grid.edges:
                                    edge_type = getattr(rule, 'edge_state_type', StateType.BINARY)
                                    if edge_type == StateType.BINARY: edge_add_state = max_edge
                                    elif edge_type == StateType.INTEGER: edge_add_state = min_edge + 1
                                    else: edge_add_state = initial_cont_edge
                                    edge_add_state = np.clip(edge_add_state, min_edge, max_edge)
                                    if self._add_edge_if_valid(node1, node2, edge_state=edge_add_state):
                                        self._modified_in_drag.add(edge_coords); modified_this_segment = True

                elif self._mouse_mode == 'scribble_increment': # Alt/Opt
                    allow_inc_dec_nodes = node_state_type == StateType.REAL
                    allow_inc_dec_edges = edge_state_type == StateType.REAL
                    if allow_inc_dec_nodes:
                        for i, coord in enumerate(coords_on_path):
                            if i == 0: continue
                            if not self.grid.is_valid_coord(coord): continue
                            if self._increment_node(coord): self._modified_in_drag.add(coord); modified_this_segment = True
                    if rule_supports_edges and allow_inc_dec_edges:
                        for i in range(len(coords_on_path) - 1):
                            node1, node2 = coords_on_path[i], coords_on_path[i+1]
                            if node1 == node2 or not self._are_valid_neighbors(node1, node2): continue
                            if self._is_node_active(node1) and self._is_node_active(node2):
                                if self._increment_edge(node1, node2): self._modified_in_drag.add(self.grid._ordered_edge(node1, node2)); modified_this_segment = True

                elif self._mouse_mode == 'scribble_decrement': # Alt+Shift Drag
                    allow_inc_dec_nodes = node_state_type == StateType.REAL
                    allow_inc_dec_edges = edge_state_type == StateType.REAL
                    if allow_inc_dec_nodes:
                        for i, coord in enumerate(coords_on_path):
                            if i == 0: continue
                            if not self.grid.is_valid_coord(coord): continue
                            if self._decrement_node(coord): self._modified_in_drag.add(coord); modified_this_segment = True
                    if rule_supports_edges and allow_inc_dec_edges:
                        for i in range(len(coords_on_path) - 1):
                            node1, node2 = coords_on_path[i], coords_on_path[i+1]
                            if node1 == node2 or not self._are_valid_neighbors(node1, node2): continue
                            if self._decrement_edge(node1, node2): self._modified_in_drag.add(self.grid._ordered_edge(node1, node2)); modified_this_segment = True

                elif self._mouse_mode == 'scribble_erase': # Standard Erase Mode (Only Shift)
                    for coord_on_path in coords_on_path:
                        if coord_on_path == last_coord: continue
                        if not self.grid.is_valid_coord(coord_on_path): continue
                        if self._is_node_active(coord_on_path):
                            if self._erase_node(coord_on_path): self._modified_in_drag.add(coord_on_path); modified_this_segment = True

                elif self._mouse_mode == 'scribble_delete_edges': # Ctrl/Cmd
                    edges_removed_in_segment = set()
                    for coord_on_path in coords_on_path:
                        if not self.grid.is_valid_coord(coord_on_path): continue
                        edges_removed_for_node = self._remove_edges_connected_to_node(coord_on_path)
                        if edges_removed_for_node: edges_removed_in_segment.update(edges_removed_for_node)
                    if edges_removed_in_segment: self._modified_in_drag.update(edges_removed_in_segment); modified_this_segment = True

                # --- Update last drag coord and redraw/clear queues if needed ---
                self._last_drag_grid_coord = current_coord
                if modified_this_segment:
                    logger.info(f"{log_prefix}Scribble segment modified grid, clearing queues.")
                    # --- ADDED: Clear queues BEFORE redraw ---
                    self.gui._clear_computation_and_render_queues()
                    # ---
                    if self.gui.grid_visualizer:
                        plot_data = self.gui.grid_visualizer._prepare_plot_data()
                        if plot_data: self.gui.grid_visualizer.update_visualization_state(invalidate_blit_cache=True, **plot_data)
                    self.gui._safe_plot_update(force=True)
                    logger.debug("    Forced redraw after modification.")

            # --- Other Modes (Panning, Lasso, Tools) ---
            elif self._mouse_mode == 'lasso_select': self._handle_lasso_drag(x_data, y_data)
            elif self._mouse_mode == 'add_edge_action': self._handle_add_edge_drag(x_data, y_data)
            elif self._mouse_mode == 'erase_action': self._handle_erase_drag(x_data, y_data) # This might modify grid
            elif self._mouse_mode == 'del_edge_action': self._handle_del_edge_drag(x_data, y_data) # This might modify grid
            elif self._mouse_mode == 'panning':
                # Panning doesn't modify grid state, no queue clear needed
                canvas_dx = (x_data - (self.pan_start_x if self.pan_start_x is not None else x_data))
                canvas_dy = (y_data - (self.pan_start_y if self.pan_start_y is not None else y_data))
                self.pan_velocity_x = canvas_dx * self.pan_sensitivity; self.pan_velocity_y = -canvas_dy * self.pan_sensitivity
                if hasattr(self, 'gui') and self.gui:
                    self.pan(self.pan_velocity_x, self.pan_velocity_y, controller=self.gui.controller)
                    self.gui._safe_plot_update() # Redraw after pan
                else: logger.warning("GUI is not properly initialized, cannot pan")
                self.pan_start_x = x_data; self.pan_start_y = y_data

        except Exception as e:
            logger.error(f"{log_prefix}Error during mouse drag processing (Mode: {getattr(self, '_mouse_mode', 'N/A')}): {e}")
            logger.error(traceback.format_exc())
        return "break" # Always break

    def _animate_pan(self):
        """Animate the panning motion with deceleration after mouse release."""
        # logger.debug(f"_animate_pan: vx={self.pan_velocity_x:.3f}, vy={self.pan_velocity_y:.3f}") # Reduce noise

        velocity_threshold = 0.1 # Increased threshold slightly
        if abs(self.pan_velocity_x) > velocity_threshold or abs(self.pan_velocity_y) > velocity_threshold:
            # Apply the pan based on the current velocity
            self.pan(self.pan_velocity_x, self.pan_velocity_y, controller=self.gui.controller)

            # --- REVERTED: Call without force ---
            # is_stopped_or_paused = (hasattr(self.gui, '_stopped') and self.gui._stopped) or \
            #                        (hasattr(self.gui, 'paused') and self.gui.paused)
            # force_redraw = is_stopped_or_paused
            # ---

            # Trigger redraw AFTER panning
            if hasattr(self.gui, '_safe_plot_update'):
                # --- REVERTED: Call without force ---
                self.gui._safe_plot_update() # Call without force
                # ---
            else:
                 logger.warning("Cannot trigger plot update from _animate_pan")

            # Apply deceleration to the velocity
            self.pan_velocity_x *= self.deceleration # Use updated deceleration
            self.pan_velocity_y *= self.deceleration # Use updated deceleration

            # Schedule the next frame of the animation
            self.pan_animation_id = self.gui.root.after(16, self._animate_pan) # ~60 FPS
        else:
            # Panning animation has effectively stopped
            self.pan_velocity_x = 0
            self.pan_velocity_y = 0
            self.pan_animation_id = None
            self.panning = False # Ensure panning flag is off
            logger.debug("Panning animation stopped naturally.")
            
    def pan(self, dx, dy, dz=0, controller=None):
        """Pan the view by a given offset (in display coordinates)."""
        log_prefix = f"ViewManager.pan(dx={dx:.2f}, dy={dy:.2f}, dz={dz:.2f}): "
        # logger.debug(log_prefix + "ENTRY") # Reduce noise

        if controller is None: controller = self.controller
        if controller is None: logger.warning(f"{log_prefix}Controller is None, cannot pan"); return
        if self.grid is None: logger.warning(f"{log_prefix}Grid is None, cannot pan"); return
        if self.coord_system is None: logger.warning(f"{log_prefix}Coordinate system is None, cannot pan"); return

        x_min, x_max = self.ax.get_xlim()
        y_min, y_max = self.ax.get_ylim()
        new_x_min = x_min - dx
        new_x_max = x_max - dx
        new_y_min = y_min - dy
        new_y_max = y_max - dy
        new_z_min, new_z_max = None, None

        self.ax.set_xlim(new_x_min, new_x_max)
        self.ax.set_ylim(new_y_min, new_y_max)
        # logger.debug(f"{log_prefix}Set axes limits: xlim=({new_x_min:.2f}, {new_x_max:.2f}), ylim=({new_y_min:.2f}, {new_y_max:.2f})") # Reduce noise

        if self.grid.dimension_type == Dimension.THREE_D and hasattr(self.ax, 'get_zlim'):
            z_min, z_max = self.ax.get_zlim()
            new_z_min = z_min - dz
            new_z_max = z_max - dz
            self.ax.set_zlim(new_z_min, new_z_max) # type: ignore
            # logger.debug(f"{log_prefix}Set zlim=({new_z_min:.2f}, {new_z_max:.2f})") # Reduce noise

        # --- Update GUI view state ---
        if hasattr(self.gui, '_view_state'):
            self.gui._view_state['xlim'] = (new_x_min, new_x_max)
            self.gui._view_state['ylim'] = (new_y_min, new_y_max)
            if new_z_min is not None and new_z_max is not None:
                self.gui._view_state['zlim'] = (new_z_min, new_z_max)
            # logger.debug(f"{log_prefix}Updated gui._view_state with new limits.") # Reduce noise
        else:
            logger.error(f"{log_prefix}Cannot update gui._view_state: Attribute not found.")
        # ---

        # --- CRITICAL: Call _safe_plot_update AFTER updating limits/state ---
        # --- REVERTED: Call without force ---
        if hasattr(self, 'gui') and self.gui and hasattr(self.gui, '_safe_plot_update'):
            # is_stopped_or_paused = (hasattr(self.gui, '_stopped') and self.gui._stopped) or \
            #                        (hasattr(self.gui, 'paused') and self.gui.paused)
            # force_redraw = is_stopped_or_paused
            # logger.debug(f"{log_prefix}Calling _safe_plot_update (force={force_redraw}).") # Reduce noise
            self.gui._safe_plot_update() # Call without force
        else:
            logger.warning(f"{log_prefix}Cannot trigger plot update.")
        # logger.debug(f"{log_prefix}EXIT") # Reduce noise

    def zoom(self, factor):
        """Zoom the view by the given factor, updating axes limits and view state."""


        log_prefix = f"ViewManager.zoom(factor={factor:.2f}): "
        logger.debug(log_prefix + "ENTRY")

        if not hasattr(self, 'grid_visualizer') or self.grid_visualizer is None:
            logger.warning(f"{log_prefix}GridVisualizer not initialized, cannot zoom.")
            return self.grid_visualizer._visualization_state.get('zoom_factor', 1.0) if hasattr(self, 'grid_visualizer') and self.grid_visualizer else 1.0

        logger.debug(f"{log_prefix}Using grid_visualizer instance ID: {id(self.grid_visualizer)}")

        # --- Set flags BEFORE updating state ---
        self.is_zooming = True
        self.grid_visualizer._recalculate_scaling = True
        logger.debug(f"{log_prefix}Set flags: is_zooming=True, _recalculate_scaling=True.")
        # ---

        if self.grid is None:
            logger.warning(f"{log_prefix}Grid object is None")
            self.is_zooming = False; self.grid_visualizer._recalculate_scaling = False
            return self.grid_visualizer._visualization_state.get('zoom_factor', 1.0) if hasattr(self, 'grid_visualizer') and self.grid_visualizer else 1.0

        # --- Calculate New Zoom and Limits ---
        current_zoom = self.grid_visualizer._visualization_state.get('zoom_factor', 1.0)
        # --- MODIFIED: Update zoom factor calculation ---
        # The factor passed in (0.8 for in, 1.25 for out) directly represents
        # the change in view size. The internal zoom factor should track the
        # inverse of this cumulative effect relative to the base view (zoom=1.0).
        # So, if factor is 0.8 (zoom in), the internal zoom factor should increase.
        # If factor is 1.25 (zoom out), the internal zoom factor should decrease.
        # Let's adjust how new_zoom is calculated based on the factor's meaning.
        # If factor < 1 (zoom in), new_zoom = current_zoom / factor
        # If factor > 1 (zoom out), new_zoom = current_zoom / factor
        # This seems counter-intuitive, let's rethink.
        # Let the internal `zoom_factor` represent the scaling applied to the *base* view size.
        # zoom_factor = 1.0 -> base view
        # zoom_factor = 0.5 -> zoomed in 2x (view size is half)
        # zoom_factor = 2.0 -> zoomed out 2x (view size is double)
        # The `factor` argument represents the *multiplier* for the current view size.
        # So, new_view_size = current_view_size * factor
        # And new_zoom_factor = current_zoom_factor * factor
        new_zoom = current_zoom * factor # Keep this calculation for the internal state
        # --- END MODIFIED ---
        logger.debug(f"{log_prefix}Zoom factors: Current={current_zoom:.3f}, New={new_zoom:.3f}")

        x_min, x_max = self.ax.get_xlim()
        y_min, y_max = self.ax.get_ylim()
        logger.debug(f"{log_prefix}Current limits: xlim=({x_min:.2f}, {x_max:.2f}), ylim=({y_min:.2f}, {y_max:.2f})")

        x_center = (x_min + x_max) / 2
        y_center = (y_min + y_max) / 2

        # --- CORRECTED: Calculate new width/height by MULTIPLYING by factor ---
        new_x_width = (x_max - x_min) * factor
        new_y_width = (y_max - y_min) * factor
        # --- END CORRECTION ---

        new_x_min = x_center - new_x_width / 2
        new_x_max = x_center + new_x_width / 2
        new_y_min = y_center - new_y_width / 2
        new_y_max = y_center + new_y_width / 2
        new_z_min, new_z_max = None, None # Initialize z limits

        if self.grid.dimension_type == Dimension.THREE_D and hasattr(self.ax, 'get_zlim'):
            z_min, z_max = self.ax.get_zlim()
            logger.debug(f"{log_prefix}Current zlim=({z_min:.2f}, {z_max:.2f})")
            z_center = (z_min + z_max) / 2
            # --- CORRECTED: Calculate new width/height by MULTIPLYING by factor ---
            new_z_width = (z_max - z_min) * factor
            # --- END CORRECTION ---
            new_z_min = z_center - new_z_width / 2
            new_z_max = z_center + new_z_width / 2

        # --- Apply New Limits Directly to Axes ---
        self.ax.set_xlim(new_x_min, new_x_max)
        self.ax.set_ylim(new_y_min, new_y_max)
        logger.debug(f"{log_prefix}Applied new limits to axes: xlim=({new_x_min:.2f}, {new_x_max:.2f}), ylim=({new_y_min:.2f}, {new_y_max:.2f})")
        if new_z_min is not None and new_z_max is not None:
            self.ax.set_zlim(new_z_min, new_z_max)
            logger.debug(f"{log_prefix}Applied new zlim=({new_z_min:.2f}, {new_z_max:.2f})")
        # ---

        # --- Update GUI's view state AFTER setting axes limits ---
        if hasattr(self.gui, '_view_state'):
            self.gui._view_state['zoom_factor'] = new_zoom # Store the updated internal zoom factor
            self.gui._view_state['xlim'] = (new_x_min, new_x_max)
            self.gui._view_state['ylim'] = (new_y_min, new_y_max)
            if new_z_min is not None and new_z_max is not None:
                self.gui._view_state['zlim'] = (new_z_min, new_z_max)
            logger.debug(f"{log_prefix}Updated gui._view_state: zoom={new_zoom:.3f}, xlim=({new_x_min:.2f}, {new_x_max:.2f}), ...")
        else:
            logger.error(f"{log_prefix}Cannot update gui._view_state: Attribute not found.")
        # ---

        # --- Update Visualizer's internal state ---
        self.grid_visualizer._visualization_state['zoom_factor'] = new_zoom
        logger.debug(f"{log_prefix}Updated visualizer state zoom_factor to {new_zoom:.3f}")
        # ---

        # --- Schedule plot update ---
        if hasattr(self, 'gui') and self.gui and hasattr(self.gui, '_safe_plot_update'):
            # Schedule the update with force=True to ensure scaling recalculation is used
            self.gui.root.after(0, lambda: self.gui._safe_plot_update(force=True))
            logger.debug(f"{log_prefix}Scheduled forced redraw after zoom.")
        else:
            logger.warning(f"{log_prefix}gui._safe_plot_update not found, cannot update plot.")
        # ---

        # --- Reset flags AFTER scheduling update ---
        self.is_zooming = False
        # ---

        logger.debug(f"{log_prefix}EXIT - Returning new zoom factor: {new_zoom:.3f}")
        return self.grid_visualizer._visualization_state.get('zoom_factor', 1.0)

    def rotate_3d(self, delta_azim, delta_elev):
        """Rotate the 3D view"""
        if self.grid.dimension_type != Dimension.THREE_D:
            logger.warning("Cannot rotate 2D view")
            return
        
        # Get current rotation
        current_azim = self.ax.azim  # type: ignore
        current_elev = self.ax.elev  # type: ignore
        
        # Calculate new rotation
        new_azim = (current_azim + delta_azim) % 360
        new_elev = max(-90, min(90, current_elev + delta_elev))
        
        # Apply rotation
        self.ax.view_init(elev=new_elev, azim=new_azim)  # type: ignore
        
        # Store the new view
        self._store_current_view()
        
        # Redraw
        self.ax.figure.canvas.draw_idle()
        logger.debug(f"3D view rotated to azim={new_azim}, elev={new_elev}")
    
    def undo_view_change(self):
        """Undo the last view change"""
        if self.view_index > 0:
            self.view_index -= 1
            self._apply_view(self.view_history[self.view_index])
            logger.debug("Undid view change")
    
    def redo_view_change(self):
        """Redo the last undone view change"""
        if self.view_index < len(self.view_history) - 1:
            self.view_index += 1
            self._apply_view(self.view_history[self.view_index])
            logger.debug("Redid view change")
                
    def reset_view(self):
        """Reset the view to show the entire grid"""
        if hasattr(self, 'view_manager') and self:
            self.fit_view_to_grid(called_from="reset_view_button") # Use ViewManager

            # --- MODIFIED: Access blitting_manager via grid_visualizer ---
            # Invalidate blitting cache
            if hasattr(self, 'grid_visualizer') and self.grid_visualizer:
                self.grid_visualizer.blitting_manager.invalidate_cache()
            else:
                logger.warning("GridVisualizer not available, cannot invalidate blit cache.")
            # ---

            # Trigger a full redraw using _safe_plot_update
            if hasattr(self, 'gui') and self.gui and hasattr(self.gui, '_safe_plot_update'):
                self.gui._safe_plot_update(force=True)
            else:
                logger.warning("gui._safe_plot_update not found, cannot update plot")
            logger.debug("View reset to show entire grid")
        else:
            logger.warning("ViewManager not initialized, cannot reset view")

    def fit_view_to_shape(self, top_left, size, padding_percent=10):
        """Fit the view to show a specific shape"""
        # Calculate bottom right
        if self.grid.dimension_type == Dimension.THREE_D:
            i_start, j_start, k_start = top_left
            # --- CORRECTED: Size is likely per dimension, not a single value ---
            # Assuming 'size' might be a tuple or list [width, height, depth]
            if isinstance(size, (int, float)): # If single value, assume cube
                size_tuple = (size, size, size)
            elif len(size) == 3:
                size_tuple = size
            else: # Fallback or error
                logger.warning(f"Invalid size '{size}' for 3D shape fit, assuming cube of size 5.")
                size_tuple = (5, 5, 5)
            bottom_right = (i_start + size_tuple[0], j_start + size_tuple[1], k_start + size_tuple[2])
            # ---
        else:  # TWO_D
            i_start, j_start = top_left
            # --- CORRECTED: Size handling for 2D ---
            if isinstance(size, (int, float)): # If single value, assume square
                size_tuple = (size, size)
            elif len(size) == 2:
                size_tuple = size
            else: # Fallback or error
                logger.warning(f"Invalid size '{size}' for 2D shape fit, assuming square of size 5.")
                size_tuple = (5, 5)
            bottom_right = (i_start + size_tuple[0], j_start + size_tuple[1])
            # ---

        # Convert to display coordinates
        top_left_display = self.coord_system.grid_to_display(top_left)
        bottom_right_display = self.coord_system.grid_to_display(bottom_right)

        # Calculate the base node size (before any zoom scaling)
        # --- Use GridVisualizer's method ---
        base_node_size = self.grid_visualizer._calculate_base_node_size() if self.grid_visualizer else GlobalSettings.Visualization.NODE_SIZE * 100
        # ---

        # Calculate bounds
        if self.grid.dimension_type == Dimension.THREE_D:
            x_min, y_min, z_min = top_left_display # type: ignore
            x_max, y_max, z_max = bottom_right_display # type: ignore

            # Add padding based on node size
            x_padding = base_node_size * padding_percent / 100.0
            y_padding = base_node_size * padding_percent / 100.0
            z_padding = base_node_size * padding_percent / 100.0

            # Set limits
            self.ax.set_xlim(x_min - x_padding, x_max + x_padding)
            self.ax.set_ylim(y_min - y_padding, y_max + y_padding)
            self.ax.set_zlim(z_min - z_padding, z_max + z_padding)  # type: ignore
        else:  # TWO_D
            x_min, y_min = top_left_display # type: ignore
            x_max, y_max = bottom_right_display # type: ignore

            # Add padding based on node size
            x_padding = base_node_size * padding_percent / 100.0
            y_padding = base_node_size * padding_percent / 100.0

            # Set limits
            self.ax.set_xlim(x_min - x_padding, x_max + x_padding)
            self.ax.set_ylim(y_min - y_padding, y_max + y_padding)

        # Store the new view
        self._store_current_view() # Corrected call

        # Redraw
        self.ax.figure.canvas.draw_idle()
        logger.debug(f"View fitted to shape at {top_left} with size {size}")
        # --- ADDED: Invalidate blitting cache ---
        if self.grid_visualizer:
            self.grid_visualizer.blitting_manager.invalidate_cache()
        # ---
   
    def set_bounds(self, x_min, x_max, y_min, y_max, z_min=None, z_max=None):
        """Set the view bounds directly."""
        self.ax.set_xlim(x_min, x_max)
        self.ax.set_ylim(y_min, y_max)
        if self.grid.dimension_type == Dimension.THREE_D and z_min is not None and z_max is not None:
            self.ax.set_zlim(z_min, z_max)
        self._store_current_view()
        self.ax.figure.canvas.draw_idle()
        logger.debug(f"View bounds set to: x=({x_min}, {x_max}), y=({y_min}, {y_max}), z=({z_min}, {z_max})" if z_min is not None else "")
                                  
    def _update_scroll_bindings(self):
        """Update scroll bindings when new widgets are added"""
        if hasattr(self, 'control_panel') and not self._tk_destroyed:
            #self._bind_mousewheel() # REMOVED
            # Schedule next update
            self.gui.root.after(1000, self._update_scroll_bindings)

    def _on_frame_configure(self, event=None):
        """Reset the scroll region to encompass the inner frame"""
        # CRITICAL FIX: Use self.gui.scrollable_control_frame
        if hasattr(self.gui, 'scrollable_control_frame') and self.gui.scrollable_control_frame:
            self.gui.scrollable_control_frame.canvas.configure(scrollregion=self.gui.scrollable_control_frame.canvas.bbox("all")) # type: ignore

    def _bound_to_mousewheel(self, event):
        """Bind mousewheel when mouse enters the frame"""
        # CRITICAL FIX: Use self.gui.scrollable_control_frame
        if hasattr(self.gui, 'scrollable_control_frame') and self.gui.scrollable_control_frame:
            self.gui.scrollable_control_frame.canvas.bind_all("<MouseWheel>",  # type: ignore
                lambda e: self.gui.scrollable_control_frame.canvas.yview_scroll(int(-1*(e.delta/120)), "units")) # type: ignore

    def _unbound_to_mousewheel(self, event):
        """Unbind mousewheel when mouse leaves the frame"""
        # CRITICAL FIX: Use self.gui.scrollable_control_frame
        if hasattr(self.gui, 'scrollable_control_frame') and self.gui.scrollable_control_frame:
            self.gui.scrollable_control_frame.canvas.unbind_all("<MouseWheel>") # type: ignore
            
    def is_child_of(self, widget, parent):
        """Check if widget is a child of parent"""
        if widget == parent:
            return True
        try:
            return self.is_child_of(widget.master, parent)
        except AttributeError:
            return False

    def _toggle_node(self, node_coords):
        """Toggle a node state based on rule type (binary, integer, real), using visibility threshold.
           Clears queues on successful modification.
           (Round 3: Use visibility threshold, respect min/max)
           (Round 14: Clear queues on modification)"""
        success = False
        log_prefix = f"_toggle_node([{node_coords}] R14): " # Updated round
        logger.debug(f"{log_prefix}Entering.")

        if self.gui.grid is None or self.gui.controller is None or self.gui.controller.rule is None:
            logger.error(f"{log_prefix}Grid, Controller, or Rule is None.")
            return False

        rule = self.gui.controller.rule
        node_idx = _ravel_multi_index(np.array(node_coords), self.grid.dimensions)

        self.gui._push_grid_state_to_undo(f"Toggle Node {node_coords}")

        try:
            current_node_state = self.grid.grid_array.ravel()[node_idx]
            new_node_state = current_node_state # Default to no change

            # --- Get Rule State Info ---
            node_type = getattr(rule, 'node_state_type', StateType.BINARY)
            min_node = getattr(rule, 'min_node_state', 0.0)
            max_node = getattr(rule, 'max_node_state', 1.0)
            initial_cont_node = rule.get_param('initial_continuous_node_state', 0.1)
            visibility_threshold = GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD
            # ---

            # --- Use visibility threshold to check if currently "active" ---
            is_currently_active = current_node_state > visibility_threshold

            if not is_currently_active:
                # Activate node
                if node_type == StateType.BINARY or node_type == StateType.INTEGER:
                    new_node_state = max_node if node_type == StateType.BINARY else min_node + 1
                else: # REAL
                    new_node_state = initial_cont_node # Use initial continuous state
                new_node_state = np.clip(new_node_state, min_node, max_node) # Ensure within bounds
                logger.debug(f"{log_prefix}Activating node {node_coords} to {new_node_state:.2f}")
            else:
                # Deactivate node (set to minimum defined by rule)
                new_node_state = min_node
                logger.debug(f"{log_prefix}Deactivating node {node_coords} to {new_node_state:.2f}")

            # Apply the state change if it actually changed
            if not np.isclose(new_node_state, current_node_state):
                try:
                    if self.grid.set_node_state(node_idx, new_node_state):
                        success = True
                        logger.debug(f"{log_prefix}Node {node_coords} toggled to state {new_node_state:.2f}")
                        # --- ADDED: Clear queues AFTER successful state change ---
                        logger.info(f"{log_prefix}Grid modified by toggle, clearing queues.")
                        self.gui._clear_computation_and_render_queues()
                        # ---
                        if hasattr(self.gui, '_safe_plot_update'):
                            logger.debug(f"{log_prefix}Triggering FORCED plot update after toggle.")
                            self.gui._safe_plot_update(force=True)
                    else:
                        logger.error(f"{log_prefix}Failed to set node state for {node_coords}")
                        self.gui._pop_undo_if_match(f"Toggle Node {node_coords}")
                except Exception as e_set_state:
                    logger.error(f"{log_prefix}EXCEPTION during grid.set_node_state for index {node_idx}: {e_set_state}")
                    logger.error(traceback.format_exc())
                    self.gui._pop_undo_if_match(f"Toggle Node {node_coords}")
                    success = False
            else:
                logger.debug(f"{log_prefix}Node state unchanged, popping undo.")
                self.gui._pop_undo_if_match(f"Toggle Node {node_coords}") # Pop if no change occurred
                success = True # Considered successful as no change was needed

        except Exception as e_outer:
             logger.error(f"{log_prefix}Outer exception in _toggle_node: {e_outer}")
             logger.error(traceback.format_exc())
             self.gui._pop_undo_if_match(f"Toggle Node {node_coords}")
             success = False
        finally:
            logger.debug(f"{log_prefix}Exiting (Success: {success}).")
        return success

    def _remove_node_edges(self, node_coords):
        """Remove all edges connected to a node."""
        if self.grid is None:
            return
        
        # Convert node_coords to 1D index
        node_idx = _ravel_multi_index(np.array(node_coords), self.grid.dimensions)
        
        # Find all edges connected to this node
        edges_to_remove = []
        for edge in self.grid.edges:
            # Check if the node is part of this edge
            node1_coords, node2_coords = edge
            node1_idx = _ravel_multi_index(np.array(node1_coords), self.grid.dimensions)
            node2_idx = _ravel_multi_index(np.array(node2_coords), self.grid.dimensions)
            
            if node1_idx == node_idx or node2_idx == node_idx:
                edges_to_remove.append(edge)
                logger.debug(f"_remove_node_edges: Edge to remove: {edge}") # ADDED
        
        # Remove the edges
        for edge in edges_to_remove:
            self.grid.edges.remove(edge)
            # Also remove from edge_states if it exists there
            if edge in self.grid.edge_states:
                del self.grid.edge_states[edge]
                logger.debug(f"_remove_node_edges: Edge state removed for: {edge}") # ADDED
        
        logger.debug(f"Removed {len(edges_to_remove)} edges connected to node {node_coords}") # ADDED
       
    def _find_edge_at_position(self, x_data: float, y_data: float) -> Optional[Tuple[Tuple[int, ...], Tuple[int, ...]]]:
        """Find the edge closest to the given display coordinates."""
        if self.grid is None or not self.grid.edges:
            return None

        min_dist_sq = float('inf')
        closest_edge_coords: Optional[Tuple[Tuple[int, ...], Tuple[int, ...]]] = None

        # Define a click tolerance based on current scaling
        # Use half the node spacing as a base tolerance in data coordinates
        click_tolerance = self.coord_system.scale_factor * 0.25 # Tolerance: 1/4 of node spacing
        click_tolerance_sq = click_tolerance ** 2

        # Iterate through a copy of the edges
        edges_to_check = list(self.grid.edges) # Check against current grid edges

        for edge_coords in edges_to_check:
            node1_coords, node2_coords = edge_coords
            node1_idx = _ravel_multi_index(np.array(node1_coords), self.grid.dimensions)
            node2_idx = _ravel_multi_index(np.array(node2_coords), self.grid.dimensions)

            # Get display coordinates from the visualizer's state if possible, else calculate
            # This assumes node positions are up-to-date in the visualizer state
            node_positions = self.grid_visualizer._visualization_state.get('node_positions', {}) # Use cached positions if available
            node1_display = node_positions.get(node1_idx)
            node2_display = node_positions.get(node2_idx)

            # If positions not cached or nodes not visible, calculate them
            if node1_display is None: node1_display = self.coord_system.grid_to_display(node1_coords)
            if node2_display is None: node2_display = self.coord_system.grid_to_display(node2_coords)

            # --- Handle different dimensions ---
            if self.grid.dimension_type == Dimension.THREE_D:
                # For 3D, project edge onto the view plane? Or calculate 3D distance?
                # Simple approach: Use 2D distance for now, might need refinement
                dist_sq = self._distance_to_line_segment_sq(
                    x_data, y_data,
                    node1_display[0], node1_display[1],
                    node2_display[0], node2_display[1]
                )
            else: # 2D
                dist_sq = self._distance_to_line_segment_sq(
                    x_data, y_data,
                    node1_display[0], node1_display[1],
                    node2_display[0], node2_display[1]
                )
            # ---

            if dist_sq < min_dist_sq:
                min_dist_sq = dist_sq
                closest_edge_coords = edge_coords # Store the coordinate tuple

        # Check if the closest edge is within tolerance
        if closest_edge_coords is not None and min_dist_sq <= click_tolerance_sq:
            logger.debug(f"Found edge {closest_edge_coords} near click (Dist: {min_dist_sq**0.5:.2f}, Tol: {click_tolerance:.2f})")
            return closest_edge_coords
        else:
            # logger.debug(f"No edge found within tolerance (Min Dist: {min_dist_sq**0.5:.2f}, Tol: {click_tolerance:.2f})") # Reduce noise
            return None

    def _distance_to_line_segment_sq(self, px: float, py: float, x1: float, y1: float, x2: float, y2: float) -> float:
        """Calculate the squared distance from a point (px, py) to a line segment ((x1,y1), (x2,y2))."""
        line_len_sq = (x2 - x1)**2 + (y2 - y1)**2
        if line_len_sq == 0: # Segment is a point
            return (px - x1)**2 + (py - y1)**2

        # Project point onto the line containing the segment
        # Parameter t represents position along the line (0=start, 1=end)
        t = ((px - x1) * (x2 - x1) + (py - y1) * (y2 - y1)) / line_len_sq
        t = max(0, min(1, t)) # Clamp t to the segment [0, 1]

        # Coordinates of the closest point on the segment
        closest_x = x1 + t * (x2 - x1)
        closest_y = y1 + t * (y2 - y1)

        # Calculate squared distance
        dx = px - closest_x
        dy = py - closest_y
        return dx*dx + dy*dy

    def _erase_node(self, node_coords: Tuple[int, ...]) -> bool:
        """Sets a node to inactive (state 0) and removes its connected edges.
           Clears queues on successful modification.
           (Round 14: Clear queues on modification)"""
        log_prefix = f"_erase_node([{node_coords}] R14): " # Updated round
        if self.grid is None:
            logger.warning(f"{log_prefix}Grid is None.")
            return False

        if not self.grid.is_valid_coord(node_coords):
            logger.warning(f"{log_prefix}Invalid coordinates {node_coords}.")
            return False

        node_idx = _ravel_multi_index(np.array(node_coords), self.grid.dimensions)
        modified = False

        if self.grid.grid_array.ravel()[node_idx] > 1e-6: # Check if node is currently active enough to erase
            if self.grid.set_node_state(node_idx, 0.0):
                logger.debug(f"{log_prefix}Erased node {node_coords} (set state to 0).")
                modified = True
                # --- ADDED: Clear queues AFTER successful state change ---
                logger.info(f"{log_prefix}Grid modified by erase, clearing queues.")
                self.gui._clear_computation_and_render_queues()
                # ---
                if self.grid_visualizer:
                    plot_data = self.grid_visualizer._prepare_plot_data()
                    if plot_data:
                         self.grid_visualizer.update_visualization_state(invalidate_blit_cache=True, **plot_data)
                         logger.debug(f"{log_prefix}Updated visualizer state after erasing node.")
                    else: logger.warning(f"{log_prefix}Failed to prepare plot data after erasing node.")

                # Trigger non-forced redraw AFTER clearing queues
                if hasattr(self.gui, '_safe_plot_update'):
                    logger.debug(f"{log_prefix}Triggering plot update after erase.")
                    self.gui._safe_plot_update() # Call without force=True
            else:
                logger.error(f"{log_prefix}Failed to set node state to 0 for {node_coords}.")
        else:
            logger.debug(f"{log_prefix}Node {node_coords} already inactive, no erase action needed.")

        return modified

    def _get_edge(self, node1_coords, node2_coords):
        """Return a consistently ordered tuple representing an edge."""
        return (node1_coords, node2_coords) if node1_coords < node2_coords else (node2_coords, node1_coords)

    def _are_valid_neighbors(self, node1_coords, node2_coords):
        """Check if two nodes are valid neighbors based on the grid's neighborhood type.
        (Round 34: Debug edge connection with detailed logging)"""
        log_prefix = "_are_valid_neighbors (R34 Debug): "
        logger.debug(f"{log_prefix}Checking if {node1_coords} and {node2_coords} are valid neighbors")
        
        if self.grid is None:
            logger.debug(f"{log_prefix}Grid is None")
            return False
        
        # Convert coordinates to indices
        node1_idx = _ravel_multi_index(np.array(node1_coords), self.grid.dimensions)
        node2_idx = _ravel_multi_index(np.array(node2_coords), self.grid.dimensions)
        logger.debug(f"{log_prefix}Node indices: {node1_idx}, {node2_idx}")
        
        # Get valid neighbors for node1
        valid_neighbors = self.grid.get_neighbors(node1_idx, self.coord_system)
        logger.debug(f"{log_prefix}Valid neighbors for {node1_coords} (idx {node1_idx}): {valid_neighbors}")
        
        # Check if node2 is a valid neighbor of node1
        is_valid = node2_idx in valid_neighbors
        logger.debug(f"{log_prefix}Is valid neighbor: {is_valid}")
        return is_valid

    def _distance_to_line(self, point_x, point_y, line_x1, line_y1, line_x2, line_y2):
        """Calculate the distance from a point to a line segment."""
        # Calculate the length of the line segment
        line_length = np.sqrt((line_x2 - line_x1)**2 + (line_y2 - line_y1)**2)
        
        if line_length == 0:
            # The line segment is just a point, return the distance to that point
            return np.sqrt((point_x - line_x1)**2 + (point_y - line_y1)**2)
        
        # Calculate the parameter t that represents the position of the closest point on the line
        t = ((point_x - line_x1) * (line_x2 - line_x1) + (point_y - line_y1) * (line_y2 - line_y1)) / line_length**2
        
        # If t is not within the line segment, clamp it to the endpoints
        t = max(0, min(1, t))
        
        # Calculate the coordinates of the closest point on the line
        closest_x = line_x1 + t * (line_x2 - line_x1)
        closest_y = line_y1 + t * (line_y2 - line_y1)
        
        # Calculate the distance from the point to the closest point on the line
        distance = np.sqrt((point_x - closest_x)**2 + (point_y - closest_y)**2)
        
        return distance

    def _convert_event_to_data_coords(self, event):
        """Convert event coordinates to data coordinates, handling both Tkinter and Matplotlib events."""
        # Check if this is a Tkinter event or a matplotlib event
        is_tkinter_event = not hasattr(event, 'button') and not hasattr(event, 'inaxes')
        logger.debug(f"_convert_event_to_data_coords: is_tkinter_event = {is_tkinter_event}") # ADDED

        if not is_tkinter_event and hasattr(event, 'xdata') and hasattr(event, 'ydata'):
            # This is a matplotlib event with valid data coordinates
            if event.xdata is not None and event.ydata is not None:
                x_data, y_data = event.xdata, event.ydata
                logger.debug(f"_convert_event_to_data_coords: Matplotlib event - x_data: {x_data}, y_data: {y_data}") # ADDED
            else:
                # Event occurred outside the axes
                logger.debug("_convert_event_to_data_coords: Matplotlib event outside axes") # ADDED
                return None, None
        else:
            # This is a Tkinter event
            # Convert Tkinter event coordinates to data coordinates
            if not hasattr(self, 'gui') or not self.gui or not hasattr(self.gui, 'canvas') or not self.gui.canvas:
                logger.warning("Cannot convert Tkinter event to data coordinates: gui or canvas not available")
                return None, None
                    
            # Get the canvas widget
            canvas_widget = self.gui.canvas.get_tk_widget()
            
            # Get canvas dimensions
            canvas_width = canvas_widget.winfo_width()
            canvas_height = canvas_widget.winfo_height()

            # Log the canvas coordinates
            logger.debug(f"_convert_event_to_data_coords: Tkinter event - Canvas coords: ({event.x}, {event.y}), Canvas size: ({canvas_width}, {canvas_height})") # ADDED

            # CRITICAL FIX: Use the correct transformation from canvas to data coordinates
            # First, convert canvas coordinates to figure coordinates
            figure = self.fig
            canvas = self.gui.canvas
            
            # Get the figure size in pixels
            figure_width_px = figure.bbox.width
            figure_height_px = figure.bbox.height
            
            # Calculate the position of the axes in the figure (in pixels)
            bbox = self.ax.get_position()
            axes_left = bbox.x0 * figure_width_px
            axes_bottom = bbox.y0 * figure_height_px
            axes_width = bbox.width * figure_width_px
            axes_height = bbox.height * figure_height_px
            
            # Log the axes position and size
            logger.debug(f"_convert_event_to_data_coords: Axes bbox - x0: {bbox.x0}, y0: {bbox.y0}, width: {bbox.width}, height: {bbox.height}") # ADDED
            logger.debug(f"_convert_event_to_data_coords: Axes position - left: {axes_left}, bottom: {axes_bottom}, width: {axes_width}, height: {axes_height}") # ADDED
            
            # Convert canvas coordinates to axes coordinates
            axes_x = (event.x - axes_left) / axes_width
            axes_y = 1.0 - (event.y - axes_bottom) / axes_height  # Invert y-axis
            
            logger.debug(f"_convert_event_to_data_coords: Axes relative coords: ({axes_x}, {axes_y})") # ADDED
            
            # Convert axes coordinates to data coordinates
            x_min, x_max = self.ax.get_xlim()
            y_min, y_max = self.ax.get_ylim()
            
            x_data = x_min + axes_x * (x_max - x_min)
            y_data = y_min + axes_y * (y_max - y_min)
            
            logger.debug(f"_convert_event_to_data_coords: Data coords: ({x_data}, {y_data})") # ADDED

        return x_data, y_data

    def _find_node_in_click_field(self, x_data: float, y_data: float) -> Optional[Tuple[int, ...]]:
        """
        Find the nearest valid grid coordinate corresponding to the given data coordinates.
        (Round 1 Fix: Convert click to nearest grid coord, check validity)
        """
        log_prefix = "_find_node_in_click_field (R1 Fix): "
        logger.debug(f"{log_prefix}Searching near data coords ({x_data:.2f}, {y_data:.2f})")

        if self.grid is None or self.coord_system is None:
            logger.warning(f"{log_prefix}Grid or CoordinateSystem is None.")
            return None

        try:
            # --- Convert Data Coordinates to Grid Coordinates ---
            # Use display_to_grid which handles the scaling and potential 3D projection implicitly
            # For 3D, display_to_grid might need refinement if clicks aren't projected well,
            # but for 2D or typical 3D views, this should give a reasonable grid point.
            # We might need the Z coordinate if it's 3D, but let's start with 2D focus.
            display_coords = (x_data, y_data)
            if self.grid.dimension_type == Dimension.THREE_D:
                # Estimate a Z coordinate (e.g., middle of the current Z view)
                # This is an approximation for clicking in 3D space.
                z_min, z_max = self.ax.get_zlim() if hasattr(self.ax, 'get_zlim') else (0, 0)
                z_data = (z_min + z_max) / 2
                display_coords = (x_data, y_data, z_data)

            grid_coords_float = self.coord_system.display_to_grid(display_coords)
            if grid_coords_float is None:
                logger.warning(f"{log_prefix}display_to_grid returned None for display coords {display_coords}.")
                return None

            # --- Round to Nearest Integer Grid Coordinates ---
            # Use np.floor and add 0.5 before casting to int for proper rounding
            nearest_grid_coords = tuple(int(c + 0.5) for c in grid_coords_float)
            logger.debug(f"{log_prefix}Converted display {display_coords} -> float grid {grid_coords_float} -> nearest int grid {nearest_grid_coords}")

            # --- Check if the Nearest Grid Coordinate is Valid ---
            if self.grid.is_valid_coord(nearest_grid_coords):
                logger.debug(f"{log_prefix}Nearest grid coordinate {nearest_grid_coords} is valid.")

                # --- Optional: Add a distance check in *grid* units ---
                # Calculate the display coords of the *center* of the nearest grid cell
                nearest_node_display_coords = self.coord_system.grid_to_display(nearest_grid_coords)
                # Calculate distance squared in display coordinates
                dist_sq = (nearest_node_display_coords[0] - x_data)**2 + (nearest_node_display_coords[1] - y_data)**2
                if self.grid.dimension_type == Dimension.THREE_D and len(nearest_node_display_coords) > 2:
                     if len(nearest_node_display_coords) > 2:
                         if len(nearest_node_display_coords) > 2 and len(display_coords) > 2:
                             dist_sq += (nearest_node_display_coords[2] - display_coords[2])**2 # Use estimated z_data

                # Define tolerance based on half the node spacing in display units
                # Use scale_factor which represents spacing in display units
                click_tolerance_display = self.coord_system.scale_factor * 0.6 # Allow slightly more than half spacing
                click_tolerance_display_sq = click_tolerance_display ** 2

                logger.debug(f"{log_prefix}Distance check: DistSq={dist_sq:.4f}, ToleranceSq={click_tolerance_display_sq:.4f}")

                if dist_sq <= click_tolerance_display_sq:
                    logger.info(f"{log_prefix}Click is within tolerance of valid grid coordinate {nearest_grid_coords}. Returning.")
                    return nearest_grid_coords
                else:
                    logger.debug(f"{log_prefix}Click is too far from the center of the nearest valid grid coordinate {nearest_grid_coords}.")
                    return None
                # --- End Optional Distance Check ---

            else:
                logger.debug(f"{log_prefix}Nearest grid coordinate {nearest_grid_coords} is invalid.")
                return None

        except Exception as e:
            logger.error(f"{log_prefix}Unexpected error: {e}")
            logger.error(traceback.format_exc())
            return None

    def _on_mouse_click(self, event):
        """Handle mouse click events for node toggling/increment/decrement based on modifiers.
           Pauses simulation, allows interaction when paused/stopped, clears queues on modification.
           (Round 11: Restrict Inc/Dec actions to REAL state types, Clear queues on modification)"""
        # Access GUI state via self.gui
        # --- ADDED: Pause simulation ---
        if hasattr(self, 'gui') and self.gui:
            self.gui._request_pause_for_interaction("Mouse Click")
        else:
            logger.error("_on_mouse_click: Cannot pause: self.gui reference is missing.")
            return "break"
        # ---

        log_prefix = "_on_mouse_click (R11 Queue Clear): " # Updated round
        logger.debug(f"{log_prefix}START")
        logger.debug(f"  Flags: running={self.gui.running}, paused={self.gui.paused}, stopped={self.gui._stopped}, transitioning={getattr(self.gui, '_is_transitioning', 'N/A')}, user_interact={getattr(self.gui, '_user_interaction_active', 'N/A')}")
        logger.debug(f"  ViewManager Flags: _mouse_mode={getattr(self, '_mouse_mode', 'N/A')}, _mouse_pressed={getattr(self, '_mouse_pressed', 'N/A')}")

        # Check if click was likely part of a drag (Unchanged)
        if hasattr(self, '_press_position') and self._press_position and hasattr(self, '_mouse_pressed') and self._mouse_pressed:
            x_data, y_data = self._convert_event_to_data_coords(event)
            if x_data is not None and y_data is not None:
                press_x, press_y = self._press_position
                distance_moved_sq = (x_data - press_x)**2 + (y_data - press_y)**2
                drag_threshold_sq = (self.coord_system.scale_factor * 0.1)**2 if self.coord_system else 1.0
                if distance_moved_sq > drag_threshold_sq:
                    logger.debug(f"{log_prefix}Ignoring click, likely end of drag (DistSq: {distance_moved_sq:.2f} > ThresholdSq: {drag_threshold_sq:.2f}).")
                    self._press_position = None
                    # Don't reset _mouse_pressed here, let release handle it
                    return "break"
            else:
                 logger.debug(f"{log_prefix}Could not get data coords for drag check.")

        # Proceed with click handling
        x_data, y_data = self._convert_event_to_data_coords(event)
        if x_data is None or y_data is None:
            logger.debug(f"{log_prefix}No data coords, returning")
            return "break"

        clicked_grid_coords = self._find_node_in_click_field(x_data, y_data)
        logger.debug(f"{log_prefix}Click coords (data): ({x_data:.2f}, {y_data:.2f})")
        logger.debug(f"{log_prefix}Found nearest valid grid coords: {clicked_grid_coords}")

        grid_modified = False # Track if this click modified the grid

        if clicked_grid_coords is not None and isinstance(clicked_grid_coords, tuple):
            # --- Refined Modifier Detection ---
            modifier_state = event.state
            logger.debug(f"  Raw event.state: {modifier_state} (Platform: {platform.system()})")
            SHIFT_MASK = 0x0001; CTRL_MASK = 0x0004; ALT_MASK = 0x0008; CMD_MASK_MAC = 0x0008; OPTION_MASK_MAC = 0x0010
            is_shift_pressed = (modifier_state & SHIFT_MASK) != 0
            is_ctrl_cmd_pressed = False; is_alt_opt_pressed = False
            if platform.system() == "Darwin":
                is_ctrl_cmd_pressed = (modifier_state & CMD_MASK_MAC) != 0 or (modifier_state & CTRL_MASK) != 0
                is_alt_opt_pressed = (modifier_state & OPTION_MASK_MAC) != 0
            else:
                is_ctrl_cmd_pressed = (modifier_state & CTRL_MASK) != 0
                is_alt_opt_pressed = (modifier_state & ALT_MASK) != 0
            logger.debug(f"  Final Modifiers: Shift={is_shift_pressed}, Ctrl/Cmd={is_ctrl_cmd_pressed}, Alt/Opt={is_alt_opt_pressed}")
            # --- End Refined Modifier Detection ---

            # --- Get Rule State Type ---
            rule = self.gui.controller.rule
            node_state_type = getattr(rule, 'node_state_type', StateType.BINARY) if rule else StateType.BINARY
            allow_inc_dec = node_state_type == StateType.REAL
            logger.debug(f"  Node State Type: {node_state_type.name}. Allow Inc/Dec: {allow_inc_dec}")
            # ---

            # --- Route Action based on modifiers FIRST ---
            if is_alt_opt_pressed and is_shift_pressed:
                if allow_inc_dec:
                    logger.debug(f"{log_prefix}Calling _decrement_node for {clicked_grid_coords}")
                    if self._decrement_node(clicked_grid_coords): grid_modified = True
                else:
                    logger.warning(f"{log_prefix}Decrement click ignored: Node state type is not REAL.")
            elif is_alt_opt_pressed:
                if allow_inc_dec:
                    logger.debug(f"{log_prefix}Calling _increment_node for {clicked_grid_coords}")
                    if self._increment_node(clicked_grid_coords): grid_modified = True
                else:
                    logger.warning(f"{log_prefix}Increment click ignored: Node state type is not REAL.")
            else: # No Alt/Opt or just Shift (Shift+Click doesn't have a separate action here)
                logger.debug(f"{log_prefix}Calling _toggle_node for {clicked_grid_coords}")
                if self._toggle_node(clicked_grid_coords): grid_modified = True
            # ---

            # --- ADDED: Clear queues if grid was modified ---
            if grid_modified:
                logger.info(f"{log_prefix}Grid modified by click action, clearing queues.")
                self.gui._clear_computation_and_render_queues()
            # ---

        else:
            logger.debug(f"{log_prefix}No valid node location found near click field")

        logger.debug(f"{log_prefix}END")
        return "break"

    def _on_mouse_press(self, event):
        """Handle mouse press events, routing based on the active tool OR MODIFIER KEY.
        Pauses simulation before processing.
        Allows interaction when paused or stopped.
        Initiates scribble draw/increment/decrement, erase, or delete edges mode.
        (Round 11: Restrict Inc/Dec modes to REAL state types)
        (Round 9: Pause simulation on press)"""
        log_prefix = "_on_mouse_press (R11 State Type Check, R9 Pause): " # Updated round
        logger.debug(f"{log_prefix}START")

        # --- ADDED: Pause simulation before handling interaction ---
        if hasattr(self, 'gui') and self.gui:
            self.gui._request_pause_for_interaction("Mouse Press")
        else:
            logger.error(f"{log_prefix}Cannot pause: self.gui reference is missing.")
            return "break" # Don't proceed if GUI ref is missing
        # ---

        logger.debug(f"  Flags: running={self.gui.running}, paused={self.gui.paused}, stopped={self.gui._stopped}, transitioning={getattr(self.gui, '_is_transitioning', 'N/A')}, user_interact={getattr(self.gui, '_user_interaction_active', 'N/A')}")

        # --- REMOVED: Redundant running check (handled by pause request) ---
        # if self.gui.running and not self.gui.paused and not self.gui._stopped: logger.debug(f"{log_prefix}Simulation actively running, ignoring mouse press."); return "break"
        # ---

        try:
            if hasattr(self.gui, '_user_interaction_active'): self.gui._user_interaction_active = True
            active_tool = self.gui.active_tool
            logger.debug(f"{log_prefix}Active Tool: {active_tool}")
            x_data, y_data = self._convert_event_to_data_coords(event)
            if x_data is None or y_data is None:
                logger.debug(f"{log_prefix}Invalid data coords, returning")
                if hasattr(self.gui, '_user_interaction_active'): self.gui._user_interaction_active = False
                return "break"

            now = time.time(); time_since_last_click = now - self._last_click_time
            is_double_click = time_since_last_click < self._double_click_threshold
            self._last_click_time = now
            logger.debug(f"{log_prefix}Click Timing: SinceLast={time_since_last_click:.3f}, Double={is_double_click}")

            self._press_position = (x_data, y_data); self._press_time = time.time(); self._mouse_pressed = True
            logger.debug(f"  Stored press position: {self._press_position}, time: {self._press_time}, _mouse_pressed=True")

            if self.pan_animation_id:
                try:
                    if self.gui and self.gui.root and self.gui.root.winfo_exists(): self.gui.root.after_cancel(self.pan_animation_id)
                except Exception as e: logger.warning(f"Error cancelling pan animation: {e}")
                finally: self.pan_animation_id = None; self.pan_velocity_x = 0; self.pan_velocity_y = 0; self.panning = False; logger.debug("  Stopped existing pan animation.")

            # --- Refined Modifier Detection ---
            modifier_state = event.state
            logger.debug(f"  Raw event.state: {modifier_state} (Platform: {platform.system()})") # Log raw state
            SHIFT_MASK = 0x0001; CTRL_MASK = 0x0004; ALT_MASK = 0x0008; CMD_MASK_MAC = 0x0008; OPTION_MASK_MAC = 0x0010
            is_shift_pressed = (modifier_state & SHIFT_MASK) != 0
            is_ctrl_cmd_pressed = False; is_alt_opt_pressed = False
            if platform.system() == "Darwin":
                is_ctrl_cmd_pressed = (modifier_state & CMD_MASK_MAC) != 0 or (modifier_state & CTRL_MASK) != 0
                is_alt_opt_pressed = (modifier_state & OPTION_MASK_MAC) != 0
                logger.debug(f"  macOS Check: Cmd/Ctrl={is_ctrl_cmd_pressed}, Opt/Alt={is_alt_opt_pressed}")
            else:
                is_ctrl_cmd_pressed = (modifier_state & CTRL_MASK) != 0
                is_alt_opt_pressed = (modifier_state & ALT_MASK) != 0
                logger.debug(f"  Win/Lin Check: Ctrl={is_ctrl_cmd_pressed}, Alt={is_alt_opt_pressed}")
            logger.debug(f"  Final Modifiers: Shift={is_shift_pressed}, Ctrl/Cmd={is_ctrl_cmd_pressed}, Alt/Opt={is_alt_opt_pressed}")
            # --- End Refined Modifier Detection ---

            start_node_coords = self._find_node_in_click_field(x_data, y_data)

            # --- Get Rule State Types ---
            rule = self.gui.controller.rule
            node_state_type = getattr(rule, 'node_state_type', StateType.BINARY) if rule else StateType.BINARY
            edge_state_type = getattr(rule, 'edge_state_type', StateType.BINARY) if rule else StateType.BINARY
            allow_inc_dec = node_state_type == StateType.REAL # Only allow inc/dec if node state is REAL
            logger.debug(f"  Rule State Types: Node={node_state_type.name}, Edge={edge_state_type.name}. Allow Inc/Dec: {allow_inc_dec}")
            # ---

            if active_tool is None: # Default interaction mode
                self.panning = False # Default to not panning
                self._mouse_mode = None # Reset mode

                # Check modifiers in order of precedence
                if is_alt_opt_pressed and is_shift_pressed:
                    # --- ADDED State Type Check ---
                    if allow_inc_dec:
                        self._mouse_mode = 'scribble_decrement'
                        self.gui._push_grid_state_to_undo("Scribble Decrement")
                        logger.info(f"  Mode set to 'scribble_decrement'. Start node: {start_node_coords}")
                    else:
                        logger.warning(f"{log_prefix}Decrement action ignored: Rule node state type is not REAL.")
                        self._mouse_mode = None # Prevent action
                    # ---
                elif is_alt_opt_pressed:
                    # --- ADDED State Type Check ---
                    if allow_inc_dec:
                        self._mouse_mode = 'scribble_increment'
                        self.gui._push_grid_state_to_undo("Scribble Increment")
                        logger.info(f"  Mode set to 'scribble_increment'. Start node: {start_node_coords}")
                    else:
                        logger.warning(f"{log_prefix}Increment action ignored: Rule node state type is not REAL.")
                        self._mouse_mode = None # Prevent action
                    # ---
                elif is_ctrl_cmd_pressed: # Ctrl/Cmd takes precedence over Shift for delete edges
                    self._mouse_mode = 'scribble_delete_edges'
                    self.gui._push_grid_state_to_undo("Scribble Delete Edges")
                    logger.info(f"  Mode set to 'scribble_delete_edges'. Start node: {start_node_coords}")
                    self._modified_in_drag = set() # Track modified edges
                    if start_node_coords: # Delete edges connected to start node immediately on press
                        edges_removed = self._remove_edges_connected_to_node(start_node_coords)
                        if edges_removed: self._modified_in_drag.update(edges_removed)
                elif is_shift_pressed:
                    self._mouse_mode = 'scribble_erase'
                    self.gui._push_grid_state_to_undo("Scribble Erase")
                    logger.info(f"  Mode set to 'scribble_erase'. Start node: {start_node_coords}")
                    if start_node_coords and self._is_node_active(start_node_coords):
                        if self._erase_node(start_node_coords): self._modified_in_drag = {start_node_coords} # Initialize modified set
                        else: self._modified_in_drag = set()
                    else: self._modified_in_drag = set()
                elif start_node_coords: # No modifiers, clicked on a node
                    self._mouse_mode = 'scribble_draw'
                    self.gui._push_grid_state_to_undo("Scribble Draw")
                    logger.info(f"  Mode set to 'scribble_draw'. Start node: {start_node_coords}")
                    self._modified_in_drag = set()
                else: # No modifiers, clicked on empty space -> PANNING
                    # --- MODIFIED: Set panning mode explicitly ---
                    self.pan_start_x = x_data; self.pan_start_y = y_data; self.panning = True; self._mouse_mode = 'panning'
                    logger.info(f"  Mode set to 'panning', panning=True")
                    # ---

                # Store common drag start info for scribble modes
                if self._mouse_mode and self._mouse_mode.startswith('scribble'):
                    self._drag_start_grid_coord = start_node_coords
                    self._last_drag_grid_coord = start_node_coords
                    if not hasattr(self, '_modified_in_drag'): self._modified_in_drag = set() # Ensure it exists

            # Tool-based logic (unchanged)
            elif active_tool == "lasso": self._handle_lasso_start(x_data, y_data); self._mouse_mode = 'lasso_select'; self.panning = False; logger.debug("  Mode set to 'lasso_select', panning=False")
            elif active_tool == "erase": self._handle_erase_press(x_data, y_data); self._mouse_mode = 'erase_action'; self.panning = False; logger.debug("  Mode set to 'erase_action', panning=False")
            elif active_tool == "add_edge": self._handle_add_edge_start(x_data, y_data); self._mouse_mode = 'add_edge_action'; self.panning = False; logger.debug("  Mode set to 'add_edge_action', panning=False")
            elif active_tool == "del_edge": self._handle_del_edge_press(x_data, y_data); self._deleted_edges_in_drag.clear(); self._mouse_mode = 'del_edge_action'; self.panning = False; logger.debug("  Mode set to 'del_edge_action', panning=False")
            else: logger.warning(f"Unhandled active tool: {active_tool}"); self._mouse_mode = None; self.panning = False; logger.debug("  Mode set to None, panning=False")

            self._drag_start_pos = (x_data, y_data)
            logger.debug(f"{log_prefix}END (Mode: {self._mouse_mode})")

        except Exception as e:
            logger.error(f"{log_prefix}Error during mouse press processing: {e}")
            logger.error(traceback.format_exc())
            self._mouse_pressed = False; self._mouse_mode = None; self.panning = False
            if hasattr(self.gui, '_user_interaction_active'): self.gui._user_interaction_active = False
        return "break"

    def _on_mouse_release(self, event):
        """Handle mouse release, routing based on the active tool or mouse mode.
        Pauses simulation, allows interaction when paused/stopped.
        Finalizes actions, clears queues if grid modified by tools or scribble.
        Prioritizes click actions if release is quick and close to press.
        (Round 8: Correct quick click routing for modified clicks)
        (Round 9: Pause simulation on release)
        (Round 11: Clear queues after tool/scribble modification)"""
        log_prefix = "_on_mouse_release (R11 Queue Clear): " # Updated round
        logger.debug(f"--- {log_prefix}START --- Mode: {self._mouse_mode}")

        # --- Pause simulation before handling interaction ---
        if hasattr(self, 'gui') and self.gui:
            self.gui._request_pause_for_interaction("Mouse Release")
        else:
            logger.error(f"{log_prefix}Cannot pause: self.gui reference is missing.")
            # Reset flags even on error
            self._is_dragging = False; self._mouse_pressed = False; self._mouse_mode = None
            self._drag_start_nodes = None; self._drag_start_pos = None; self._press_position = None; self._press_time = 0
            self._edge_tool_start_node_coords = None; self._remove_temp_line(); self._deleted_edges_in_drag.clear()
            self._lasso_points = []; self._remove_lasso_line(); self._drag_start_grid_coord = None; self._last_drag_grid_coord = None; self._modified_in_drag = set()
            if hasattr(self, '_last_active_node_in_drag'): delattr(self, '_last_active_node_in_drag')
            if hasattr(self, 'panning') and self.panning: self.panning = False
            if hasattr(self.gui, '_user_interaction_active'): self.gui._user_interaction_active = False
            return "break"
        # ---

        grid_modified_by_release = False # Track if this release specifically modified grid
        modified_during_release = False # Track modifications specifically during this release phase

        if not hasattr(self, '_mouse_pressed') or not self._mouse_pressed:
            logger.debug(f"{log_prefix}Mouse was not pressed, ignoring release.")
            if hasattr(self.gui, '_user_interaction_active'): self.gui._user_interaction_active = False
            return "break"

        try:
            x_data, y_data = self._convert_event_to_data_coords(event)
            if x_data is None or y_data is None:
                logger.debug(f"{log_prefix}Invalid data coords, resetting state.")
                # Reset flags even if coords invalid
                self._is_dragging = False; self._mouse_pressed = False; self._mouse_mode = None
                self._drag_start_nodes = None; self._drag_start_pos = None; self._press_position = None; self._press_time = 0
                self._edge_tool_start_node_coords = None; self._remove_temp_line(); self._deleted_edges_in_drag.clear()
                self._lasso_points = []; self._remove_lasso_line(); self._drag_start_grid_coord = None; self._last_drag_grid_coord = None; self._modified_in_drag = set()
                if hasattr(self, '_last_active_node_in_drag'): delattr(self, '_last_active_node_in_drag')
                if hasattr(self, 'panning') and self.panning: self.panning = False
                if hasattr(self.gui, '_user_interaction_active'): self.gui._user_interaction_active = False
                return "break"

            time_diff = time.time() - self._press_time if hasattr(self, '_press_time') and self._press_time > 0 else 1.0
            distance_moved = 0.0
            if hasattr(self, '_press_position') and self._press_position:
                press_x, press_y = self._press_position
                distance_moved = ((x_data - press_x)**2 + (y_data - press_y)**2)**0.5

            CLICK_TIME_THRESHOLD = 0.35
            CLICK_DIST_THRESHOLD = self.coord_system.scale_factor * 0.15 if self.coord_system else 5.0
            is_quick_click = time_diff < CLICK_TIME_THRESHOLD and distance_moved < CLICK_DIST_THRESHOLD
            logger.debug(f"{log_prefix}time_diff={time_diff:.3f}s, dist_moved={distance_moved:.2f}, is_click={is_quick_click}, mode={self._mouse_mode}")

            # --- Handle Quick Click FIRST ---
            if is_quick_click and self._mouse_mode != 'panning':
                clicked_grid_coords = self._find_node_in_click_field(x_data, y_data)
                grid_modified_by_click = False
                if clicked_grid_coords:
                    logger.info(f"{log_prefix}Detected quick click on node {clicked_grid_coords}. Routing based on initial press mode: {self._mouse_mode}")
                    if self._mouse_mode == 'scribble_increment':
                        if self._increment_node(clicked_grid_coords): grid_modified_by_click = True
                    elif self._mouse_mode == 'scribble_decrement':
                        if self._decrement_node(clicked_grid_coords): grid_modified_by_click = True
                    elif self._mouse_mode == 'scribble_erase':
                        if self._erase_node(clicked_grid_coords): grid_modified_by_click = True
                    elif self._mouse_mode == 'scribble_delete_edges':
                        if self._remove_edges_connected_to_node(clicked_grid_coords): grid_modified_by_click = True
                        if grid_modified_by_click: self.gui._safe_plot_update(force=True) # Force redraw for edge delete
                    elif self._mouse_mode == 'scribble_draw':
                        if self._toggle_node(clicked_grid_coords): grid_modified_by_click = True
                    else:
                        logger.warning(f"{log_prefix}Unexpected mode '{self._mouse_mode}' for quick click, defaulting to toggle.")
                        if self._toggle_node(clicked_grid_coords): grid_modified_by_click = True

                    # --- ADDED: Clear queues if quick click modified grid ---
                    if grid_modified_by_click:
                        logger.info(f"{log_prefix}Grid modified by quick click action, clearing queues.")
                        self.gui._clear_computation_and_render_queues()
                    # ---
                else:
                    logger.debug(f"{log_prefix}Quick click on empty space, no action.")

                # Reset flags and mode AFTER handling click
                self._is_dragging = False; self._mouse_pressed = False; self._mouse_mode = None
                self._drag_start_nodes = None; self._drag_start_pos = None; self._press_position = None; self._press_time = 0
                self._edge_tool_start_node_coords = None; self._remove_temp_line(); self._deleted_edges_in_drag.clear()
                self._lasso_points = []; self._remove_lasso_line(); self._drag_start_grid_coord = None; self._last_drag_grid_coord = None; self._modified_in_drag = set()
                if hasattr(self, '_last_active_node_in_drag'): delattr(self, '_last_active_node_in_drag')
                if hasattr(self.gui, '_user_interaction_active'): self.gui._user_interaction_active = False
                logger.debug(f"{log_prefix}Mouse state reset after quick click.")
                logger.debug(f"--- {log_prefix}END (Quick Click Handled) ---")
                return "break"
            # --- END Quick Click Handling ---

            # --- Route based on mouse mode (Drag Release Logic) ---
            if self._mouse_mode in ['scribble_draw', 'scribble_erase', 'scribble_delete_edges', 'scribble_increment', 'scribble_decrement']:
                logger.debug(f"{log_prefix}Finalizing SCRIBBLE action: {self._mouse_mode}")
                final_coord = self._find_node_in_click_field(x_data, y_data)
                last_drag_coord = getattr(self, '_last_drag_grid_coord', None)
                modified_during_final_segment = False # Track modification in this specific segment

                try:
                    if final_coord and last_drag_coord and final_coord != last_drag_coord:
                        logger.debug(f"  Processing final segment: {last_drag_coord} -> {final_coord}")
                        # [ Scribble final segment processing logic - unchanged ]
                        if self._mouse_mode == 'scribble_draw':
                            final_node_is_active = self._is_node_active(final_coord)
                            if not final_node_is_active:
                                if self._activate_node(final_coord): self._modified_in_drag.add(final_coord); modified_during_final_segment = True; final_node_is_active = True
                            if final_node_is_active and self._is_node_active(last_drag_coord):
                                rule_supports_edges = self.gui.controller.rule.get_param('edge_initialization', 'RANDOM') != 'NONE' if self.gui.controller and self.gui.controller.rule else False
                                if rule_supports_edges:
                                    edge_coords = self.grid._ordered_edge(last_drag_coord, final_coord)
                                    if edge_coords not in self.grid.edges:
                                        edge_type = getattr(self.gui.controller.rule, 'edge_state_type', StateType.BINARY); min_edge = getattr(self.gui.controller.rule, 'min_edge_state', 0.0); max_edge = getattr(self.gui.controller.rule, 'max_edge_state', 1.0); initial_cont_edge = self.gui.controller.rule.get_param('initial_continuous_edge_state', 0.1)
                                        if edge_type == StateType.BINARY: edge_add_state = max_edge
                                        elif edge_type == StateType.INTEGER: edge_add_state = min_edge + 1
                                        else: edge_add_state = initial_cont_edge
                                        edge_add_state = np.clip(edge_add_state, min_edge, max_edge)
                                        if self._add_edge_if_valid(last_drag_coord, final_coord, edge_state=edge_add_state): self._modified_in_drag.add(edge_coords); modified_during_final_segment = True
                        elif self._mouse_mode == 'scribble_erase':
                            if self._is_node_active(final_coord):
                                if self._erase_node(final_coord): self._modified_in_drag.add(final_coord); modified_during_final_segment = True
                        elif self._mouse_mode == 'scribble_delete_edges':
                            edges_removed = self._remove_edges_connected_to_node(final_coord)
                            if edges_removed: 
                                flattened_edges = {node for edge in edges_removed for node in edge}
                                self._modified_in_drag.update(flattened_edges)
                                modified_during_final_segment = True
                            edge_coords = self.grid._ordered_edge(last_drag_coord, final_coord)
                            if edge_coords in self.grid.edges:
                                if self._remove_specific_edge(edge_coords): self._modified_in_drag.add(edge_coords); modified_during_final_segment = True
                        elif self._mouse_mode == 'scribble_increment':
                             if self.grid.is_valid_coord(final_coord):
                                 if self._increment_node(final_coord): self._modified_in_drag.add(final_coord); modified_during_final_segment = True
                             if self._is_node_active(last_drag_coord) and self._is_node_active(final_coord):
                                 if self._increment_edge(last_drag_coord, final_coord): self._modified_in_drag.add(self.grid._ordered_edge(last_drag_coord, final_coord)); modified_during_final_segment = True
                        elif self._mouse_mode == 'scribble_decrement':
                             if self.grid.is_valid_coord(final_coord):
                                 if self._decrement_node(final_coord): self._modified_in_drag.add(final_coord); modified_during_final_segment = True
                             if self._is_node_active(last_drag_coord) and self._is_node_active(final_coord):
                                 if self._decrement_edge(last_drag_coord, final_coord): self._modified_in_drag.add(self.grid._ordered_edge(last_drag_coord, final_coord)); modified_during_final_segment = True

                    # --- ADDED: Clear queues if final segment modified grid ---
                    if modified_during_final_segment:
                        logger.info(f"{log_prefix}Grid modified by final scribble segment, clearing queues.")
                        self.gui._clear_computation_and_render_queues()
                        # Trigger redraw AFTER clearing queues
                        logger.debug("  Final segment modified, forcing complete redraw.")
                        if self.gui.grid_visualizer: self.gui.grid_visualizer.blitting_manager.invalidate_cache()
                        self.gui._safe_plot_update(force=True)
                    # ---

                except Exception as final_segment_err:
                    logger.error(f"{log_prefix}ERROR during final segment processing for {self._mouse_mode}: {final_segment_err}")
                    logger.error(traceback.format_exc())
                    undo_action = f"Scribble {self._mouse_mode.split('_')[-1].capitalize()}"
                    self.gui._pop_undo_if_match(undo_action)

                # Check if *any* modification happened during the entire drag for undo
                total_modified = (hasattr(self, '_modified_in_drag') and self._modified_in_drag)
                if total_modified:
                    logger.info(f"Scribble action '{self._mouse_mode}' modified elements. Keeping undo state.")
                else:
                    undo_action = f"Scribble {self._mouse_mode.split('_')[-1].capitalize()}"
                    self.gui._pop_undo_if_match(undo_action)
                    logger.info(f"Scribble action '{self._mouse_mode}' made no changes. Popped undo state.")

            # --- Tool Actions ---
            elif self._mouse_mode == 'lasso_select': logger.debug(f"{log_prefix}Finalizing LASSO selection"); self._handle_lasso_release(x_data, y_data) # No queue clear needed
            elif self._mouse_mode == 'erase_action':
                logger.debug(f"{log_prefix}Finalizing ERASE action");
                # Check if erase actually happened during drag/press
                grid_was_modified = hasattr(self, '_modified_in_drag') and self._modified_in_drag
                self._handle_erase_release(x_data, y_data);
                if grid_was_modified:
                    logger.info(f"{log_prefix}Grid modified by erase tool, clearing queues.")
                    self.gui._clear_computation_and_render_queues()
            elif self._mouse_mode == 'add_edge_action':
                logger.debug(f"{log_prefix}Finalizing ADD EDGE action");
                grid_modified_by_release = self._handle_add_edge_release(x_data, y_data);
                if grid_modified_by_release:
                    logger.info(f"{log_prefix}Grid modified by add edge tool, clearing queues.")
                    self.gui._clear_computation_and_render_queues()
            elif self._mouse_mode == 'del_edge_action':
                logger.debug(f"{log_prefix}Finalizing DELETE EDGE action");
                # Check if edges were deleted BEFORE clearing the tracking set
                grid_was_modified = hasattr(self, '_deleted_edges_in_drag') and self._deleted_edges_in_drag
                self._handle_del_edge_release(x_data, y_data);
                if grid_was_modified:
                    logger.info(f"{log_prefix}Grid modified by delete edge tool, clearing queues.")
                    self.gui._clear_computation_and_render_queues()
            # --- Panning ---
            elif self._mouse_mode == 'panning':
                logger.debug(f"{log_prefix}Handling PANNING RELEASE")
                if is_quick_click: logger.debug("  Quick click on background (no action).")
                else:
                    logger.debug("  Panning finished, starting deceleration animation.")
                    if abs(self.pan_velocity_x) > 0.1 or abs(self.pan_velocity_y) > 0.1:
                        if self.pan_animation_id:
                            try:
                                if self.gui and self.gui.root and self.gui.root.winfo_exists(): self.gui.root.after_cancel(self.pan_animation_id)
                            except Exception as e: logger.warning(f"Error cancelling pan animation ID {self.pan_animation_id}: {e}")
                        self.pan_animation_id = self.gui.root.after(16, self._animate_pan)
                    else: self.panning = False
            else: logger.debug(f"Unhandled mouse mode on release: {self._mouse_mode}")

            # Trigger non-forced redraw if grid modified by actions OTHER than toggle/scribble (handled above)
            # if grid_modified_by_release and self._mouse_mode not in ['scribble_draw', 'scribble_erase', 'scribble_delete_edges', 'scribble_increment', 'scribble_decrement']:
            #     logger.debug(f"{log_prefix}Grid modified by tool/action ({self._mouse_mode}), triggering plot update.")
            #     self.gui._safe_plot_update() # Redraw handled by queue clear + next render cycle

        except Exception as e:
            logger.error(f"Error in _on_mouse_release: {e}")
            logger.error(traceback.format_exc())
        finally:
            # Reset flags and mode
            self._is_dragging = False; self._mouse_pressed = False; self._mouse_mode = None
            self._drag_start_nodes = None; self._drag_start_pos = None; self._press_position = None; self._press_time = 0
            self._edge_tool_start_node_coords = None; self._remove_temp_line(); self._deleted_edges_in_drag.clear()
            self._lasso_points = []; self._remove_lasso_line(); self._drag_start_grid_coord = None; self._last_drag_grid_coord = None; self._modified_in_drag = set()
            if hasattr(self, '_last_processed_coord_in_final_segment'): delattr(self, '_last_processed_coord_in_final_segment')
            if hasattr(self, '_last_active_node_in_drag'): delattr(self, '_last_active_node_in_drag')
            if hasattr(self, 'panning') and self.panning and self._mouse_mode != 'panning': self.panning = False
            if hasattr(self.gui, '_user_interaction_active'): self.gui._user_interaction_active = False
            logger.debug(f"{log_prefix}Mouse state reset (finally block)")
            logger.debug(f"--- {log_prefix}END ---")
        return "break"

    def _remove_specific_edge(self, edge_coords: Tuple[Tuple[int, ...], Tuple[int, ...]]) -> bool:
        """Removes a specific edge given its coordinate tuple. Clears queues on success. Returns True if removed.
           (Round 14: Clear queues on modification)"""
        log_prefix = f"_remove_specific_edge({edge_coords} R14): " # Updated round
        if self.grid is None: return False
        if edge_coords not in self.grid.edges: return False # Edge doesn't exist

        try:
            node1_coords, node2_coords = edge_coords
            idx1 = _ravel_multi_index(np.array(node1_coords), self.grid.dimensions)
            idx2 = _ravel_multi_index(np.array(node2_coords), self.grid.dimensions)
            self.grid.remove_edge(idx1, idx2)
            logger.debug(f"{log_prefix}Removed specific edge: {edge_coords}")
            # --- ADDED: Clear queues AFTER successful edge removal ---
            logger.info(f"{log_prefix}Grid modified by edge remove, clearing queues.")
            self.gui._clear_computation_and_render_queues()
            # ---
            return True
        except Exception as e:
            logger.warning(f"{log_prefix}Error removing specific edge {edge_coords}: {e}")
            return False
        
    def _remove_edges_connected_to_node(self, node_coords: Tuple[int, ...]) -> Set[Tuple[Tuple[int, ...], Tuple[int, ...]]]:
        """Removes all edges connected to the given node coordinates. Clears queues if edges were removed.
           Returns the set of removed edge coordinate tuples.
           (Round 14: Clear queues on modification)"""
        log_prefix = f"_remove_edges_connected_to_node({node_coords} R14): " # Updated round
        removed_edges_set = set()
        if self.grid is None: return removed_edges_set

        node_idx = _ravel_multi_index(np.array(node_coords), self.grid.dimensions)
        edges_to_remove = []
        # Iterate over a copy to avoid modifying set during iteration
        for edge_coords_tuple in list(self.grid.edges):
            n1_coords, n2_coords = edge_coords_tuple
            if n1_coords == node_coords or n2_coords == node_coords:
                edges_to_remove.append(edge_coords_tuple)

        if edges_to_remove:
            logger.debug(f"{log_prefix}Removing {len(edges_to_remove)} edges connected to {node_coords}")
            for edge_coords in edges_to_remove:
                try:
                    idx1 = _ravel_multi_index(np.array(edge_coords[0]), self.grid.dimensions)
                    idx2 = _ravel_multi_index(np.array(edge_coords[1]), self.grid.dimensions)
                    self.grid.remove_edge(idx1, idx2)
                    removed_edges_set.add(edge_coords) # Add the removed edge to the set
                except Exception as e:
                    logger.warning(f"{log_prefix}Error removing edge {edge_coords} connected to {node_coords}: {e}")

            # --- ADDED: Clear queues AFTER removing edges ---
            if removed_edges_set: # Only clear if edges were actually removed
                logger.info(f"{log_prefix}Grid modified by removing connected edges, clearing queues.")
                self.gui._clear_computation_and_render_queues()
            # ---
        else:
            logger.debug(f"{log_prefix}No edges found connected to {node_coords}.")

        return removed_edges_set

    def _toggle_edge(self, edge_coords: Tuple[Tuple[int, ...], Tuple[int, ...]]):
        """
        Toggles or modifies the state of an existing edge based on rule type.
        If the edge doesn't exist and nodes are eligible, it might create it (binary/integer).
        (Round 19: Use rule state info for inactivity check and state changes)
        """
        success = False
        log_prefix = f"_toggle_edge([{edge_coords}]): "
        logger.debug(f"{log_prefix}Entering.")

        if self.grid is None or self.gui.controller is None or self.gui.controller.rule is None:
            logger.error(f"{log_prefix}Grid, Controller, or Rule is None.")
            return False

        rule = self.gui.controller.rule
        node1_coords, node2_coords = edge_coords # Assume ordered
        node1_idx = _ravel_multi_index(np.array(node1_coords), self.grid.dimensions)
        node2_idx = _ravel_multi_index(np.array(node2_coords), self.grid.dimensions)

        # --- Get Rule State Info ---
        node_type = getattr(rule, 'node_state_type', StateType.BINARY)
        min_node = getattr(rule, 'min_node_state', 0.0)
        edge_type = getattr(rule, 'edge_state_type', StateType.BINARY)
        min_edge = getattr(rule, 'min_edge_state', 0.0)
        max_edge = getattr(rule, 'max_edge_state', 1.0)
        initial_cont_edge = rule.get_param('initial_continuous_edge_state', 0.1)
        # ---

        # Check if nodes themselves are active enough (using rule's min_node_state)
        node1_state = self.grid.grid_array.ravel()[node1_idx]
        node2_state = self.grid.grid_array.ravel()[node2_idx]
        nodes_active_enough = abs(node1_state - min_node) > 1e-6 and abs(node2_state - min_node) > 1e-6

        edge_exists = edge_coords in self.grid.edges
        current_edge_state = self.grid.edge_states.get(edge_coords, min_edge) # Default to min_edge

        self.gui._push_grid_state_to_undo(f"Toggle Edge {edge_coords}")

        try:
            new_edge_state = current_edge_state
            edge_modified = False

            if edge_exists:
                # Edge exists, toggle means deactivate/set to min
                new_edge_state = min_edge
                logger.debug(f"{log_prefix}Edge exists. Deactivating edge {edge_coords} to {new_edge_state:.2f}")
                self.grid.remove_edge(node1_idx, node2_idx) # Remove the edge
                edge_modified = True # Edge was removed
            elif nodes_active_enough:
                # Edge doesn't exist, but nodes are active: Create/Activate edge
                if edge_type == StateType.BINARY or edge_type == StateType.INTEGER:
                    new_edge_state = min_edge + 1 # Activate to first step
                else: # REAL
                    new_edge_state = initial_cont_edge
                new_edge_state = np.clip(new_edge_state, min_edge, max_edge)
                logger.debug(f"{log_prefix}Edge doesn't exist, nodes active. Creating edge {edge_coords} with state {new_edge_state:.2f}")
                self.grid.add_edge(node1_idx, node2_idx, edge_state=new_edge_state)
                edge_modified = True # Edge was added
            else:
                # Edge doesn't exist and nodes not active enough, do nothing
                logger.debug(f"{log_prefix}Edge doesn't exist and nodes not active enough. No action.")
                self.gui._pop_undo_if_match(f"Toggle Edge {edge_coords}") # Pop undo as no change happened

            # Trigger redraw only if an edge was actually added or removed
            if edge_modified:
                success = True
                if hasattr(self.gui, '_safe_plot_update'):
                    logger.debug(f"{log_prefix}Triggering FORCED plot update after edge toggle.")
                    self.gui._safe_plot_update(force=True)
            else:
                success = True # No change needed is also success

        except Exception as e_toggle:
            logger.error(f"{log_prefix}EXCEPTION during edge toggle: {e_toggle}")
            logger.error(traceback.format_exc())
            self.gui._pop_undo_if_match(f"Toggle Edge {edge_coords}") # Pop undo on error
            success = False
        finally:
            logger.debug(f"{log_prefix}Exiting (Success: {success}).")

        return success

    def _handle_erase_press(self, x_data: float, y_data: float):
        """Handle mouse press for the erase tool. Erases the node under the cursor."""
        log_prefix = "_handle_erase_press: "
        logger.info(f"{log_prefix}Erase Press/Action at ({x_data:.2f}, {y_data:.2f})")
        node_coords = self._find_node_in_click_field(x_data, y_data)
        modified = False
        if node_coords:
            # Push undo state BEFORE erasing
            self.gui._push_grid_state_to_undo("Erase Node (Press)")
            if self._erase_node(node_coords):
                modified = True
            else:
                # Pop undo state if erase failed
                self.gui._pop_undo_if_match("Erase Node (Press)")
        # Trigger redraw immediately if modified
        if modified:
            self.gui._safe_plot_update(force=True)

    def _handle_del_edge_release(self, x_data: float, y_data: float):
        """Finalize delete edge action (clear temporary drag state)."""
        log_prefix = "_handle_del_edge_release: "
        logger.info(f"{log_prefix}Delete Edge Release at ({x_data:.2f}, {y_data:.2f})")
        # Clear the set tracking edges deleted during this specific drag operation
        self._deleted_edges_in_drag.clear()
        logger.debug(f"{log_prefix}Cleared _deleted_edges_in_drag set.")
        # No redraw needed here as the actual deletion happened during drag/press

    def _is_node_active(self, node_coords):
        """Check if a node is visually active based on the visibility threshold, regardless of rule state type."""
        if self.grid is None:
            return False

        try:
            # Use the global visibility threshold for interaction checks
            visibility_threshold = GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD
            state = self.grid.grid_array[node_coords]
            is_active = state > visibility_threshold
            # logger.debug(f"_is_node_active: Node {node_coords} state: {state:.4f} vs Threshold: {visibility_threshold:.4f} -> Active: {is_active}") # Reduce noise
            return is_active
        except IndexError:
             logger.error(f"_is_node_active: IndexError accessing state for {node_coords}. Grid shape: {self.grid.grid_array.shape}")
             return False
        except Exception as e:
             logger.error(f"_is_node_active: Error getting state for {node_coords}: {e}")
             return False
        
    def _activate_node(self, node_coords):
        """Activate a node by setting its state based on rule type, respecting min/max.
           (Round 5: Handle different state types for activation)"""
        success = False
        log_prefix = f"_activate_node([{node_coords}]): "
        if self.grid is None or self.gui.controller is None or self.gui.controller.rule is None:
            logger.error(f"{log_prefix}Grid, Controller, or Rule is None.")
            return False

        rule = self.gui.controller.rule
        node_idx = _ravel_multi_index(np.array(node_coords), self.grid.dimensions)

        # Push undo state BEFORE changing state
        self.gui._push_grid_state_to_undo(f"Activate Node {node_coords}")

        try:
            current_node_state = self.grid.grid_array.ravel()[node_idx]

            # --- Get Rule State Info ---
            node_type = getattr(rule, 'node_state_type', StateType.BINARY)
            min_node = getattr(rule, 'min_node_state', 0.0)
            max_node = getattr(rule, 'max_node_state', 1.0)
            initial_cont_node = rule.get_param('initial_continuous_node_state', 0.1)
            # ---

            # --- Determine Activation State based on Type ---
            new_node_state = current_node_state # Default to no change
            if node_type == StateType.BINARY:
                new_node_state = max_node # Activate to max (usually 1.0)
            elif node_type == StateType.INTEGER:
                new_node_state = min_node + 1 # Activate to first integer step above min
            else: # REAL
                # Activate to the initial continuous state, but ensure it's > min_node
                new_node_state = max(initial_cont_node, min_node + 1e-6) # Add epsilon to ensure > min

            new_node_state = np.clip(new_node_state, min_node, max_node) # Ensure within bounds
            # ---

            # Apply the state change only if it actually changed
            if not np.isclose(new_node_state, current_node_state):
                logger.debug(f"{log_prefix}Activating node {node_coords} from {current_node_state:.3f} to {new_node_state:.3f} (Type: {node_type.name})")
                try:
                    if self.grid.set_node_state(node_idx, new_node_state):
                        success = True
                    else:
                        logger.error(f"{log_prefix}grid.set_node_state returned False for index {node_idx}.")
                except Exception as e_set_state:
                    logger.error(f"{log_prefix}EXCEPTION during grid.set_node_state for index {node_idx}: {e_set_state}")
                    logger.error(traceback.format_exc())
                    success = False

                if not success:
                    self.gui._pop_undo_if_match(f"Activate Node {node_coords}") # Pop undo if activation failed
            else:
                logger.debug(f"{log_prefix}Node {node_coords} already considered active or target state is same as current. No change needed.")
                self.gui._pop_undo_if_match(f"Activate Node {node_coords}") # Pop undo if no change occurred
                success = True # Considered successful as no change was needed

        except Exception as e_outer:
             logger.error(f"{log_prefix}Outer exception in _activate_node: {e_outer}")
             logger.error(traceback.format_exc())
             self.gui._pop_undo_if_match(f"Activate Node {node_coords}")
             success = False

        return success

    def _set_node_active_for_drawing(self, node_coords: Tuple[int, ...]) -> bool:
        """
        Explicitly sets a node's state to 1.0 for drawing purposes,
        updating necessary grid structures. Bypasses rule logic.
        Returns True if successful, False otherwise.
        """
        if self.grid is None:
            logger.warning("_set_node_active_for_drawing: Grid is None.")
            return False

        if not self.grid.is_valid_coord(node_coords):
            logger.warning(f"_set_node_active_for_drawing: Invalid coordinates {node_coords}.")
            return False

        try:
            node_idx = _ravel_multi_index(np.array(node_coords), self.grid.dimensions)

            # --- Directly modify grid state ---
            self.grid.grid_array.ravel()[node_idx] = 1.0
            logger.debug(f"_set_node_active_for_drawing: Set node {node_coords} (idx {node_idx}) state to 1.0")

            # --- Update active_nodes set ---
            self.grid.active_nodes.add(int(node_idx))

            # --- Update spatial hash ---
            if self.grid.spatial_hash is not None:
                self.grid.spatial_hash.update_node(int(node_idx), np.array(node_coords))
            else:
                logger.warning(f"Spatial hash is None, cannot update node {node_idx} in hash.")

            # --- Invalidate neighbor cache ---
            self.grid._invalidate_neighbor_cache(int(node_idx))

            # --- Notify observers (optional but good practice) ---
            # self.grid.notify_observers() # Maybe too frequent, rely on redraw after full action

            return True
        except Exception as e:
            logger.error(f"Error in _set_node_active_for_drawing for {node_coords}: {e}")
            return False

    def _increment_node(self, node_coords: Tuple[int, ...]):
        """Increments the state of a node based on rule type (for Alt+Click), using visibility threshold.
           Clears queues on successful modification.
           (Round 9: Ensure redraw even if clamped at max)
           (Round 14: Clear queues on modification)"""
        success = False
        log_prefix = f"_increment_node([{node_coords}] R14): " # Updated round
        logger.debug(f"{log_prefix}Entering.")

        if self.grid is None or self.gui.controller is None or self.gui.controller.rule is None:
            logger.error(f"{log_prefix}Grid, Controller, or Rule is None.")
            return False

        rule = self.gui.controller.rule
        node_idx = _ravel_multi_index(np.array(node_coords), self.grid.dimensions)

        self.gui._push_grid_state_to_undo(f"Increment Node {node_coords}")

        try:
            current_node_state = self.grid.grid_array.ravel()[node_idx]
            intended_new_state = current_node_state # Store the state *before* clipping

            # Get Rule State Info
            node_type = getattr(rule, 'node_state_type', StateType.BINARY)
            min_node = getattr(rule, 'min_node_state', 0.0)
            max_node = getattr(rule, 'max_node_state', 1.0)
            initial_cont_node = rule.get_param('initial_continuous_node_state', 0.1)
            visibility_threshold = GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD

            is_currently_active = current_node_state > visibility_threshold

            if not is_currently_active:
                # Activate node
                if node_type == StateType.BINARY or node_type == StateType.INTEGER:
                    intended_new_state = max_node if node_type == StateType.BINARY else min_node + 1
                else: # REAL
                    intended_new_state = initial_cont_node
                logger.debug(f"{log_prefix}Activating node {node_coords} to {intended_new_state:.3f}")
            else:
                # Increment active node
                if node_type == StateType.BINARY: intended_new_state = max_node
                elif node_type == StateType.INTEGER: intended_new_state = current_node_state + 1
                else: intended_new_state = current_node_state + 0.1 # Increase by fixed amount
                logger.debug(f"{log_prefix}Incrementing node {node_coords} from {current_node_state:.3f} to {intended_new_state:.3f}")

            # Clip the state AFTER calculating the intended change
            new_node_state_clipped = np.clip(intended_new_state, min_node, max_node)
            logger.debug(f"{log_prefix}Intended state {intended_new_state:.3f} clipped to {new_node_state_clipped:.3f}")

            state_changed = not np.isclose(new_node_state_clipped, current_node_state)

            if state_changed:
                if self.grid.set_node_state(node_idx, new_node_state_clipped):
                    success = True
                    # --- ADDED: Clear queues AFTER successful state change ---
                    logger.info(f"{log_prefix}Grid modified by increment, clearing queues.")
                    self.gui._clear_computation_and_render_queues()
                    # ---
                    # Redraw is handled separately below
                else:
                    logger.error(f"{log_prefix}Failed to set node state."); self.gui._pop_undo_if_match(f"Increment Node {node_coords}")
            else:
                logger.debug(f"{log_prefix}Node state unchanged after clipping, popping undo."); self.gui._pop_undo_if_match(f"Increment Node {node_coords}"); success = True # No change needed is success

            # Force redraw if the increment attempt was made on an active node OR if activation occurred
            if success and (is_currently_active or state_changed):
                 if hasattr(self.gui, '_safe_plot_update'):
                     logger.debug(f"{log_prefix}Triggering FORCED plot update after increment attempt (Success: {success}, State Changed: {state_changed}).")
                     self.gui._safe_plot_update(force=True)

        except Exception as e_inc:
            logger.error(f"{log_prefix}EXCEPTION during node increment: {e_inc}")
            logger.error(traceback.format_exc())
            self.gui._pop_undo_if_match(f"Increment Node {node_coords}")
            success = False
        finally:
            logger.debug(f"{log_prefix}Exiting (Success: {success}).")
        return success

    def _decrement_node(self, node_coords: Tuple[int, ...]):
        """Decrements the state of a node based on rule type (for Alt+Shift+Click), using visibility threshold.
           Clears queues on successful modification.
           (Round 6: Adjust REAL decrement, ensure redraw)
           (Round 14: Clear queues on modification)"""
        success = False
        log_prefix = f"_decrement_node([{node_coords}] R14): " # Updated round
        logger.debug(f"{log_prefix}Entering.")

        if self.grid is None or self.gui.controller is None or self.gui.controller.rule is None:
            logger.error(f"{log_prefix}Grid, Controller, or Rule is None.")
            return False

        rule = self.gui.controller.rule
        node_idx = _ravel_multi_index(np.array(node_coords), self.grid.dimensions)

        self.gui._push_grid_state_to_undo(f"Decrement Node {node_coords}")

        try:
            current_node_state = self.grid.grid_array.ravel()[node_idx]
            new_node_state = current_node_state

            # Get Rule State Info
            node_type = getattr(rule, 'node_state_type', StateType.BINARY)
            min_node = getattr(rule, 'min_node_state', 0.0)
            max_node = getattr(rule, 'max_node_state', 1.0) # Needed for clip
            visibility_threshold = GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD

            is_currently_active = current_node_state > visibility_threshold

            if is_currently_active: # Only decrement if visually active
                if node_type == StateType.BINARY: new_node_state = min_node
                elif node_type == StateType.INTEGER: new_node_state = current_node_state - 1
                else: new_node_state = current_node_state - 0.1 # Decrease by fixed amount
                new_node_state = np.clip(new_node_state, min_node, max_node) # Ensure within bounds
                logger.debug(f"{log_prefix}Decrementing node {node_coords} from {current_node_state:.3f} to {new_node_state:.3f}")

                if not np.isclose(new_node_state, current_node_state):
                    if self.grid.set_node_state(node_idx, new_node_state):
                        success = True
                        # --- ADDED: Clear queues AFTER successful state change ---
                        logger.info(f"{log_prefix}Grid modified by decrement, clearing queues.")
                        self.gui._clear_computation_and_render_queues()
                        # ---
                        # Force redraw AFTER clearing queues
                        if hasattr(self.gui, '_safe_plot_update'):
                            logger.debug(f"{log_prefix}Triggering FORCED plot update after decrement.")
                            self.gui._safe_plot_update(force=True)
                    else:
                        logger.error(f"{log_prefix}Failed to set node state."); self.gui._pop_undo_if_match(f"Decrement Node {node_coords}")
                else:
                    logger.debug(f"{log_prefix}Node state unchanged (already at min?), popping undo."); self.gui._pop_undo_if_match(f"Decrement Node {node_coords}"); success = True
            else:
                logger.debug(f"{log_prefix}Node already inactive (state {current_node_state:.3f} <= threshold {visibility_threshold:.3f}), no decrement action. Popping undo.")
                self.gui._pop_undo_if_match(f"Decrement Node {node_coords}")
                success = True # No change needed is success

        except Exception as e_dec:
            logger.error(f"{log_prefix}EXCEPTION during node decrement: {e_dec}")
            logger.error(traceback.format_exc())
            self.gui._pop_undo_if_match(f"Decrement Node {node_coords}")
            success = False
        finally:
            logger.debug(f"{log_prefix}Exiting (Success: {success}).")
        return success

    def _increment_edge(self, node1_coords: Tuple[int, ...], node2_coords: Tuple[int, ...]) -> bool:
        """Increments the state of an edge between two nodes based on rule type.
           Clears queues on successful modification. Returns True if modified.
           (Round 11: Restrict to REAL edge state type)
           (Round 14: Clear queues on modification)"""
        log_prefix = f"_increment_edge({node1_coords}, {node2_coords} R14): " # Updated round
        if self.grid is None or self.gui.controller is None or self.gui.controller.rule is None:
            logger.error(f"{log_prefix}Grid, Controller, or Rule is None.")
            return False

        rule = self.gui.controller.rule
        edge_type = getattr(rule, 'edge_state_type', StateType.BINARY)

        # --- State Type Check ---
        if edge_type != StateType.REAL:
            logger.warning(f"{log_prefix}Ignoring increment edge: Edge state type is {edge_type.name}, not REAL.")
            return False
        # ---

        min_edge = getattr(rule, 'min_edge_state', 0.0)
        max_edge = getattr(rule, 'max_edge_state', 1.0)
        initial_cont_edge = rule.get_param('initial_continuous_edge_state', 0.1)

        edge_coords = self.grid._ordered_edge(node1_coords, node2_coords)
        edge_exists = edge_coords in self.grid.edges
        current_edge_state = self.grid.edge_states.get(edge_coords, min_edge)
        new_edge_state = current_edge_state
        modified = False

        node1_idx = _ravel_multi_index(np.array(node1_coords), self.grid.dimensions)
        node2_idx = _ravel_multi_index(np.array(node2_coords), self.grid.dimensions)

        if edge_exists:
            # Only increment REAL type
            new_edge_state = current_edge_state + 0.1 # Increase by fixed amount
            logger.debug(f"{log_prefix}Incrementing existing edge state {current_edge_state:.3f} -> {new_edge_state:.3f}")
        else: # Create edge if it doesn't exist (only for REAL type)
            new_edge_state = initial_cont_edge
            logger.debug(f"{log_prefix}Creating edge with initial state {new_edge_state:.3f}")

        new_edge_state = np.clip(new_edge_state, min_edge, max_edge)

        if not np.isclose(new_edge_state, current_edge_state) or not edge_exists:
            # Push undo state BEFORE changing grid state
            self.gui._push_grid_state_to_undo(f"Increment Edge {edge_coords}")
            try:
                if not edge_exists and abs(new_edge_state - min_edge) > 1e-6:
                    self.grid.add_edge(node1_idx, node2_idx, edge_state=new_edge_state)
                    modified = True
                elif edge_exists:
                    self.grid.set_edge_state(node1_idx, node2_idx, new_edge_state)
                    modified = True

                if modified:
                    logger.debug(f"{log_prefix}Edge state updated to {new_edge_state:.3f}")
                    # --- ADDED: Clear queues AFTER successful modification ---
                    logger.info(f"{log_prefix}Grid modified by edge increment/add, clearing queues.")
                    self.gui._clear_computation_and_render_queues()
                    # ---
                else:
                    # Pop undo if no modification occurred (e.g., already at max and tried to create)
                    self.gui._pop_undo_if_match(f"Increment Edge {edge_coords}")

            except Exception as e:
                 logger.error(f"{log_prefix}Error adding/setting edge state: {e}")
                 self.gui._pop_undo_if_match(f"Increment Edge {edge_coords}") # Pop undo on error
                 modified = False # Ensure modified is False on error

        else:
            logger.debug(f"{log_prefix}Edge state not modified.")

        return modified

    def _decrement_edge(self, node1_coords: Tuple[int, ...], node2_coords: Tuple[int, ...]) -> bool:
        """Decrements the state of an edge, removing it if it reaches minimum.
           Clears queues on successful modification. Returns True if modified.
           (Round 11: Restrict to REAL edge state type)
           (Round 14: Clear queues on modification)"""
        log_prefix = f"_decrement_edge({node1_coords}, {node2_coords} R14): " # Updated round
        if self.grid is None or self.gui.controller is None or self.gui.controller.rule is None:
            logger.error(f"{log_prefix}Grid, Controller, or Rule is None.")
            return False

        rule = self.gui.controller.rule
        edge_type = getattr(rule, 'edge_state_type', StateType.BINARY)

        # --- State Type Check ---
        if edge_type != StateType.REAL:
            logger.warning(f"{log_prefix}Ignoring decrement edge: Edge state type is {edge_type.name}, not REAL.")
            return False
        # ---

        min_edge = getattr(rule, 'min_edge_state', 0.0)
        max_edge = getattr(rule, 'max_edge_state', 1.0) # Needed for clip

        edge_coords = self.grid._ordered_edge(node1_coords, node2_coords)
        edge_exists = edge_coords in self.grid.edges
        modified = False

        if not edge_exists:
            logger.debug(f"{log_prefix}Edge does not exist, cannot decrement.")
            return False # Cannot decrement non-existent edge

        current_edge_state = self.grid.edge_states.get(edge_coords, min_edge)
        new_edge_state = current_edge_state

        if abs(current_edge_state - min_edge) > 1e-6: # Only decrement if not already at minimum
            # Push undo state BEFORE changing grid state
            self.gui._push_grid_state_to_undo(f"Decrement Edge {edge_coords}")
            try:
                # Only decrement REAL type
                new_edge_state = current_edge_state - 0.1 # Decrease by fixed amount
                new_edge_state = np.clip(new_edge_state, min_edge, max_edge) # Ensure within bounds
                logger.debug(f"{log_prefix}Decrementing edge state {current_edge_state:.3f} -> {new_edge_state:.3f}")

                if abs(new_edge_state - min_edge) < 1e-6:
                    # Reached minimum, remove the edge
                    if self._remove_specific_edge(edge_coords): # This now handles its own queue clear
                        modified = True
                        logger.debug(f"{log_prefix}Edge reached minimum state, removed (queue cleared by _remove_specific_edge).")
                    else:
                        logger.warning(f"{log_prefix}Failed to remove edge {edge_coords} after decrement.")
                        self.gui._pop_undo_if_match(f"Decrement Edge {edge_coords}") # Pop undo if remove failed
                elif not np.isclose(new_edge_state, current_edge_state):
                    # Update edge state if it changed and didn't reach minimum
                    node1_idx = _ravel_multi_index(np.array(node1_coords), self.grid.dimensions)
                    node2_idx = _ravel_multi_index(np.array(node2_coords), self.grid.dimensions)
                    self.grid.set_edge_state(node1_idx, node2_idx, new_edge_state)
                    modified = True
                    logger.debug(f"{log_prefix}Edge state updated to {new_edge_state:.3f}")
                    # --- ADDED: Clear queues AFTER successful state update ---
                    logger.info(f"{log_prefix}Grid modified by edge decrement, clearing queues.")
                    self.gui._clear_computation_and_render_queues()
                    # ---
                else:
                    logger.debug(f"{log_prefix}Edge state not modified after decrement calculation.")
                    self.gui._pop_undo_if_match(f"Decrement Edge {edge_coords}") # Pop undo if no change

            except Exception as e:
                 logger.error(f"{log_prefix}Error decrementing edge state: {e}")
                 self.gui._pop_undo_if_match(f"Decrement Edge {edge_coords}") # Pop undo on error
                 modified = False # Ensure modified is False on error
        else:
            logger.debug(f"{log_prefix}Edge already at minimum state ({current_edge_state:.3f}), no decrement action.")

        # Redraw is handled by caller or subsequent render cycle

        return modified

    def _add_edge_if_valid(self, node1_coords: Tuple[int, ...], node2_coords: Tuple[int, ...], edge_state: Optional[float] = None) -> bool:
        """
        Add an edge between two nodes if they are valid neighbors.
        Clears queues on successful modification.
        Accepts an optional edge_state.
        (Round 6: Added edge_state parameter)
        (Round 14: Clear queues on modification)
        """
        log_prefix = "_add_edge_if_valid (R14 Queue Clear): " # Updated round
        logger.debug(f"{log_prefix}Attempting to add edge between {node1_coords} and {node2_coords} with state {edge_state}")
        success = False # Default to failure

        if self.grid is None:
            logger.debug(f"{log_prefix}Grid is None, cannot add edge")
            return False

        # --- Check neighbors FIRST ---
        if not self._are_valid_neighbors(node1_coords, node2_coords):
            logger.debug(f"{log_prefix}Nodes are not valid neighbors: {node1_coords}, {node2_coords}")
            return False
        # ---

        edge = self._get_edge(node1_coords, node2_coords)
        logger.debug(f"{log_prefix}Ordered edge: {edge}")

        if edge not in self.grid.edges:
            node1_idx = _ravel_multi_index(np.array(node1_coords), self.grid.dimensions)
            node2_idx = _ravel_multi_index(np.array(node2_coords), self.grid.dimensions)
            logger.debug(f"{log_prefix}Adding edge between {node1_coords} and {node2_coords} (indices: {node1_idx}, {node2_idx})")

            # Push undo state BEFORE adding edge
            self.gui._push_grid_state_to_undo(f"Add Edge {edge}")

            # Check if both nodes are active
            node1_active = self._is_node_active(node1_coords)
            node2_active = self._is_node_active(node2_coords)
            logger.debug(f"{log_prefix}Node1 active: {node1_active}, Node2 active: {node2_active}")

            if not node1_active or not node2_active:
                logger.debug(f"{log_prefix}Cannot add edge - one or both nodes are inactive")
                self.gui._pop_undo_if_match(f"Add Edge {edge}") # Pop undo if nodes inactive
                return False

            # --- Use provided edge_state or default ---
            state_to_set = edge_state
            if state_to_set is None:
                # Determine default based on rule if state not provided
                if self.gui.controller and self.gui.controller.rule:
                    rule = self.gui.controller.rule
                    edge_type = getattr(rule, 'edge_state_type', StateType.BINARY)
                    min_edge = getattr(rule, 'min_edge_state', 0.0)
                    max_edge = getattr(rule, 'max_edge_state', 1.0)
                    initial_cont_edge = rule.get_param('initial_continuous_edge_state', 0.1)
                    if edge_type == StateType.BINARY: state_to_set = max_edge
                    elif edge_type == StateType.INTEGER: state_to_set = min_edge + 1
                    else: state_to_set = initial_cont_edge
                    state_to_set = np.clip(state_to_set, min_edge, max_edge)
                else:
                    state_to_set = 1.0 # Fallback default
                logger.debug(f"{log_prefix}edge_state not provided, using default: {state_to_set:.2f}")
            # ---

            try:
                # --- Pass state_to_set to add_edge ---
                self.grid.add_edge(node1_idx, node2_idx, edge_state=state_to_set)
                # ---
                edge_added = edge in self.grid.edges
                logger.debug(f"{log_prefix}Edge added to grid.edges: {edge_added}")
                if edge_added:
                    logger.info(f"{log_prefix}Successfully added edge: {node1_coords} <-> {node2_coords} with state {state_to_set:.2f}")
                    success = True
                    # --- ADDED: Clear queues AFTER successful edge addition ---
                    logger.info(f"{log_prefix}Grid modified by edge add, clearing queues.")
                    self.gui._clear_computation_and_render_queues()
                    # ---
                else:
                    logger.error(f"{log_prefix}Failed to add edge - not in grid.edges after add_edge call")
                    success = False
            except Exception as e_add_edge:
                logger.error(f"{log_prefix}EXCEPTION during grid.add_edge between indices {node1_idx} and {node2_idx}: {e_add_edge}")
                logger.error(traceback.format_exc())
                success = False

            if success:
                # Redraw handled by caller (_on_mouse_drag or _handle_add_edge_release)
                pass
            else:
                # Pop undo if add_edge failed or raised exception
                self.gui._pop_undo_if_match(f"Add Edge {edge}")

            return success
        else:
            logger.debug(f"{log_prefix}Edge already exists between {node1_coords} and {node2_coords}")
            return False # Indicate edge already existed
        
    def _erase_selected_nodes(self) -> bool:
        """Erases all nodes currently in the GUI selection."""
        if not self.gui or not self.grid: return False
        # --- MODIFIED: Access current_selection via self.gui ---
        selection_nodes = self.gui.current_selection.get('nodes')
        # ---
        if not selection_nodes:
            logger.info("Erase Selected Nodes: No selection found.")
            return False

        logger.debug(f"Erasing {len(selection_nodes)} selected nodes.")
        modified = False
        nodes_erased_count = 0
        # --- MODIFIED: Access _push_grid_state_to_undo via self.gui ---
        self.gui._push_grid_state_to_undo("Erase Selected Nodes")
        # ---
        for sel_coords in list(selection_nodes): # Iterate copy
            if self._erase_node(sel_coords):
                nodes_erased_count += 1
                modified = True
        logger.debug(f"Erased {nodes_erased_count} nodes from selection.")

        if modified:
            self.gui._safe_plot_update(force=True)
        # ---
        return modified

    def _add_edges_within_selection(self) -> bool:
        """Adds edges between all valid neighbor pairs within the current GUI selection."""
        if not self.gui or not self.grid: return False
        # --- MODIFIED: Access current_selection via self.gui ---
        selection_nodes = self.gui.current_selection.get('nodes')
        # ---
        if not selection_nodes or len(selection_nodes) < 2:
            logger.info("Add Edges Within Selection: No selection or not enough nodes.")
            return False

        logger.debug(f"Adding edges within selection ({len(selection_nodes)} nodes).")
        modified = False
        edges_added_count = 0
        # --- MODIFIED: Access _push_grid_state_to_undo via self.gui ---
        self.gui._push_grid_state_to_undo("Add Edges in Selection")
        # ---
        nodes_list = list(selection_nodes)
        for i in range(len(nodes_list)):
            for j in range(i + 1, len(nodes_list)): # Avoid self-loops and duplicates
                node1_coords = nodes_list[i]
                node2_coords = nodes_list[j]
                # Attempt to add edge if they are valid neighbors
                if self._add_edge_if_valid(node1_coords, node2_coords):
                    edges_added_count += 1
                    modified = True
        logger.info(f"Added {edges_added_count} edges within selection.")

        if modified:
            self.gui._safe_plot_update(force=True)
        # ---
        return modified

    def _delete_edges_within_selection(self) -> bool:
        """Deletes all edges connecting two nodes that are both within the current GUI selection."""
        if not self.gui or not self.grid: return False
        # --- MODIFIED: Access current_selection via self.gui ---
        selection_nodes = self.gui.current_selection.get('nodes')
        # ---
        if not selection_nodes or len(selection_nodes) < 2:
            logger.info("Delete Edges Within Selection: No selection or not enough nodes.")
            return False

        logger.debug(f"Deleting internal edges for selection ({len(selection_nodes)} nodes).")
        modified = False
        edges_to_remove_sel = set()
        removed_count = 0

        for edge_coords in list(self.grid.edges): # Iterate copy
            n1, n2 = edge_coords
            if n1 in selection_nodes and n2 in selection_nodes:
                edges_to_remove_sel.add(edge_coords)

        if edges_to_remove_sel:
            # --- MODIFIED: Access _push_grid_state_to_undo via self.gui ---
            self.gui._push_grid_state_to_undo("Delete Edges in Selection")
            # ---
            logger.debug(f"Found {len(edges_to_remove_sel)} internal edges to remove.")
            for edge_coords in edges_to_remove_sel:
                try:
                    node1_coords, node2_coords = edge_coords
                    node1_idx = _ravel_multi_index(np.array(node1_coords), self.grid.dimensions)
                    node2_idx = _ravel_multi_index(np.array(node2_coords), self.grid.dimensions)
                    self.grid.remove_edge(node1_idx, node2_idx)
                    removed_count += 1
                    modified = True
                except Exception as e: logger.error(f"  Error deleting edge {edge_coords}: {e}")
            if modified: logger.info(f"Deleted {removed_count} internal edges from selection.")
        else:
            logger.debug("No internal edges found in selection.")

        if modified:
            self.gui._safe_plot_update(force=True)
        # ---
        return modified

    def _get_selection_display_bounds(self) -> Optional[Tuple[float, float, float, float]]:
        """Calculates the bounding box of the current selection in display coordinates."""
        if not self.gui or not self.grid: return None
        selection_nodes_coords = self.gui.current_selection.get('nodes')
        if not selection_nodes_coords: return None

        min_x, max_x = float('inf'), float('-inf')
        min_y, max_y = float('inf'), float('-inf')
        # min_z, max_z = float('inf'), float('-inf') # Not needed for 2D check

        node_positions = self.grid.get_node_positions() # Get all display positions

        for node_coords_grid in selection_nodes_coords:
            node_idx = _ravel_multi_index(np.array(node_coords_grid), self.grid.dimensions)
            display_pos = node_positions.get(node_idx)
            if display_pos:
                min_x = min(min_x, display_pos[0])
                max_x = max(max_x, display_pos[0])
                min_y = min(min_y, display_pos[1])
                max_y = max(max_y, display_pos[1])
                # if self.grid.dimension_type == Dimension.THREE_D and len(display_pos) > 2:
                #     min_z = min(min_z, display_pos[2])
                #     max_z = max(max_z, display_pos[2])

        if min_x == float('inf'): # No valid positions found
            return None

        # Add a small buffer based on node size for easier grabbing
        zoom = self._view_state.get('zoom_factor', 1.0)
        node_radius_display = (self.grid_visualizer._calculate_node_size(zoom)**0.5) / 2.0 if self.grid_visualizer else 1.0
        # Convert points to data units (approximate)
        # This conversion is complex, let's use a simpler fixed buffer in data coords for now
        buffer = self.coord_system.scale_factor * 0.5 # Half node spacing

        return (min_x - buffer, max_x + buffer, min_y - buffer, max_y + buffer)

    def _on_enter_canvas(self, event):
        """Reset last mouse position when entering the canvas."""
        logger.debug("_on_enter_canvas: Mouse entered plot area.")
        self._last_mouse_pos = (event.x, event.y) # Initialize position on enter

    def _on_leave_canvas(self, event):
        """Stop panning animation smoothly when leaving the canvas."""
        logger.debug("_on_leave_canvas: Mouse left plot area.")
        # --- REMOVED: Clearing _last_mouse_pos (not used for wheel panning) ---
        # self._last_mouse_pos = None

        # --- MODIFIED: Stop animation smoothly by setting velocity to zero ---
        # This allows the _animate_pan loop to finish gracefully.
        self.pan_velocity_x = 0
        self.pan_velocity_y = 0
        logger.debug("  Set pan velocity to 0 on leave.")
        # ---

        # --- REMOVED: Immediate cancellation of animation ID ---

    def _handle_lasso_start(self, x_data, y_data):
        """Initiate lasso selection, clear previous state, force redraw, THEN capture background."""
        log_prefix = "_handle_lasso_start (R24 Blit Fix): " # Updated round
        logger.info(f"{log_prefix}Lasso Start at ({x_data:.2f}, {y_data:.2f})")
        self._lasso_points = [(x_data, y_data)] # Start polygon list
        self._remove_lasso_line() # Remove any previous line

        # Clear previous selection in GUI
        selection_cleared = False
        if self.gui.current_selection.get('nodes') or self.gui.current_selection.get('edges'):
            self.gui.current_selection['nodes'] = set()
            self.gui.current_selection['edges'] = set()
            selection_cleared = True
            logger.debug(f"{log_prefix}Cleared previous selection.")

        # Update editor buttons immediately
        if hasattr(self.gui, 'shape_editor_window') and self.gui.shape_editor_window and self.gui.shape_editor_window.winfo_exists():
            self.gui.shape_editor_window._update_action_button_states()

        # --- MODIFIED: Force redraw FIRST ---
        if selection_cleared:
            logger.debug(f"{log_prefix}Forcing redraw to clear selection highlights.")
            # Use force=True to ensure a full redraw happens now
            self.gui._safe_plot_update(force=True)
            # Ensure the draw completes before capturing background
            self.fig.canvas.flush_events()
            logger.debug(f"{log_prefix}Flush events called after forced redraw.")
        else:
            logger.debug(f"{log_prefix}No selection to clear.")
        # --- END MODIFIED ---

        # --- Capture background AFTER potential redraw ---
        if self.grid_visualizer and self.grid_visualizer.blitting_manager.enabled:
            logger.debug(f"{log_prefix}Attempting background capture for blitting.")
            try:
                # Ensure canvas is drawn before capturing (might be redundant after force=True, but safe)
                self.fig.canvas.draw_idle()
                self.fig.canvas.flush_events()
                if self.fig.canvas.get_renderer() is None:
                     logger.warning(f"{log_prefix}Renderer not available, cannot capture background.")
                     self.grid_visualizer.blitting_manager.invalidate_cache()
                else:
                    # Capture the background *now*
                    self.grid_visualizer.blitting_manager.background = self.fig.canvas.copy_from_bbox(self.ax.bbox)
                    if self.grid_visualizer.blitting_manager.background:
                        logger.info(f"{log_prefix}Background captured successfully for lasso.")
                    else:
                        logger.error(f"{log_prefix}Background capture FAILED (result is None).")
                        self.grid_visualizer.blitting_manager.invalidate_cache()
            except Exception as e_bg:
                logger.error(f"{log_prefix}Error capturing background: {e_bg}")
                self.grid_visualizer.blitting_manager.invalidate_cache()
        else:
            logger.debug(f"{log_prefix}Blitting disabled or visualizer missing, not capturing background.")
        # ---

    def _handle_lasso_drag(self, x_data, y_data):
        """Update lasso polygon during drag and provide visual feedback.
           (Round 24 Fix: Check background buffer before restore)"""
        log_prefix = "_handle_lasso_drag (R24 Blit Fix): " # Updated round
        if not self._lasso_points: return

        self._lasso_points.append((x_data, y_data))
        if len(self._lasso_points) < 2: return

        points_to_draw = self._lasso_points + [self._lasso_points[0]]
        xs, ys = zip(*points_to_draw)

        # --- Draw or update temporary line ---
        if self.grid.dimension_type == Dimension.THREE_D:
            z_min, z_max = self.ax.get_zlim() if hasattr(self.ax, 'get_zlim') else (0, 0)
            z_plane = (z_min + z_max) / 2
            zs = [z_plane] * len(xs)
            if self._lasso_line is None:
                self._lasso_line, = self.ax.plot(xs, ys, zs, color='grey', linestyle='dashed', zorder=10, animated=True) # type: ignore
                logger.debug(f"{log_prefix}Created 3D lasso line artist.")
            else:
                self._lasso_line.set_data_3d(xs, ys, zs) # type: ignore
            self.ax.draw_artist(self._lasso_line) # type: ignore
        else: # 2D
            if self._lasso_line is None:
                self._lasso_line, = self.ax.plot(xs, ys, color='grey', linestyle='dashed', zorder=10, animated=True)
                logger.debug(f"{log_prefix}Created 2D lasso line artist.")
            else:
                self._lasso_line.set_data(xs, ys)
            self.ax.draw_artist(self._lasso_line)
        # ---

        # --- Blit the changes ---
        if self.grid_visualizer and self.grid_visualizer.blitting_manager.is_valid() and self._lasso_line:
            # --- ADDED: Check if background buffer exists ---
            bg_buffer = self.grid_visualizer.blitting_manager.background
            if bg_buffer is None:
                logger.warning(f"{log_prefix}Blitting valid but background buffer is None. Skipping blit.")
                return
            # --- END ADDED ---
            logger.debug(f"{log_prefix}Blitting is VALID. Background type: {type(bg_buffer)}")
            try:
                logger.debug(f"{log_prefix}  Restoring background...")
                self.fig.canvas.restore_region(bg_buffer)
                logger.debug(f"{log_prefix}  Drawing lasso artist...")
                self.ax.draw_artist(self._lasso_line)
                logger.debug(f"{log_prefix}  Blitting ax.bbox...")
                self.fig.canvas.blit(self.ax.bbox)
                logger.debug(f"{log_prefix}Blitted lasso drag update.")
            except Exception as e:
                logger.error(f"{log_prefix}Error during lasso drag blit: {e}")
                if self.grid_visualizer: self.grid_visualizer.blitting_manager.invalidate_cache()
        else:
            if not self.grid_visualizer: logger.debug(f"{log_prefix}Blitting skipped: grid_visualizer is None.")
            elif not self.grid_visualizer.blitting_manager.is_valid(): logger.debug(f"{log_prefix}Blitting skipped: BlittingManager cache is invalid.")
            elif not self._lasso_line: logger.debug(f"{log_prefix}Blitting skipped: _lasso_line is None.")
        # ---

    def _handle_lasso_release(self, x_data, y_data):
        """Finalize lasso selection by finding nodes within the polygon.
           Schedules ONE redraw at the end with the final selection.
           (Moved back to ViewManager, accesses GUI via self.gui in Round 11)"""
        log_prefix = "_handle_lasso_release (R11 ViewManager Fix): " # Updated round
        logger.info(f"{log_prefix}Lasso Release at ({x_data:.2f}, {y_data:.2f})")

        # --- Access GUI ---
        if not hasattr(self, 'gui') or self.gui is None:
            logger.error(f"{log_prefix}Cannot handle release: self.gui reference is missing.")
            return
        # ---

        # Store final points before removing line
        final_lasso_points = list(self._lasso_points) # Access own attribute
        if final_lasso_points: # Add the release point if list is not empty
             final_lasso_points.append((x_data, y_data))

        # Remove line (own method, no redraw)
        self._remove_lasso_line() # Access own attribute

        # Check if enough points for a polygon
        if not final_lasso_points or len(final_lasso_points) < 3:
            logger.debug(f"{log_prefix}Lasso too small or no points, clearing selection.")
            self.gui.current_selection['nodes'] = set() # Access GUI attribute
            self.gui.current_selection['edges'] = set() # Access GUI attribute
            self._lasso_points = [] # Access own attribute
            self.gui._update_editor_buttons_if_open() # Access GUI method
            # Schedule redraw AFTER clearing selection
            if hasattr(self.gui, 'root') and self.gui.root and self.gui.root.winfo_exists():
                self.gui.root.after(0, lambda: self.gui._safe_plot_update(force=True, selection_to_highlight=set())) # Access GUI method
            else: logger.error(f"{log_prefix}Cannot schedule redraw: self.gui.root is not available.")
            return

        # Create Matplotlib Path
        try:
            from matplotlib.path import Path
            lasso_path = Path(final_lasso_points + [final_lasso_points[0]])
        except ImportError:
            logger.error(f"{log_prefix}Matplotlib Path not available for lasso selection.")
            self._lasso_points = [] # Access own attribute
            return

        # Find nodes within the polygon
        selected_node_coords = set()
        # --- Access grid and visualizer via GUI ---
        if self.gui.grid and self.gui.grid_visualizer:
            vis_state = self.gui.grid_visualizer._visualization_state
            vis_x = vis_state.get('x_coords')
            vis_y = vis_state.get('y_coords')
            vis_indices = vis_state.get('indices')

            if vis_x is not None and vis_y is not None and vis_indices is not None and len(vis_x) == len(vis_indices):
                points_to_check = np.column_stack([vis_x, vis_y])
                if points_to_check.size > 0:
                    contained_mask = lasso_path.contains_points(points_to_check)
                    contained_original_indices = vis_indices[contained_mask]
                    for node_idx in contained_original_indices:
                        try:
                            node_coords = tuple(_unravel_index(node_idx, self.gui.grid.dimensions)) # Access GUI grid
                            selected_node_coords.add(node_coords)
                        except IndexError: logger.warning(f"{log_prefix}Lasso: Index {node_idx} out of bounds for grid dimensions {self.gui.grid.dimensions}")
                        except Exception as e: logger.error(f"{log_prefix}Lasso: Error unraveling index {node_idx}: {e}")
                else: logger.debug(f"{log_prefix}Lasso: No visible nodes to check.")
            else: logger.warning(f"{log_prefix}Lasso: Mismatch in visualizer state arrays or arrays are empty.")
        else: logger.warning(f"{log_prefix}Lasso: Grid or GridVisualizer not available via GUI.")
        # ---

        logger.info(f"{log_prefix}Lasso selected {len(selected_node_coords)} nodes.")

        # Update GUI selection state
        self.gui.current_selection['nodes'] = selected_node_coords # Access GUI attribute
        self.gui.current_selection['edges'] = set() # Access GUI attribute
        logger.debug(f"{log_prefix}Updated self.gui.current_selection['nodes'] (Size: {len(self.gui.current_selection['nodes'])}).")

        # Clear lasso points list
        self._lasso_points = [] # Access own attribute

        # Update editor buttons
        self.gui._update_editor_buttons_if_open() # Access GUI method

        # Schedule ONE forced redraw AFTER updating selection
        logger.debug(f"{log_prefix}Scheduling ONE forced redraw AFTER selection update, passing {len(selected_node_coords)} selected nodes.")
        if hasattr(self.gui, 'root') and self.gui.root and self.gui.root.winfo_exists():
            # Pass the calculated set directly
            self.gui.root.after(0, lambda sel=selected_node_coords: self.gui._safe_plot_update(force=True, selection_to_highlight=sel)) # Access GUI method
        else:
            logger.error(f"{log_prefix}Cannot schedule redraw: self.gui.root is not available.")

    def _remove_lasso_line(self):
        """Removes the temporary lasso line artist WITHOUT forcing redraw."""
        if self._lasso_line:
            try:
                self._lasso_line.remove()
                logger.debug("Removed temporary lasso line.")
            except ValueError: pass # May already be removed
            except Exception as e: logger.warning(f"Error removing temporary lasso line: {e}")
            finally:
                self._lasso_line = None
                # --- REMOVED: Forced redraw ---

    def _handle_erase_start(self, x_data, y_data):
        """Erase node at the starting position."""
        logger.info(f"Erase Start/Action at ({x_data:.2f}, {y_data:.2f})")
        node_coords = self._find_node_in_click_field(x_data, y_data)
        modified = False
        if node_coords:
            modified = self._erase_node(node_coords)
        # Trigger redraw immediately if modified
        if modified:
            self.gui._safe_plot_update(force=True)

    def _handle_erase_drag(self, x_data, y_data):
        """Erase nodes during drag. If selection exists, erase all selected nodes."""
        # logger.debug(f"Erase Drag at ({x_data:.2f}, {y_data:.2f})") # Reduce noise
        modified = False
        selection_nodes = self.gui.current_selection.get('nodes')

        # --- MODIFIED: Always erase selection if it exists ---
        if selection_nodes:
            # Selection exists: Erase all selected nodes
            logger.debug(f"Erase drag with selection active. Erasing {len(selection_nodes)} selected nodes.")
            nodes_erased_in_batch = 0
            # Use list() to avoid modifying set during iteration if _erase_node modifies selection indirectly
            for sel_coords in list(selection_nodes):
                if self._erase_node(sel_coords):
                    nodes_erased_in_batch += 1
                    # Optionally remove from selection immediately, or clear at the end
                    # selection_nodes.remove(sel_coords)
            if nodes_erased_in_batch > 0:
                modified = True
                logger.debug(f"Erased {nodes_erased_in_batch} nodes from selection.")
            # Clear selection after erasing all
            self.gui.current_selection['nodes'] = set()
            self.gui.current_selection['edges'] = set()
            # Update editor buttons
            if hasattr(self.gui, 'shape_editor_window') and self.gui.shape_editor_window and self.gui.shape_editor_window.winfo_exists():
                self.gui.shape_editor_window._update_action_button_states()
        else:
            # No selection: Erase single node under cursor
            node_coords = self._find_node_in_click_field(x_data, y_data)
            if node_coords:
                modified = self._erase_node(node_coords)
        # ---

        # Trigger redraw immediately if modified
        if modified:
            self.gui._push_grid_state_to_undo("Erase Nodes (Selection/Drag)")
            self.gui._safe_plot_update(force=True)

    def _handle_erase_release(self, x_data: float, y_data: float):
        """Finalize erase action (clear temporary drag state)."""
        log_prefix = "_handle_erase_release: "
        logger.info(f"{log_prefix}Erase Release at ({x_data:.2f}, {y_data:.2f})")
        # --- REMOVED call to _clear_selection_after_action ---
        if hasattr(self, '_erased_in_drag'):
            delattr(self, '_erased_in_drag')

    def _handle_add_edge_start(self, x_data, y_data):
        """Identify starting node for edge addition and provide visual feedback."""
        logger.info(f"Add Edge Start at ({x_data:.2f}, {y_data:.2f})")
        self._remove_temp_line() # Remove any previous temp line
        start_node_coords = self._find_node_in_click_field(x_data, y_data)
        self._edge_tool_start_node_coords = start_node_coords # Store potential start node
        logger.debug(f"  Potential start node for add edge: {start_node_coords}")
        # TODO: Add visual feedback (e.g., highlight start node) - Deferred

    def _handle_add_edge_drag(self, x_data, y_data):
        """Provide visual feedback (temporary line) during edge drag."""
        # logger.debug(f"Add Edge Drag to ({x_data:.2f}, {y_data:.2f})") # Reduce noise
        if self._edge_tool_start_node_coords is None:
            return # No start node selected

        # Get display coordinates of start node
        start_node_display = self.coord_system.grid_to_display(self._edge_tool_start_node_coords)

        # Draw or update temporary line
        line_data = [(start_node_display[0], start_node_display[1]), (x_data, y_data)]
        if self.grid.dimension_type == Dimension.THREE_D:
            # 3D line handling (might need adjustment based on Line3DCollection usage)
            line_data_3d = [(start_node_display[0], start_node_display[1], start_node_display[2]),
                            (x_data, y_data, start_node_display[2])] # Assume drag on XY plane for now
            if self._edge_tool_temp_line is None:
                # Create Line3D object (not Line3DCollection for a single line)
                self._edge_tool_temp_line, = self.ax.plot(
                    [p[0] for p in line_data_3d],
                    [p[1] for p in line_data_3d],
                    [p[2] for p in line_data_3d],
                    color='grey', linestyle='dashed', zorder=10
                ) # type: ignore
                logger.debug("Created 3D temp edge line artist.")
            else:
                # Update existing Line3D artist
                self._edge_tool_temp_line.set_data_3d(
                    [p[0] for p in line_data_3d],
                    [p[1] for p in line_data_3d],
                    [p[2] for p in line_data_3d]
                ) # type: ignore
            self.ax.draw_artist(self._edge_tool_temp_line) # type: ignore
        else: # 2D
            if self._edge_tool_temp_line is None:
                self._edge_tool_temp_line, = self.ax.plot([line_data[0][0], line_data[1][0]],
                                                          [line_data[0][1], line_data[1][1]],
                                                          color='grey', linestyle='dashed', zorder=10)
                logger.debug("Created 2D temp edge line artist.")
            else:
                self._edge_tool_temp_line.set_data([line_data[0][0], line_data[1][0]],
                                                   [line_data[0][1], line_data[1][1]])
            self.ax.draw_artist(self._edge_tool_temp_line)
        # ---

        # --- Blit the changes ---
        # --- MODIFIED: Access blitting_manager via grid_visualizer ---
        if self.grid_visualizer and self.grid_visualizer.blitting_manager.is_valid() and self._edge_tool_temp_line:
        # ---
            try:
                self.fig.canvas.restore_region(self.grid_visualizer.blitting_manager.background) # Use grid_visualizer
                self.ax.draw_artist(self._edge_tool_temp_line)
                self.fig.canvas.blit(self.ax.bbox)
                # logger.debug("Blitted add edge drag update.") # Reduce noise
            except Exception as e:
                logger.error(f"Error during add edge drag blit: {e}")
                if self.grid_visualizer: self.grid_visualizer.blitting_manager.invalidate_cache() # Invalidate if blit fails
        # ---

    def _handle_add_edge_release(self, x_data: float, y_data) -> bool:
        """Finalize edge addition. Connects nodes within selection if active, otherwise uses drag start/end."""
        logger.info(f"Add Edge Release at ({x_data:.2f}, {y_data:.2f})")
        grid_modified = False
        selection_nodes = self.gui.current_selection.get('nodes')

        # Remove temporary line regardless of outcome
        self._remove_temp_line()

        if selection_nodes:
            logger.debug(f"Add edge release with selection active. Connecting nodes within selection ({len(selection_nodes)} nodes).")
            if self.grid:
                nodes_list = list(selection_nodes)
                edges_added_count = 0
                for i in range(len(nodes_list)):
                    for j in range(i + 1, len(nodes_list)): # Avoid self-loops and duplicates
                        node1_coords = nodes_list[i]
                        node2_coords = nodes_list[j]
                        if self._add_edge_if_valid(node1_coords, node2_coords):
                            edges_added_count += 1
                            grid_modified = True
                logger.info(f"Added {edges_added_count} edges within selection.")
                # --- REMOVED call to _clear_selection_after_action ---
                # Clearing selection is now handled by the SimulationGUI method that calls this logic
            else:
                logger.error("Cannot add edges to selection: Grid is None.")

        else: # --- Original Drag-and-Drop Logic ---
            start_node_coords = self._edge_tool_start_node_coords
            end_node_coords = self._find_node_in_click_field(x_data, y_data)
            logger.debug(f"Add Edge Release (Drag): Start={start_node_coords}, End={end_node_coords}")

            if start_node_coords and end_node_coords and start_node_coords != end_node_coords:
                if self.grid:
                    logger.debug(f"  Attempting to add edge between {start_node_coords} and {end_node_coords}")
                    if self._add_edge_if_valid(start_node_coords, end_node_coords):
                        grid_modified = True
                        logger.info(f"  Successfully added edge: {start_node_coords} <-> {end_node_coords}")
                        if hasattr(self.gui, '_safe_plot_update'):
                            logger.debug("Triggering plot update after edge drag-add.")
                            self.gui._safe_plot_update() # Non-forced update
                    else:
                        logger.debug("  Edge not added (likely not valid neighbors or already exists).")
                else:
                    logger.error("  Cannot add edge: Grid is None.")
            else:
                logger.debug("  Invalid start/end node for edge addition or dragged to same node.")

        self._edge_tool_start_node_coords = None # Clear start node

        if grid_modified:
            self.gui._push_grid_state_to_undo("Add Edge(s)")

        return grid_modified

    def _handle_del_edge_press(self, x_data, y_data):
        """Delete edge closest to the press position or all edges within selection if selection exists."""
        logger.info(f"Delete Edge Press at ({x_data:.2f}, {y_data:.2f})")
        modified = False
        # --- MODIFIED: Access current_selection via self.gui ---
        selection_nodes = self.gui.current_selection.get('nodes')
        # ---

        # --- MODIFIED: Prioritize deleting selection edges ---
        if selection_nodes:
            # Selection exists: Delete all internal edges
            logger.debug(f"Delete edge press with selection active. Deleting internal edges for {len(selection_nodes)} nodes.")
            edges_to_remove_sel = set()
            if self.grid:
                for edge_coords in list(self.grid.edges): # Iterate copy
                    n1, n2 = edge_coords
                    if n1 in selection_nodes and n2 in selection_nodes:
                        edges_to_remove_sel.add(edge_coords)

                if edges_to_remove_sel:
                    logger.debug(f"Found {len(edges_to_remove_sel)} internal edges to remove.")
                    for edge_coords in edges_to_remove_sel:
                         # Check drag history (optional, maybe remove for selection clear?)
                         # if edge_coords not in self._deleted_edges_in_drag:
                            try:
                                node1_coords, node2_coords = edge_coords
                                node1_idx = _ravel_multi_index(np.array(node1_coords), self.grid.dimensions)
                                node2_idx = _ravel_multi_index(np.array(node2_coords), self.grid.dimensions)
                                self.grid.remove_edge(node1_idx, node2_idx)
                                # self._deleted_edges_in_drag.add(edge_coords) # Don't track for selection clear
                                modified = True
                            except Exception as e: logger.error(f"  Error deleting edge {edge_coords}: {e}")
                    if modified: logger.info(f"Deleted {len(edges_to_remove_sel)} internal edges from selection.")
                else: logger.debug("No internal edges found in selection.")
            else: logger.error("Cannot delete edges: Grid is None.")
            # Clear selection after deleting internal edges
            self.gui.current_selection['nodes'] = set()
            self.gui.current_selection['edges'] = set()
            if hasattr(self.gui, 'shape_editor_window') and self.gui.shape_editor_window and self.gui.shape_editor_window.winfo_exists():
                self.gui.shape_editor_window._update_action_button_states()

        else:
            # No selection: Delete specific edge near click
            edge_to_delete = self._find_edge_at_position(x_data, y_data)
            if edge_to_delete:
                if edge_to_delete not in self._deleted_edges_in_drag: # Still track for single delete drag
                    logger.debug(f"  Attempting to delete specific edge: {edge_to_delete}")
                    if self.grid:
                        try:
                            node1_coords, node2_coords = edge_to_delete
                            node1_idx = _ravel_multi_index(np.array(node1_coords), self.grid.dimensions)
                            node2_idx = _ravel_multi_index(np.array(node2_coords), self.grid.dimensions)
                            self.grid.remove_edge(node1_idx, node2_idx)
                            self._deleted_edges_in_drag.add(edge_to_delete)
                            modified = True
                            logger.info(f"  Successfully deleted edge: {edge_to_delete}")
                        except Exception as e: logger.error(f"  Error deleting edge: {e}")
                    else: logger.error("  Cannot delete edge: Grid is None.")
                else: logger.debug(f"  Edge {edge_to_delete} already deleted in this drag.")
            else: logger.debug("  No edge found near click to delete.")
        # ---

        # Trigger redraw immediately if modified
        if modified:
            # --- MODIFIED: Access _push_grid_state_to_undo via self.gui ---
            self.gui._push_grid_state_to_undo("Delete Edge(s) (Selection/Click)")
            # ---
            self.gui._safe_plot_update(force=True)

    def _handle_del_edge_drag(self, x_data, y_data):
        """Delete edges during drag."""
        # logger.debug(f"Delete Edge Drag at ({x_data:.2f}, {y_data:.2f})") # Reduce noise
        # Call press logic on drag to continuously delete edges under cursor
        self._handle_del_edge_press(x_data, y_data)

    def _remove_temp_line(self):
        """Removes the temporary line artist used for edge creation feedback."""
        if self._edge_tool_temp_line:
            try:
                self._edge_tool_temp_line.remove()
                logger.debug("Removed temporary edge line.")
            except ValueError: # May already be removed
                pass
            except Exception as e:
                logger.warning(f"Error removing temporary edge line: {e}")
            finally:
                self._edge_tool_temp_line = None
                # --- MODIFIED: Access blitting_manager via grid_visualizer ---
                # Force redraw if blitting was used to clear the line artifact
                if self.grid_visualizer and self.grid_visualizer.blitting_manager.is_valid():
                # ---
                    self.gui._safe_plot_update(force=True)


################################################
#               SIMULATION CONTROL             #
################################################

class SimulationController(Observable):
    """Comprehensive control over simulation parameters and execution"""

    def __init__(self, rule_name: str,
                 neighborhood_type: Optional[NeighborhoodType] = None,
                 dimension_type: Optional[Dimension] = None,
                 initial_density: float = 0.3,
                 initialize_state: bool = True,
                 update_callback: Optional[Callable[[], None]] = None,
                 app_paths: Dict[str, str] = {},
                 gui: Optional['SimulationGUI'] = None):
        """
        Initializes the SimulationController.
        (Round 42: Add inactive_pools list)
        (Round 6: Create analytics queue here and pass to manager)
        """
        try:
            super().__init__() # Initialize Observable
            logger.info(f"GlobalSettings.Simulation.NUM_PROCESSES = {GlobalSettings.Simulation.NUM_PROCESSES}")
            unique_id = str(uuid.uuid4())
            self._unique_id = 'g' + hashlib.md5(unique_id.encode()).hexdigest()[:8]
            self._observers = []
            self.interrupt_requested = False
            self.auto_stabilize = True
            self._update_callback = update_callback
            self.app_paths = app_paths

            self.gui = gui

            # --- Analytics System Initialization ---
            self.analytics_data_in_queue: queue.Queue[Dict[str, Any]] = queue.Queue()
            logger.debug(f"SimulationController created analytics_data_in_queue with ID: {id(self.analytics_data_in_queue)}")
            self.metric_registry = MetricRegistry()
            self.analyzer_registry = AnalyzerRegistry()
            self.metric_registry.register(BasicCountsCalculator)
            self.analyzer_registry.register(StabilityAnalyzer)
            report_dir_path = self.app_paths.get('reports', DEFAULT_REPORT_DIR)
            if report_dir_path is None: logger.error("Could not determine report directory path. Using default."); report_dir_path = DEFAULT_REPORT_DIR
            self.analytics_manager = AnalyticsManager(
                metric_registry=self.metric_registry,
                analyzer_registry=self.analyzer_registry,
                data_in_queue=self.analytics_data_in_queue,
                report_dir=report_dir_path
            )
            self.analytics_manager.start()
            logger.info("AnalyticsManager initialized and started.")
            # --- End Analytics System Initialization ---

            self.log_queue_manager = multiprocessing.Manager()
            self.log_queue = self.log_queue_manager.Queue(-1)
            logger.info("Created multiprocessing Manager Queue for logging.")

            if dimension_type is None: self.dimension_type = GlobalSettings.Simulation.DIMENSION_TYPE
            elif isinstance(dimension_type, Dimension): self.dimension_type = dimension_type
            else: raise ValueError(f"Invalid dimension_type: {dimension_type}. Must be a Dimension enum.")

            if neighborhood_type is None: self.neighborhood_type = GlobalSettings.Simulation.NEIGHBORHOOD_TYPE
            elif isinstance(neighborhood_type, NeighborhoodType): self.neighborhood_type = neighborhood_type
            else: raise ValueError(f"Invalid neighborhood_type: {neighborhood_type}. Must be a NeighborhoodType enum.")

            # --- Preset Loading Logic (remains the same) ---
            presets_path = os.path.join(app_paths['config_presets'], 'grid_presets.json')
            self.grid_preset_manager = GridPresetManager.get_instance(app_paths)
            default_preset_obj: Optional[GridPreset] = None
            if self.grid_preset_manager.default_preset_name:
                preset = self.grid_preset_manager.get_preset(self.grid_preset_manager.default_preset_name)
                if preset:
                    logger.info(f"Loading grid dimensions from default preset: {preset.name}")
                    self.dimensions = tuple(preset.dimensions)
                    self.neighborhood_type = NeighborhoodType[preset.neighborhood_type]
                    rule_name = preset.rule_name # Use rule name from preset
                    default_preset_obj = preset
                else:
                    logger.warning(f"Default preset '{self.grid_preset_manager.default_preset_name}' not found, using global defaults.")
                    self.dimensions = GlobalSettings.Simulation.get_grid_dimensions()
            else:
                logger.info("No default preset specified, using global defaults.")
                self.dimensions = GlobalSettings.Simulation.get_grid_dimensions()
            # --- End Preset Loading Logic ---

            self.rule_name: str = rule_name # Use rule_name determined above

            try: rule_data = RuleLibraryManager.get_rule(rule_name)
            except ValueError as e: logger.error(f"Error loading rule {rule_name}: {e}"); raise
            metadata_dict = {k: v for k, v in rule_data.items() if k != 'params' and k != '_ignored_params'}
            metadata_dict.setdefault('position', 1); metadata_dict.setdefault('category', 'Unknown'); metadata_dict.setdefault('author', GlobalSettings.Defaults.DEFAULT_AUTHOR); metadata_dict.setdefault('url', GlobalSettings.Defaults.DEFAULT_URL); metadata_dict.setdefault('email', GlobalSettings.Defaults.DEFAULT_EMAIL); metadata_dict.setdefault('date_created', datetime.now().strftime("%Y-%m-%d")); metadata_dict.setdefault('date_modified', datetime.now().strftime("%Y-%m-%d")); metadata_dict.setdefault('version', '1.0'); metadata_dict.setdefault('description', 'No description available.'); metadata_dict.setdefault('tags', []); metadata_dict.setdefault('dimension_compatibility', ["TWO_D", "THREE_D"]); metadata_dict.setdefault('neighborhood_compatibility', []); metadata_dict.setdefault('parent_rule', None); metadata_dict.setdefault('rating', None); metadata_dict.setdefault('notes', None); metadata_dict.setdefault('allowed_initial_conditions', ["Random"]); metadata_dict.setdefault('allow_rule_tables', True); metadata_dict.setdefault('favorite', False)
            metadata = RuleMetadata(**metadata_dict) # Create metadata object
            try: self.rule = RuleLibrary.create_rule(rule_name, metadata)
            except ValueError as e: logger.error(f"Error creating rule {self.rule_name}: {e}"); raise
            if 'params' in rule_data: self.rule.params = copy.deepcopy(rule_data['params'])
            else: self.rule.params = {}
            self.rule.params['initial_density'] = initial_density

            self.grid: Optional['Grid'] = None
            self.generation = 0
            self.stats = SimulationStats()
            self.perf_logger = perf_logger
            self.perf_monitor = PerformanceMonitor()
            self.max_neighbors = self._calculate_max_neighbors()
            self._neighborhood_cache: Dict[int, NeighborhoodData] = {}
            self._cache_lock = threading.Lock()
            self._caching_mode = "partial"
            self._cache_hits = 0; self._cache_misses = 0
            self._full_cache_threshold = GlobalSettings.Cache.FULL_CACHE_THRESHOLD
            self._partial_cache_threshold = GlobalSettings.Cache.PARTIAL_CACHE_THRESHOLD
            self._full_cache_memory_threshold = GlobalSettings.Cache.FULL_CACHE_MEMORY_THRESHOLD
            self._partial_cache_memory_threshold = GlobalSettings.Cache.PARTIAL_CACHE_MEMORY_THRESHOLD
            self._cache_check_interval = GlobalSettings.Cache.CACHE_CHECK_INTERVAL
            self.shared_mem = None; self.shared_array = None
            self._update_lock = threading.Lock()
            self._shared_memory_unlinked = False
            self._edge_states_shared_memory_unlinked = False
            self._shutdown_complete = False
            self.apply_tiebreakers = False
            self.edges: Set[Tuple[Tuple[int, ...], Tuple[int, ...]]] = set()
            self.edge_states: Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float] = {}
            self._cached_unscaled_positions = None; self._cached_positions = None
            self._cached_dimensions = None; self._cached_spacing = None
            self._cached_dimension_type = None
            self._initial_setup_complete = False
            self.node_history_depth = 10
            self.node_history: Dict[int, List[float]] = {}
            self.node_attributes: Dict[int, Dict[str, Any]] = {}
            self.rows, self.cols, self.depth = 0, 0, 0
            if self.dimension_type == Dimension.TWO_D: self.rows, self.cols = self.dimensions; self.depth = 1
            elif self.dimension_type == Dimension.THREE_D: self.rows, self.cols, self.depth = self.dimensions
            self.coord_system = None
            self._view_state = {'zoom_factor': 1.0, 'center_grid': (0, 0, 0)}
            self.process_pool: Optional[Union[ProcessPoolExecutor, ThreadPoolExecutor]] = None
            # --- ADDED: List to track inactive pools ---
            self.inactive_pools: List[Union[ProcessPoolExecutor, ThreadPoolExecutor]] = []
            # ---

            self._initialize_process_pool()

        except Exception as e:
            logger.error(f"Error setting up SimulationController: {e}")
            raise

    @staticmethod
    def _init_worker():
        """Initialize worker process"""
        try:
            worker_id = mp.current_process().name
            print(f"Worker {worker_id} initializing")
            root_logger = logging.getLogger()
            
            # Log existing handlers before clearing
            print(f"Worker {worker_id} handlers before clearing: {[str(h) for h in root_logger.handlers]}")
            
            # Disable logging in worker processes
            root_logger.handlers = []
            root_logger.addHandler(logging.NullHandler())
            
            # Log final handler state
            print(f"Worker {worker_id} final handlers: {[str(h) for h in root_logger.handlers]}")
            
        except Exception as e:
            print(f"Error in worker initialization: {e}")

    def _initialize_process_pool(self, force_recreate: bool = False) -> bool:
        """
        Initialize the process or thread pool, passing the logging queue.
        Optionally forces recreation by shutting down the existing pool first
        and adding it to the inactive_pools list.
        (Round 6: Default to ThreadPoolExecutor)
        (Round 42: Add old pool to inactive_pools list)
        (Round 41: Add force_recreate flag and non-blocking shutdown of old pool)
        """
        log_prefix = f"Controller._initialize_process_pool (Force={force_recreate} R6 ThreadPool): " # Updated round
        logger.info(f"{log_prefix}>>> ENTERING <<<")
        pool_created_successfully = False
        try:
            # --- MODIFIED: Default to ThreadPoolExecutor ---
            # We will still check USE_PARALLEL_PROCESSING, but the default choice is now ThreadPool
            use_parallel = GlobalSettings.USE_PARALLEL_PROCESSING
            num_processes = GlobalSettings.Simulation.NUM_PROCESSES
            logger.info(f"{log_prefix}Attempting init. USE_PARALLEL={use_parallel}, NUM_PROCESSES={num_processes}")

            # Determine if we *should* use ProcessPool based on settings
            should_use_process_pool = use_parallel and num_processes > 1
            logger.info(f"{log_prefix}Calculated should_use_process_pool = {should_use_process_pool}")
            # --- END MODIFIED ---

            needs_recreation = False
            reason = ""

            if force_recreate:
                needs_recreation = True
                reason = "Forced recreation requested."
            elif self.process_pool is None: needs_recreation = True; reason = "Pool is None."
            elif getattr(self.process_pool, '_broken', False): needs_recreation = True; reason = "Pool is broken."
            # --- MODIFIED: Check against desired pool type ---
            elif should_use_process_pool and not isinstance(self.process_pool, ProcessPoolExecutor): needs_recreation = True; reason = f"Pool type mismatch (Should be ProcessPool, is {type(self.process_pool).__name__})."
            elif not should_use_process_pool and not isinstance(self.process_pool, ThreadPoolExecutor): needs_recreation = True; reason = f"Pool type mismatch (Should be ThreadPool, is {type(self.process_pool).__name__})."
            # --- END MODIFIED ---

            if needs_recreation:
                logger.warning(f"{log_prefix}Recreating process pool. Reason: {reason}")
                if self.process_pool is not None:
                    old_pool = self.process_pool
                    old_pool_id = id(old_pool)
                    logger.info(f"{log_prefix}Attempting non-blocking shutdown of existing pool (ID: {old_pool_id}, wait=False, cancel=True)...")
                    try:
                        old_pool.shutdown(wait=False, cancel_futures=True)
                        logger.info(f"{log_prefix}Non-blocking shutdown initiated for old pool (ID: {old_pool_id}).")
                        if not hasattr(self, 'inactive_pools'): self.inactive_pools = []
                        self.inactive_pools.append(old_pool)
                        logger.info(f"{log_prefix}Added old pool (ID: {old_pool_id}) to inactive_pools list for later cleanup.")
                    except Exception as e_shutdown: logger.error(f"{log_prefix}Error during non-blocking shutdown of existing pool (ID: {old_pool_id}): {e_shutdown}")
                    finally:
                        self.process_pool = None
                        logger.debug(f"{log_prefix}Set self.process_pool reference to None.")

                # --- MODIFIED: Create ThreadPoolExecutor by default unless ProcessPool is explicitly needed ---
                logger.info(f"{log_prefix}Based on should_use_process_pool={should_use_process_pool}, attempting to create new pool...")
                if should_use_process_pool:
                    logger.info(f"{log_prefix}>>> EXECUTING ProcessPoolExecutor branch (should_use_process_pool was True)")
                    try:
                        log_queue_arg = self.log_queue if hasattr(self, 'log_queue') else None
                        self.process_pool = ProcessPoolExecutor(
                            max_workers=num_processes,
                            initializer=_worker_initializer_func,
                            initargs=(log_queue_arg,) # type: ignore [reportArgumentType]
                        )
                        logger.info(f"{log_prefix}Successfully created NEW ProcessPoolExecutor with {num_processes} workers (ID: {id(self.process_pool)}).")
                        pool_created_successfully = True
                    except Exception as e_proc:
                         logger.error(f"{log_prefix}Failed to create ProcessPoolExecutor: {e_proc}. Falling back to ThreadPool.")
                         self.process_pool = ThreadPoolExecutor(max_workers=num_processes) # Use num_processes for threads too
                         logger.info(f"{log_prefix}Initialized fallback ThreadPoolExecutor (max_workers={num_processes}) (ID: {id(self.process_pool)}).")
                         pool_created_successfully = True
                else:
                    logger.info(f"{log_prefix}>>> EXECUTING ThreadPoolExecutor branch (should_use_process_pool was False)")
                    self.process_pool = ThreadPoolExecutor(max_workers=num_processes) # Use num_processes for threads
                    logger.info(f"{log_prefix}Successfully created ThreadPoolExecutor (max_workers={num_processes}) (ID: {id(self.process_pool)}).")
                    pool_created_successfully = True
                # --- END MODIFIED ---
            else:
                pool_type = type(self.process_pool).__name__
                logger.info(f"{log_prefix}Existing process pool is suitable (Type: {pool_type}, ID: {id(self.process_pool)}).")
                pool_created_successfully = True

            if self.process_pool is not None:
                 pool_type = type(self.process_pool).__name__
                 logger.info(f"{log_prefix}Final pool state - Type: {pool_type}, ID: {id(self.process_pool)}")
                 return True
            else:
                 logger.error(f"{log_prefix}Failed to establish a valid process pool.")
                 return False

        except Exception as e:
            logger.error(f"{log_prefix}Unexpected error: {e}")
            logger.error(traceback.format_exc())
            try:
                if self.process_pool is not None: self.process_pool.shutdown(wait=False)
                self.process_pool = ThreadPoolExecutor(max_workers=GlobalSettings.Simulation.NUM_PROCESSES) # Use num_processes
                logger.info(f"{log_prefix}Falling back to ThreadPoolExecutor after unexpected error.")
                pool_created_successfully = True
                return True
            except Exception as e2:
                logger.error(f"{log_prefix}Failed to initialize fallback thread pool after error: {e2}")
                return False
        finally:
            logger.info(f"{log_prefix}>>> EXITING (Success={pool_created_successfully}) <<<")

    def _cleanup_inactive_pools(self, timeout_per_pool: float = 1.0):
        """
        Attempts to properly shut down pools stored in the inactive_pools list.
        Removes pools from the list if shutdown is successful or times out repeatedly.
        (Round 42: New method)
        """
        log_prefix = "Controller._cleanup_inactive_pools: "
        if not hasattr(self, 'inactive_pools') or not self.inactive_pools:
            # logger.debug(f"{log_prefix}No inactive pools to clean up.") # Reduce log noise
            return

        logger.info(f"{log_prefix}Attempting cleanup of {len(self.inactive_pools)} inactive pool(s)...")
        pools_to_remove = []
        for i, pool in enumerate(self.inactive_pools):
            pool_id = id(pool)
            logger.debug(f"{log_prefix}Checking inactive pool {i+1}/{len(self.inactive_pools)} (ID: {pool_id})...")
            try:
                # Attempt shutdown with a short timeout
                pool.shutdown(wait=True, cancel_futures=True) # Use wait=True here
                logger.info(f"{log_prefix}Successfully shut down inactive pool (ID: {pool_id}).")
                pools_to_remove.append(pool)
            except TimeoutError: # This exception might not be raised by shutdown, check _shutdown flag?
                logger.warning(f"{log_prefix}Timeout trying to shut down inactive pool (ID: {pool_id}). Will retry later.")
                # Check internal flag if possible (may vary by Python version/implementation)
                if getattr(pool, '_shutdown', False) or getattr(pool, '_shutdown_thread', False):
                     logger.info(f"{log_prefix}Pool (ID: {pool_id}) appears to be shutting down or shut down despite timeout. Removing from list.")
                     pools_to_remove.append(pool)
            except Exception as e:
                logger.error(f"{log_prefix}Error shutting down inactive pool (ID: {pool_id}): {e}. Removing from list.")
                pools_to_remove.append(pool) # Remove if error occurs

        # Remove successfully cleaned pools from the list
        if pools_to_remove:
            logger.debug(f"{log_prefix}Removing {len(pools_to_remove)} pools from inactive list.")
            for pool in pools_to_remove:
                try:
                    self.inactive_pools.remove(pool)
                except ValueError:
                    pass # Already removed somehow
            logger.info(f"{log_prefix}Finished cleanup attempt. {len(self.inactive_pools)} pool(s) remain inactive.")

    def cleanup(self):
        """Clean up controller resources, including logging queue manager, process pool, analytics manager,
           and any remaining inactive pools.
           (Round 42: Add cleanup for inactive_pools)
           (Round 1: Add analytics manager stop)
           (Round 32: Shutdown manager first, increase pool timeout)"""
        try:
            if hasattr(self, '_is_cleaning_up') and self._is_cleaning_up:
                logger.warning("Controller cleanup() called while already cleaning up, skipping")
                return

            self._is_cleaning_up = True
            logger.info("Starting SimulationController cleanup (Round 42 Inactive Pool Cleanup)") # Updated round

            self.interrupt_requested = True # Signal any ongoing controller tasks

            # --- 1. Logging Queue Manager Shutdown FIRST ---
            if hasattr(self, 'log_queue_manager') and self.log_queue_manager:
                try:
                    logger.info("Shutting down logging queue manager...")
                    self.log_queue_manager.shutdown()
                    logger.info("Logging queue manager shut down.")
                except Exception as e: logger.error(f"Error shutting down logging queue manager: {e}")
                finally: self.log_queue_manager = None; self.log_queue = None
            else: logger.debug("Logging queue manager is None or doesn't exist, skipping shutdown.")
            # ---

            # --- 2. Analytics Manager Shutdown ---
            if hasattr(self, 'analytics_manager') and self.analytics_manager:
                try:
                    logger.info("Stopping AnalyticsManager thread...")
                    self.analytics_manager.stop()
                    logger.info("AnalyticsManager stopped.")
                except Exception as e: logger.error(f"Error stopping AnalyticsManager: {e}")
                finally: self.analytics_manager = None
            else: logger.debug("AnalyticsManager is None or doesn't exist, skipping stop.")
            # ---

            # --- 3. Active Process Pool Shutdown ---
            pool_instance_id = "N/A"
            pool_shutdown_timeout = 5.0
            if hasattr(self, 'process_pool') and self.process_pool is not None:
                pool_instance_id = id(self.process_pool)
                logger.info(f"Shutting down ACTIVE process pool (ID: {pool_instance_id}, wait=True, cancel_futures=True, timeout={pool_shutdown_timeout}s)...")
                shutdown_start_time = time.time()
                try:
                    self.process_pool.shutdown(wait=True, cancel_futures=True)
                    shutdown_duration = time.time() - shutdown_start_time
                    logger.info(f"ACTIVE Process pool (ID: {pool_instance_id}) shut down successfully in {shutdown_duration:.2f}s.")
                except Exception as e:
                    shutdown_duration = time.time() - shutdown_start_time
                    logger.error(f"Error shutting down ACTIVE process pool (ID: {pool_instance_id}) after {shutdown_duration:.2f}s: {e}")
                    logger.error(traceback.format_exc())
                finally: self.process_pool = None; logger.debug("Set ACTIVE process_pool reference to None.")
            else: logger.debug("ACTIVE Process pool is None or doesn't exist, skipping shutdown.")
            # ---

            # --- ADDED: 4. Inactive Process Pool Shutdown ---
            if hasattr(self, 'inactive_pools') and self.inactive_pools:
                logger.info(f"Attempting final shutdown of {len(self.inactive_pools)} remaining inactive pool(s)...")
                # Use a copy for iteration as we might modify the list
                inactive_pools_copy = list(self.inactive_pools)
                for i, pool in enumerate(inactive_pools_copy):
                    pool_id = id(pool)
                    logger.info(f"Shutting down INACTIVE pool {i+1}/{len(inactive_pools_copy)} (ID: {pool_id}, wait=True, timeout=2.0s)...")
                    try:
                        pool.shutdown(wait=True, cancel_futures=True) # Wait briefly
                        logger.info(f"INACTIVE pool (ID: {pool_id}) shut down successfully.")
                    except Exception as e:
                        logger.error(f"Error during final shutdown of INACTIVE pool (ID: {pool_id}): {e}")
                    # Attempt to remove from original list regardless of success/failure during final cleanup
                    try: self.inactive_pools.remove(pool)
                    except ValueError: pass
                logger.info("Finished final shutdown attempt for inactive pools.")
                self.inactive_pools.clear() # Clear the list definitively
            else: logger.debug("No inactive pools found for final cleanup.")
            # --- END ADDED ---

            # --- 5. Grid Cleanup ---
            if hasattr(self, 'grid') and self.grid is not None:
                logger.debug("Calling Grid.cleanup() from Controller")
                try: self.grid.cleanup(); logger.info("Grid cleanup called from Controller")
                except Exception as grid_clean_err: logger.error(f"Error during Grid cleanup: {grid_clean_err}")
                finally: self.grid = None
            else: logger.debug("Grid is None, skipping grid cleanup call.")
            # ---

            # --- 6. Clear other references ---
            if hasattr(self, 'stats'): del self.stats; logger.info("Simulation stats deleted")
            if hasattr(self, 'perf_logger'): del self.perf_logger; logger.info("Performance logger deleted successfully")
            if hasattr(self, 'rule'): del self.rule; logger.info("Rule deleted")

            logger.info("Controller cleanup completed")

        except Exception as e:
            logger.error(f"Error in controller cleanup: {e}")
            logger.error(traceback.format_exc())
        finally:
             # --- MODIFIED: Use correct flag name ---
             if hasattr(self, '_is_cleaning_up'): self._is_cleaning_up = False
             logger.debug("Reset _is_cleaning_up flag in controller")
             # ---

    def get_view_center(self) -> Tuple[int, ...]:
        """Get the center of the view in grid coordinates."""
        return self._view_state['center_grid']

    def get_view_state(self):
        """Return the current view state."""
        return self._view_state

    def set_grid(self, grid: 'Grid'):
        """Update the grid reference and re-initialize dependent components."""
        old_grid_id = id(self.grid) if self.grid else None
        logger.debug(f"Setting new grid in GridVisualizer (Old ID: {old_grid_id}, New ID: {id(grid)})") # Enhanced logging

        # --- CRITICAL: Unregister from the old grid before setting the new one ---
        if self.grid:
            logger.debug(f"Unregistering from old grid: {id(self.grid)}")
            self.grid.remove_observer(self) # type: ignore [reportArgumentType] # Pylance seems confused about self type here
        # --- END CRITICAL FIX ---

        self.grid = grid
        logger.debug(f"New grid set in GridVisualizer: {self.grid._unique_id if self.grid else 'None'}, ID: {id(self.grid) if self.grid else 'None'}")

        # --- ADDED: Clear edge artists when grid changes ---
        if hasattr(self, '_edge_lines') and self._edge_lines is not None:
            try:
                self._edge_lines.remove()
                logger.debug("Removed existing 2D edge lines in set_grid")
            except Exception as e:
                logger.warning(f"Error removing _edge_lines in set_grid: {e}")
            self._edge_lines = None
        if hasattr(self, '_edge_lines_3d') and self._edge_lines_3d is not None:
            try:
                for line in self._edge_lines_3d: # type: ignore
                    line.remove()
                logger.debug("Removed existing 3D edge lines in set_grid")
            except Exception as e:
                logger.warning(f"Error removing _edge_lines_3d in set_grid: {e}")
            self._edge_lines_3d = None
        # --- END ADDED ---

        # Reset cached data
        self.reset() # Reset also clears artists, but explicit clear above is safer

        # Ensure coord_system is initialized before updating parameters
        if self.coord_system is None:
            self.coord_system = CoordinateSystem(
                grid_dimensions=grid.dimensions,
                node_spacing=GlobalSettings.Visualization.NODE_SPACING,
                dimension_type=grid.dimension_type
            )
        else:
            # Update coordinate system with the actual grid dimensions
            self.coord_system.update_parameters(
                grid_dimensions=grid.dimensions,
                node_spacing=GlobalSettings.Visualization.NODE_SPACING,
                dimension_type=grid.dimension_type
            )
        logger.debug("Updated coordinate system with new grid parameters")

        # Re-register with the new grid
        self.register_with_grid() # type: ignore [reportAttributeAccessIssue] # Pylance seems confused about self type here

        # Re-initialize the debugger with the new grid
        # CRITICAL FIX: Pass the gui parameter to the VisualizationDebugger
        self.debugger = VisualizationDebugger(self.grid, self.ax, self.coord_system, self.gui) # type: ignore [reportAttributeAccessIssue] # Pylance seems confused about self.ax

        logger.debug("Grid updated in GridVisualizer")

    def set_node_spacing(self, spacing: float):
        """Set the node spacing."""
        GlobalSettings.Visualization.set_node_spacing(spacing)
        # Invalidate cached positions in the Grid
        if self.grid is not None:
            self.grid._cached_positions = None
            self.grid._cached_unscaled_positions = None
        self.notify_observers()  # Notify to trigger redraw

    def set_zoom(self, factor: float):
        """Set the zoom factor."""
        self._view_state['zoom_factor'] = factor
        self.notify_observers()  # Notify to trigger redraw

    def reset_view(self):
        """Reset the view to the default."""
        self._reset_view_state()
        self.notify_observers()  # Notify to trigger redraw

    def _reset_view_state(self):
        """Reset view-related state variables."""
        self._view_state = {
            'zoom_factor': 1.0,
            'center_grid': (self.dimensions[1] // 2, self.dimensions[0] // 2, self.dimensions[2] // 2 if self.dimension_type == Dimension.THREE_D else 0)
        }

    def get_visualization_state(self):
        """Get all necessary data for visualization."""
        if self.grid is None:
            return {}  # Return empty dict if no grid

        # Get node positions (scaled)
        node_positions = self.grid.get_node_positions()
        x_coords = np.array([pos[0] for pos in node_positions.values()])
        y_coords = np.array([pos[1] for pos in node_positions.values()])
        z_coords = np.array([pos[2] for pos in node_positions.values()]) if self.grid.dimension_type == Dimension.THREE_D else None

        # Get node states
        states = self.grid.grid_array.ravel()

        # --- Corrected active node tracking ---
        current_active_nodes = set()
        if self.grid.dimension_type == Dimension.THREE_D:
            for i, j, k in np.ndindex(self.grid.dimensions):
                if self.grid.grid_array[i, j, k] > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD:
                    current_active_nodes.add((i, j, k))
        else:
            for i, j in np.ndindex(self.grid.dimensions):
                if self.grid.grid_array[i, j] > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD:
                    current_active_nodes.add((i, j))

        new_nodes = current_active_nodes - self.previous_active_nodes
        removed_nodes = self.previous_active_nodes - current_active_nodes
        self.previous_active_nodes = current_active_nodes
        # --- End corrected active node tracking ---

        # Get edge segments and colors
        segments = []
        colors = []
        
        # --- Corrected edge tracking ---
        current_edges = set()
        for edge, edge_state in self.grid.get_edges():
            pos1 = node_positions.get(_ravel_multi_index(np.array(edge[0]), self.grid.dimensions))
            pos2 = node_positions.get(_ravel_multi_index(np.array(edge[1]), self.grid.dimensions))
            if pos1 is not None and pos2 is not None:
                segments.append([pos1, pos2])
                # Determine edge color (simplified for now)
                colors.append(GlobalSettings.Colors.NODE_EDGE_OLD)
            current_edges.add((edge[0], edge[1])) # Add as tuple of tuples

        new_edges = current_edges - self.previous_edges
        removed_edges = self.previous_edges - current_edges  # Corrected line
        self.previous_edges = current_edges
        # --- End corrected edge tracking ---

        return {
            'x_coords': x_coords,
            'y_coords': y_coords,
            'z_coords': z_coords,
            'states': states,
            'segments': segments,
            'colors': colors,
            'new_nodes': new_nodes,
            'removed_nodes': removed_nodes, # Added
            'new_edges': new_edges,
            'removed_edges': removed_edges, # Added
            'zoom_factor': self._view_state['zoom_factor'],
            'center_grid': self._view_state['center_grid'],
            'dimension_type': self.dimension_type
        }

    def set_node_density(self, density: float):
        """Set the initial node density and reinitialize the grid."""
        if self.grid is None:
            return

        # Update global setting (optional, if you want to track it globally)
        GlobalSettings.Simulation.INITIAL_NODE_DENSITY = density

        # Re-initialize the grid with the new density
        self._initialize_random_state(density)
        self.grid.initialize_edges(self.rule.get_param('edge_initialization', 'RANDOM')) # Re-initialize edges
        self.notify_observers()

    def set_edge_density(self, density: float):
        """Set the target edge density and update the grid."""
        if self.grid is None:
            return

        # Calculate the target number of edges
        active_nodes = np.sum(self.grid.grid_array > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD)
        max_possible_edges = active_nodes * self.grid.max_neighbors // 2
        target_edge_count = int(max_possible_edges * density)

        # Get the current edges
        current_edges = self.grid.edges.copy()  # Work with a copy
        current_edge_count = len(current_edges)

        logger.debug(f"Target edge count: {target_edge_count}, Current edge count: {current_edge_count}")

        if current_edge_count < target_edge_count:
            # Add edges
            edges_to_add = target_edge_count - current_edge_count
            logger.debug(f"Adding {edges_to_add} edges")
            added_count = 0
            attempts = 0  # Limit attempts to prevent infinite loop
            
            # Get active node indices
            active_indices = np.where(self.grid.grid_array.ravel() > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD)[0]
            
            while added_count < edges_to_add and attempts < 2 * edges_to_add: # Limit attempts
                attempts += 1
                # Randomly select an active node
                node1_idx = np.random.choice(active_indices)
                
                # Get valid neighbors of the selected node
                neighbors = self.grid.get_neighbors(node1_idx, self.grid.coord_system)
                
                # Filter out inactive neighbors
                active_neighbors = [n for n in neighbors if n >= 0 and self.grid.grid_array.ravel()[n] > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD]
                
                if active_neighbors:
                    # Randomly select a neighbor
                    node2_idx = np.random.choice(active_neighbors)
                    
                    # Ensure consistent edge representation (smaller index first)
                    node1_coords = tuple(_unravel_index(node1_idx, self.dimensions))
                    node2_coords = tuple(_unravel_index(node2_idx, self.dimensions))
                    edge = self.grid._ordered_edge(node1_coords, node2_coords)
                    if edge not in current_edges:
                        self.grid.add_edge(node1_idx, node2_idx)  # Use Grid's add_edge, passing indices
                        current_edges.add(edge)  # Update the copy
                        added_count += 1

        elif current_edge_count > target_edge_count:
            # Remove edges
            edges_to_remove = current_edge_count - target_edge_count
            logger.debug(f"Removing {edges_to_remove} edges")
            removed_count = 0
            
            # Convert the set of edges to a list for random sampling
            edges_list = list(current_edges)
            
            # Randomly select edges to remove
            edges_to_remove_list = random.sample(edges_list, min(edges_to_remove, len(edges_list)))
            
            for edge in edges_to_remove_list:
                node1_coords = tuple(_unravel_index(edge[0][0], self.dimensions))
                node2_coords = tuple(_unravel_index(edge[1][0], self.dimensions))
                node1_idx = _ravel_multi_index(np.array(node1_coords), self.grid.dimensions)
                node2_idx = _ravel_multi_index(np.array(node2_coords), self.grid.dimensions)
                self.grid.remove_edge(node1_idx, node2_idx)  # Use Grid's remove_edge, passing indices
                removed_count += 1

        # Notify observers (GridVisualizer) to update
        self.notify_observers()

    def _calculate_max_neighbors(self) -> int:
        """Calculate maximum possible neighbors based on neighborhood type"""
        if self.neighborhood_type == NeighborhoodType.VON_NEUMANN:
            if self.dimension_type == Dimension.TWO_D:
                return 4
            elif self.dimension_type == Dimension.THREE_D:
                return 6
            else:
                raise ValueError(f"Invalid dimension type {self.dimension_type} for VON_NEUMANN neighborhood")
        elif self.neighborhood_type == NeighborhoodType.MOORE:
            if self.dimension_type == Dimension.TWO_D:
                return 8
            elif self.dimension_type == Dimension.THREE_D:
                return 26
            else:
                raise ValueError(f"Invalid dimension type {self.dimension_type} for MOORE neighborhood")
        elif self.neighborhood_type == NeighborhoodType.HEX:
            if self.dimension_type == Dimension.TWO_D:
                return 6
            else:
                raise ValueError(f"Invalid dimension type {self.dimension_type} for HEX neighborhood")
        elif self.neighborhood_type == NeighborhoodType.HEX_PRISM:
            if self.dimension_type == Dimension.THREE_D:
                return 12
            else:
                raise ValueError(f"Invalid dimension type {self.dimension_type} for HEX_PRISM neighborhood")
        else:
            raise ValueError(f"Invalid neighborhood type: {self.neighborhood_type}")

    @timer_decorator
    def step(self) -> Optional[Dict[str, Any]]: # Original signature restored
        """
        Perform one simulation step (computation only) and return the results.
        Handles standard rules and rules requiring post-update step (parallelizing final state calc).
        Passes actual data copies (not SHM meta) to the communication queue.
        Conditionally pushes data to the analytics queue.
        Manages temporary SHM segment names per step.
        Creates SHM in controller and passes META to grid method.
        Ensures correct dtype for previous arrays in snapshot.
        (Round 23: Explicit dtype casting for snapshot arrays)
        (Round 22: Ensure correct dtype for previous arrays in snapshot)
        (Round 5: Add dtype logging for previous arrays)
        """
        # --- Import necessary modules ---
        from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed
        from multiprocessing import shared_memory, Lock as mpLock
        from multiprocessing.shared_memory import SharedMemory
        import uuid
        import queue # For queue.Full check
        # ---

        logger = logging.getLogger(__name__)
        detailed_logging_enabled = LogSettings.Performance.ENABLE_DETAILED_LOGGING # Get flag
        log_prefix = f"Controller.step (Gen {self.generation} R23 Snapshot Dtype): " # Updated round
        if detailed_logging_enabled: logger.detail(f"{log_prefix}ENTRY") # type: ignore [attr-defined]

        # --- Initialize variables ---
        final_states_to_apply: Optional[np.ndarray] = None
        final_edges_this_step: Set[Tuple[Tuple[int, ...], Tuple[int, ...]]] = set()
        worker_durations: List[float] = []

        # --- Shared Memory Variables ---
        # Handles for temporary SHM created *this step*
        original_states_shm = None; original_states_shm_name = None; original_states_shm_meta = None
        eligibility_phase1_shm = None; eligibility_phase1_shm_name = None; eligibility_proxy_shm_meta = None
        prev_state_shm = None; prev_state_shm_name = None; prev_state_shm_meta_p3 = None
        prev_degree_shm = None; prev_degree_shm_name = None; prev_degree_shm_meta = None
        prev_active_shm = None; prev_active_shm_name = None; prev_active_shm_meta = None
        final_degree_shm = None; final_degree_shm_name = None; final_degree_shm_meta = None
        # ---

        grid_id_short = self.grid._unique_id[:4] if self.grid and self.grid._unique_id else "gXXX"
        step_shm_suffix = f"{self.generation:06d}_{uuid.uuid4().hex[:4]}"

        try:
            # --- Initial checks ---
            if self.grid is None: raise RuntimeError("Grid is None")
            if self.rule is None: raise ValueError("Rule is not set.")
            if not self._initialize_process_pool(): raise RuntimeError("Process pool initialization failed.")
            if self.process_pool is None: raise RuntimeError("Process pool is None after initialization attempt.")
            # ---

            # --- Store state BEFORE update ---
            start_time = time.time()
            original_states_local = self.grid.grid_array.ravel().copy()
            original_edges = self.grid.edges.copy()
            original_edge_states = self.grid.edge_states.copy()
            previous_node_degrees_local = self.grid.previous_degree_array.copy() if self.grid.previous_degree_array is not None else None
            previous_active_neighbors_local = self.grid.previous_active_neighbor_array.copy() if self.grid.previous_active_neighbor_array is not None else None
            # ---

            # --- Determine nodes to update ---
            # [ Nodes to update logic remains the same ]
            if self.rule.requires_post_edge_state_update or self.rule.needs_neighbor_degrees or self.rule.needs_neighbor_active_counts:
                nodes_to_update_list = list(range(self.grid.total_nodes))
            else:
                nodes_to_update = set(self.grid.previous_active_nodes_set)
                for node_idx in self.grid.previous_active_nodes_set:
                    if self.grid.spatial_hash is None: logger.error(f"{log_prefix}Spatial hash is None! Aborting."); return None
                    neighbors = self.grid.get_neighbors(node_idx, self.grid.coord_system)
                    nodes_to_update.update(n for n in neighbors if n != -1)
                nodes_to_update_list = sorted(list(nodes_to_update))
            logger.debug(f"{log_prefix}Updating {len(nodes_to_update_list)} nodes.")
            # ---

            # --- Create ALL necessary TEMP SHM segments HERE in Controller ---
            # [ SHM Creation logic remains the same ]
            logger.debug(f"{log_prefix}Creating temporary SHM segments for step {self.generation}...")
            original_states_shm_name = f"/{grid_id_short}_orig_{step_shm_suffix}"
            try:
                try: SharedMemory(name=original_states_shm_name).unlink()
                except FileNotFoundError: pass
                original_states_shm = SharedMemory(name=original_states_shm_name, create=True, size=original_states_local.nbytes)
                original_states_array_shm = np.ndarray(original_states_local.shape, dtype=original_states_local.dtype, buffer=original_states_shm.buf)
                np.copyto(original_states_array_shm, original_states_local)
                original_states_shm_meta = {'name': original_states_shm_name, 'shape': original_states_local.shape, 'dtype': original_states_local.dtype}
                logger.debug(f"  Created SHM for original_states: {original_states_shm_name}")
            except Exception as shm_create_err: logger.error(f"  Failed to create SHM for original_states: {shm_create_err}"); raise
            if previous_node_degrees_local is not None:
                prev_degree_shm_name = f"/{grid_id_short}_pdeg_{step_shm_suffix}"
                try:
                    try: SharedMemory(name=prev_degree_shm_name).unlink()
                    except FileNotFoundError: pass
                    prev_degree_shm = SharedMemory(name=prev_degree_shm_name, create=True, size=previous_node_degrees_local.nbytes)
                    prev_degree_array_shm = np.ndarray(previous_node_degrees_local.shape, dtype=previous_node_degrees_local.dtype, buffer=prev_degree_shm.buf)
                    np.copyto(prev_degree_array_shm, previous_node_degrees_local)
                    prev_degree_shm_meta = {'name': prev_degree_shm_name, 'shape': previous_node_degrees_local.shape, 'dtype': previous_node_degrees_local.dtype}
                    logger.debug(f"  Created SHM for prev_degree_array: {prev_degree_shm_name}")
                except Exception as shm_deg_err: logger.error(f"  Failed to create SHM for prev_degree_array: {shm_deg_err}"); prev_degree_shm = None; prev_degree_shm_name = None; prev_degree_shm_meta = None
            if previous_active_neighbors_local is not None:
                prev_active_shm_name = f"/{grid_id_short}_pact_{step_shm_suffix}"
                try:
                    try: SharedMemory(name=prev_active_shm_name).unlink()
                    except FileNotFoundError: pass
                    prev_active_shm = SharedMemory(name=prev_active_shm_name, create=True, size=previous_active_neighbors_local.nbytes)
                    prev_active_array_shm = np.ndarray(previous_active_neighbors_local.shape, dtype=previous_active_neighbors_local.dtype, buffer=prev_active_shm.buf)
                    np.copyto(prev_active_array_shm, previous_active_neighbors_local)
                    prev_active_shm_meta = {'name': prev_active_shm_name, 'shape': previous_active_neighbors_local.shape, 'dtype': previous_active_neighbors_local.dtype}
                    logger.debug(f"  Created SHM for prev_active_neighbors: {prev_active_shm_name}")
                except Exception as shm_pa_err: logger.error(f"  Failed to create SHM for prev_active_count: {shm_pa_err}"); prev_active_shm = None; prev_active_shm_name = None; prev_active_shm_meta = None
            # ---

            # ==============================================================
            # --- Conditional Execution Based on Rule Type ---
            # ==============================================================
            if not self.rule.requires_post_edge_state_update:
                # --- Standard Rule Path ---
                # [ Standard rule logic remains the same ]
                logger.debug(f"{log_prefix}Executing Standard Update Path.")
                worker_kwargs_standard = {
                    'original_states_shm_meta': original_states_shm_meta,
                    'prev_degree_shm_meta': prev_degree_shm_meta,
                    'neighbor_indices_shm_meta': self.grid._neighbor_indices_shm_meta,
                    'grid_shape': self.grid.grid_array.shape,
                    'grid_dtype': self.grid.grid_array.dtype,
                    'edge_states_copy': original_edge_states,
                    'prev_active_shm_meta': prev_active_shm_meta,
                    'rule': self.rule,
                    'params_copy': copy.deepcopy(self.rule.params),
                    'grid_dimensions': self.grid.dimensions,
                    'grid_neighborhood_type': self.grid.neighborhood_type,
                    'grid_boundary_condition': self.rule.get_param('grid_boundary', 'bounded')
                }
                assert self.process_pool is not None, "Process pool cannot be None here"
                standard_results, worker_durations = self.grid.update_grid_parallel(
                    worker_func=Grid._process_standard_chunk,
                    process_pool=self.process_pool,
                    nodes_to_update=nodes_to_update_list,
                    # chunk_size removed, handled internally by update_grid_parallel
                    pass_grid_directly=False,
                    **worker_kwargs_standard
                )
                if standard_results is None: raise RuntimeError("Standard rule parallel processing failed.")
                final_states_to_apply = original_states_local.copy()
                all_proposed_edges: Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float] = {}
                for i, result_item in enumerate(standard_results):
                    if isinstance(result_item, tuple) and len(result_item) == 2:
                        state, edges_dict = result_item
                        if i < len(nodes_to_update_list):
                            node_idx = nodes_to_update_list[i]
                            if 0 <= node_idx < final_states_to_apply.size: final_states_to_apply[node_idx] = state
                            else: logger.warning(f"{log_prefix}Node index {node_idx} out of bounds for final_states_to_apply.")
                            if isinstance(edges_dict, dict): all_proposed_edges.update(edges_dict)
                            else: logger.warning(f"{log_prefix}Invalid edges_dict type ({type(edges_dict)}) for node {node_idx}, skipping update.")
                        else: logger.error(f"{log_prefix}Result index {i} out of bounds for nodes_to_update_list.")
                    else: logger.error(f"{log_prefix}Invalid result item format at index {i}: {result_item}")
                with self.grid._update_lock:
                    self.grid.edges.clear(); self.grid.edge_states.clear();
                    for edge_coords, edge_state in all_proposed_edges.items():
                        if isinstance(edge_coords, tuple) and len(edge_coords) == 2 and isinstance(edge_coords[0], tuple) and isinstance(edge_coords[1], tuple):
                            self.grid.edges.add(edge_coords); self.grid.edge_states[edge_coords] = edge_state
                    final_edges_this_step = self.grid.edges.copy()
                if not self.rule.skip_standard_tiebreakers:
                    tiebreaker_type_str = self.rule.get_param('tiebreaker_type', 'RANDOM')
                    enable_tiebreakers = GlobalSettings.ENABLE_TIEBREAKERS
                    if enable_tiebreakers:
                        self.grid._apply_edge_tiebreakers(final_states_to_apply, TieBreaker[tiebreaker_type_str].value, enable_tiebreakers)
                        final_edges_this_step = self.grid.edges.copy()
                logger.debug(f"{log_prefix}Standard Path Complete. Final edges: {len(final_edges_this_step)}")
                # --- End Standard Rule Logic ---

            else:
                # --- THREE-PHASE LOGIC ---
                # [ Phase 1, SHM creation, Phase 2, Edge Apply, Phase 2.5, Final Degree SHM - Unchanged ]
                logger.debug(f"{log_prefix}Executing Three-Phase Update Path.")
                worker_kwargs_phase1 = {
                    'original_states_shm_meta': original_states_shm_meta, 'edge_states_copy': original_edge_states,
                    'prev_degree_shm_meta': prev_degree_shm_meta, 'prev_active_shm_meta': prev_active_shm_meta,
                    'rule': self.rule, 'params_copy': copy.deepcopy(self.rule.params), 'grid_dimensions': self.grid.dimensions,
                    'grid_neighborhood_type': self.grid.neighborhood_type, 'grid_boundary_condition': self.rule.get_param('grid_boundary', 'bounded'),
                    'neighbor_indices_shm_meta': self.grid._neighbor_indices_shm_meta
                }
                assert self.process_pool is not None, "Process pool cannot be None here"
                eligibility_proxies_result, durations_p1 = self.grid.update_grid_parallel(
                    worker_func=Grid._process_states_only, process_pool=self.process_pool, nodes_to_update=nodes_to_update_list,
                    # chunk_size removed
                    pass_grid_directly=False, **worker_kwargs_phase1
                )
                if eligibility_proxies_result is None: raise RuntimeError("Phase 1 (Eligibility) failed.")
                eligibility_proxies = np.array(eligibility_proxies_result) if isinstance(eligibility_proxies_result, list) else eligibility_proxies_result
                if not isinstance(eligibility_proxies, np.ndarray): raise TypeError(f"Phase 1 result is not a numpy array, type: {type(eligibility_proxies)}")
                worker_durations.extend(durations_p1); logger.debug(f"{log_prefix}Phase 1 Complete. Eligibility Proxies shape: {eligibility_proxies.shape}")
                try:
                    eligibility_phase1_shm_name = f"/{grid_id_short}_el_p1_{step_shm_suffix}"
                    try: SharedMemory(name=eligibility_phase1_shm_name).unlink()
                    except FileNotFoundError: pass
                    eligibility_phase1_shm = SharedMemory(name=eligibility_phase1_shm_name, create=True, size=eligibility_proxies.nbytes)
                    eligibility_phase1_array_shm = np.ndarray(eligibility_proxies.shape, dtype=eligibility_proxies.dtype, buffer=eligibility_phase1_shm.buf)
                    np.copyto(eligibility_phase1_array_shm, eligibility_proxies)
                    eligibility_proxy_shm_meta = {'name': eligibility_phase1_shm_name, 'shape': eligibility_proxies.shape, 'dtype': eligibility_proxies.dtype}
                    logger.debug(f"{log_prefix}Created TEMP SHM for Phase 1 eligibility proxies: {eligibility_phase1_shm_name}")
                except Exception as shm_err: logger.error(f"{log_prefix}Failed to create TEMP SHM for Phase 1 eligibility proxies: {shm_err}"); raise
                worker_kwargs_phase2 = {
                    'original_states_shm_meta': original_states_shm_meta, 'edge_states_copy': original_edge_states,
                    'prev_degree_shm_meta': prev_degree_shm_meta, 'prev_active_shm_meta': prev_active_shm_meta,
                    'rule': self.rule, 'params_copy': copy.deepcopy(self.rule.params), 'grid_dimensions': self.grid.dimensions,
                    'grid_neighborhood_type': self.grid.neighborhood_type, 'grid_boundary_condition': self.rule.get_param('grid_boundary', 'bounded'),
                    'eligibility_proxy_shm_name': eligibility_phase1_shm_name, 'neighbor_indices_shm_meta': self.grid._neighbor_indices_shm_meta
                }
                assert self.process_pool is not None, "Process pool cannot be None here"
                computed_edges_list, durations_p2 = self.grid.update_grid_parallel(
                    worker_func=Grid._process_edges_only, process_pool=self.process_pool, nodes_to_update=nodes_to_update_list,
                    # chunk_size removed
                    pass_grid_directly=False, **worker_kwargs_phase2
                )
                if computed_edges_list is None: raise RuntimeError("Phase 2 (Edges) failed.")
                worker_durations.extend(durations_p2); computed_edges: Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float] = {}; [computed_edges.update(d) for d in computed_edges_list if isinstance(d, dict)]
                logger.debug(f"{log_prefix}Phase 2 Complete. Computed {len(computed_edges)} proposed edges.")
                with self.grid._update_lock: self.grid.edges = set(computed_edges.keys()); self.grid.edge_states = computed_edges; final_edges_this_step = self.grid.edges.copy(); logger.debug(f"{log_prefix}Applied {len(final_edges_this_step)} edges to grid.")
                logger.debug(f"{log_prefix}Starting Phase 2.5: Final Degree Calculation.")
                final_degree_array = np.zeros(self.grid.total_nodes, dtype=np.int32); degree_calc_start = time.time()
                for edge_coords in final_edges_this_step:
                    try:
                        node1_coords, node2_coords = edge_coords; idx1 = _ravel_multi_index(np.array(node1_coords), self.grid.dimensions); idx2 = _ravel_multi_index(np.array(node2_coords), self.grid.dimensions)
                        if 0 <= idx1 < self.grid.total_nodes: final_degree_array[idx1] += 1
                        if 0 <= idx2 < self.grid.total_nodes: final_degree_array[idx2] += 1
                    except Exception as degree_calc_err: logger.error(f"{log_prefix}Error processing edge {edge_coords} for final degree calculation: {degree_calc_err}")
                degree_calc_duration = time.time() - degree_calc_start; logger.info(f"{log_prefix}Phase 2.5 Complete. Calculated final degrees in {degree_calc_duration:.4f}s (Sum: {np.sum(final_degree_array)}).")
                try:
                    final_degree_shm_name = f"/{grid_id_short}_fd_p25_{step_shm_suffix}"
                    try: SharedMemory(name=final_degree_shm_name).unlink()
                    except FileNotFoundError: pass
                    final_degree_shm = SharedMemory(name=final_degree_shm_name, create=True, size=final_degree_array.nbytes)
                    final_degree_array_shm = np.ndarray(final_degree_array.shape, dtype=final_degree_array.dtype, buffer=final_degree_shm.buf)
                    np.copyto(final_degree_array_shm, final_degree_array)
                    final_degree_shm_meta = {'name': final_degree_shm_name, 'shape': final_degree_array.shape, 'dtype': final_degree_array.dtype}
                    logger.debug(f"{log_prefix}Created TEMP SHM for final degrees: {final_degree_shm_name}")
                except Exception as shm_err: logger.error(f"{log_prefix}Failed to create TEMP SHM for final degrees: {shm_err}"); raise
                logger.debug(f"{log_prefix}Starting Phase 3: Final State Calculation (Parallel).")
                try:
                    prev_state_shm_name = f"/{grid_id_short}_ps_p3_{step_shm_suffix}"
                    try: SharedMemory(name=prev_state_shm_name).unlink()
                    except FileNotFoundError: pass
                    prev_state_shm = SharedMemory(name=prev_state_shm_name, create=True, size=original_states_local.nbytes)
                    prev_state_array_shm = np.ndarray(original_states_local.shape, dtype=original_states_local.dtype, buffer=prev_state_shm.buf)
                    np.copyto(prev_state_array_shm, original_states_local)
                    prev_state_shm_meta_p3 = {'name': prev_state_shm_name, 'shape': original_states_local.shape, 'dtype': original_states_local.dtype}
                    logger.debug(f"{log_prefix}Created TEMP SHM for previous states (Phase 3): {prev_state_shm_name}")
                except Exception as shm_err: logger.error(f"{log_prefix}Failed to create TEMP SHM for Phase 3 prev_state: {shm_err}"); raise
                worker_kwargs_phase3 = {
                    'eligibility_proxy_shm_meta': eligibility_proxy_shm_meta, 'prev_state_shm_meta': prev_state_shm_meta_p3,
                    'prev_degree_shm_meta': prev_degree_shm_meta, 'neighbor_indices_shm_meta': self.grid._neighbor_indices_shm_meta,
                    'grid_shape': self.grid.grid_array.shape, 'grid_dtype': self.grid.grid_array.dtype,
                    'final_edges_this_step': final_edges_this_step, 'previous_edges': original_edges,
                    'previous_edge_states': original_edge_states, 'prev_active_shm_meta': prev_active_shm_meta,
                    'rule': self.rule, 'params_copy': copy.deepcopy(self.rule.params), 'grid_dimensions': self.grid.dimensions,
                    'detailed_logging_enabled': detailed_logging_enabled, # Pass flag
                    'final_degree_shm_meta': final_degree_shm_meta
                }
                assert self.process_pool is not None, "Process pool cannot be None here"
                final_states_result, durations_p3 = self.grid.update_grid_parallel(
                     worker_func=Grid._process_final_state_chunk, process_pool=self.process_pool, nodes_to_update=nodes_to_update_list,
                     # chunk_size removed
                     pass_grid_directly=False, **worker_kwargs_phase3
                )
                if final_states_result is None: raise RuntimeError("Phase 3 (Final State) failed.")
                final_states_to_apply = np.array(final_states_result) if isinstance(final_states_result, list) else final_states_result
                if not isinstance(final_states_to_apply, np.ndarray): raise TypeError(f"Phase 3 result is not a numpy array, type: {type(final_states_to_apply)}")
                worker_durations.extend(durations_p3); logger.debug(f"{log_prefix}Phase 3 Complete. Final States shape: {final_states_to_apply.shape}")
                # --- End Phase 3 ---

            # ==============================================================
            # --- Common Logic AFTER Conditional Execution ---
            # ==============================================================
            # [ Apply Final States, Update History - Unchanged ]
            if final_states_to_apply is None: raise RuntimeError("Final states were not computed.")
            with self.grid._update_lock:
                np.copyto(self.grid.grid_array.ravel(), final_states_to_apply)
                if detailed_logging_enabled: logger.detail(f"{log_prefix}Applied final states to grid_array.") # type: ignore [attr-defined]
                if self.grid.shared_array is not None: np.copyto(self.grid.shared_array, self.grid.grid_array)
                self.grid.active_nodes.clear(); final_active_indices = np.where(self.grid.grid_array.ravel() > 1e-6)[0]; self.grid.active_nodes.update(final_active_indices)
                if detailed_logging_enabled: logger.detail(f"{log_prefix}Updated active nodes set ({len(self.grid.active_nodes)} active).") # type: ignore [attr-defined]
            state_after_lock = self.grid.grid_array.ravel(); changed_node_indices_raw = np.where(state_after_lock != original_states_local)[0]
            valid_changed_indices = changed_node_indices_raw[changed_node_indices_raw < self.grid.total_nodes]
            if len(valid_changed_indices) != len(changed_node_indices_raw): logger.warning(f"{log_prefix}Filtered out {len(changed_node_indices_raw) - len(valid_changed_indices)} invalid indices from changed_node_indices.")
            if valid_changed_indices.size > 0:
                unraveled_coords = np.unravel_index(valid_changed_indices, self.grid.dimensions)
                self.grid.last_updated_nodes = set(map(tuple, np.array(unraveled_coords).T))
            else: self.grid.last_updated_nodes = set()

            # --- Calculate and Assign Previous Arrays ---
            if self.rule.needs_neighbor_degrees or self.rule.needs_neighbor_active_counts:
                new_degree_array = np.zeros(self.grid.total_nodes, dtype=np.int32)
                new_active_neighbor_array = np.zeros(self.grid.total_nodes, dtype=np.int32)
                activity_threshold = 1e-6
                current_final_edges = self.grid.edges.copy() # Use the final edges from this step
                current_final_states_flat = self.grid.grid_array.ravel() # Use final states

                if self.rule.needs_neighbor_degrees:
                    for edge_coords in current_final_edges:
                        try:
                            node1_coords, node2_coords = edge_coords
                            idx1 = _ravel_multi_index(np.array(node1_coords), self.grid.dimensions)
                            idx2 = _ravel_multi_index(np.array(node2_coords), self.grid.dimensions)
                            if 0 <= idx1 < self.grid.total_nodes: new_degree_array[idx1] += 1
                            if 0 <= idx2 < self.grid.total_nodes: new_degree_array[idx2] += 1
                        except Exception as degree_calc_err: logger.error(f"{log_prefix}Error processing edge {edge_coords} for degree calculation: {degree_calc_err}")
                    # --- ADDED: Log dtype BEFORE assignment ---
                    logger.debug(f"{log_prefix}Calculated new_degree_array. Dtype: {new_degree_array.dtype}, Shape: {new_degree_array.shape}, Sum: {np.sum(new_degree_array)}")
                    self.grid.previous_degree_array = new_degree_array # Assign calculated array
                    if detailed_logging_enabled: logger.detail(f"{log_prefix}Updated previous_degree_array for next step.") # type: ignore [attr-defined]
                else: self.grid.previous_degree_array = None

                if self.rule.needs_neighbor_active_counts:
                    for node_idx in range(self.grid.total_nodes):
                        count = 0
                        neighbors_indices = self.grid.get_neighbors(node_idx, self.grid.coord_system)
                        for neighbor_idx in neighbors_indices:
                            if neighbor_idx != -1 and 0 <= neighbor_idx < current_final_states_flat.size and current_final_states_flat[neighbor_idx] > activity_threshold: count += 1
                        new_active_neighbor_array[node_idx] = count
                    # --- ADDED: Log dtype BEFORE assignment ---
                    logger.debug(f"{log_prefix}Calculated new_active_neighbor_array. Dtype: {new_active_neighbor_array.dtype}, Shape: {new_active_neighbor_array.shape}, Sum: {np.sum(new_active_neighbor_array)}")
                    self.grid.previous_active_neighbor_array = new_active_neighbor_array # Assign calculated array
                    if detailed_logging_enabled: logger.detail(f"{log_prefix}Updated previous_active_neighbor_array for next step.") # type: ignore [attr-defined]
                else: self.grid.previous_active_neighbor_array = None
            # --- END Calculate and Assign ---

            self.grid.previous_active_nodes_set = self.grid.active_nodes.copy()
            if detailed_logging_enabled: logger.detail(f"{log_prefix}Updated grid's previous_active_nodes_set.") # type: ignore [attr-defined]
            self.generation += 1
            if detailed_logging_enabled: logger.detail(f"{log_prefix}Incremented generation to {self.generation}") # type: ignore [attr-defined]

            # --- Prepare Snapshot Dictionary ---
            logger.debug(f"{log_prefix}Preparing FLAT snapshot with data copies for queue.")
            rule_coloring_params = {};
            if self.rule:
                try: rule_coloring_params['use_state_coloring'] = self.rule.get_param('use_state_coloring', False); rule_coloring_params['node_colormap'] = self.rule.get_param('node_colormap', 'plasma'); rule_coloring_params['use_state_coloring_edges'] = self.rule.get_param('use_state_coloring_edges', False); rule_coloring_params['edge_colormap'] = self.rule.get_param('edge_colormap', 'viridis')
                except Exception as param_err: logger.error(f"{log_prefix}Error extracting rule params for snapshot: {param_err}")

            # --- MODIFIED: Ensure correct dtype when copying ---
            prev_deg_copy = self.grid.previous_degree_array.copy().astype(np.int32) if self.grid.previous_degree_array is not None else None
            prev_act_copy = self.grid.previous_active_neighbor_array.copy().astype(np.int32) if self.grid.previous_active_neighbor_array is not None else None
            # ---

            # --- ADDED: Log dtype BEFORE putting on queue ---
            logger.debug(f"{log_prefix}Snapshot Dtypes BEFORE queue:")
            logger.debug(f"  previous_degree_array: {prev_deg_copy.dtype if prev_deg_copy is not None else 'None'}")
            logger.debug(f"  previous_active_neighbor_array: {prev_act_copy.dtype if prev_act_copy is not None else 'None'}")
            # ---

            queue_item_to_send = {
                'grid_array': self.grid.grid_array.copy(),
                'previous_degree_array': prev_deg_copy, # Use validated copy
                'previous_active_neighbor_array': prev_act_copy, # Use validated copy
                'edges': self.grid.edges.copy(), 'edge_states': self.grid.edge_states.copy(), 'active_nodes': self.grid.active_nodes.copy(),
                'generation': self.generation, 'boundary_condition': self.rule.get_param('grid_boundary', 'bounded') if self.rule else 'bounded',
                'num_chunks': GlobalSettings.Simulation.CHUNK_SIZE if GlobalSettings.Simulation.CHUNK_SIZE > 0 else self.grid._calculate_dynamic_chunk_size(),
                'rule_coloring_params': rule_coloring_params
            }
            if detailed_logging_enabled: logger.detail(f"{log_prefix}FLAT Snapshot with data copies created for Gen {self.generation}") # type: ignore [attr-defined]
            # ---

            # [ Analytics Push - Unchanged ]
            analytics_enabled = False
            if hasattr(self, 'gui') and self.gui and hasattr(self.gui, 'analytics_enabled_var'):
                try: analytics_enabled = self.gui.analytics_enabled_var.get(); logger.debug(f"{log_prefix}Analytics Enabled Check: {analytics_enabled}")
                except Exception as e_var: logger.error(f"{log_prefix}Error getting analytics_enabled_var: {e_var}"); analytics_enabled = False
            else: logger.warning(f"{log_prefix}Cannot check analytics_enabled_var: GUI or variable missing.")
            if analytics_enabled:
                logger.debug(f"{log_prefix}Analytics IS enabled, preparing data...")
                if hasattr(self, 'analytics_data_in_queue') and self.analytics_data_in_queue:
                    try:
                        analytics_data = {
                            'generation': self.generation, 'grid_array': self.grid.grid_array.copy(), 'edges': self.grid.edges.copy(),
                            'edge_states': self.grid.edge_states.copy(), 'rule_name': self.rule.name, 'rule_params': copy.deepcopy(self.rule.params),
                            'active_node_count': len(self.grid.active_nodes), 'edge_count': len(self.grid.edges), 'total_nodes': self.grid.total_nodes,
                            'grid_array_snapshot': self.grid.grid_array.copy(), 'edge_snapshot_coo': self._get_edge_snapshot_coo(),
                            'active_node_indices': list(self.grid.active_nodes),
                        }
                        self.analytics_data_in_queue.put_nowait(analytics_data)
                        logger.info(f"{log_prefix}Pushed data for Gen {self.generation} to analytics queue.")
                    except queue.Full: logger.warning(f"{log_prefix}Analytics data queue full, discarding data for Gen {self.generation}.")
                    except Exception as analytics_err: logger.error(f"{log_prefix}Error pushing data to analytics queue: {analytics_err}")
                else: logger.warning(f"{log_prefix}Analytics enabled but queue not found.")
            else: logger.debug(f"{log_prefix}Analytics NOT enabled, skipping data push.")

            if detailed_logging_enabled: logger.detail(f"{log_prefix}EXIT - Returning snapshot") # type: ignore [attr-defined]
            return queue_item_to_send

        except Exception as e:
            logger.error(f"{log_prefix}Error during simulation step: {e}")
            logger.error(traceback.format_exc())
            return None
        finally:
            # --- Corrected SHM Cleanup Logic ---
            shm_list_to_clean = [
                (original_states_shm, original_states_shm_name, "Original States (Step Temp)"),
                (eligibility_phase1_shm, eligibility_phase1_shm_name, "Phase 1 Eligibility"),
                (final_degree_shm, final_degree_shm_name, "Final Degrees (Phase 2.5)"),
                (prev_state_shm, prev_state_shm_name, "Previous State (Phase 3)"),
                (prev_degree_shm, prev_degree_shm_name, "Previous Degree (Step Temp)"),
                (prev_active_shm, prev_active_shm_name, "Previous Active Neighbors")
            ]
            for instance, name, description in shm_list_to_clean:
                if name:
                    try:
                        shm_to_unlink = SharedMemory(name=name, create=False)
                        shm_to_unlink.close()
                        shm_to_unlink.unlink()
                        logger.debug(f"{log_prefix}Unlinked TEMP SHM for {description}: {name}")
                    except FileNotFoundError:
                        logger.debug(f"{log_prefix}TEMP SHM for {description} ({name}) already unlinked or never created.")
                    except Exception as unlink_err:
                        logger.error(f"{log_prefix}Error unlinking TEMP SHM for {description} ({name}): {unlink_err}")
                if instance:
                    try:
                        instance.close()
                        logger.debug(f"{log_prefix}Closed TEMP SHM instance for {description}: {name}")
                    except Exception as close_err:
                        logger.error(f"{log_prefix}Error closing TEMP SHM instance for {description} ({name}): {close_err}")
            # --- END Corrected SHM Cleanup ---

    def __del__(self):
        """Ensure cleanup on deletion"""
        self.cleanup()

    def add_observer(self, observer: Observer) -> None:
        """Add an observer to be notified of updates."""
        if observer not in self._observers:
            self._observers.append(observer)

    def remove_observer(self, observer: Observer) -> None:
        """Remove an observer."""
        if observer in self._observers:
            self._observers.remove(observer)

    def notify_observers(self) -> None:
        """Notify all observers of a change."""
        for obs in self._observers:
            obs.update(self)  # Pass the grid as the subject

    def _initialize_random_state(self, node_density: float, edge_initialization_type: str = 'RANDOM'):
        """Initializes node states and populates the spatial hash grid, respecting initial_conditions parameter.
           (Round 26: Skip randomization if condition is Pattern/Shape)"""

        log_prefix = f"SimulationGUI._initialize_random_state(Density={node_density:.2f}, EdgeType={edge_initialization_type}): "
        logger.info(f"{log_prefix}--- ENTRY ---")

        if self.grid is None or self.grid.grid_array is None:
            logger.error(f"{log_prefix}Grid or grid_array is None, cannot initialize state.")
            return

        # --- Clear Grid and Spatial Hash ---
        self.grid.grid_array.fill(0.0)
        if self.grid.spatial_hash is not None:
            self.grid.spatial_hash.clear()
            logger.debug(f"{log_prefix}Cleared grid array and spatial hash.")
        else:
            logger.warning(f"{log_prefix}Spatial hash is None, cannot clear.")
        # ---

        # --- Get the initial conditions type from the rule parameters ---
        initial_conditions_type = "Random" # Default
        if self.rule:
            initial_conditions_type = self.rule.get_param('initial_conditions', "Random")
        logger.info(f"{log_prefix}Rule's initial_conditions parameter is '{initial_conditions_type}'.")
        # ---

        # --- MODIFIED: Only randomize if initial_conditions is actually "Random" ---
        if initial_conditions_type == "Random":
            logger.info(f"{log_prefix}Applying random node initialization based on density.")
            total_nodes = np.prod(self.dimensions)
            active_cells = int(total_nodes * node_density)
            grid_size = self.grid.grid_array.size

            if active_cells > 0:
                active_cells = min(active_cells, grid_size)
                active_indices = np.random.choice(grid_size, size=active_cells, replace=False)
                if self.grid.grid_array is not None:
                    self.grid.grid_array.ravel()[active_indices] = 1.0
                    logger.debug(f"{log_prefix}Initialized {active_cells} active nodes with random state.")
                else:
                    logger.error(f"{log_prefix}grid_array became None unexpectedly.")
                    return
            else:
                logger.warning(f"{log_prefix}No active cells to initialize (density={node_density:.2f}).")
        else:
            # If not "Random", assume the correct pattern was already applied by InitialConditionManager or preset
            logger.info(f"{log_prefix}Skipping random node initialization because initial_conditions is '{initial_conditions_type}'. State should already be set.")
        # --- END MODIFIED ---

        # --- Populate Spatial Hash with ALL nodes (regardless of state) ---
        if self.grid.spatial_hash is not None:
            logger.debug(f"{log_prefix}Populating spatial hash with ALL {self.grid.total_nodes} nodes.")
            for idx in range(self.grid.total_nodes):
                grid_coords = _unravel_index(idx, self.dimensions)
                self.grid.spatial_hash.update_node(idx, np.array(grid_coords))
            logger.debug(f"{log_prefix}Spatial hash populated.")
        else:
            logger.error(f"{log_prefix}Spatial hash is None, cannot populate.")
        # ---

        # --- Update active nodes set based on the final grid_array state ---
        self.grid.update_active_nodes()
        logger.debug(f"{log_prefix}Updated grid.active_nodes set: {len(self.grid.active_nodes)} active nodes.")
        self.grid.previous_active_nodes_set = self.grid.active_nodes.copy()
        logger.debug(f"{log_prefix}Initialized grid.previous_active_nodes_set.")
        # ---

        # --- Initialize edges based on the specified type ---
        # This should happen AFTER nodes are set, whether randomly or by pattern
        logger.debug(f"{log_prefix}Initializing edges with type: {edge_initialization_type}")
        self.grid.initialize_edges(edge_initialization_type) # Use the Grid's method
        logger.debug(f"{log_prefix}Edges initialized. Count: {len(self.grid.edges)}")
        # ---

        logger.debug(f"{log_prefix}Exiting.")

    def _create_rule_instance(self, rule_data: Dict[str, Any]) -> Rule:
            """Create rule instance based on rule data from library"""

            try:
                # Use the rule name to look up the factory function
                rule_name = rule_data['name']

                # --- MODIFIED: Filter metadata_dict ---
                metadata_dict = {k: v for k, v in rule_data.items() if k != 'params' and k != '_ignored_params'} # Exclude params AND _ignored_params
                # --- END MODIFIED ---

                # Add default position if missing (needed for RuleMetadata)
                metadata_dict.setdefault('position', 1)

                metadata = RuleMetadata(**metadata_dict) # Create metadata object
                rule = RuleLibrary.create_rule(rule_name, metadata) # Create the rule instance

                # Set parameters
                rule.params = rule_data.get('params', {}) # Use .get() for safety

                return rule
            except Exception as e:
                logger.error(f"Error creating rule {rule_data.get('name', 'Unknown')}: {e}")
                raise

    def set_rule(self, rule: 'Rule'):
        """Update the rule instance used by the grid"""
        try:
            logger.debug(f"Entering Grid.set_rule with rule: {rule.name}")
            # Store the new rule instance
            self.rule = rule  # We now expect a Rule INSTANCE
            logger.debug(f"Stored new rule instance: {rule.name}")

            # Log the rule change and its parameters
            logger.info(f"Grid updated to use rule: {rule.name}")
            logger.debug(f"Grid rule parameters: {rule.params}")

            # Invalidate any cached rule data
            if hasattr(self.rule, 'invalidate_cache'):
                logger.debug("Invalidating rule cache")
                self.rule.invalidate_cache()
                logger.debug("Rule cache invalidated")

            # ADDED LOGGING: Log the Grid's unique_id
            if hasattr(self, 'grid') and self.grid:
                logger.debug(f"Grid ID in set_rule: {self.grid._unique_id}")

        except Exception as e:
            logger.error(f"Error updating grid rule: {str(e)}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            # Don't reraise - handle gracefully
            return False

        logger.debug("Grid.set_rule completed successfully")
        return True
    
    def _load_rule_from_library(self, rule_name: str, params: Optional[Dict[str, Any]] = None) -> Rule:
        """Load rule from library and set parameters"""
        try:
            # Get rule data from library
            rule_data = RuleLibraryManager.get_rule(rule_name)
            
            # Create rule instance
            rule_type = rule_data['type']
            metadata = RuleMetadata(**rule_data)
            rule = RuleLibrary.create_rule(rule_type, metadata)
            
            # Set parameters
            if params:
                rule.params = params
            else:
                rule.params = rule_data['params']
                
            return rule
        except Exception as e:
            logger.error(f"Error loading rule {rule_name}: {e}")
            raise
                                
    def _initialize_grid_state(self, density: float, edge_initialization_type: str = 'RANDOM'):
        """Initializes both nodes and edges with the given density and initialization type."""

        # CRITICAL FIX: Clear the grid array first to ensure we start fresh
        if self.grid is not None and self.grid.grid_array is not None:
            self.grid.grid_array.fill(0.0)  # Reset all cells to inactive (0.0)
        else:
            logger.error("Grid is None, cannot initialize random state")
            return

        # Get the initial conditions type from the rule parameters
        initial_conditions_type = self.rule.get_param('initial_conditions', "Random")

        # Initialize nodes with random state
        if initial_conditions_type != "ShapeShifting":
            total_nodes = np.prod(self.dimensions)
            active_cells = int(total_nodes * density)
            
            # CRITICAL FIX: Ensure active_indices are within the valid range
            # Get the actual size of the flattened grid array
            grid_size = self.grid.grid_array.size
            
            # Generate random indices within the valid range
            if active_cells > 0:
                # Ensure we don't try to activate more cells than exist
                active_cells = min(active_cells, grid_size)
                # Generate unique random indices
                active_indices = np.random.choice(grid_size, size=active_cells, replace=False)
                
                if self.grid.grid_array is not None:
                    self.grid.grid_array.ravel()[active_indices] = 1.0  # Set active nodes directly
                else:
                    logger.error("grid_array is None, cannot set active nodes")
                    return
            else:
                logger.warning("No active cells to initialize (density too low)")

        # Initialize edges using the specified type
        initialization_type = edge_initialization_type if edge_initialization_type else 'RANDOM'
        logger.debug(f"Initializing edges with type: {initialization_type}")
        self.grid.initialize_edges(initialization_type)

        # --- REMOVED: No longer needed with dynamic neighbor calculation ---
        # Rebuild neighbors *after* initializing nodes and edges
        # self.grid.rebuild_neighbors()

    @timer_decorator
    def reset(self, initial_density: Optional[float] = None, edge_initialization_type: str = 'RANDOM'):
        """Reset simulation to initial state"""
        try:
            logger.debug("=============== Entering reset_simulation SimulationController ===============")

            # Stop any running simulation
            self.running = False
            self.paused = False
            if hasattr(self, 'interrupt_requested'):
                self.interrupt_requested = False
                logger.debug("Interruption requested flag reset")

            # Clear existing state in the *grid*
            if self.grid is not None:
                logger.debug(f"reset_simulation: Calling self.grid.clear_grid(), grid ID = {self.grid._unique_id}")
                self.grid.clear_grid()  # THIS LINE WAS MISSING, AND IS CRITICAL
                logger.debug("Grid cleared successfully")
            else:
                logger.debug("reset_simulation: self.grid is None, cannot clear")

            # Reset counters and flags
            logger.debug("Resetting counters and flags")
            self.generation = 0
            self.step_count = 0  # CRITICAL: Reset the step_count
            self.is_running = False
            if hasattr(self, 'last_updated_nodes') and self.grid is not None:
                self.last_updated_nodes = set()
            if hasattr(self, 'last_updated_edges') and self.grid is not None:
                self.last_updated_edges = set()
            logger.debug("Counters and flags reset")

            # Reset statistics
            logger.debug("Resetting statistics")
            self.stats.reset()
            if hasattr(self, 'perf_logger') and self.perf_logger:
                self.perf_logger.reset()

            # Initialize the grid with a random state
            if self.rule is not None:
                initial_conditions_type = self.rule.get_param('initial_conditions', "Random")
                if initial_conditions_type == "Random":
                    if initial_density is None:
                        initial_density = GlobalSettings.Simulation.INITIAL_NODE_DENSITY
                    self._initialize_random_state(initial_density, edge_initialization_type)
                else:
                    # Handle other initial conditions (e.g., ShapeShifting)
                    if self.grid is not None:
                        self.rule.initialize_grid_state(self.grid)
                    else:
                        logger.error("Grid is None, cannot initialize grid state")
                        return

            logger.info("Simulation reset complete")

        except Exception as e:
            logger.error(f"Error in simulation reset: {str(e)}")
            raise

    def request_interrupt(self):
        """Request interruption of current step calculation"""
        self.interrupt_requested = True
        logger.info("Interruption requested")

    def _update_statistics(self):
        """Update simulation statistics"""
        active_cells = np.sum(self.grid.grid_array > 0) if self.grid and self.grid.grid_array is not None else 0
        total_cells = np.prod(self.dimensions)

        try:
            # Calculate edge_density using a list comprehension and filtering out None values
            edge_densities = []
            for idx in range(total_cells):
                # Create a NeighborhoodData object for the current node
                if self.grid is not None:
                    neighborhood = self.grid.create_neighborhood_data(idx)
                    # Call get_metric on the RULE, passing the NeighborhoodData object and the grid
                    metric_value = self.rule.get_metric('edge_density', neighborhood)  # Pass only the neighborhood
                    if metric_value is not None:  # Only append if we got a valid value
                        edge_densities.append(metric_value)
                else:
                    logger.error("Grid is None, cannot create neighborhood data")
                    continue

            # Calculate the mean only if we have valid values
            edge_density = float(np.mean(edge_densities)) if edge_densities else 0.0

        except Exception as e:
            logger.error(f"Error calculating edge density: {e}")
            edge_density = 0.0  # Handle cases where edge density might be undefined

        performance_stats = self.perf_logger.get_stats()

        self.stats.update(
            generation=self.generation,
            active_ratio=active_cells / total_cells,
            edge_density=edge_density,
            # Add individual performance metrics instead of the whole dictionary
            simulation_avg_time=performance_stats.get('step', {}).get('avg', 0.0),
            grid_avg_time=self.grid.get_performance_stats().get('grid_stats', {}).get('avg_update_time', 0.0) if self.grid else 0.0,
            rule_avg_time=self.rule.get_performance_stats().get('avg_compute_time', 0.0)
        )

    def _get_edge_snapshot_coo(self) -> Optional[Tuple[List[int], List[int], List[float]]]:
        """
        Helper method to create a COO (Coordinate List) representation of the current edge state.
        Returns (rows, cols, data) where rows/cols are node indices and data is edge state.
        Returns None if grid or edges are unavailable.
        (Round 2: New method for analytics)
        """
        if self.grid is None or self.grid.edges is None or self.grid.edge_states is None:
            logger.warning("_get_edge_snapshot_coo: Grid, edges, or edge_states is None.")
            return None

        rows = []
        cols = []
        data = []
        try:
            for edge_coords, state in self.grid.edge_states.items():
                node1_coords, node2_coords = edge_coords
                # Convert coordinates to flat indices
                idx1 = _ravel_multi_index(np.array(node1_coords), self.grid.dimensions)
                idx2 = _ravel_multi_index(np.array(node2_coords), self.grid.dimensions)
                # Add both directions for undirected graph representation if needed by metric
                rows.extend([idx1, idx2])
                cols.extend([idx2, idx1])
                data.extend([state, state]) # Use the same state for both directions
            return rows, cols, data
        except Exception as e:
            logger.error(f"Error creating COO edge snapshot: {e}")
            return None
        
    def _check_stabilization(self):
        """Check if simulation has stabilized"""
        if self.generation > GlobalSettings.Simulation.MIN_GENERATIONS:
            recent_activity = self.stats.get_recent_activity(
                window=GlobalSettings.Simulation.STABILITY_WINDOW
            )
            
            if np.std(recent_activity) < GlobalSettings.Simulation.STABILITY_THRESHOLD:
                logger.info(f"Simulation stabilized at generation {self.generation}")
                self.is_running = False

    def get_state(self) -> Dict[str, Any]:
        """Get current simulation state with direct array access"""
        state = {
            'generation': self.generation,
            'grid_state': self.grid.grid_array if self.grid is not None else None,  # Direct array access
            'stats': self.stats.get_current(),
            'performance': self.perf_logger.get_stats()
        }
        # CRITICAL: Convert edges set to a list of tuples for serialization
        if self.grid is not None: # Check that the grid exists
            state['edges'] = list(self.grid.edges) # Get edges directly from the grid
        else:
            state['edges'] = []
        return state

    def set_state(self, state: Dict[str, Any]):
        """Set controller state from dictionary"""
        try:
            # Update grid state
            if 'grid_state' in state and self.grid is not None and self.grid.grid_array is not None:
                try:
                    # Check if the shape of the loaded grid_state matches the current grid
                    if self.grid.grid_array.shape != np.array(state['grid_state']).shape:
                        logger.warning(f"Shape mismatch between loaded grid_state and current grid. Skipping grid state update.")
                    else:
                        np.copyto(self.grid.grid_array, np.array(state['grid_state']))
                except Exception as e:
                    logger.error(f"Error copying grid state: {e}")
            else:
                logger.warning("grid_state not found in state or grid is None, cannot load grid state")

            # Update edges
            if 'edges' in state and self.grid is not None:
                # Clear existing edges
                self.grid.edges.clear()

                # Add edges from the loaded state
                for edge in state['edges']:
                    if isinstance(edge, (tuple, list)) and len(edge) == 2:
                        node1, node2 = edge
                        # Ensure they are integers
                        if isinstance(node1, (int, np.integer)) and isinstance(node2, (int, np.integer)):
                            node1, node2 = int(node1), int(node2)
                            self.grid.add_edge(node1, node2)  # Use Grid's add_edge
                        else:
                            logger.warning(f"Invalid node types in edge: {edge}")
                    else:
                        logger.warning(f"Invalid edge format: {edge}")
            else:
                logger.warning("edges not found in state or grid is None, cannot load edges")

            # Update generation count
            if 'generation' in state:
                self.generation = state['generation']

            # Update other attributes if needed
            if 'stats' in state:
                self.stats.update(**state['stats'])

            logger.info(f"Controller state updated from dictionary")
        except Exception as e:
            logger.error(f"Error setting controller state: {e}")
            raise
        
    def set_neighborhood_type(self, neighborhood_type: NeighborhoodType):
        """Change the neighborhood type and reinitialize grid"""

        try:
            if neighborhood_type != self.neighborhood_type:
                # Validate compatibility
                if (neighborhood_type == NeighborhoodType.HEX_PRISM and
                    self.dimension_type != Dimension.THREE_D):
                    self.dimension_type = Dimension.THREE_D
                    GlobalSettings.Simulation.DIMENSION_TYPE = Dimension.THREE_D
                    self.dimensions = GlobalSettings.Simulation.get_grid_dimensions()
                    logger.info(f"HEX_PRISM neighborhood requires 3D, changed dimension type to: {self.dimension_type.name}")
                elif (neighborhood_type == NeighborhoodType.HEX and
                    self.dimension_type == Dimension.THREE_D):
                    self.dimension_type = Dimension.TWO_D
                    GlobalSettings.Simulation.DIMENSION_TYPE = Dimension.TWO_D
                    self.dimensions = GlobalSettings.Simulation.get_grid_dimensions()
                    logger.info(f"HEX neighborhood requires 2D, changed dimension type to: {self.dimension_type.name}")

                # Update neighborhood type
                self.neighborhood_type = neighborhood_type

                # Reinitialize grid with new neighborhood type
                if self.grid is not None and self.coord_system is not None:
                    # --- CORRECTED ARGUMENTS for reinitialize ---
                    self.grid.reinitialize(
                        self.dimensions,
                        self.neighborhood_type,
                        self.dimension_type,
                        self.coord_system,    # Pass coord_system positionally
                        rule=self.rule,       # Pass rule via keyword
                        gui=self.grid.gui,    # Pass existing gui reference from grid via keyword
                        unique_id=self._unique_id
                    )
                    # --- END CORRECTION ---
                else:
                    logger.error("Grid or CoordinateSystem is not initialized. Cannot reinitialize.")
                    return # Added return on error

                # Reset simulation state
                self.generation = 0
                # self.is_running = False # is_running is not a controller attribute

                logger.info(f"Reinitialized grid with new neighborhood type: {neighborhood_type.name}")

        except Exception as e:
            logger.error(f"Error setting neighborhood type: {e}")
            raise


################################################
#                 GUI COMPONENTS               #
################################################


class ScrollableFrame(tk.Frame):
    """A scrollable frame that works consistently across platforms"""
    def __init__(self, container, gui, *args, **kwargs):
        super().__init__(container, *args, **kwargs)
        self.gui = gui # Store the SimulationGUI instance
        # Create canvas and scrollbar
        self.canvas = tk.Canvas(self, highlightthickness=0, bg=kwargs.get('bg', '#404040'))
        self.scrollbar = tk.Scrollbar(self, orient="vertical", command=self.canvas.yview)
        
        # Create frame inside canvas for content
        self.scrolled_frame = tk.Frame(self.canvas, bg=kwargs.get('bg', '#404040'))
        self.scrolled_frame.bind(
            "<Configure>",
            lambda e: self.canvas.configure(scrollregion=self.canvas.bbox("all"))
        )
        
        # Create window in canvas
        self.canvas_frame = self.canvas.create_window((0, 0), window=self.scrolled_frame, anchor="nw")
        
        # Configure canvas scrolling
        self.canvas.configure(yscrollcommand=self.scrollbar.set)
        
        # Bind canvas resize to frame resize
        self.canvas.bind('<Configure>', self._on_canvas_configure)
        
        # Pack scrollbar and canvas
        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        self.canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)

        # Bind mouse wheel to all widgets
        self._bind_mouse_scroll(self)
        self._bind_mouse_scroll(self.canvas)
        self._bind_mouse_scroll(self.scrolled_frame)

        # Bind to frame changes to catch new widgets
        self.scrolled_frame.bind('<Configure>', self._on_frame_configure)
        
        # Bind mouse enter/leave events to enable/disable scrolling
        self.bind("<Enter>", self._on_enter)
        self.canvas.bind("<Enter>", self._on_enter)
        self.scrolled_frame.bind("<Enter>", self._on_enter)
        
        self.bind("<Leave>", self._on_leave)
        self.canvas.bind("<Leave>", self._on_leave)
        self.scrolled_frame.bind("<Leave>", self._on_leave)

    def destroy(self):
        """Clean up bindings and destroy widgets properly"""
        try:
            # Unbind mouse wheel events
            try:
                self.unbind_all("<MouseWheel>")
                self.unbind_all("<Button-4>")
                self.unbind_all("<Button-5>")
            except Exception as e:
                logger.warning(f"Error unbinding mouse wheel events: {e}")
            
            # Destroy child widgets in a controlled manner
            if hasattr(self, 'scrolled_frame') and self.scrolled_frame:
                for child in list(self.scrolled_frame.winfo_children()):
                    try:
                        if hasattr(child, 'destroy'):
                            child.destroy()
                    except Exception as e:
                        logger.warning(f"Error destroying child widget: {e}")
            
            # Destroy canvas and scrollbar
            if hasattr(self, 'canvas') and self.canvas:
                try:
                    self.canvas.destroy()
                except Exception as e:
                    logger.warning(f"Error destroying canvas: {e}")
            
            if hasattr(self, 'scrollbar') and self.scrollbar:
                try:
                    self.scrollbar.destroy()
                except Exception as e:
                    logger.warning(f"Error destroying scrollbar: {e}")
            
            # Call parent destroy
            super().destroy()
            
        except Exception as e:
            logger.error(f"Error in ScrollableFrame.destroy: {e}")
            
    def _on_canvas_configure(self, event):
        """Handle canvas resize"""
        # Update the width of the frame to fill canvas
        self.canvas.itemconfig(self.canvas_frame, width=event.width)

    def _on_frame_configure(self, event=None):
        """Bind mouse wheel to all widgets when frame changes"""
        self._bind_to_all_children(self.scrolled_frame)
        self.canvas.configure(scrollregion=self.canvas.bbox("all"))

    def _bind_to_all_children(self, widget):
        """Recursively bind mouse wheel to all children"""
        self._bind_mouse_scroll(widget)
        for child in widget.winfo_children():
            self._bind_to_all_children(child)

    def bind_child_scroll(self, widget):
        """Bind mouse wheel events for all platforms to a child widget"""
        self._bind_mouse_scroll(widget)

    def _bind_mouse_scroll(self, widget):
        """Bind mouse wheel events for all platforms"""
        # Windows/macOS
        widget.bind("<MouseWheel>", self._on_mousewheel, add="+")
        
        # Linux
        widget.bind("<Button-4>", self._on_mousewheel, add="+")
        widget.bind("<Button-5>", self._on_mousewheel, add="+")

    def _on_mousewheel(self, event):
        """Cross-platform mouse wheel scrolling. Only scrolls the control panel
           if the event occurs over the panel itself, not the plot canvas.
           (Round 18: Add check for event origin)"""
        log_prefix = "ScrollableFrame._on_mousewheel (R18): " # Updated round

        # --- Check if event occurred over the Matplotlib canvas ---
        try:
            # Get the widget directly under the mouse cursor at the event's screen coordinates
            widget_under_mouse = event.widget.winfo_containing(event.x_root, event.y_root)

            # Check if the GUI and its canvas exist
            if hasattr(self.gui, 'canvas') and self.gui.canvas:
                plot_canvas_widget = self.gui.canvas.get_tk_widget()

                # Check if the widget under the mouse is the plot canvas or a child of it
                is_over_plot = False
                curr = widget_under_mouse
                while curr is not None:
                    if curr == plot_canvas_widget:
                        is_over_plot = True
                        break
                    # Check if master exists before accessing
                    if hasattr(curr, 'master'):
                        curr = curr.master
                    else:
                        break # Reached top level without master

                if is_over_plot:
                    logger.debug(f"{log_prefix}Event over plot canvas. Allowing propagation for ViewManager.")
                    return # Do nothing, let the event propagate to the binding on the plot canvas
            else:
                logger.warning(f"{log_prefix}GUI canvas not found, cannot determine event origin accurately.")

        except Exception as e:
            logger.error(f"{log_prefix}Error checking event origin: {e}")
            # Proceed with caution, might scroll incorrectly

        # --- If NOT over the plot canvas, proceed with scrolling the control panel ---
        logger.debug(f"{log_prefix}Event likely over control panel. Attempting to scroll.")
        if self.scrollbar.winfo_ismapped() and self.scrollbar.get() != (0.0, 1.0):  # Only scroll if scrollbar visible and needed
            if event.num == 4 or event.num == 5:  # Linux scroll up/down
                delta = -1 if event.num == 4 else 1
            elif hasattr(event, 'delta'): # Windows/macOS
                delta_val = event.delta if event.delta is not None else 0
                delta = -1 * int(delta_val / 120) if abs(delta_val) >= 120 else -1 * int(np.sign(delta_val))
            else:
                delta = 0 # Unknown event type

            if delta != 0 and hasattr(self, 'canvas'):
                try:
                    self.canvas.yview_scroll(delta, "units")
                    logger.debug(f"{log_prefix}Scrolled control panel canvas by {delta} units.")
                    return "break"  # Prevent event propagation ONLY if we scrolled the panel
                except tk.TclError as e:
                    logger.warning(f"{log_prefix}TclError scrolling control panel canvas: {e}")
                except Exception as e:
                    logger.error(f"{log_prefix}Error scrolling control panel canvas: {e}")

        # If scrollbar not needed or event not handled, allow propagation
        logger.debug(f"{log_prefix}Scrollbar not needed or event not handled for panel scroll.")
        return

    def _on_enter(self, event):
        """Bind mouse wheel events when mouse enters the frame"""
        # Bind to this widget for local scrolling
        # self._bind_mouse_scroll(self.scrolled_frame) # REMOVED
        # logger.debug("Bound local mouse wheel events to ScrollableFrame")
        pass

    def _on_leave(self, event):
        """Unbind mouse wheel events when mouse leaves the frame"""
        # Only unbind if mouse is actually leaving the entire scrollable area
        # Check if the mouse is still within our widget tree
        # x, y = event.x_root, event.y_root # REMOVED
        # widget_under_mouse = event.widget.winfo_containing(x, y) # REMOVED
        
        # If the widget under mouse is not part of our frame, unbind
        # if widget_under_mouse is None or not self.is_child_of(widget_under_mouse, self): # REMOVED
        #     # Unbind from this widget
        #     try:
        #         self.unbind_all("<MouseWheel>") # REMOVED
        #         self.unbind_all("<Button-4>") # REMOVED
        #         self.unbind_all("<Button-5>") # REMOVED
        #     except Exception as e:
        #         logger.warning(f"Error unbinding mouse wheel events: {e}") # REMOVED
        #     logger.debug("Unbound local mouse wheel events from ScrollableFrame") # REMOVED
        pass

    def is_child_of(self, widget, parent):
        """Check if widget is a child of parent"""
        if widget == parent:
            return True
        try:
            return self.is_child_of(widget.master, parent)
        except AttributeError:
            return False

    def add_widget(self, widget):
        """Add a widget and ensure it has scroll binding"""
        widget.pack(in_=self.scrolled_frame)
        self._bind_to_all_children(widget)

class ToolTip:
    """Creates a tooltip for a given widget"""
    def __init__(self, widget, text):
        self.widget = widget
        self.text = text
        self.tipwindow = None
        self.id = None
        self.x = self.y = 0

        # Store binding IDs for proper cleanup
        self.enter_id = widget.bind("<Enter>", self.enter, add="+")
        self.leave_id = widget.bind("<Leave>", self.leave, add="+")

    def showtip(self, event=None):
        """Display text in tooltip window"""
        if self.tipwindow or not self.widget or not self.widget.winfo_exists():
            return

        x = y = 0
        try:
            x, y, cx, cy = self.widget.bbox("insert")
            x += self.widget.winfo_rootx() + 25
            y += self.widget.winfo_rooty() + 20
        except (TypeError, tk.TclError):
            # If bbox fails, use widget coordinates
            x = self.widget.winfo_rootx() + self.widget.winfo_width() // 2
            y = self.widget.winfo_rooty() + self.widget.winfo_height() + 5

        # Creates a toplevel window
        self.tipwindow = tw = tk.Toplevel(self.widget)
        # Leaves only the label and destroys other windows
        tw.wm_overrideredirect(True)
        tw.wm_geometry("+%d+%d" % (x, y))

        try:
            # Create label with error handling
            # --- MODIFIED: Increased font size from 8 to 11 ---
            label = tk.Label(tw, text=self.text, justify=tk.LEFT,
                          background="#ffffe0", relief=tk.SOLID, borderwidth=1,
                          font="tahoma 11 normal", foreground='black') # Increased font size
            # --- END MODIFIED ---
            label.pack()
        except Exception as e:
            logger.warning(f"Error creating tooltip label: {e}")
            if self.tipwindow:
                self.tipwindow.destroy()
                self.tipwindow = None

    def hidetip(self):
        """Hides the tooltip"""
        tw = self.tipwindow
        self.tipwindow = None
        if tw and tw.winfo_exists():
            try:
                tw.destroy()
            except Exception as e:
                logger.warning(f"Error destroying tooltip window: {e}")

    def enter(self, event=None):
        """Handles mouse enter event"""
        if self.widget and self.widget.winfo_exists():
            self.id = self.widget.after(500, self.showtip)

    def leave(self, event=None):
        """Handles mouse leave event"""
        if self.id and self.widget and self.widget.winfo_exists():
            try:
                self.widget.after_cancel(self.id)
            except Exception as e:
                logger.warning(f"Error canceling tooltip timer: {e}")
        self.id = None
        if self.tipwindow:
            self.hidetip()

    def destroy(self):
        """Unbind events to prevent memory leaks"""
        if self.widget and self.widget.winfo_exists():
            try:
                # Unbind events using stored binding IDs
                if hasattr(self, 'enter_id') and self.enter_id:
                    self.widget.unbind("<Enter>", self.enter_id)
                if hasattr(self, 'leave_id') and self.leave_id:
                    self.widget.unbind("<Leave>", self.leave_id)
            except Exception as e:
                logger.warning(f"Error unbinding tooltip events: {e}")
                
        # Cancel any pending timer
        if self.id and self.widget and self.widget.winfo_exists():
            try:
                self.widget.after_cancel(self.id)
            except Exception as e:
                logger.warning(f"Error canceling tooltip timer during destroy: {e}")
                
        # Hide tooltip if visible
        if self.tipwindow:
            self.hidetip()
            
        # Clear references
        self.widget = None
        self.id = None

class ChangeTracker:
    """Tracks changes to rule parameters, metadata, and rule tables within the RuleEditorWindow."""
    def __init__(self):
        self.original_state: Dict[str, Any] = {} # Store the complete initial state (params, meta, tables)
        self.current_state: Dict[str, Any] = {} # Store the current state being edited
        self.undo_stack: List[Dict[str, Any]] = [] # Stores {'field_type': 'param'/'meta'/'table', 'name': str, 'old': Any, 'new': Any}
        self.redo_stack: List[Dict[str, Any]] = []
        self._is_modified = False
        logger.debug("ChangeTracker initialized.")

    def initialize(self, initial_data: Dict[str, Any]):
        """Initialize with the complete rule data (params, metadata, tables)."""
        self.original_state = copy.deepcopy(initial_data)
        self.current_state = copy.deepcopy(initial_data)
        self.undo_stack.clear()
        self.redo_stack.clear()
        self._is_modified = False
        logger.debug(f"ChangeTracker initialized with data for rule: {initial_data.get('name', 'N/A')}")

    def track_change(self, field_type: str, name: str, old_value: Any, new_value: Any):
        """Track a change to a specific field (parameter, metadata, or rule table)."""
        # Basic check for actual change
        if old_value == new_value:
            # logger.debug(f"ChangeTracker: No actual change detected for {field_type} '{name}'. Skipping track.") # Reduce noise
            return

        logger.debug(f"ChangeTracker: Tracking change for {field_type} '{name}': {old_value} -> {new_value}")
        self.undo_stack.append({
            'field_type': field_type,
            'name': name,
            'old': old_value,
            'new': new_value
        })

        # Update the current state dictionary
        if field_type == 'param':
            self.current_state.setdefault('params', {})[name] = new_value
        elif field_type == 'meta':
            self.current_state[name] = new_value
        elif field_type == 'table':
            # Assume 'name' is the table name (e.g., 'state_rule_table')
            self.current_state.setdefault('params', {})[name] = new_value
        else:
            logger.warning(f"ChangeTracker: Unknown field_type '{field_type}' for tracking.")

        self.redo_stack.clear()  # Clear redo stack on new change
        self._is_modified = True
        logger.debug(f"  Undo stack depth: {len(self.undo_stack)}, Redo stack cleared. Modified: {self._is_modified}")

    def undo(self) -> Optional[Dict[str, Any]]:
        """Undo last change, updating current_state."""
        if not self.undo_stack:
            logger.debug("ChangeTracker: Undo stack empty.")
            return None

        change = self.undo_stack.pop()
        self.redo_stack.append(change)
        field_type = change['field_type']
        name = change['name']
        old_value = change['old']

        logger.debug(f"ChangeTracker: Undoing change for {field_type} '{name}' back to: {old_value}")

        # Revert the change in the current_state dictionary
        if field_type == 'param':
            self.current_state.setdefault('params', {})[name] = old_value
        elif field_type == 'meta':
            self.current_state[name] = old_value
        elif field_type == 'table':
            self.current_state.setdefault('params', {})[name] = old_value
        else:
            logger.warning(f"ChangeTracker: Unknown field_type '{field_type}' during undo.")

        self._update_modified_state()
        logger.debug(f"  Undo stack depth: {len(self.undo_stack)}, Redo stack depth: {len(self.redo_stack)}. Modified: {self._is_modified}")
        return change # Return the change dict for UI update

    def redo(self) -> Optional[Dict[str, Any]]:
        """Redo last undone change, updating current_state."""
        if not self.redo_stack:
            logger.debug("ChangeTracker: Redo stack empty.")
            return None

        change = self.redo_stack.pop()
        self.undo_stack.append(change)
        field_type = change['field_type']
        name = change['name']
        new_value = change['new']

        logger.debug(f"ChangeTracker: Redoing change for {field_type} '{name}' to: {new_value}")

        # Re-apply the change in the current_state dictionary
        if field_type == 'param':
            self.current_state.setdefault('params', {})[name] = new_value
        elif field_type == 'meta':
            self.current_state[name] = new_value
        elif field_type == 'table':
            self.current_state.setdefault('params', {})[name] = new_value
        else:
            logger.warning(f"ChangeTracker: Unknown field_type '{field_type}' during redo.")

        self._update_modified_state()
        logger.debug(f"  Undo stack depth: {len(self.undo_stack)}, Redo stack depth: {len(self.redo_stack)}. Modified: {self._is_modified}")
        return change # Return the change dict for UI update

    def is_modified(self) -> bool:
        """Check if current_state differs from original_state."""
        return self._is_modified

    def _update_modified_state(self):
        """Update the modified state by comparing current_state to original_state."""
        # Perform a deep comparison if necessary, or rely on undo stack presence
        self._is_modified = bool(self.undo_stack) or self.current_state != self.original_state
        # logger.debug(f"ChangeTracker: Updated modified state to: {self._is_modified}") # Reduce noise

    def can_undo(self) -> bool:
        """Check if there are any actions to undo."""
        return bool(self.undo_stack)

    def can_redo(self) -> bool:
        """Check if there are any actions to redo."""
        return bool(self.redo_stack)

    def get_current_state(self) -> Dict[str, Any]:
        """Returns a deep copy of the current tracked state."""
        return copy.deepcopy(self.current_state)
    
class ValidatedEntry(tk.Entry):
    """Entry widget with tooltip and color support"""

    def __init__(self, master=None, **kwargs):
        super().__init__(master, **kwargs)
        self._tooltip = None
        self._bg_original = self.cget("background")  # Store original background color
        self._fg_original = self.cget("foreground")  # Store original foreground color

    def set_tooltip(self, text):
        """Set or update tooltip text"""
        if self._tooltip:
            self._tooltip.text = text
        else:
            self._tooltip = ToolTip(self, text) # Use ToolTip class

    def remove_tooltip(self):
        """Remove tooltip"""
        if self._tooltip:
            self._tooltip.destroy()
            self._tooltip = None

    def destroy(self):
        """Clean up tooltip before destroying widget"""
        if self._tooltip:
            self._tooltip.destroy()
        super().destroy()

    def highlight_invalid(self, error_msg: str):
        """Highlight the field as invalid and show a tooltip."""
        self.config(bg='#ffebeb', fg='black')  # Light red background, black text
        self.set_tooltip(error_msg)

    def clear_highlight(self):
        """Restore the original background and foreground colors."""
        self.config(bg=self._bg_original, fg=self._fg_original)
        self.remove_tooltip()

class EntryWithTooltip(tk.Entry):
    """Entry widget with tooltip and color support"""
    _tooltip: Optional[ToolTip]
    _bg_original: str
    _fg_original: str

class RuleColorSettingsModal(tk.Toplevel):
    """Modal window for editing rule-specific color override parameters."""

    def __init__(self, parent_editor: 'RuleEditorWindow', initial_color_params: Dict[str, Optional[str]]):
        super().__init__(parent_editor)
        self.parent_editor = parent_editor
        self.initial_params = initial_color_params
        self.color_vars: Dict[str, tk.StringVar] = {}
        self.widgets: Dict[str, Dict[str, tk.Widget]] = {} # Store entry, canvas, button per param

        self.title("Configure Rule-Specific Colors")
        self.transient(parent_editor)
        self.geometry("450x400") # Adjust size as needed
        self.resizable(False, False)
        self.protocol("WM_DELETE_WINDOW", self._cancel)

        # --- FIX: Set modal background ---
        self.configure(bg="#404040")
        # ---

        self._create_widgets()
        self.grab_set()
        self.focus_set()
        self.wait_window(self)

    def _create_widgets(self):
        modal_bg = "#404040" # Define background color
        self.configure(bg=modal_bg) # Set main window background

        main_frame = tk.Frame(self, padx=10, pady=10, bg=modal_bg) # Set frame background
        main_frame.pack(fill=tk.BOTH, expand=True)

        override_param_names = [
            'rule_background_color', 'rule_node_base_color', 'rule_node_color',
            'rule_new_node_color', 'rule_default_edge_color', 'rule_new_edge_color'
        ]

        for param_name in override_param_names:
            current_value = self.initial_params.get(param_name)
            current_value_str = str(current_value) if current_value is not None else ""

            # --- FIX: Set param_container_frame background ---
            param_container_frame = tk.Frame(main_frame, bg=modal_bg)
            param_container_frame.pack(fill=tk.X, pady=2)
            param_container_frame.columnconfigure(0, weight=0)
            param_container_frame.columnconfigure(1, weight=1)
            # ---

            display_name = ' '.join(word.capitalize() for word in param_name.split('_'))
            if display_name.startswith("Rule "): display_name = display_name[5:]
            # --- FIX: Set label background/foreground ---
            tk.Label(param_container_frame, text=display_name, width=20, anchor="w", bg=modal_bg, fg="white").grid(row=0, column=0, sticky="w", padx=5)
            # ---

            # --- FIX: Set sub-frame background ---
            picker_sub_frame = tk.Frame(param_container_frame, bg=modal_bg)
            picker_sub_frame.grid(row=0, column=1, sticky="ew")
            picker_sub_frame.columnconfigure(0, weight=1)
            picker_sub_frame.columnconfigure(1, weight=0)
            picker_sub_frame.columnconfigure(2, weight=0)
            # ---

            color_var = tk.StringVar(value=current_value_str)
            self.color_vars[param_name] = color_var

            # --- Use standard entry styling (dark theme) ---
            entry = tk.Entry(picker_sub_frame, textvariable=color_var, width=10, bg="#000000", fg="white", insertbackground="white")
            entry.grid(row=0, column=0, sticky="ew", padx=(0, 2))
            # ---

            preview_bg = current_value_str if current_value_str and current_value_str.startswith('#') and len(current_value_str) == 7 else 'SystemButtonFace'
            canvas = tk.Canvas(picker_sub_frame, width=30, height=20, bg=preview_bg, highlightthickness=1, highlightbackground="grey50")
            canvas.grid(row=0, column=1, padx=2)

            button = tk.Button(picker_sub_frame, text="Choose...",
                               command=lambda p=param_name, v=color_var, c=canvas: self._open_color_picker(p, v, c))
            button.grid(row=0, column=2, padx=2)

            self.widgets[param_name] = {'entry': entry, 'canvas': canvas, 'button': button}

        # --- FIX: Set button_frame background ---
        button_frame = tk.Frame(main_frame, bg=modal_bg)
        button_frame.pack(side=tk.BOTTOM, fill=tk.X, pady=(10, 0))
        # ---
        tk.Button(button_frame, text="Apply & Close", command=self._apply_and_close).pack(side=tk.LEFT, padx=10)
        tk.Button(button_frame, text="Cancel", command=self._cancel).pack(side=tk.RIGHT, padx=10)

    def _open_color_picker(self, param_name: str, color_var: tk.StringVar, preview_canvas: tk.Canvas):
        """Opens color chooser for the modal.
           (Round 18 Fix: Omit initialcolor argument entirely if color is invalid/empty)"""
        current_color = color_var.get()
        initial_color_hex: Optional[str] = None # Initialize as None

        # Validate the current color string
        if current_color and isinstance(current_color, str) and current_color.startswith('#') and len(current_color) == 7:
            try:
                # Attempt to get RGB tuple to validate the color name/hex
                self.winfo_rgb(current_color)
                initial_color_hex = current_color # Assign only if valid hex AND recognized by Tkinter
            except tk.TclError:
                logger.warning(f"Current color '{current_color}' for {param_name} is not a valid Tkinter color name. Opening chooser without initial color.")
                initial_color_hex = None # Set to None if Tkinter doesn't recognize it
        else:
            # Set to None if not a valid hex format or empty
            initial_color_hex = None

        logger.debug(f"Opening color picker for '{param_name}'. Valid Initial Hex: {initial_color_hex}")

        # --- FIX: Call askcolor differently based on whether initial_color_hex is valid ---
        color_info = None
        try:
            if initial_color_hex:
                # Call WITH initialcolor if valid
                logger.debug("Calling askcolor WITH initialcolor.")
                color_info = colorchooser.askcolor(initialcolor=initial_color_hex, title=f"Choose Color for {param_name}", parent=self)
            else:
                # Call WITHOUT initialcolor if invalid or None
                logger.debug("Calling askcolor WITHOUT initialcolor.")
                color_info = colorchooser.askcolor(title=f"Choose Color for {param_name}", parent=self)
        except tk.TclError as e:
            logger.error(f"TclError calling askcolor for {param_name} (initial={initial_color_hex}): {e}")
            messagebox.showerror("Color Chooser Error", f"Could not open color chooser:\n{e}", parent=self)
            return # Abort if askcolor fails
        # ---

        if color_info and color_info[1]: # Check if user selected a color (result is not None)
            new_color_hex = color_info[1]
            logger.debug(f"Color chosen: {new_color_hex}")
            color_var.set(new_color_hex)
            try:
                if preview_canvas.winfo_exists():
                    preview_canvas.config(bg=new_color_hex)
            except tk.TclError: pass
            except Exception as e: logger.warning(f"Error updating preview canvas: {e}")
        else:
            logger.debug("Color selection cancelled or failed.")

    def _apply_and_close(self):
        """Apply changes to the parent editor's state and close."""
        log_prefix = "RuleColorSettingsModal._apply_and_close: "
        logger.debug(f"{log_prefix}Applying color changes.")
        parent_tracker = self.parent_editor._get_change_tracker()
        if not parent_tracker:
            logger.error(f"{log_prefix}Parent editor's change tracker not found.")
            messagebox.showerror("Error", "Cannot apply changes: Parent editor state lost.", parent=self)
            return

        changes_made = False
        for param_name, color_var in self.color_vars.items():
            new_value_str = color_var.get()
            new_value = new_value_str if new_value_str and new_value_str.startswith('#') and len(new_value_str) == 7 else None
            old_value = parent_tracker.current_state.get('params', {}).get(param_name)

            if new_value != old_value:
                logger.debug(f"  Tracking change for {param_name}: {old_value} -> {new_value}")
                parent_tracker.track_change('param', param_name, old_value, new_value)
                changes_made = True

        if changes_made:
            logger.info(f"{log_prefix}Changes applied to parent editor's tracker.")
            self.parent_editor._update_editor_buttons()
            if self.parent_editor.parent and hasattr(self.parent_editor.parent, '_safe_plot_update'):
                 self.parent_editor.parent._safe_plot_update(force=True)
        else:
            logger.debug(f"{log_prefix}No changes detected.")

        self._cancel()

    def _cancel(self):
        """Close the modal without applying changes."""
        self.grab_release()
        self.destroy()

class RuleEditorWindow(tk.Toplevel):
    """A window for editing rule parameters, metadata, and rule tables."""

    # --- MODIFIED: Use the more specific type hint for the class attribute ---
    parameter_entries: Dict[str, Union[
        tk.Entry, tk.OptionMenu, ttk.OptionMenu, ttk.Combobox,
        tk.Checkbutton, ttk.Checkbutton, ValidatedEntry,
        Dict[str, Any] # For color picker structure
    ]]
    # ---

    metadata_fields: Dict[str, tk.Widget]
    selected_tab: Optional[str]
    _widget_attributes: Dict[str, Dict[str, str]]
    _tooltips: Dict[str, ToolTip]
    tab_change_binding: Optional[str]
    controller: Optional['SimulationController']
    widgets: Dict[str, tk.Widget]
    row_widgets: Dict[str, Tuple[tk.Frame, List[Union[tk.Entry, tk.StringVar]]]]
    default_var: tk.StringVar
    default_widget: Optional[Union[tk.Entry, tk.OptionMenu]]
    table_type: Optional[str]
    _is_updating: bool
    _error_state: bool
    table_name: Optional[str]
    summary_label: Optional[tk.Label]
    running: bool
    enable_tab_change_event: bool
    current_tab_index: int
    initial_conditions_var: tk.StringVar
    app_paths: Dict[str, str]
    notebook: Optional[ttk.Notebook]
    name_var: tk.StringVar
    change_tracker: ChangeTracker
    # --- MODIFIED: Update type hint for _editor_buttons ---
    _editor_buttons: Dict[str, Union[tk.Button, tk.Checkbutton]]
    # ---
    message_bar_label: Optional[tk.Label]
    use_override_var: tk.BooleanVar
    parent: 'SimulationGUI'
    rule_name: str
    rule_data: Dict[str, Any]
    top_button_frame: tk.Frame
    param_frame: tk.Frame
    visualization_frame: tk.Frame
    rule_table_frame: tk.Frame
    metadata_frame: tk.Frame
    rule_table_scrollable: Optional[ScrollableFrame] = None
    state_table_scrollable: Optional[ScrollableFrame] = None
    edge_table_scrollable: Optional[ScrollableFrame] = None
    favorite_var: tk.BooleanVar
    parameter_entry_details: Dict[str, Dict[str, Any]] = {}
    category_manager_window: Optional[tk.Toplevel] = None
    manage_categories_button: Optional[tk.Button] = None
    # --- ADDED: Attributes for buttons moved to top row ---
    add_rule_row_button: Optional[tk.Button] = None
    randomize_table_button: Optional[tk.Button] = None
    favorite_checkbutton: Optional[tk.Checkbutton] = None # Added favorite checkbox attribute
    # ---
    # --- ADDED: Attribute for eligibility description labels ---
    eligibility_description_labels: Dict[str, tk.Label] = {}
    # ---
    # --- ADDED: Attribute for tracking tab recreation ---
    _is_recreating_tab: bool = False
    # ---
    # --- ADDED: Attribute for caching values during recreation ---
    cached_parameter_values: Optional[Dict[str, Any]] = None
    cached_metadata_values: Optional[Dict[str, Any]] = None
    # ---
    # --- ADDED: Attribute to store sub-frames for dynamic groups ---
    sub_frames: Dict[str, tk.Frame] = {}
    # ---
    # --- ADDED: Attribute for color override configure button ---
    configure_override_button: Optional[tk.Button] = None
    # ---

    def __init__(self, parent: 'SimulationGUI', rule_name: str, selected_tab=None):
        """Initialize the Rule Editor window.
           (Round 10: Add self._viz_vars)"""
        logger.info(f"RuleEditorWindow.__init__: Initializing for rule_name='{rule_name}'")

        if not parent or not parent.root or not parent.root.winfo_exists():
            logger.error("RuleEditorWindow: Invalid parent window.")
            raise ValueError("Cannot create RuleEditorWindow with invalid parent.")

        super().__init__(parent.root) # Initialize Toplevel
        self.parent = parent
        try:
            # Load the full rule data using the provided rule_name
            self.rule_data = RuleLibraryManager.get_rule(rule_name)
            logger.info(f"RuleEditorWindow.__init__: Loaded rule_data for '{self.rule_data.get('name', 'N/A')}' (Type: {self.rule_data.get('type', 'N/A')})")
            params_preview = dict(list(self.rule_data.get('params', {}).items())[:5])
            logger.debug(f"  Params preview: {params_preview}")
        except ValueError as e:
            logger.error(f"RuleEditorWindow.__init__: Failed to get rule data for '{rule_name}': {e}. Closing editor.")
            messagebox.showerror("Error", f"Could not load data for rule '{rule_name}'.", parent=parent.root)
            self.after(10, self.destroy) # Schedule destroy after error message
            return # Stop initialization

        self.rule_name = rule_name # Store the specific rule name for this editor instance
        self.title(f"Rule Editor - {self.rule_name}")
        self.transient(parent.root) # Make window transient for parent
        logger.debug("Set RuleEditorWindow as transient for the main application window.")
        self.geometry("750x1350") # Set initial size
        self.resizable(True, True)

        # --- Initialize Attributes BEFORE creating widgets ---
        self.parameter_entries = {}
        self.metadata_fields = {}
        self._viz_vars: Dict[str, Union[tk.StringVar, tk.BooleanVar]] = {} # ADDED: Store viz tab variables
        self.selected_tab = selected_tab
        self._widget_attributes = {}
        self._tooltips = {}
        self.tab_change_binding = None
        self.controller = self.parent.controller # Reference to main controller
        self.widgets = {} # General widget storage if needed
        self.row_widgets = {} # For rule table rows
        self.default_var = tk.StringVar()
        self.default_widget = None
        self.table_type = None
        self._is_updating = False
        self._error_state = False
        self.table_name = None
        self.summary_label = None
        self.running = getattr(self.parent, 'running', False) # Get current running state
        self.enable_tab_change_event = True
        self.current_tab_index = 0
        initial_cond_default = self.rule_data.get('params', {}).get('initial_conditions', "Random")
        self.initial_conditions_var = tk.StringVar(value=initial_cond_default)
        self.app_paths = self.parent.app_paths # Copy app paths reference
        self.notebook = None
        self.name_var = tk.StringVar(value=self.rule_data.get('name', rule_name)) # Use loaded name
        self.change_tracker = ChangeTracker() # Initialize change tracking
        self._editor_buttons = {}
        self.message_bar_label = None
        self.favorite_var = tk.BooleanVar(value=self.rule_data.get('favorite', False))
        self.parameter_entry_details = {} # For complex widgets like color pickers
        self.category_manager_window = None
        self.manage_categories_button = None
        self.add_rule_row_button = None
        self.randomize_table_button = None
        self.favorite_checkbutton = None
        self.permutation_widget_containers: Dict[str, tk.Frame] = {}
        self._widget_order: Dict[str, List[tk.Widget]] = defaultdict(list)

        # Initialize use_override_var based on loaded rule data or rule defaults
        use_override_default = False
        temp_rule_instance_for_defaults = None
        try:
            rule_type_name = self.rule_data.get('type')
            if rule_type_name:
                temp_metadata_dict = {k: v for k, v in self.rule_data.items() if k != 'params' and k != '_ignored_params'}; temp_metadata_dict.setdefault('position', 1); temp_metadata = RuleMetadata(**temp_metadata_dict); temp_rule_instance_for_defaults = RuleLibrary.create_rule(self.rule_name, temp_metadata);
                if hasattr(temp_rule_instance_for_defaults, 'PARAMETER_METADATA'): use_override_default = temp_rule_instance_for_defaults.PARAMETER_METADATA.get('use_rule_specific_colors', {}).get('default', False)
                else: logger.warning(f"Rule '{self.rule_name}' missing PARAMETER_METADATA.")
            else: logger.warning(f"Rule data for '{self.rule_name}' missing 'type', cannot get default override value.")
        except Exception as e: logger.warning(f"Error creating temporary rule instance for defaults: {e}")
        initial_override_value = self.rule_data.get('params', {}).get('use_rule_specific_colors', use_override_default)
        self.use_override_var = tk.BooleanVar(value=initial_override_value)
        logger.debug(f"Initialized self.use_override_var with value: {self.use_override_var.get()}")

        # --- Positioning Logic ---
        parent_x = parent.root.winfo_rootx(); parent_y = parent.root.winfo_rooty(); parent_width = parent.root.winfo_width(); parent_height = parent.root.winfo_height()
        editor_width = 750; editor_height = 1350; editor_x = parent_x + parent_width + 10; editor_y = parent_y + (parent_height - editor_height) // 2
        self.geometry(f"{editor_width}x{editor_height}+{max(0, editor_x)}+{max(0, editor_y)}")

        # --- Create Widgets ---
        self._create_widgets() # This populates the frames and parameter_entries

        # --- Final Setup ---
        self.protocol("WM_DELETE_WINDOW", self._on_rule_editor_close)
        # Initialize change tracker with the specific rule data loaded for this editor
        self.change_tracker.initialize(self.rule_data)
        self._update_editor_buttons() # Set initial button states

        # --- Initial calls to update visibility ---
        self.after(100, self._update_permutation_widgets_visibility)
        # ---

        # Bind Shift+Return shortcut
        self.bind("<Shift-Return>", lambda event: self._apply_parameters_from_shortcut(event))
        logger.debug("Bound <Shift-Return> to _apply_parameters_from_shortcut")

        logger.debug("RuleEditorWindow initialization complete.")

    def _create_parameter_tab(self) -> tk.Frame:    
        """Creates the parameter tab content."""
        frame = tk.Frame(self.notebook)
        # Create a scrollable frame *inside* the tab
        scrollable = ScrollableFrame(frame, self.parent)
        scrollable.pack(fill=tk.BOTH, expand=True)

        # Add parameter fields into the scrollable frame's inner frame
        # --- MODIFIED: Update cast to match _create_parameter_fields signature ---
        self._create_parameter_fields(
            scrollable.scrolled_frame, self.rule_name, self, self.rule_data,
            cast(MutableMapping[str, Union[tk.Entry, tk.OptionMenu, ttk.OptionMenu, ttk.Combobox, tk.Checkbutton, ttk.Checkbutton, ValidatedEntry, Dict[str, Any]]], self.parameter_entries)
        )
        return frame

    def _create_rule_table_tab(self) -> tk.Frame: # Renamed method
        """Creates the combined rule table tab content.
           (Round 7: Remove button creation from here)"""
        frame = tk.Frame(self.notebook)

        # Check if rule allows tables and if either table exists
        allow_tables = self.rule_data.get('allow_rule_tables', True)
        has_state_table = 'state_rule_table' in self.rule_data.get('params', {})
        has_edge_table = 'edge_rule_table' in self.rule_data.get('params', {})

        if not allow_tables or (not has_state_table and not has_edge_table):
            message_label = tk.Label(frame, text="This rule does not use rule tables.", wraplength=600)
            message_label.pack(padx=10, pady=10)
            return frame

        # Create a scrollable frame *inside* the tab
        scrollable = ScrollableFrame(frame, self.parent)
        scrollable.pack(fill=tk.BOTH, expand=True)

        # Determine which table type to display
        if has_state_table:
            table_type = 'state'
            table_data = self.rule_data['params'].get('state_rule_table', {})
            self.table_name = 'state_rule_table'
            logger.info("Displaying State Rule Table in combined tab.")
        elif has_edge_table:
            table_type = 'edge'
            table_data = self.rule_data['params'].get('edge_rule_table', {})
            self.table_name = 'edge_rule_table'
            logger.info("Displaying Edge Rule Table in combined tab.")
        else:
            logger.error("No rule table data found despite checks!")
            return frame

        # Create rule table entries directly in the scrollable frame
        self._create_rule_table_entries(scrollable.scrolled_frame, table_type, table_data)

        # Store a reference to the scrollable frame
        self.rule_table_scrollable = scrollable

        # --- REMOVED: Button creation moved to _create_widgets ---
        # randomize_btn = tk.Button(...)
        # button_frame = tk.Frame(frame) ...
        # self._create_rule_table_button_section(...)
        # ---

        return frame

    def _create_state_rule_table_tab(self) -> tk.Frame:
        """Creates the state rule table tab content."""
        frame = tk.Frame(self.notebook)

        # If the rule doesn't use rule tables, display a message
        if 'state_rule_table' not in self.rule_data['params']:
            message_label = tk.Label(frame, text="This rule does not use a state rule table.", wraplength=600)
            message_label.pack(padx=10, pady=10)
            return frame

        # Create a scrollable frame *inside* the tab
        scrollable = ScrollableFrame(frame, self.parent)  # Pass parent (SimulationGUI)
        scrollable.pack(fill=tk.BOTH, expand=True)

        # Get rule data
        rule_data = self.rule_data

        # Create state rule table entries directly in the scrollable frame
        state_table_data = rule_data['params'].get('state_rule_table', {})
        self._create_rule_table_entries(scrollable.scrolled_frame, 'state', state_table_data)
        
        # Store a reference to the scrollable frame
        self.state_table_scrollable = scrollable

        # Add randomize button
        state_randomize_btn = tk.Button(
            frame,
            text="Randomize State Rule Table",
            command=lambda: self._randomize_specific_rule_table('state_rule_table')
        )
        state_randomize_btn.pack(fill=tk.X, padx=5, pady=5)

        # Add button section at the bottom
        button_frame = tk.Frame(frame)
        button_frame.pack(side=tk.BOTTOM, fill=tk.X, padx=5, pady=5)
        self._create_rule_table_button_section(button_frame, self.rule_name)

        return frame

    def _create_edge_rule_table_tab(self) -> tk.Frame:
        """Creates the edge rule table tab content."""
        frame = tk.Frame(self.notebook)

        # If the rule doesn't use rule tables, display a message
        if 'edge_rule_table' not in self.rule_data['params']:
            message_label = tk.Label(frame, text="This rule does not use an edge rule table.", wraplength=600)
            message_label.pack(padx=10, pady=10)
            return frame

        # Create a scrollable frame *inside* the tab
        scrollable = ScrollableFrame(frame, self.parent)  # Pass parent (SimulationGUI)
        scrollable.pack(fill=tk.BOTH, expand=True)

        # Get rule data
        rule_data = self.rule_data

        # Create edge rule table entries directly in the scrollable frame
        edge_table_data = rule_data['params'].get('edge_rule_table', {})
        self._create_rule_table_entries(scrollable.scrolled_frame, 'edge', edge_table_data)
        
        # Store a reference to the scrollable frame
        self.edge_table_scrollable = scrollable

        # Add randomize button
        edge_randomize_btn = tk.Button(
            frame,
            text="Randomize Edge Rule Table",
            command=lambda: self._randomize_specific_rule_table('edge_rule_table')
        )
        edge_randomize_btn.pack(fill=tk.X, padx=5, pady=5)

        # Add button section at the bottom
        button_frame = tk.Frame(frame)
        button_frame.pack(side=tk.BOTTOM, fill=tk.X, padx=5, pady=5)
        self._create_rule_table_button_section(button_frame, self.rule_name)

        return frame

    def _create_metadata_tab(self) -> tk.Frame:
        """Create the metadata tab content.
           (Round 8: Remove button section)"""
        frame = tk.Frame(self.notebook)

        # Create a scrollable frame *inside* the tab
        scrollable = ScrollableFrame(frame, self.parent)
        scrollable.pack(fill=tk.BOTH, expand=True)

        # Add metadata fields
        self._create_metadata_fields(scrollable.scrolled_frame, self.rule_name, self, self.rule_data, self.metadata_fields)

        return frame

    def _create_widgets(self):
        """Create the main layout and widgets for the editor, including the new Visualization tab,
           message bar, and two rows of consolidated buttons at the bottom.
           (Round 9: Add Favorite checkbox to top button row)
           (Round 8: Reorganize buttons between top/bottom rows, add Regenerate JSON to top row)
           (Round 7: Rearrange buttons into two rows, manage tab-specific button visibility)
           (Round 4: Add Manage Categories button)
           (Round 1: Add message bar, two button rows)
           (Round 22: Add Visualization tab, consolidated buttons)"""
        # [ Previous code remains the same up to top_button_frame creation ]
        button_bg = "#e1e1e1"; button_fg = "black"; button_disabled_fg = "black"
        self.active_tool_bg = "#a1d9ed"
        button_disabled_fg = 'grey50'

        # --- Main Content Area (Notebook) ---
        self.notebook = ttk.Notebook(self)
        self.notebook.pack(fill=tk.BOTH, expand=True, padx=10, pady=(10, 5))

        # --- Create tabs ---
        self.param_frame = self._create_parameter_tab()
        self.visualization_frame = self._create_visualization_tab()
        self.rule_table_frame = self._create_rule_table_tab()
        self.metadata_frame = self._create_metadata_tab() # Metadata fields created here

        self.notebook.add(self.param_frame, text="Parameters")
        self.notebook.add(self.visualization_frame, text="Visualization")
        self.notebook.add(self.rule_table_frame, text="Rule Table")
        self.notebook.add(self.metadata_frame, text="Rule Info")

        # Disable Rule Table tab if needed
        allow_tables = self.rule_data.get('allow_rule_tables', True)
        has_state_table = 'state_rule_table' in self.rule_data.get('params', {})
        has_edge_table = 'edge_rule_table' in self.rule_data.get('params', {})
        self.is_rule_table_active = allow_tables and (has_state_table or has_edge_table)
        if not self.is_rule_table_active:
            try: self.notebook.tab(2, state="disabled")
            except tk.TclError as e: logger.warning(f"TclError disabling rule table tab (index 2): {e}")

        # --- Message Bar ---
        self.message_bar_label = tk.Label(self, text="", anchor="w", fg="green", wraplength=730)
        self.message_bar_label.pack(fill=tk.X, padx=10, pady=(0, 5))

        # --- Bottom Button Row (Core Actions) ---
        bottom_button_frame = tk.Frame(self)
        bottom_button_frame.pack(side=tk.BOTTOM, fill=tk.X, padx=10, pady=(5, 10))
        button_width = 15
        apply_btn = tk.Button(bottom_button_frame, text="Apply Parameters", width=button_width, command=self._apply_parameters, disabledforeground=button_disabled_fg)
        apply_btn.pack(side=tk.LEFT, padx=2, pady=2)
        close_btn = tk.Button(bottom_button_frame, text="Close", width=button_width // 2, command=self._on_rule_editor_close, disabledforeground=button_disabled_fg)
        close_btn.pack(side=tk.RIGHT, padx=2, pady=2)
        delete_btn = tk.Button(bottom_button_frame, text="Delete Rule", width=button_width, command=self.delete_rule, disabledforeground=button_disabled_fg)
        delete_btn.pack(side=tk.RIGHT, padx=2, pady=2)
        save_btn = tk.Button(bottom_button_frame, text="Save Rule", width=button_width, command=lambda: self._save_rule_with_confirmation(self.rule_name, self._get_current_rule_data(), self), disabledforeground=button_disabled_fg)
        save_btn.pack(side=tk.RIGHT, padx=2, pady=2)

        # --- Top Button Row (Contextual/Other Actions) ---
        self.top_button_frame = tk.Frame(self)
        self.top_button_frame.pack(side=tk.BOTTOM, fill=tk.X, padx=10, pady=(0, 5))

        # Left-aligned buttons in top row
        undo_btn = tk.Button(self.top_button_frame, text=" Undo", width=button_width // 2, command=lambda: self._undo_parameter_change(self.parameter_entries), disabledforeground=button_disabled_fg)
        undo_btn.pack(side=tk.LEFT, padx=2, pady=2)
        redo_btn = tk.Button(self.top_button_frame, text=" Redo", width=button_width // 2, command=lambda: self._redo_parameter_change(self.parameter_entries), disabledforeground=button_disabled_fg)
        redo_btn.pack(side=tk.LEFT, padx=2, pady=2)
        reset_btn = tk.Button(self.top_button_frame, text="Reset to Defaults", width=button_width, command=lambda: self._reset_parameters_to_defaults(self.rule_name, self.parameter_entries), disabledforeground=button_disabled_fg)
        reset_btn.pack(side=tk.LEFT, padx=2, pady=2)
        regenerate_btn = tk.Button(self.top_button_frame, text="Regenerate JSON File", command=lambda: self._regenerate_json_file(), disabledforeground=button_disabled_fg)
        regenerate_btn.pack(side=tk.LEFT, padx=5, pady=2)
        self.manage_categories_button = tk.Button(self.top_button_frame, text="Manage Categories...", command=self._open_category_manager, disabledforeground=button_disabled_fg)
        self.manage_categories_button.pack(side=tk.LEFT, padx=2, pady=2)

        # --- ADDED: Favorite Checkbox (Right-aligned in top row) ---
        # self.favorite_var is initialized in __init__ based on rule_data
        self.favorite_checkbutton = tk.Checkbutton(
            self.top_button_frame,
            text="Favorite ",
            variable=self.favorite_var,
            anchor=tk.W,
            command=self._on_favorite_change # Add a callback if needed for immediate tracking
        )
        self.favorite_checkbutton.pack(side=tk.RIGHT, padx=5, pady=2)
        # --- END ADDED ---

        # --- Create Rule Table specific buttons (initially hidden) ---
        self.add_rule_row_button = tk.Button(self.top_button_frame, text="Add Rule Row", command=self._add_rule_row, disabledforeground=button_disabled_fg)
        self.randomize_table_button = tk.Button(self.top_button_frame, text="Randomize Table", command=lambda: self._randomize_specific_rule_table(self.table_name or ""), disabledforeground=button_disabled_fg)

        # Store ALL button references
        self._editor_buttons = {
            'apply': apply_btn, 'undo': undo_btn, 'redo': redo_btn,
            'save': save_btn, 'reset': reset_btn, 'delete': delete_btn,
            'close': close_btn, 'manage_categories': self.manage_categories_button,
            'add_rule_row': self.add_rule_row_button,
            'randomize_table': self.randomize_table_button,
            'regenerate_json': regenerate_btn,
            'favorite': self.favorite_checkbutton # Added favorite
        }
        self._update_editor_buttons()

        # Bind tab change event AFTER buttons are created
        self.tab_change_binding = self.notebook.bind("<<NotebookTabChanged>>", self._on_tab_changed)

        # Select initial tab and trigger initial button visibility update
        initial_tab_index = 0
        if self.selected_tab is not None:
            tab_map = {"Parameters": 0, "Visualization": 1, "Rule Table": 2, "Rule Info": 3}
            initial_tab_index = tab_map.get(self.selected_tab, 0)
        try:
            self.notebook.select(initial_tab_index)
            self._update_contextual_buttons(initial_tab_index)
        except tk.TclError:
            logger.warning("Error selecting initial tab, defaulting.");
            self.notebook.select(0)
            self._update_contextual_buttons(0)

    def _recreate_parameter_tab_content(self, rule_data: Optional[Dict[str, Any]] = None):
        """Recreate the content frame for the parameters tab, ensuring proper cleanup
           and preventing callbacks during recreation. Updates visibility after restoring values.
           (Round 31 Fix: Update visibility AFTER restoring cached values)"""
        log_prefix = "_recreate_parameter_tab_content (R31 Final Visibility Update): "
        # --- Guard against re-entry ---
        if hasattr(self, '_is_recreating_tab') and self._is_recreating_tab:
            logger.warning(f"{log_prefix}Already recreating, skipping.")
            return
        self._is_recreating_tab = True # Set flag
        logger.debug(f"{log_prefix}Set _is_recreating_tab = True")
        # ---

        try:
            if rule_data is None: rule_data = self.rule_data
            if not rule_data: logger.error(f"{log_prefix}No rule data available."); self._is_recreating_tab = False; return
            rule_name = rule_data['name']

            if self.param_frame is not None and self.param_frame.winfo_exists():
                logger.info(f"{log_prefix}Recreating content for parameter tab.")

                # Destroy ALL children of self.param_frame
                logger.debug(f"{log_prefix}Destroying ALL children of param_frame...")
                for widget in list(self.param_frame.winfo_children()):
                    try: widget.destroy()
                    except Exception as e: logger.warning(f"{log_prefix}Error destroying widget: {e}")
                logger.debug(f"{log_prefix}Finished destroying children.")

                # Clear the instance parameter state dictionaries
                logger.debug(f"{log_prefix}Clearing instance parameter state dictionaries.")
                self.parameter_entries.clear()
                if hasattr(self, 'permutation_widget_containers'): self.permutation_widget_containers.clear()
                if hasattr(self, 'parameter_entry_details'): self.parameter_entry_details.clear()
                if hasattr(self, '_viz_vars'): self._viz_vars.clear()
                if hasattr(self, 'sub_frames'): self.sub_frames.clear()

                # Create NEW ScrollableFrame and content_frame
                logger.debug(f"{log_prefix}Creating new ScrollableFrame.")
                param_scrollable = ScrollableFrame(self.param_frame, self.parent)
                param_scrollable.pack(side=tk.TOP, fill=tk.BOTH, expand=True)
                content_frame = param_scrollable.scrolled_frame
                logger.debug(f"{log_prefix}New ScrollableFrame and content_frame created.")

                # Schedule field creation
                def delayed_create_parameter_fields():
                    logger.debug(f"{log_prefix}Executing delayed_create_parameter_fields.")
                    try:
                        # Create fields (populates self.parameter_entries)
                        self._create_parameter_fields(
                            content_frame, rule_name, self,
                            rule_data, cast(MutableMapping[str, Union[tk.Entry, tk.OptionMenu, ttk.OptionMenu, ttk.Combobox, tk.Checkbutton, ttk.Checkbutton, ValidatedEntry, Dict[str, Any]]], self.parameter_entries)
                        )

                        # Restore cached values (this might trigger callbacks, guarded by flag)
                        if hasattr(self, 'cached_parameter_values') and self.cached_parameter_values:
                            logger.debug(f"{log_prefix}Restoring cached parameter values.")
                            self._set_tab_widget_values(self.parameter_entries, self.cached_parameter_values)

                        # --- FIX: Clear the flag BEFORE the final visibility update ---
                        self._is_recreating_tab = False
                        logger.debug(f"{log_prefix}Cleared _is_recreating_tab = False (before final visibility update)")
                        # ---

                        # --- FIX: Update visibility AFTER restoring values ---
                        logger.debug(f"{log_prefix}Calling FINAL _update_permutation_widgets_visibility.")
                        self._update_permutation_widgets_visibility()
                        # ---

                        if param_scrollable and param_scrollable.winfo_exists():
                            self.after(50, lambda c=param_scrollable.canvas: c.configure(scrollregion=c.bbox("all")))
                            logger.debug(f"{log_prefix}Scheduled scrollregion update.")
                    except Exception as e_delay:
                         logger.error(f"{log_prefix}Error in delayed_create_parameter_fields: {e_delay}")
                         logger.error(traceback.format_exc())
                         # --- Ensure flag is cleared even on error within delay ---
                         self._is_recreating_tab = False
                         logger.debug(f"{log_prefix}Cleared _is_recreating_tab = False (in delayed func exception)")
                         # ---

                self.after(50, delayed_create_parameter_fields)
            else:
                logger.error(f"{log_prefix}Parameter frame (self.param_frame) is None or destroyed.")
                self._is_recreating_tab = False # Clear flag on error
                logger.debug(f"{log_prefix}Cleared _is_recreating_tab = False (param_frame error)")

        except Exception as e:
            logger.error(f"{log_prefix}Error recreating parameter tab content: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Error", f"Failed to recreate parameter tab content: {e}")
            self._is_recreating_tab = False # Clear flag on error
            logger.debug(f"{log_prefix}Cleared _is_recreating_tab = False (outer exception)")

    def _recreate_rule_table_tab_content(self, rule_data: Optional[Dict[str, Any]] = None):
        """Recreate the content frame for the combined rule table tab.
           (Round 4: Removed call to _bind_mouse_wheel_to_all_widgets)"""
        try:
            if rule_data is None: rule_data = self.rule_data
            if not rule_data: logger.error("No rule data for rule table tab."); return

            rule_name = rule_data['name']
            target_frame = self.rule_table_frame

            for widget in list(target_frame.winfo_children()): widget.destroy()

            allow_tables = rule_data.get('allow_rule_tables', True)
            has_state_table = 'state_rule_table' in rule_data.get('params', {})
            has_edge_table = 'edge_rule_table' in rule_data.get('params', {})

            if not allow_tables or (not has_state_table and not has_edge_table):
                message_label = tk.Label(target_frame, text="This rule does not use rule tables.", wraplength=600)
                message_label.pack(padx=10, pady=10)
                return

            rule_table_scrollable = ScrollableFrame(target_frame, self.parent)
            rule_table_scrollable.pack(fill=tk.BOTH, expand=True)
            self.rule_table_scrollable = rule_table_scrollable

            if has_state_table:
                table_type = 'state'; table_data = rule_data['params'].get('state_rule_table', {}); self.table_name = 'state_rule_table'
            elif has_edge_table:
                table_type = 'edge'; table_data = rule_data['params'].get('edge_rule_table', {}); self.table_name = 'edge_rule_table'
            else: return

            # Create rule table entries
            self._create_rule_table_entries(rule_table_scrollable.scrolled_frame, table_type, table_data)

            # --- REMOVED: Call to _bind_mouse_wheel_to_all_widgets ---
            # self._bind_mouse_wheel_to_all_widgets(rule_table_scrollable.scrolled_frame, rule_table_scrollable)
            # ---

            # Add randomize button
            randomize_btn = tk.Button(
                target_frame, text=f"Randomize {table_type.title()} Rule Table",
                command=lambda: self._randomize_specific_rule_table(self.table_name or "")
            )
            randomize_btn.pack(fill=tk.X, padx=5, pady=5)

            # Add button section at the bottom
            button_frame = tk.Frame(target_frame)
            button_frame.pack(side=tk.BOTTOM, fill=tk.X, padx=5, pady=5)
            self._create_rule_table_button_section(button_frame, self.rule_name)

        except Exception as e:
            logger.error(f"Error recreating rule table tab content: {e}")
            messagebox.showerror("Error", f"Failed to recreate rule table tab content: {e}")

    def _recreate_metadata_tab_content(self, rule_data: Optional[Dict[str, Any]] = None):
        """Recreate the content frame for the metadata tab.
           (Round 4: Removed call to _bind_mouse_wheel_to_all_widgets)"""
        try:
            # If rule_data is not provided, use the stored rule_data
            if rule_data is None:
                rule_data = self.rule_data

            # Ensure rule_data is valid
            if not rule_data:
                logger.error("No rule data available to recreate tab content.")
                return

            rule_name = rule_data['name']

            if self.metadata_frame is not None:
                # Clear existing content
                for widget in list(self.metadata_frame.winfo_children()):
                    widget.destroy()

                # Create scrollable frame for metadata
                metadata_scrollable = ScrollableFrame(self.metadata_frame, self.parent)
                # DO NOT DELETE THIS COMMENT:  `expand=True` and `fill=BOTH` are CRUCIAL for correct layout.
                metadata_scrollable.pack(fill=tk.BOTH, expand=True) # Ensure it expands

                # Create metadata fields
                metadata_fields = {}

                # Schedule metadata field creation
                def delayed_create_metadata_fields():
                    self._create_metadata_fields(metadata_scrollable.scrolled_frame, rule_name, self, rule_data, metadata_fields)
                    self.metadata_fields.update(metadata_fields) # Update the main dictionary

                    # Restore cached values
                    if hasattr(self, 'cached_metadata_values') and self.cached_metadata_values:
                        self._set_tab_widget_values(self.metadata_fields, self.cached_metadata_values)

                    # --- REMOVED: Call to _bind_mouse_wheel_to_all_widgets ---
                    # metadata_scrollable._bind_to_all_children(metadata_scrollable.scrolled_frame)
                    # ---

                    # Update scroll region
                    metadata_scrollable.canvas.configure(scrollregion=metadata_scrollable.canvas.bbox("all"))

                self.after(50, delayed_create_metadata_fields)

                # Create metadata button section at the bottom of metadata_frame (outside scrollable)
                metadata_button_frame = tk.Frame(self.metadata_frame)
                # DO NOT DELETE THIS COMMENT: Must pack at BOTTOM *after* the scrollable frame.
                metadata_button_frame.pack(side=tk.BOTTOM, fill=tk.X, padx=5, pady=5)
                self._create_metadata_button_section(
                    metadata_button_frame,
                    rule_name
                )

        except Exception as e:
            logger.error(f"Error recreating metadata tab content: {e}")
            messagebox.showerror("Error", f"Failed to recreate metadata tab content: {e}")

    def _recreate_visualization_tab_content(self, rule_data: Optional[Dict[str, Any]] = None):
        """Recreate the content frame for the Visualization tab.
           (Round 21: Add _is_recreating_tab flag)"""
        log_prefix = "_recreate_visualization_tab_content (R21 Flag Guard): "
        if hasattr(self, '_is_recreating_tab') and self._is_recreating_tab:
            logger.warning(f"{log_prefix}Already recreating, skipping.")
            return
        self._is_recreating_tab = True # Set flag
        logger.debug(f"{log_prefix}Set _is_recreating_tab = True")
        try:
            if rule_data is None: rule_data = self.rule_data
            if not rule_data: logger.error("No rule data for visualization tab."); return

            rule_name = rule_data['name']
            target_frame = self.visualization_frame

            if target_frame is None:
                logger.error("Visualization tab frame (self.visualization_frame) is None.")
                return

            # Clear existing content
            for widget in list(target_frame.winfo_children()):
                widget.destroy()

            # Clear relevant dictionaries
            viz_keys_to_remove = [k for k, v in self.parameter_entries.items() if isinstance(v, dict) or (hasattr(v, 'master') and v.master.master == target_frame)]
            for k in viz_keys_to_remove: self.parameter_entries.pop(k, None)
            if hasattr(self, 'parameter_entry_details'): self.parameter_entry_details.clear()
            if hasattr(self, '_viz_vars'): self._viz_vars.clear()

            # Create scrollable frame
            scrollable = ScrollableFrame(target_frame, self.parent)
            scrollable.pack(fill=tk.BOTH, expand=True)
            content_frame = scrollable.scrolled_frame

            # --- Get Rule Instance and Merged Metadata ---
            if not self.controller or not self.controller.rule or self.controller.rule.name != rule_name:
                try: temp_rule_data = RuleLibraryManager.get_rule(rule_name); temp_metadata_dict = {k: v for k, v in temp_rule_data.items() if k != 'params' and k != '_ignored_params'}; temp_metadata_dict.setdefault('position', 1); temp_metadata = RuleMetadata(**temp_metadata_dict); rule_instance = RuleLibrary.create_rule(rule_name, temp_metadata); rule_instance.params = copy.deepcopy(temp_rule_data.get('params', {}))
                except Exception as e: logger.error(f"Failed to create temporary rule instance for '{rule_name}': {e}"); return
            else: rule_instance = self.controller.rule
            base_metadata = getattr(Rule, 'PARAMETER_METADATA', {}); subclass_metadata = getattr(rule_instance, 'PARAMETER_METADATA', {}); merged_metadata = RuleEditorWindow._merge_metadata(base_metadata, subclass_metadata); exclude_set = getattr(rule_instance, 'EXCLUDE_EDITOR_PARAMS', set())

            # --- Group visualization parameters ---
            viz_groups: Dict[str, List[str]] = defaultdict(list)
            use_override_toggle_param: Optional[str] = None
            for param_name, param_info in merged_metadata.items():
                if param_name in exclude_set: continue
                group = param_info.get('parameter_group', 'Other Settings')
                if group.startswith("Visualization"):
                    if group == "Visualization Overrides":
                        if param_name == 'use_rule_specific_colors': use_override_toggle_param = param_name
                    else:
                        viz_groups[group].append(param_name)

            # --- Create Sections ---
            group_frame_bg = content_frame.cget('bg')

            # 1. Standard Visualization Groups
            preferred_viz_order = ["Visualization: Nodes", "Visualization: Edges"]
            for group_name in preferred_viz_order:
                if group_name in viz_groups:
                    group_label_frame = ttk.LabelFrame(content_frame, text=group_name, padding=(5, 5))
                    group_label_frame.pack(fill=tk.X, padx=5, pady=5)
                    inner_content_frame = tk.Frame(group_label_frame, bg=group_frame_bg)
                    inner_content_frame.pack(fill=tk.BOTH, expand=True, padx=2, pady=2)
                    param_names_in_group = sorted(viz_groups[group_name], key=lambda p: 0 if 'mode' in p else 1)
                    for param_name in param_names_in_group:
                        param_info = merged_metadata[param_name]
                        self._create_single_parameter_widget(inner_content_frame, param_name, param_info, self.rule_data, cast(MutableMapping[str, Union[tk.Entry, tk.OptionMenu, ttk.OptionMenu, ttk.Combobox, tk.Checkbutton, ttk.Checkbutton, ValidatedEntry, Dict[str, Any]]], self.parameter_entries))

            # 2. Override Control Section (Checkbox + Button)
            override_control_frame = tk.LabelFrame(content_frame, text="Rule Color Override", bg=group_frame_bg, fg="white", bd=2, relief=tk.GROOVE)
            override_control_frame.pack(fill=tk.X, padx=5, pady=10)
            override_content_frame = tk.Frame(override_control_frame, bg=group_frame_bg)
            override_content_frame.pack(fill=tk.X, expand=True)

            if use_override_toggle_param:
                param_info = merged_metadata[use_override_toggle_param]
                self._create_single_parameter_widget(override_content_frame, use_override_toggle_param, param_info, self.rule_data, cast(MutableMapping[str, Union[tk.Entry, tk.OptionMenu, ttk.OptionMenu, ttk.Combobox, tk.Checkbutton, ttk.Checkbutton, ValidatedEntry, Dict[str, Any]]], self.parameter_entries))
            else: logger.warning("Parameter 'use_rule_specific_colors' not found in metadata!")

            self.configure_override_button = tk.Button(
                override_content_frame,
                text="Configure Rule-Specific Colors...",
                command=self._open_rule_color_modal,
                state=tk.DISABLED # Initial state
            )
            self.configure_override_button.pack(pady=5, padx=5)
            self._editor_buttons['configure_override_colors'] = self.configure_override_button

            # --- Restore cached values for this tab (excluding overrides) ---
            viz_params_to_restore = {}
            if hasattr(self, 'change_tracker') and self.change_tracker:
                current_params = self.change_tracker.current_state.get('params', {})
                for k, v in current_params.items():
                    param_group = merged_metadata.get(k, {}).get('parameter_group', '')
                    if k in self.parameter_entries and param_group.startswith("Visualization") and param_group != "Visualization Overrides":
                        viz_params_to_restore[k] = v
                    elif k == 'use_rule_specific_colors':
                        viz_params_to_restore[k] = v
            else: logger.warning("Change tracker not available, cannot restore cached values accurately.")

            self._set_tab_widget_values(self.parameter_entries, viz_params_to_restore)
            # ---

            # --- Initial state setting for override button ---
            initial_override_state = False
            if hasattr(self, 'use_override_var') and isinstance(self.use_override_var, tk.BooleanVar):
                initial_override_state = self.use_override_var.get()
            self._toggle_override_widgets_state(initial_override_state) # This now toggles the button

            # Update scroll region
            scrollable.canvas.configure(scrollregion=scrollable.canvas.bbox("all"))

        except Exception as e:
            logger.error(f"Error recreating visualization tab content: {e}")
            messagebox.showerror("Error", f"Failed to recreate visualization tab content: {e}")
        finally:
            self._is_recreating_tab = False # Clear flag
            logger.debug(f"{log_prefix}Cleared _is_recreating_tab = False")

    def _on_eligibility_metric_change(self, *args):
        """Callback when birth/survival metric or aggregation changes.
           (Round 26: Call new update method)"""
        # --- ADDED: Guard against execution during recreation ---
        if hasattr(self, '_is_recreating_tab') and self._is_recreating_tab:
            logger.debug("_on_eligibility_metric_change: Skipping because tab is recreating.")
            return
        # ---
        log_prefix = "RuleEditorWindow._on_eligibility_metric_change: "
        logger.debug(f"{log_prefix}Callback triggered.")
        self._update_permutation_widgets_visibility() # Call the updated method

    def _on_final_death_metric_change(self, *args):
        """Callback when final_death_check_metric changes.
           Updates visibility of corresponding counts/range widgets.
           (Round 12: New method)"""
        log_prefix = "RuleEditorWindow._on_final_death_metric_change: "
        logger.debug(f"{log_prefix}Callback triggered.")
        self._update_permutation_widgets_visibility()

    @staticmethod
    def _parse_dynamic_param_name(param_name: str) -> Tuple[str, str, Optional[str]]:
        """
        Robustly parses base, metric, agg from a dynamic name.
        Handles names with or without aggregation suffixes, and metrics with underscores.
        Accepts both AVG and AVERAGE as aggregation suffixes.
        """
        logger = logging.getLogger(__name__)
        log_prefix = "ROL-U._parse_dynamic_param_name (Final Robust): "

        known_metrics = {
            "DEGREE", "CLUSTERING", "BETWEENNESS", "ACTIVE_NEIGHBOR_COUNT",
            "SYMMETRY_STATE", "SYMMETRY_DEGREE", "NEIGHBOR_DEGREE_VARIANCE", "NEIGHBOR_DEGREE_STDDEV"
        }
        known_aggregations = {"SUM", "AVG", "AVERAGE"}
        agg_normalization = {"AVERAGE": "AVG", "AVG": "AVG", "SUM": "SUM"}

        base_prefixes = sorted([
            "birth_eligibility_range", "birth_eligibility_values",
            "survival_eligibility_range", "survival_eligibility_values",
            "final_life_metric_range", "final_life_metric_values",
            "final_death_metric_range", "final_death_metric_values"
        ], key=len, reverse=True)

        base = param_name
        metric = "UNKNOWN"
        agg: Optional[str] = None

        matched_base = None
        for prefix in base_prefixes:
            if param_name.startswith(prefix + '_'):
                matched_base = prefix
                break

        if matched_base:
            base = matched_base
            remainder = param_name[len(matched_base) + 1:]
            # Split from the right on the last underscore
            if '_' in remainder:
                metric_candidate, agg_candidate = remainder.rsplit('_', 1)
                if agg_candidate in known_aggregations:
                    agg = agg_normalization[agg_candidate]
                    metric = metric_candidate
                else:
                    metric = remainder
                    agg = None
            else:
                metric = remainder
                agg = None

            if metric not in known_metrics:
                logger.warning(f"{log_prefix}Parsed metric '{metric}' from '{param_name}' is NOT in known_metrics {known_metrics}. Setting to UNKNOWN.")
                metric = "UNKNOWN"
                agg = None
        else:
            logger.warning(f"{log_prefix}Could not reliably parse metric from dynamic param name: {param_name}")

        logger.debug(f"{log_prefix}Parsed '{param_name}' -> Base='{base}', Metric='{metric}', Agg='{agg}'")
        return base, metric or "UNKNOWN", agg

    def _update_permutation_widgets_visibility(self):
        """
        Selectively destroys old permutation widgets and creates/shows new ones
        based on the rule's get_dynamic_parameter_metadata method, preserving
        unaffected widgets and their values. Ensures static methods are called correctly.
        (Round 7: Add detailed logging for widget creation)
        """
        log_prefix = "RuleEditorWindow._update_permutation_widgets_visibility (R7 Create Log): " # Updated round
        logger.debug(f"{log_prefix}Updating visibility and widgets...")

        # --- Guard against execution during recreation ---
        if hasattr(self, '_is_recreating_tab') and self._is_recreating_tab:
            logger.debug(f"{log_prefix}Skipping because tab is recreating.")
            return
        # ---

        # --- Get current selections and rule instance ---
        if not self.controller or not self.controller.rule:
            logger.error(f"{log_prefix}Controller or rule is None. Cannot update dynamic widgets.")
            return
        rule_instance = self.controller.rule
        rule_class = rule_instance.__class__ # Get the specific class of the current rule
        # ---

        # --- Check if the rule instance supports the necessary methods ---
        supports_dynamic_names = hasattr(rule_instance, '_get_expected_dynamic_param_names_from_selectors') and callable(getattr(rule_instance, '_get_expected_dynamic_param_names_from_selectors', None))
        supports_dynamic_meta = hasattr(rule_instance, 'get_dynamic_parameter_metadata') and callable(getattr(rule_instance, 'get_dynamic_parameter_metadata', None))
        supports_parse = hasattr(rule_class, '_parse_dynamic_param_name') and callable(getattr(rule_class, '_parse_dynamic_param_name', None))

        if not (supports_dynamic_names and supports_dynamic_meta and supports_parse):
            logger.debug(f"{log_prefix}Rule type {rule_class.__name__} does not fully support dynamic parameters (Names:{supports_dynamic_names}, Meta:{supports_dynamic_meta}, Parse:{supports_parse}). Skipping dynamic update.")
            if hasattr(self, 'permutation_widget_containers'):
                for container in self.permutation_widget_containers.values():
                    if container and container.winfo_exists(): container.pack_forget()
            return
        # ---

        birth_metric = self._get_widget_value_safe('birth_metric_type', 'DEGREE')
        birth_agg_raw = self._get_widget_value_safe('birth_metric_aggregation', 'SUM')
        survival_metric = self._get_widget_value_safe('survival_metric_type', 'DEGREE')
        survival_agg_raw = self._get_widget_value_safe('survival_metric_aggregation', 'SUM')
        final_check_metric = self._get_widget_value_safe('final_check_metric', 'DEGREE')

        birth_agg = "AVG" if birth_agg_raw == "AVERAGE" else birth_agg_raw
        survival_agg = "AVG" if survival_agg_raw == "AVERAGE" else survival_agg_raw
        logger.debug(f"{log_prefix}Current Selectors: BirthM={birth_metric}, BirthA={birth_agg}, SurvM={survival_metric}, SurvA={survival_agg}, FinalM={final_check_metric}")

        # --- Calculate ALL Expected Dynamic Parameter Names ---
        expected_dynamic_names = set()
        try:
            get_dynamic_names_method = getattr(rule_instance, '_get_expected_dynamic_param_names_from_selectors')
            expected_dynamic_names = get_dynamic_names_method(
                {'birth_metric_type': birth_metric, 'birth_metric_aggregation': birth_agg,
                 'survival_metric_type': survival_metric, 'survival_metric_aggregation': survival_agg,
                 'final_check_metric': final_check_metric}
            )
            logger.debug(f"{log_prefix}Expected dynamic params based on current selectors: {expected_dynamic_names}")
        except Exception as dyn_err:
            logger.error(f"{log_prefix}Error getting expected dynamic param names for {rule_instance.name}: {dyn_err}")
        # ---

        # --- Get ALL Existing Dynamic Widget Names ---
        if not hasattr(self, 'permutation_widget_containers'): self.permutation_widget_containers = {}
        existing_dynamic_names = set(self.permutation_widget_containers.keys())
        logger.debug(f"{log_prefix}Existing dynamic widgets: {existing_dynamic_names}")
        # ---

        # --- Compare Sets ---
        widgets_to_remove = existing_dynamic_names - expected_dynamic_names
        widgets_to_create = expected_dynamic_names - existing_dynamic_names
        widgets_to_keep = existing_dynamic_names.intersection(expected_dynamic_names)
        logger.debug(f"{log_prefix}Widgets to Remove: {widgets_to_remove}")
        logger.debug(f"{log_prefix}Widgets to Create: {widgets_to_create}")
        logger.debug(f"{log_prefix}Widgets to Keep: {widgets_to_keep}")
        # ---

        # --- Destroy Widgets to Remove ---
        if widgets_to_remove:
            logger.debug(f"{log_prefix}Destroying {len(widgets_to_remove)} outdated permutation widgets/containers.")
            for param_name in widgets_to_remove:
                widget_container = self.permutation_widget_containers.pop(param_name, None)
                if widget_container and isinstance(widget_container, tk.Frame) and widget_container.winfo_exists():
                    for child in list(widget_container.winfo_children()): child.destroy()
                    widget_container.destroy()
                removed_widget = self.parameter_entries.pop(param_name, None)
        # ---

        # --- Create Widgets to Create ---
        if widgets_to_create:
            logger.debug(f"{log_prefix}Creating {len(widgets_to_create)} new dynamic widgets.")
            for full_param_name in widgets_to_create:
                logger.debug(f"{log_prefix}  Processing creation for: '{full_param_name}'") # LOGGING
                # Call static parse method using the specific rule_class
                try:
                    if hasattr(rule_class, '_parse_dynamic_param_name') and callable(getattr(rule_class, '_parse_dynamic_param_name', None)):
                        parse_method = getattr(rule_class, '_parse_dynamic_param_name')
                        base_name, metric, agg = parse_method(full_param_name)
                        logger.debug(f"{log_prefix}    Parsed: Base='{base_name}', Metric='{metric}', Agg='{agg}'") # LOGGING
                    else:
                        logger.error(f"{log_prefix}    Rule class {rule_class.__name__} missing callable method _parse_dynamic_param_name for '{full_param_name}'. Skipping widget creation.")
                        continue
                except Exception as parse_err:
                    logger.error(f"{log_prefix}    Error parsing dynamic param name '{full_param_name}' using {rule_class.__name__}._parse_dynamic_param_name: {parse_err}")
                    continue

                # Determine target frame
                target_sub_frame = None
                target_frame_name = "None" # For logging
                if base_name.startswith("birth_"): target_sub_frame = self.sub_frames.get('birth_criteria'); target_frame_name = 'birth_criteria'
                elif base_name.startswith("survival_"): target_sub_frame = self.sub_frames.get('survival_criteria'); target_frame_name = 'survival_criteria'
                elif base_name.startswith("final_life_"): target_sub_frame = self.sub_frames.get('life_criteria'); target_frame_name = 'life_criteria'
                elif base_name.startswith("final_death_"): target_sub_frame = self.sub_frames.get('death_criteria'); target_frame_name = 'death_criteria'
                logger.debug(f"{log_prefix}    Target sub-frame name: '{target_frame_name}', Found: {target_sub_frame is not None and target_sub_frame.winfo_exists()}") # LOGGING

                # Skip non-aggregated metrics for SUM/AVERAGE based permutations
                is_non_aggregated_eligibility = metric in ["SYMMETRY_STATE", "SYMMETRY_DEGREE", "NEIGHBOR_DEGREE_VARIANCE", "NEIGHBOR_DEGREE_STDDEV"] and not base_name.startswith("final_")
                if is_non_aggregated_eligibility and agg is not None:
                    logger.debug(f"{log_prefix}    Skipping creation for '{full_param_name}' (non-aggregated metric with aggregation).")
                    continue
                if is_non_aggregated_eligibility: agg = None # Ensure agg is None for these

                if metric and target_sub_frame and target_sub_frame.winfo_exists():
                    # Call the rule's method to get dynamic metadata
                    logger.debug(f"{log_prefix}    Getting dynamic metadata for Base='{base_name}', Metric='{metric}', Agg='{agg}'") # LOGGING
                    dynamic_meta = rule_instance.get_dynamic_parameter_metadata(base_name, metric, agg)
                    if dynamic_meta:
                        logger.debug(f"{log_prefix}    Dynamic metadata retrieved. Calling _create_single_parameter_widget for '{full_param_name}'.") # LOGGING
                        created_container = self._create_single_parameter_widget(
                            target_sub_frame, full_param_name, dynamic_meta,
                            self.rule_data, self.parameter_entries
                        )
                        if created_container:
                            self.permutation_widget_containers[full_param_name] = created_container
                            logger.debug(f"{log_prefix}    Widget container CREATED and STORED for '{full_param_name}'.") # LOGGING
                        else:
                            logger.error(f"{log_prefix}    _create_single_parameter_widget FAILED to return a container for '{full_param_name}'.") # LOGGING
                    else:
                        logger.debug(f"{log_prefix}    Rule did not provide dynamic metadata for {base_name}, {metric}, {agg}. Widget not created.")
                elif not metric: logger.warning(f"{log_prefix}    Could not determine metric for base name '{base_name}' during creation.")
                elif not target_sub_frame or not target_sub_frame.winfo_exists(): logger.warning(f"{log_prefix}    Target sub-frame '{target_frame_name}' not found or destroyed during creation.")
        # ---

        # --- Handle clustering_denominator_type visibility ---
        # [ Logic remains the same ]
        clustering_widget_container = self.permutation_widget_containers.get('clustering_denominator_type')
        show_clustering_denom = (birth_metric == "CLUSTERING" or survival_metric == "CLUSTERING")
        if 'clustering_denominator_type' not in self.parameter_entries and show_clustering_denom:
             param_name_clust = 'clustering_denominator_type'
             static_merged_metadata = getattr(Rule, 'PARAMETER_METADATA', {})
             if param_name_clust in static_merged_metadata:
                 param_info_clust = static_merged_metadata[param_name_clust]
                 target_frame_clust = self.sub_frames.get('clustering_config')
                 if target_frame_clust and target_frame_clust.winfo_exists():
                     logger.debug(f"{log_prefix}Creating widget for 'clustering_denominator_type'.")
                     created_container = self._create_single_parameter_widget(target_frame_clust, param_name_clust, param_info_clust, self.rule_data, self.parameter_entries)
                     if created_container: self.permutation_widget_containers[param_name_clust] = created_container
                     clustering_widget_container = self.permutation_widget_containers.get(param_name_clust)
                 else: logger.error(f"{log_prefix}Cannot create clustering widget: Target frame missing.")
             else: logger.warning(f"{log_prefix}Static metadata for 'clustering_denominator_type' not found.")
        if clustering_widget_container and isinstance(clustering_widget_container, tk.Frame):
            is_currently_visible = clustering_widget_container.winfo_ismapped()
            if show_clustering_denom and not is_currently_visible: clustering_widget_container.pack(fill=tk.X, pady=1); logger.debug(f"{log_prefix}Showing 'clustering_denominator_type'.")
            elif not show_clustering_denom and is_currently_visible: clustering_widget_container.pack_forget(); logger.debug(f"{log_prefix}Hiding 'clustering_denominator_type'.")
        elif show_clustering_denom: logger.warning(f"{log_prefix}Could not find container frame for clustering_denominator_type to manage visibility.")
        # ---

        # Update scroll region for parameter tab if it exists
        if hasattr(self, 'param_frame') and self.param_frame:
            for child in self.param_frame.winfo_children():
                if isinstance(child, ScrollableFrame):
                    self.after(100, lambda c=child.canvas: c.configure(scrollregion=c.bbox("all")))
                    break

        logger.debug(f"{log_prefix}Finished updating widget visibility.")

    @staticmethod
    def _merge_metadata(base_meta: Dict[str, Dict[str, Any]], sub_meta: Dict[str, Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:
        """
        Intelligently merges base and subclass parameter metadata.
        Subclass values for 'default', 'allowed_values', 'min', 'max',
        'parameter_group', and 'description' override base values if provided.
        Type mismatches are logged.
        """
        merged = copy.deepcopy(base_meta) # Start with a copy of the base

        for param_name, sub_info in sub_meta.items():
            if param_name in merged:
                # Parameter exists in base, update specific fields
                base_info = merged[param_name]
                # Check for type mismatch (log warning, prefer subclass type)
                if 'type' in sub_info and 'type' in base_info and sub_info['type'] != base_info['type']:
                    logger.warning(f"Metadata Merge: Type mismatch for '{param_name}'. Base: {base_info['type']}, Subclass: {sub_info['type']}. Using subclass type.")
                    base_info['type'] = sub_info['type'] # Prefer subclass type

                # Override specific keys if present in subclass info
                for key in ['default', 'allowed_values', 'min', 'max', 'parameter_group', 'description', 'element_type']:
                    if key in sub_info:
                        base_info[key] = sub_info[key]
                # Update the merged dictionary entry
                merged[param_name] = base_info
            else:
                # Parameter only exists in subclass, add it directly
                merged[param_name] = copy.deepcopy(sub_info)

        return merged

    def _create_rule_table_entries(self, parent: tk.Frame, table_type: str, table_data: Dict[str, Any]):
        """Create rule table entries with validation and tooltips.
           (Round 7: Remove Add Row button creation)"""
        self.table_type = table_type
        self.table_name = 'state_rule_table' if table_type == 'state' else 'edge_rule_table'
        logger.debug(f"_create_rule_table_entries: Creating entries for table_type='{table_type}', table_name='{self.table_name}'")

        for child in parent.winfo_children(): child.destroy()
        self.row_widgets = {}

        # --- REMOVED: Add Row button creation moved to _create_widgets ---
        # button_frame = tk.Frame(parent)
        # button_frame.pack(fill=tk.X, padx=5, pady=5)
        # add_button = tk.Button(button_frame, text="Add Rule Row", command=self._add_rule_row)
        # add_button.pack(side=tk.LEFT, padx=5, pady=5)
        # ---

        default_frame = tk.Frame(parent)
        default_frame.pack(fill=tk.X, padx=5, pady=5)
        tk.Label(default_frame, text="Default:").pack(side="left", padx=5)

        if table_type == 'state':
            self.default_var = tk.StringVar(value=str(table_data.get("default", "0")))
            default_entry = self._create_validated_entry(default_frame, 3, 'state')
            default_entry.insert(0, str(table_data.get("default", "0")))
            default_entry.pack(side="left")
            self.default_widget = default_entry
        else: # edge
            self.default_var = tk.StringVar(value=table_data.get("default", "maintain"))
            default_menu = tk.OptionMenu(default_frame, self.default_var, "add", "remove", "maintain")
            default_menu.pack(side="left")
            self.default_widget = default_menu

        table_frame = tk.Frame(parent)
        table_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        self.table_frame = table_frame

        column_width = 15
        if table_type == 'state': headers = ["Current State", "Neighbor Pattern", "Connection Pattern", "New State", ""]
        else: headers = ["Self State", "Neighbor State", "Connection Pattern", "Action", ""]

        header_row = tk.Frame(table_frame)
        header_row.pack(fill=tk.X, pady=2)
        for i, header in enumerate(headers):
            width = 5 if i == len(headers) - 1 else column_width
            header_label = tk.Label(header_row, text=header, width=width, font=("TkDefaultFont", 10, "bold"), anchor="center", bg="white", fg="black", relief=tk.RIDGE)
            header_label.grid(row=0, column=i, padx=2, sticky="ew")
        for i in range(len(headers) - 1): header_row.grid_columnconfigure(i, weight=1)
        header_row.grid_columnconfigure(len(headers) - 1, weight=0)

        row_num = 1
        for key, value in table_data.items():
            if key == "default": continue
            row_frame = tk.Frame(table_frame); row_frame.pack(fill=tk.X, pady=2)
            components = key.strip("()").split(",")
            entries = []
            for i, comp in enumerate(components):
                entry = self._create_validated_entry(row_frame, i, table_type)
                entry.insert(0, comp.strip()); entry.config(width=column_width); entry.grid(row=0, column=i, padx=2, sticky="ew")
                entries.append(entry)
            if table_type == 'state':
                value_entry = self._create_validated_entry(row_frame, len(components), table_type)
                value_entry.insert(0, str(value)); value_entry.config(width=column_width); value_entry.grid(row=0, column=len(components), padx=2, sticky="ew")
                entries.append(value_entry)
            else: # edge
                value_var = tk.StringVar(value=value)
                value_menu = self._create_validated_menu(row_frame, value_var, ["add", "remove", "maintain"])
                value_menu.config(width=column_width-2); value_menu.grid(row=0, column=len(components), padx=2, sticky="ew")
                entries.append(value_var)
            delete_btn = tk.Button(row_frame, text="X", command=lambda r=row_frame: self._safe_delete_row(r))
            delete_btn.grid(row=0, column=len(components) + 1, padx=2)
            for i in range(len(headers) - 1): row_frame.grid_columnconfigure(i, weight=1)
            row_frame.grid_columnconfigure(len(headers) - 1, weight=0)
            row_key = f"row_{row_num}"; self.row_widgets[row_key] = (row_frame, entries); row_num += 1

    def _create_header(self, parent, table_type):
        """Create header for rule table"""
        header_frame = tk.Frame(parent)
        header_frame.pack(fill="x", padx=5, pady=5)

        if table_type == 'state':
            headers = ["Current State", "Neighbor Pattern", "Connection Pattern", "New State", ""]
        else:  # edge
            headers = ["Self State", "Neighbor State", "Connection Pattern", "Action", ""]

        # Create dummy entries for alignment with consistent width
        for i, header in enumerate(headers):
            dummy_entry = tk.Entry(header_frame, width=15, font=("TkDefaultFont", 10, "bold"))
            dummy_entry.insert(0, header)
            # CRITICAL FIX: Use grid instead of pack, and set background to white with black text
            dummy_entry.config(state="readonly", readonlybackground="white", relief=tk.FLAT, foreground='black')
            dummy_entry.grid(row=0, column=i, padx=5, pady=2) # Use grid
                
    def _create_validated_entry(self, parent: tk.Frame, column_index: Optional[int], table_type: Optional[str]) -> ValidatedEntry:
        """Create entry widget. Binds validation only for rule table cells.
           Sets insertbackground to black and selection colors for visibility.
           (Round 10: Set selection colors, ensure black insertbackground)
           (Round 8: Force black insertbackground, remove focus background change)
           (Round 1: Set insertbackground)"""
        # --- MODIFIED: Set selection colors ---
        entry = ValidatedEntry(parent,
                               selectbackground="grey50", # Background of selected text
                               selectforeground="white") # Color of selected text
        # ---
        widget_id = str(entry)

        # --- Force black insertbackground for cursor visibility ---
        entry.config(insertbackground='black')
        # logger.debug(f"Set insertbackground to 'black' for entry widget.") # Reduce noise
        # ---

        # Store original colors immediately upon creation
        self._widget_attributes[widget_id] = {
            'bg_original': entry.cget('background'),
            'fg_original': entry.cget('foreground')
        }

        # --- REMOVED: FocusIn binding that changed background ---

        is_rule_table_cell = table_type is not None and column_index is not None

        if is_rule_table_cell:
            # logger.debug(f"Binding FocusOut/Return for Rule Table cell (Col: {column_index}, Type: {table_type})") # Reduce noise
            entry.bind("<FocusOut>", lambda event, w=entry, p_name=None, col_idx=column_index, tbl_type=table_type: self._handle_entry_focus_out(event, w, p_name, col_idx, tbl_type))
            entry.bind("<Return>", lambda event, w=entry, p_name=None, col_idx=column_index, tbl_type=table_type: self._handle_entry_focus_out(event, w, p_name, col_idx, tbl_type))
        else:
             param_name = None
             if hasattr(self, 'parameter_entries'):
                 found = False
                 for name, widget_ref in self.parameter_entries.items():
                     actual_widget = widget_ref if isinstance(widget_ref, tk.Widget) else (widget_ref.get('entry') if isinstance(widget_ref, dict) else None)
                     if actual_widget == entry:
                         param_name = name
                         found = True
                         break
             # logger.debug(f"NOT binding FocusOut/Return for Parameter field: {param_name}") # Reduce noise

        return entry

    def _create_validated_menu(self, parent: tk.Frame, var: tk.StringVar, options: List[str]) -> tk.OptionMenu:
        """Create an option menu with validation and error recovery"""
        menu = tk.OptionMenu(parent, var, *options)
        
        def on_select(*args):
            if not self._is_updating:
                def update():
                    # Validation happens in _safe_update
                    pass
                self._safe_update(update)
                
        var.trace('w', on_select)
        return menu

    def _add_rule_row(self, key=None, value=None):
        """Add a new row to the rule table"""
        # Get the parent frame based on the current tab
        if not hasattr(self, 'notebook') or self.notebook is None:
            return
            
        current_tab_index = self.notebook.index(self.notebook.select())
        if current_tab_index == 1:  # State rule table tab
            if not hasattr(self, 'state_table_scrollable') or self.state_table_scrollable is None:
                return
            scrollable_frame = self.state_table_scrollable.scrolled_frame
            table_type = 'state'
        elif current_tab_index == 2:  # Edge rule table tab
            if not hasattr(self, 'edge_table_scrollable') or self.edge_table_scrollable is None:
                return
            scrollable_frame = self.edge_table_scrollable.scrolled_frame
            table_type = 'edge'
        else:
            return  # Not on a rule table tab
        
        # Find the table frame (should be the third child after button_frame and default_frame)
        table_frame = None
        for child in scrollable_frame.winfo_children():
            if isinstance(child, tk.Frame) and len(child.winfo_children()) > 0:
                # Look for a frame that contains our table rows
                if hasattr(self, 'table_frame') and child == self.table_frame:
                    table_frame = child
                    break
        
        if not table_frame:
            # If table frame not found, something is wrong - the table should have been created in _create_rule_table_entries
            logger.error("Table frame not found when adding a new row")
            return
        
        # Create a new row in the table
        row_frame = tk.Frame(table_frame)
        row_frame.pack(fill=tk.X, pady=2)

        entries = []
        
        # Determine number of columns based on table type
        if table_type == 'state':
            num_columns = 5  # Current State, Neighbor Pattern, Connection Pattern, New State, Delete
        else:  # edge
            num_columns = 5  # Self State, Neighbor State, Connection Pattern, Action, Delete

        # Create entries for each component based on table type
        if table_type == 'state':
            # Current state entry
            current_state_var = tk.StringVar(value="-1" if key is None else key.strip("()").split(",")[0].strip())
            current_state_menu = tk.OptionMenu(row_frame, current_state_var, "-1", "0", "1")
            current_state_menu.config(width=13)  # Set width to match header
            current_state_menu.grid(row=0, column=0, padx=2, sticky="ew")
            entries.append(current_state_var)

            # Neighbor pattern entry
            neighbor_pattern = ValidatedEntry(row_frame, width=15)  # Set width to match header
            if key is not None:
                neighbor_pattern.insert(0, key.strip("()").split(",")[1].strip())
            else:
                neighbor_pattern.insert(0, "00000000")  # Default pattern
            neighbor_pattern.grid(row=0, column=1, padx=2, sticky="ew")
            entries.append(neighbor_pattern)

            # Connection pattern entry
            connection_pattern = ValidatedEntry(row_frame, width=15)  # Set width to match header
            if key is not None:
                connection_pattern.insert(0, key.strip("()").split(",")[2].strip())
            else:
                connection_pattern.insert(0, "00000000")  # Default pattern
            connection_pattern.grid(row=0, column=2, padx=2, sticky="ew")
            entries.append(connection_pattern)

            # New state entry
            new_state_var = tk.StringVar(value="0" if value is None else str(value))
            new_state_menu = tk.OptionMenu(row_frame, new_state_var, "-1", "0", "1")
            new_state_menu.config(width=13)  # Set width to match header
            new_state_menu.grid(row=0, column=3, padx=2, sticky="ew")
            entries.append(new_state_var)

        else:  # edge table
            # Self state entry
            self_state_var = tk.StringVar(value="0" if key is None else key.strip("()").split(",")[0].strip())
            self_state_menu = tk.OptionMenu(row_frame, self_state_var, "0", "1")
            self_state_menu.config(width=13)  # Set width to match header
            self_state_menu.grid(row=0, column=0, padx=2, sticky="ew")
            entries.append(self_state_var)

            # Neighbor state entry
            neighbor_state_var = tk.StringVar(value="0" if key is None else key.strip("()").split(",")[1].strip())
            neighbor_state_menu = tk.OptionMenu(row_frame, neighbor_state_var, "0", "1")
            neighbor_state_menu.config(width=13)  # Set width to match header
            neighbor_state_menu.grid(row=0, column=1, padx=2, sticky="ew")
            entries.append(neighbor_state_var)

            # Connection pattern entry
            connection_pattern = ValidatedEntry(row_frame, width=15)  # Set width to match header
            if key is not None:
                connection_pattern.insert(0, key.strip("()").split(",")[2].strip())
            else:
                connection_pattern.insert(0, "00000000")  # Default pattern
            connection_pattern.grid(row=0, column=2, padx=2, sticky="ew")
            entries.append(connection_pattern)

            # Action entry
            action_var = tk.StringVar(value="maintain" if value is None else value)
            action_menu = tk.OptionMenu(row_frame, action_var, "add", "remove", "maintain")
            action_menu.config(width=13)  # Set width to match header
            action_menu.grid(row=0, column=3, padx=2, sticky="ew")
            entries.append(action_var)

        # Delete button
        delete_btn = tk.Button(row_frame, text="X", command=lambda: self._safe_delete_row(row_frame))
        delete_btn.grid(row=0, column=4, padx=2)

        # Set column weights to match header row
        for i in range(num_columns):
            row_frame.grid_columnconfigure(i, weight=1)

        # Store row widgets
        if not hasattr(self, 'row_widgets'):
            self.row_widgets = {}
        row_key = f"row_{len(self.row_widgets)}"
        self.row_widgets[row_key] = (row_frame, entries)

        # Bind validation and update events
        for entry in entries:
            if isinstance(entry, tk.Entry):
                entry.bind('<FocusOut>', lambda event, row=row_key: self._validate_and_update_rule_table_row(row_key))
                entry.bind('<Return>', lambda event, row=row_key: self._validate_and_update_rule_table_row(row_key))
            elif isinstance(entry, tk.StringVar):
                entry.trace_add("write", lambda *args, row=row_key: self._validate_and_update_rule_table_row(row_key))

        # Update scroll region
        if current_tab_index == 1 and hasattr(self, 'state_table_scrollable') and self.state_table_scrollable is not None:  # State rule table tab
            self.state_table_scrollable.canvas.configure(scrollregion=self.state_table_scrollable.canvas.bbox("all"))
        elif current_tab_index == 2 and hasattr(self, 'edge_table_scrollable') and self.edge_table_scrollable is not None:  # Edge rule table tab
            self.edge_table_scrollable.canvas.configure(scrollregion=self.edge_table_scrollable.canvas.bbox("all"))

        return row_frame, entries

    def _safe_delete_row(self, row_frame: tk.Frame):
        """Safely delete a row with confirmation and recovery"""
        if messagebox.askyesno("Confirm Delete", "Are you sure you want to delete this rule?"):
            def delete_row():
                # Find the row key for this frame
                row_key_to_delete = None
                for row_key, (frame, _) in self.row_widgets.items():
                    if frame == row_frame:
                        row_key_to_delete = row_key
                        break
                
                if row_key_to_delete:
                    # Remove from row_widgets dictionary
                    self.row_widgets.pop(row_key_to_delete)
                    
                # Destroy the frame
                row_frame.destroy()
                
                # Update current state after deletion
                self._current_state = self.get_table_data()
                
                # Update the rule table data
                self._update_rule_table_data()
                    
            self._safe_update(delete_row)

    def _validate_and_update_rule_table_row(self, row_key: str):
        """Validate and update a row in the rule table"""
        if not hasattr(self, 'row_widgets') or row_key not in self.row_widgets:
            return

        row_frame, entries = self.row_widgets[row_key]
        
        # Make sure table_type is not None
        if not hasattr(self, 'table_type') or self.table_type is None:
            # Try to determine table_type from the current tab
            if hasattr(self, 'notebook') and self.notebook is not None:
                current_tab_index = self.notebook.index(self.notebook.select())
                if current_tab_index == 1:
                    table_type = 'state'
                elif current_tab_index == 2:
                    table_type = 'edge'
                else:
                    return  # Not on a rule table tab
            else:
                return  # Can't determine table_type
        else:
            table_type = self.table_type

        # Validate entries
        valid = True

        if table_type == 'state':
            # Validate current state
            current_state = entries[0].get() if isinstance(entries[0], tk.Entry) else entries[0].get()
            if not self._validate_rule_table_cell(table_type, 0, current_state):
                valid = False

            # Validate neighbor pattern
            neighbor_pattern = entries[1].get() if isinstance(entries[1], tk.Entry) else entries[1].get()
            if not self._validate_rule_table_cell(table_type, 1, neighbor_pattern):
                valid = False

            # Validate connection pattern
            connection_pattern = entries[2].get() if isinstance(entries[2], tk.Entry) else entries[2].get()
            if not self._validate_rule_table_cell(table_type, 2, connection_pattern):
                valid = False

            # Validate new state
            new_state = entries[3].get() if isinstance(entries[3], tk.Entry) else entries[3].get()
            if not self._validate_rule_table_cell(table_type, 3, new_state):
                valid = False

        else:  # edge table
            # Validate self state
            self_state = entries[0].get() if isinstance(entries[0], tk.Entry) else entries[0].get()
            if not self._validate_rule_table_cell(table_type, 0, self_state):
                valid = False

            # Validate neighbor state
            neighbor_state = entries[1].get() if isinstance(entries[1], tk.Entry) else entries[1].get()
            if not self._validate_rule_table_cell(table_type, 1, neighbor_state):
                valid = False

            # Validate connection pattern
            connection_pattern = entries[2].get() if isinstance(entries[2], tk.Entry) else entries[2].get()
            if not self._validate_rule_table_cell(table_type, 2, connection_pattern):
                valid = False
                
            # Validate action
            action = entries[3].get() if isinstance(entries[3], tk.Entry) else entries[3].get()
            if not self._validate_rule_table_cell(table_type, 3, action):
                valid = False

        # Highlight row based on validation
        for entry in entries:
            if isinstance(entry, tk.Entry):
                entry.config(bg='#ffebeb' if not valid else 'white')

        # Update table data if valid
        if valid:
            self._update_rule_table_data()
            
    def _validate_rule_table_cell(self, table_type: str, column_index: int, value: str, widget: Optional[tk.Entry] = None) -> bool:
        """Validate rule table cell value"""
        try:
            is_valid = False
            error_msg = ""

            if table_type == 'state':
                if column_index == 0:  # current_state
                    try:
                        val = int(value)
                        is_valid = val in [-1, 0, 1]
                        error_msg = "Must be -1, 0, or 1"
                    except ValueError:
                        error_msg = "Must be an integer"
                elif column_index == 1:  # neighbor_pattern
                    is_valid = all(c in '01IN' for c in value) and len(value) == 8
                    error_msg = "Must be 8 digits of 0s, 1s, Is, or Ns"
                elif column_index == 2:  # connection_pattern
                    is_valid = all(c in '01I' for c in value) and len(value) == 8
                    error_msg = "Must be 8 digits of 0s, 1s, and Is"
                elif column_index == 3:  # new_state
                    try:
                        val = int(value)
                        is_valid = val in [-1, 0, 1]
                        error_msg = "Must be -1, 0, or 1"
                    except ValueError:
                        error_msg = "Must be an integer"
            elif table_type == 'edge':
                if column_index in [0, 1]:  # self_state, neighbor_state
                    try:
                        val = int(value)
                        is_valid = val in [0, 1]
                        error_msg = "Must be 0 or 1"
                    except ValueError:
                        error_msg = "Must be an integer"
                elif column_index == 2:  # connection_pattern
                    is_valid = all(c in '01I' for c in value) and len(value) == 8
                    error_msg = "Must be 8 digits of 0s, 1s and Is"
                elif column_index == 3:  # action
                    is_valid = value in ["add", "remove", "maintain"]
                    error_msg = "Must be 'add', 'remove', or 'maintain'"

            # Apply visual feedback if widget provided
            if widget is not None:
                if is_valid:
                    self._highlight_field(widget, True)
                    self._remove_tooltip(widget)
                else:
                    self._highlight_field(widget, False, error_msg)

            return is_valid

        except Exception as e:
            logger.error(f"Error validating rule table cell: {e}")
            return False

    def _update_rule_table_data(self):
        """Update the rule table data from the UI"""
        # Get the current tab index to determine which table to update
        if not hasattr(self, 'notebook') or self.notebook is None:
            return

        current_tab_index = self.notebook.index(self.notebook.select())

        if current_tab_index == 1:  # State rule table tab
            table_type = 'state'
            table_name = 'state_rule_table'
        elif current_tab_index == 2:  # Edge rule table tab
            table_type = 'edge'
            table_name = 'edge_rule_table'
        else:
            return  # Not on a rule table tab

        # Start with the default value
        new_table_data = {}

        # Add default value if it exists
        if hasattr(self, 'default_var') and self.default_var is not None:
            default_value = self.default_var.get()
            if table_type == 'state':
                try:
                    default_value = int(default_value)
                except ValueError:
                    default_value = 0
            new_table_data['default'] = default_value

        # Add all rows from the UI
        if hasattr(self, 'row_widgets'):
            for _, (_, entries) in self.row_widgets.items():
                if table_type == 'state':
                    # Get values from entries
                    current_state = entries[0].get() if isinstance(entries[0], tk.Entry) else entries[0].get()
                    neighbor_pattern = entries[1].get() if isinstance(entries[1], tk.Entry) else entries[1].get()
                    connection_pattern = entries[2].get() if isinstance(entries[2], tk.Entry) else entries[2].get()
                    new_state = entries[3].get() if isinstance(entries[3], tk.Entry) else entries[3].get()

                    # Create key and convert value to int
                    key = f"({current_state}, {neighbor_pattern}, {connection_pattern})"
                    try:
                        value = int(new_state)
                    except ValueError:
                        value = 0

                    # Add to data
                    new_table_data[key] = value
                else:  # edge
                    # Get values from entries
                    self_state = entries[0].get() if isinstance(entries[0], tk.Entry) else entries[0].get()
                    neighbor_state = entries[1].get() if isinstance(entries[1], tk.Entry) else entries[1].get()
                    connection_pattern = entries[2].get() if isinstance(entries[2], tk.Entry) else entries[2].get()
                    action = entries[3].get() if isinstance(entries[3], tk.Entry) else entries[3].get()

                    # Create key
                    key = f"({self_state}, {neighbor_state}, {connection_pattern})"

                    # Add to data
                    new_table_data[key] = action

        # Update the controller's rule parameters
        # --- ADDED: Check if rule exists ---
        if hasattr(self, 'parent') and self.parent is not None and hasattr(self.parent, 'controller') and self.parent.controller and self.parent.controller.rule:
            self.parent.controller.rule.params[table_name] = new_table_data
            # --- REMOVED: Obsolete invalidate_cache call ---
            # self.parent.controller.rule.invalidate_cache()
            # ---

            # Update visualization if running
            if hasattr(self.parent, 'running') and self.parent.running:
                self.parent._safe_plot_update()
        else:
            logger.error("Cannot update rule table data: Controller or rule is missing.")

    def get_table_data(self) -> Dict[str, Any]:
        """Get the current table data with validation"""
        # Get the current tab index to determine which table to get
        if not hasattr(self, 'notebook') or self.notebook is None:
            return {}
            
        current_tab_index = self.notebook.index(self.notebook.select())
        
        if current_tab_index == 1:  # State rule table tab
            table_type = 'state'
            table_name = 'state_rule_table'
        elif current_tab_index == 2:  # Edge rule table tab
            table_type = 'edge'
            table_name = 'edge_rule_table'
        else:
            return {}  # Not on a rule table tab
        
        # Start with the default value
        data = {}
        
        # Add default value if it exists
        if hasattr(self, 'default_var') and self.default_var is not None:
            default_value = self.default_var.get()
            if table_type == 'state':
                try:
                    default_value = int(default_value)
                except ValueError:
                    default_value = 0
            data['default'] = default_value
        
        # Add all rows from the UI
        if hasattr(self, 'row_widgets'):
            for _, (_, entries) in self.row_widgets.items():
                if table_type == 'state':
                    # Get values from entries
                    current_state = entries[0].get() if isinstance(entries[0], tk.Entry) else entries[0].get()
                    neighbor_pattern = entries[1].get() if isinstance(entries[1], tk.Entry) else entries[1].get()
                    connection_pattern = entries[2].get() if isinstance(entries[2], tk.Entry) else entries[2].get()
                    new_state = entries[3].get() if isinstance(entries[3], tk.Entry) else entries[3].get()
                    
                    # Create key and convert value to int
                    key = f"({current_state}, {neighbor_pattern}, {connection_pattern})"
                    try:
                        value = int(new_state)
                    except ValueError:
                        value = 0
                    
                    # Add to data
                    data[key] = value
                else:  # edge
                    # Get values from entries
                    self_state = entries[0].get() if isinstance(entries[0], tk.Entry) else entries[0].get()
                    neighbor_state = entries[1].get() if isinstance(entries[1], tk.Entry) else entries[1].get()
                    connection_pattern = entries[2].get() if isinstance(entries[2], tk.Entry) else entries[2].get()
                    action = entries[3].get() if isinstance(entries[3], tk.Entry) else entries[3].get()
                    
                    # Create key
                    key = f"({self_state}, {neighbor_state}, {connection_pattern})"
                    
                    # Add to data
                    data[key] = action
        
        return data

    def set_table_data(self, table_data: Dict[str, Any]):
        """Set the table data and update the UI."""
        # Get the current tab index to determine which table to set
        if not hasattr(self, 'notebook') or self.notebook is None:
            return
            
        current_tab_index = self.notebook.index(self.notebook.select())
        
        if current_tab_index == 1:  # State rule table tab
            if not hasattr(self, 'state_table_scrollable') or self.state_table_scrollable is None:
                return
            scrollable_frame = self.state_table_scrollable.scrolled_frame
            table_type = 'state'
        elif current_tab_index == 2:  # Edge rule table tab
            if not hasattr(self, 'edge_table_scrollable') or self.edge_table_scrollable is None:
                return
            scrollable_frame = self.edge_table_scrollable.scrolled_frame
            table_type = 'edge'
        else:
            return  # Not on a rule table tab
        
        # Recreate the table entries with the new data
        self._create_rule_table_entries(scrollable_frame, table_type, table_data)
        
    def _randomize_specific_rule_table(self, table_name: str):
        """Randomize a specific rule table."""
        try:
            if table_name == 'state_rule_table':
                scrollable = getattr(self, 'state_table_scrollable', None)
                table_type = 'state'
            elif table_name == 'edge_rule_table':
                scrollable = getattr(self, 'edge_table_scrollable', None)
                table_type = 'edge'
            else:
                messagebox.showerror("Error", f"Invalid table name: {table_name}")
                return

            if scrollable is None:
                messagebox.showerror("Error", f"Scrollable frame for {table_name} not found.")
                return

            # Clear existing rows
            for row_key, (row_frame, _) in list(self.row_widgets.items()):
                row_frame.destroy()
            self.row_widgets.clear()

            # Generate new random table
            new_table = {}

            if table_type == 'state':
                new_table['default'] = random.choice([-1, 0, 1])
                # Update the default value in the UI
                self.default_var.set(str(new_table['default']))

                # Add a reasonable number of random rules (not all combinations)
                num_rules = random.randint(5, 20)
                for _ in range(num_rules):
                    current_state = random.choice(["-1", "0", "1"])
                    neighbor_pattern = ''.join(random.choice(['0', '1']) for _ in range(8))
                    connection_pattern = ''.join(random.choice(['0', '1']) for _ in range(8))
                    new_state = random.choice([-1, 0, 1])

                    key = f"({current_state}, {neighbor_pattern}, {connection_pattern})"
                    new_table[key] = new_state

            else:  # edge
                new_table['default'] = random.choice(["add", "remove", "maintain"])
                # Update the default value in the UI
                self.default_var.set(new_table['default'])

                # Add a reasonable number of random rules
                num_rules = random.randint(5, 20)
                for _ in range(num_rules):
                    self_state = random.choice(["0", "1"])
                    neighbor_state = random.choice(["0", "1"])
                    connection_pattern = ''.join(random.choice(['0', '1']) for _ in range(8))
                    action = random.choice(["add", "remove", "maintain"])

                    key = f"({self_state}, {neighbor_state}, {connection_pattern})"
                    new_table[key] = action

            # Update the table data and redraw
            # --- ADDED: Check if rule exists ---
            if hasattr(self, 'parent') and self.parent is not None and hasattr(self.parent, 'controller') and self.parent.controller and self.parent.controller.rule:
                self.parent.controller.rule.params[table_name] = new_table
                # --- REMOVED: Obsolete invalidate_cache call ---
                # self.parent.controller.rule.invalidate_cache()
                # ---
            else:
                logger.error("Cannot randomize rule table: Controller or rule is missing.")
                return
            # ---

            # Recreate the table entries
            self._create_rule_table_entries(scrollable.scrolled_frame, table_type, new_table)

            messagebox.showinfo("Success", f"{table_name} randomized successfully.")

        except Exception as e:
            logger.error(f"Error randomizing {table_name}: {e}")
            messagebox.showerror("Error", f"Failed to randomize {table_name}: {e}")

    def _add_all_rule_table_rows(self):
        """Add all possible rows to the rule table"""
        # Get the current tab index to determine which table to add rows to
        if self.notebook is not None:
            current_tab_index = self.notebook.index(self.notebook.select())
        
        if current_tab_index == 1:  # State rule table tab
            table_type = 'state'
            table_name = 'state_rule_table'
            scrollable = self.state_table_scrollable
        elif current_tab_index == 2:  # Edge rule table tab
            table_type = 'edge'
            table_name = 'edge_rule_table'
            scrollable = self.edge_table_scrollable
        else:
            return  # Not on a rule table tab
        
        # Get the current neighborhood type from the rule
        neighborhood_type_str = self.parent.controller.rule.get_param("neighborhood_type", "MOORE")
        dimension_type_str = self.parent.controller.rule.get_param("dimension_type", "TWO_D")
        
        # Calculate the neighborhood size based on neighborhood type and dimension
        neighborhood_size = 8  # Default for MOORE in 2D
        
        if neighborhood_type_str == "MOORE":
            if dimension_type_str == "TWO_D":
                neighborhood_size = 8
            elif dimension_type_str == "THREE_D":
                neighborhood_size = 26
            elif neighborhood_type_str == "HEX":
                neighborhood_size = 6
            elif dimension_type_str == "HEX_PRISM":
                neighborhood_size = 12
        
        elif neighborhood_type_str == "VON_NEUMANN":
            if dimension_type_str == "TWO_D":
                neighborhood_size = 4
            elif dimension_type_str == "THREE_D":
                neighborhood_size = 6
            elif neighborhood_type_str == "HEX":
                neighborhood_size = 6
            elif neighborhood_type_str == "HEX_PRISM":
                neighborhood_size = 12
        
        # Show warning if adding all rows would be too many
        if table_type == 'state':
            total_possible_rows = 3 * (2**neighborhood_size) * (2**neighborhood_size)
        else:  # edge
            total_possible_rows = 2 * 2 * (2**neighborhood_size)
            
        if total_possible_rows > 1000:
            if not messagebox.askyesno("Warning", 
                                    f"Adding all rows would create {total_possible_rows} entries, which may cause performance issues. Continue?",
                                    icon='warning'):
                return
            
        # Get existing keys to avoid duplicates
        existing_keys = set()
        for _, (_, entries) in self.row_widgets.items():
            if table_type == 'state':
                current_state = entries[0].get() if isinstance(entries[0], tk.Entry) else entries[0].get()
                neighbor_pattern = entries[1].get() if isinstance(entries[1], tk.Entry) else entries[1].get()
                connection_pattern = entries[2].get() if isinstance(entries[2], tk.Entry) else entries[2].get()
                key = f"({current_state}, {neighbor_pattern}, {connection_pattern})"
            else:  # edge
                self_state = entries[0].get() if isinstance(entries[0], tk.Entry) else entries[0].get()
                neighbor_state = entries[1].get() if isinstance(entries[1], tk.Entry) else entries[1].get()
                connection_pattern = entries[2].get() if isinstance(entries[2], tk.Entry) else entries[2].get()
                key = f"({self_state}, {neighbor_state}, {connection_pattern})"
            existing_keys.add(key)
        
        # Add rows in batches to avoid freezing the UI
        def add_batch(batch_size=50):
            batch_count = 0
            
            if table_type == 'state':
                for current_state in ["-1", "0", "1"]:
                    # Generate all possible neighbor patterns (limited to a reasonable number)
                    for neighbor_pattern in [''.join(p) for p in itertools.product('01', repeat=neighborhood_size)][:100]:
                        # Generate all possible connection patterns (limited to a reasonable number)
                        for connection_pattern in [''.join(p) for p in itertools.product('01', repeat=neighborhood_size)][:100]:
                            key = f"({current_state}, {neighbor_pattern}, {connection_pattern})"
                            if key not in existing_keys and key not in self.parent.controller.rule.params[table_name]:
                                self._add_rule_row(key, 0)  # Default new state is 0
                                existing_keys.add(key)
                                batch_count += 1
                                if batch_count >= batch_size:
                                    # Schedule next batch
                                    self.after(10, lambda: add_batch(batch_size))
                                    return
            else:  # edge
                for self_state in ["0", "1"]:
                    for neighbor_state in ["0", "1"]:
                        # Generate all possible connection patterns (limited to a reasonable number)
                        for connection_pattern in [''.join(p) for p in itertools.product('01', repeat=neighborhood_size)][:100]:
                            key = f"({self_state}, {neighbor_state}, {connection_pattern})"
                            if key not in existing_keys and key not in self.parent.controller.rule.params[table_name]:
                                self._add_rule_row(key, "maintain")  # Default action is maintain
                                existing_keys.add(key)
                                batch_count += 1
                                if batch_count >= batch_size:
                                    # Schedule next batch
                                    self.after(10, lambda: add_batch(batch_size))
                                    return
                
            # Update the table data after all batches are added
            self._update_rule_table_data()
        
        # Start adding batches
        add_batch()

    def _clear_rule_table_rows(self):
        """Clear all rows from the rule table, keeping the default value."""
        try:
            # Get the current tab index to determine which table to clear
            if self.notebook is not None:
                current_tab_index = self.notebook.index(self.notebook.select())
            else:
                logger.error("Notebook not found, cannot clear rule table.")
                return

            if current_tab_index == 1:  # State rule table tab
                table_type = 'state'
                table_name = 'state_rule_table'
                scrollable = getattr(self, 'state_table_scrollable', None)
            elif current_tab_index == 2:  # Edge rule table tab
                table_type = 'edge'
                table_name = 'edge_rule_table'
                scrollable = getattr(self, 'edge_table_scrollable', None)
            else:
                return  # Not on a rule table tab

            # Clear existing rows
            for row_key, (row_frame, _) in list(self.row_widgets.items()):
                row_frame.destroy()
            self.row_widgets.clear()

            # Create a new empty table, keeping the default
            new_table = {}
            if hasattr(self, 'default_var') and self.default_var is not None:
                default_value = self.default_var.get()
                if table_type == 'state':
                    try:
                        default_value = int(default_value)
                    except ValueError:
                        default_value = 0
                new_table['default'] = default_value
            else:
                # Set a reasonable default if default_var is missing
                new_table['default'] = 0 if table_type == 'state' else 'maintain'
                logger.warning("Default variable not found, using fallback default for rule table.")

            # Update the table data and redraw
            # --- ADDED: Check if rule exists ---
            if hasattr(self, 'parent') and self.parent is not None and hasattr(self.parent, 'controller') and self.parent.controller and self.parent.controller.rule:
                self.parent.controller.rule.params[table_name] = new_table
                # --- REMOVED: Obsolete invalidate_cache call ---
                # self.parent.controller.rule.invalidate_cache()
                # ---
            else:
                logger.error("Cannot clear rule table data: Controller or rule is missing.")
                return # Stop if rule cannot be updated
            # ---

            # Update visualization if running
            if hasattr(self.parent, 'running') and self.parent.running:
                self.parent._safe_plot_update()

        except Exception as e:
            logger.error(f"Error clearing rule table: {e}")
            messagebox.showerror("Error", f"Failed to clear rule table: {e}")

    def _delete_rule_table_rows(self):
        """Delete all rows from the rule table, including the default value."""
        try:
            # Get the current tab index to determine which table to delete
            if self.notebook is not None:
                current_tab_index = self.notebook.index(self.notebook.select())
            else:
                logger.error("Notebook not found, cannot delete rule table.")
                return

            if current_tab_index == 1:  # State rule table tab
                table_name = 'state_rule_table'
                scrollable = getattr(self, 'state_table_scrollable', None)
            elif current_tab_index == 2:  # Edge rule table tab
                table_name = 'edge_rule_table'
                scrollable = getattr(self, 'edge_table_scrollable', None)
            else:
                return  # Not on a rule table tab

            # Clear existing rows
            for row_key, (row_frame, _) in list(self.row_widgets.items()):
                row_frame.destroy()
            self.row_widgets.clear()

            # Create a new empty table
            new_table = {}

            # Update the table data and redraw
            # --- ADDED: Check if rule exists ---
            if hasattr(self, 'parent') and self.parent is not None and hasattr(self.parent, 'controller') and self.parent.controller and self.parent.controller.rule:
                self.parent.controller.rule.params[table_name] = new_table
                # --- REMOVED: Obsolete invalidate_cache call ---
                # self.parent.controller.rule.invalidate_cache()
                # ---
            else:
                logger.error("Cannot delete rule table data: Controller or rule is missing.")
                return # Stop if rule cannot be updated
            # ---

            # Update visualization if running
            if hasattr(self.parent, 'running') and self.parent.running:
                self.parent._safe_plot_update()

        except Exception as e:
            logger.error(f"Error deleting rule table: {e}")
            messagebox.showerror("Error", f"Failed to delete rule table: {e}")

    def _safe_update(self, update_func: Callable) -> bool:
        """Safely execute an update with error recovery"""
        if self._is_updating:
            return False
            
        self._is_updating = True
        self._error_state = False
        
        try:
            # Store current state before update
            self._previous_state = self.get_table_data()
            
            # Execute update
            update_func()
            
            # Update succeeded - store new state
            self._current_state = self.get_table_data()
            
            return True
            
        except Exception as e:
            logger.error(f"Error during table update: {e}")
            self._error_state = True
            
            # Attempt recovery
            try:
                self.set_table_data(self._previous_state)
                logger.info("Successfully recovered to previous state")
            except Exception as recovery_error:
                logger.error(f"Error during recovery: {recovery_error}")
                messagebox.showerror(
                    "Critical Error",
                    "Failed to recover from error. Please close and reopen the editor."
                )
            return False
            
        finally:
            self._is_updating = False

    def _create_rule_table_button_section(self, button_frame: tk.Frame, rule_name: str) -> tk.Frame:
        """Create button section for rule table tab"""
        # Left side buttons (editing controls)
        left_frame = tk.Frame(button_frame)
        left_frame.pack(side=tk.LEFT, fill=tk.X, expand=True)

        # Add Row button
        add_row_btn = tk.Button(left_frame, text="Add Row",
                            command=self._add_rule_row)
        add_row_btn.pack(side=tk.LEFT, padx=5)

        # Add All Rows button
        add_all_btn = tk.Button(left_frame, text="Add All Rows",
                            command=self._add_all_rule_table_rows)
        add_all_btn.pack(side=tk.LEFT, padx=5)

        # Clear All Rows button
        clear_all_btn = tk.Button(left_frame, text="Clear All Rows",
                                command=self._clear_rule_table_rows)
        clear_all_btn.pack(side=tk.LEFT, padx=5)

        # Delete All Rows button
        delete_all_btn = tk.Button(left_frame, text="Delete All Rows",
                                command=self._delete_rule_table_rows)
        delete_all_btn.pack(side=tk.LEFT, padx=5)

        # Right side buttons (save/close)
        right_frame = tk.Frame(button_frame)
        right_frame.pack(side=tk.RIGHT)

        save_btn = tk.Button(right_frame, text="Save",
                            command=lambda: self._save_rule_with_confirmation(rule_name, self._get_current_rule_data(), self))
        save_btn.pack(side=tk.LEFT, padx=5)

        close_btn = tk.Button(right_frame, text="Close",
                            command=lambda: self._on_rule_editor_close())
        close_btn.pack(side=tk.LEFT, padx=5)

        return button_frame

    def _create_parameter_button_section(self, button_frame: tk.Frame, rule_name: str) -> tk.Frame:
        """Create button section with apply, undo/redo and reset functionality for parameter tab"""
        # Left side buttons (editing controls)
        left_frame = tk.Frame(button_frame)
        left_frame.pack(side=tk.LEFT, fill=tk.X, expand=True)

        # --- ADDED: Apply Parameters Button ---
        apply_btn = tk.Button(left_frame, text="Apply Parameters",
                             command=self._apply_parameters)
        apply_btn.pack(side=tk.LEFT, padx=5)
        # ---

        # Undo button
        undo_btn = tk.Button(left_frame, text=" Undo",
                            command=lambda: self._undo_parameter_change(self.parameter_entries))
        undo_btn.pack(side=tk.LEFT, padx=5)

        # Redo button
        redo_btn = tk.Button(left_frame, text=" Redo",
                            command=lambda: self._redo_parameter_change(cast(Mapping[str, Union[tk.Entry, tk.OptionMenu, ttk.OptionMenu, ttk.Combobox, tk.Checkbutton, ttk.Checkbutton]], self.parameter_entries)))
        redo_btn.pack(side=tk.LEFT, padx=5)

        # Reset to Defaults button
        reset_btn = tk.Button(left_frame, text="Reset to Defaults",
                            command=lambda: self._reset_parameters_to_defaults(rule_name, self.parameter_entries))
        reset_btn.pack(side=tk.LEFT, padx=5)

        # Right side buttons (save/close)
        right_frame = tk.Frame(button_frame)
        right_frame.pack(side=tk.RIGHT)

        save_btn = tk.Button(right_frame, text="Save Rule", # Changed text for clarity
                            command=lambda: self._save_rule_with_confirmation(rule_name, self._get_current_rule_data(), self))
        save_btn.pack(side=tk.LEFT, padx=5)

        close_btn = tk.Button(right_frame, text="Close",
                            command=lambda: self._on_rule_editor_close())
        close_btn.pack(side=tk.LEFT, padx=5)

        # Store buttons for state updates
        self._editor_buttons = {
            'apply': apply_btn, # Added apply button
            'undo': undo_btn,
            'redo': redo_btn,
            'save': save_btn,
            'reset': reset_btn,
        }
        self._update_editor_buttons() # Initial state update

        return button_frame

    def _create_metadata_button_section(self, button_frame: tk.Frame, rule_name: str) -> tk.Frame:
        """Create button section with save/close functionality for metadata tab.
           (Round 8: Removed Regenerate JSON button)"""
        # Left side - empty spacer
        left_frame = tk.Frame(button_frame)
        left_frame.pack(side=tk.LEFT, fill=tk.X, expand=True)


        # Right side buttons (save/close) - These are now redundant
        right_frame = tk.Frame(button_frame)
        right_frame.pack(side=tk.RIGHT)

        return button_frame # Return empty frame for now

    def _apply_parameters(self):
        """
        Validates and applies ALL parameter values from the UI to the controller's rule,
        regardless of whether they have changed. Correctly detects colormap changes.
        Pauses the simulation if it's running during the update.
        Forces a redraw if parameters are applied while stopped or paused.
        Clears grid neighborhood cache on success. Provides feedback via the message bar.
        (Round 50: Force redraw if stopped/paused after apply)
        """
        log_prefix = f"RuleEditorWindow._apply_parameters (Rule: {self.rule_name} R50): " # Updated round
        logger.info(f"{log_prefix}Applying ALL parameter values from UI...")
        if not hasattr(self, 'parent') or not self.parent or not self.parent.controller or not self.parent.controller.rule:
            logger.error(f"{log_prefix}Parent GUI Controller or its rule not available.")
            self._show_message("Error: Controller or rule missing.", error=True)
            return

        target_rule = self.parent.controller.rule
        logger.info(f"{log_prefix}Targeting Rule Instance ID: {id(target_rule)} (Name: {target_rule.name})")

        was_running = self.parent.running
        was_paused = self.parent.paused
        was_stopped = self.parent._stopped # Check initial stopped state
        logger.debug(f"{log_prefix}State before apply: was_running={was_running}, was_paused={was_paused}, was_stopped={was_stopped}")

        # Pause if running continuously
        if was_running and not was_paused:
            logger.info(f"{log_prefix}Simulation is running, pausing for parameter update.")
            self.parent._pause_computation(reason="Apply Parameters")
        elif was_paused:
             logger.info(f"{log_prefix}Simulation was already paused, no need to pause again.")
        elif was_stopped:
             logger.info(f"{log_prefix}Simulation was stopped, no pause needed.")

        try:
            values_to_apply: Dict[str, Any] = {}
            tracker = self._get_change_tracker()
            original_state_data = tracker.original_state if tracker else {}
            if not original_state_data:
                logger.warning(f"{log_prefix}Change tracker original state not found, using current params as baseline for undo.")
                original_params = copy.deepcopy(target_rule.params)
            else:
                original_params = original_state_data.get('params', {})

            validation_failed = False
            failed_params_msgs: Dict[str, str] = {}

            # --- Phase 1: Validate all parameters and collect current values ---
            logger.debug(f"{log_prefix}Phase 1: Validating and collecting all parameters...")
            # [Validation logic remains the same as Round 45]
            for param_name, widget_info in self.parameter_entries.items():
                if param_name.endswith('_rule_table'): continue
                widget_to_check_state: Optional[tk.Widget] = None
                if isinstance(widget_info, tk.Widget): widget_to_check_state = widget_info
                elif isinstance(widget_info, dict) and 'entry' in widget_info: widget_to_check_state = widget_info['entry']
                widget_state = tk.DISABLED
                try:
                    if widget_to_check_state and widget_to_check_state.winfo_exists(): widget_state = widget_to_check_state.cget('state')
                    else: widget_state = tk.NORMAL
                except (AttributeError, tk.TclError): widget_state = tk.NORMAL
                if widget_state == tk.DISABLED:
                    if param_name in target_rule.params: values_to_apply[param_name] = target_rule.params[param_name]
                    continue
                value_str = ""; value_actual = None; is_color_picker = False
                if isinstance(widget_info, tk.Widget): widget_to_get_from = widget_info
                elif isinstance(widget_info, dict) and 'var' in widget_info and 'entry' in widget_info:
                    is_color_picker = True; color_var = widget_info.get('var')
                    if isinstance(color_var, tk.StringVar): value_str = color_var.get(); value_actual = value_str if value_str and value_str.startswith('#') else None
                    else: logger.warning(f"{log_prefix}Color picker for '{param_name}' has invalid 'var'."); continue
                else: logger.warning(f"{log_prefix}Unhandled item type for '{param_name}': {type(widget_info)}"); continue
                if not is_color_picker and widget_to_get_from:
                    if isinstance(widget_to_get_from, (tk.Entry, ValidatedEntry)): value_str = widget_to_get_from.get()
                    elif isinstance(widget_to_get_from, tk.OptionMenu): var_name = widget_to_get_from.cget('textvariable'); value_str = self.parent.root.globalgetvar(var_name) if var_name and self.parent.root else ""
                    elif isinstance(widget_to_get_from, ttk.Combobox): value_str = widget_to_get_from.get()
                    elif isinstance(widget_to_get_from, tk.Checkbutton):
                        var_name = widget_to_get_from.cget('variable')
                        if var_name: 
                            try: 
                                value_actual = bool(self.parent.root.globalgetvar(var_name)) 
                            except tk.TclError: value_actual = None
                        else: logger.warning(f"{log_prefix}No variable for Checkbutton '{param_name}'."); continue
                    else: logger.warning(f"{log_prefix}Unhandled widget type '{type(widget_to_get_from)}' for param '{param_name}'."); continue
                param_info = target_rule.PARAMETER_METADATA.get(param_name, {}); is_valid = True; error_msg = ""; new_value = None
                try:
                    if value_actual is not None: new_value = value_actual # Use pre-processed bool/color/None
                    else: new_value = self._convert_parameter_value(param_name, value_str)
                    if param_name in ('node_colormap', 'edge_colormap') and new_value == "(None)": new_value = None
                    if not target_rule._validate_parameter(param_name, new_value):
                        is_valid = False; error_msg = "Value is invalid (out of range or not allowed)."
                        try: self._convert_parameter_value(param_name, value_str)
                        except ValueError as ve: error_msg = str(ve)
                        except: pass
                except ValueError as e: is_valid = False; error_msg = str(e)
                except Exception as e: is_valid = False; error_msg = f"Unexpected validation error: {e}"; logger.error(f"{log_prefix}Unexpected error processing '{param_name}': {e}"); logger.error(traceback.format_exc())
                if is_valid: values_to_apply[param_name] = new_value; self._highlight_field(widget_info, True); self._remove_tooltip_widget_info(widget_info)
                else: validation_failed = True; failed_params_msgs[param_name] = error_msg; self._highlight_field(widget_info, False, error_msg)
            # --- End Validation ---

            if validation_failed:
                logger.error(f"{log_prefix}Validation failed. No changes applied.")
                error_list = "\n - ".join([f"{name}: {msg}" for name, msg in failed_params_msgs.items()])
                self._show_message(f"Validation Error:\n - {error_list}", error=True)
                # Resume only if it was running AND not paused initially
                if was_running and not was_paused:
                    logger.info(f"{log_prefix}Resuming simulation after validation failure.")
                    self.parent._resume_computation(reason="Apply Parameters Failed Validation")
                return

            # --- Phase 2: Apply collected values ---
            logger.info(f"{log_prefix}Applying {len(values_to_apply)} parameter values...")
            changes_applied_successfully = True
            parameters_actually_changed = False

            for param_name, new_value in values_to_apply.items():
                try:
                    current_controller_value = target_rule.params.get(param_name)
                    value_changed = False # Check if value actually changed
                    if isinstance(new_value, float) and isinstance(current_controller_value, (int, float)): value_changed = not np.isclose(new_value, float(current_controller_value))
                    elif isinstance(new_value, int) and isinstance(current_controller_value, (int, float)): value_changed = not np.isclose(float(new_value), float(current_controller_value))
                    elif isinstance(new_value, bool) and isinstance(current_controller_value, (int, bool)): value_changed = bool(new_value) != bool(current_controller_value)
                    else: value_changed = new_value != current_controller_value

                    if value_changed:
                        parameters_actually_changed = True
                        if tracker := self._get_change_tracker():
                            tracker.track_change('param', param_name, current_controller_value, new_value)
                        logger.debug(f"    Tracked change for {param_name}: {current_controller_value} -> {new_value}")

                    if target_rule.update_parameter(param_name, new_value): logger.debug(f"  Applied '{param_name}' = {target_rule.params[param_name]}")
                    else:
                        logger.error(f"{log_prefix}Rule's update_parameter failed for '{param_name}' with value '{new_value}'."); changes_applied_successfully = False
                        widget_info = self.parameter_entries.get(param_name);
                        if widget_info: self._highlight_field(widget_info, False, "Apply Failed")
                except Exception as apply_err: logger.error(f"{log_prefix}Error applying change for '{param_name}': {apply_err}"); changes_applied_successfully = False

            if changes_applied_successfully:
                self.parent.update_prep_params_from_rule() # Update prep thread params
                if self.parent.grid:
                    with self.parent.grid._cache_lock: self.parent.grid._neighborhood_data_cache.clear()
                    logger.info(f"{log_prefix}Cleared Grid neighborhood data cache after applying parameters.")
                else: logger.warning(f"{log_prefix}Grid not found, cannot clear neighborhood cache.")

                if tracker := self._get_change_tracker():
                    tracker.initialize(self._get_current_rule_data())
                    logger.debug(f"{log_prefix}Re-initialized change tracker original values with current state.")

                logger.info(f"{log_prefix}Parameters applied successfully.")
                self._show_message("Parameter Change Applied Successfully!", error=False)
                self._update_editor_buttons()

                # --- MODIFIED: Force redraw if stopped or paused ---
                # Check the state *after* applying parameters
                is_currently_stopped = self.parent._stopped
                is_currently_paused = self.parent.paused
                is_currently_running = self.parent.running

                if parameters_actually_changed and (is_currently_stopped or is_currently_paused):
                    logger.info(f"{log_prefix}Parameters changed and simulation stopped/paused. Forcing redraw.")
                    if hasattr(self.parent, '_safe_plot_update'):
                        self.parent._safe_plot_update(force=True)
                elif parameters_actually_changed and not is_currently_running:
                    # This covers the case where it was stopped before clicking Apply
                    logger.info(f"{log_prefix}Parameters changed and simulation was not running. Forcing redraw.")
                    if hasattr(self.parent, '_safe_plot_update'):
                        self.parent._safe_plot_update(force=True)
                elif parameters_actually_changed:
                    # If running, invalidate blit cache so next render picks up changes
                    logger.debug(f"{log_prefix}Parameters changed while running. Invalidating blit cache for next render.")
                    if hasattr(self.parent, 'grid_visualizer') and self.parent.grid_visualizer:
                        self.parent.grid_visualizer.blitting_manager.invalidate_cache()
                # --- END MODIFIED ---

            else:
                 self._show_message("Error applying some parameters. Check logs.", error=True)

        finally:
            # Resume only if it was running AND not paused initially
            if was_running and not was_paused:
                logger.info(f"{log_prefix}Resuming simulation after parameter application attempt (was running, not paused).")
                self.parent._resume_computation(reason="Apply Parameters Complete")
            elif was_paused:
                 logger.info(f"{log_prefix}Simulation was paused before apply, leaving it paused.")

    def _save_rule_changes(self):
        """Save the current rule data (parameters and metadata) to the library."""
        log_prefix = f"RuleEditorWindow._save_rule_changes (Rule: {self.rule_name}): "
        logger.info(f"{log_prefix}Attempting to save rule changes.")

        try:
            # Get current data from UI
            current_rule_data = self._get_current_rule_data()
            if not current_rule_data:
                logger.error(f"{log_prefix}Failed to get current rule data. Aborting save.")
                messagebox.showerror("Error", "Could not retrieve current rule data to save.", parent=self)
                return False

            # Validate rule tables before saving
            params = current_rule_data.get('params', {})
            if 'state_rule_table' in params:
                try:
                    self._validate_rule_table(params['state_rule_table'], 'state')
                except ValueError as e:
                    messagebox.showerror("Validation Error", f"Invalid State Rule Table:\n{e}", parent=self)
                    if self.notebook is not None:
                        if self.notebook is not None:
                            self.notebook.select(1) # Switch to rule table tab
                        else:
                            logger.error("Cannot switch to rule table tab: self.notebook is None")
                    else:
                        logger.error("Cannot switch to rule table tab: self.notebook is None")
                    return False
            if 'edge_rule_table' in params:
                try:
                    self._validate_rule_table(params['edge_rule_table'], 'edge')
                except ValueError as e:
                    messagebox.showerror("Validation Error", f"Invalid Edge Rule Table:\n{e}", parent=self)
                    if self.notebook is not None:
                        self.notebook.select(1) # Switch to rule table tab
                    return False

            # Save using RuleLibraryManager
            manager = RuleLibraryManager.get_instance()
            if manager.save_rule(self.rule_name, current_rule_data):
                logger.info(f"{log_prefix}Rule '{self.rule_name}' saved successfully via manager.")

                # --- REMOVED update_prep_params_from_rule call from here ---

                # Reset change tracker after successful save
                if tracker := self._get_change_tracker():
                    tracker.initialize(current_rule_data.get('params', {}))
                self._update_editor_buttons() # Update button states

                # Update the main GUI's rule instance selector (in case name/category changed)
                self.parent._update_rule_instance_selector()
                # Ensure the current rule remains selected in the main GUI dropdown
                self.parent.rule_instance_var.set(self.rule_name)

                messagebox.showinfo("Save Successful", f"Rule '{self.rule_name}' saved successfully.", parent=self)
                return True
            else:
                logger.error(f"{log_prefix}RuleLibraryManager failed to save rule '{self.rule_name}'.")
                messagebox.showerror("Save Error", f"Failed to save rule '{self.rule_name}'. Check logs.", parent=self)
                return False

        except Exception as e:
            logger.error(f"{log_prefix}Error saving rule changes: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Save Error", f"An unexpected error occurred while saving: {e}", parent=self)
            return False
           
    def _regenerate_json_file(self):
        """Regenerate the rules.json file using RuleLibraryManager."""
        try:
            RuleLibraryManager.get_instance().regenerate_library()
            messagebox.showinfo("Success", "Successfully regenerated rules.json file.")
        except Exception as e:
            logger.error(f"Error regenerating rules.json: {e}")
            messagebox.showerror("Error", f"Failed to regenerate rules.json: {e}")

    def _highlight_field(self, widget_info: Union[tk.Widget, Dict[str, Any]], is_valid: bool = True, error_msg: str = "") -> None:
        """Highlight a field based on validation status (yellow for valid, red for invalid).
           Handles both standard widgets and color picker dictionaries.
           (Round 7: Handle Union type for widget_info)"""
        widget: Optional[tk.Widget] = None
        widget_id: Optional[str] = None

        # --- Determine the actual widget and its ID ---
        if isinstance(widget_info, tk.Widget):
            widget = widget_info
            widget_id = str(widget)
        elif isinstance(widget_info, dict) and 'entry' in widget_info and isinstance(widget_info['entry'], tk.Widget):
            widget = widget_info['entry'] # Target the entry for highlighting
            widget_id = str(widget)
        else:
            logger.warning(f"Cannot highlight: Invalid widget_info type '{type(widget_info)}' or missing 'entry'.")
            return

        if widget is None or not widget.winfo_exists():
            logger.warning(f"Cannot highlight: Widget is None or destroyed (ID: {widget_id}).")
            return
        # ---

        # --- Check if widget supports direct background/foreground config ---
        can_configure_colors = isinstance(widget, (tk.Entry, ValidatedEntry, tk.Text))

        if is_valid:
            if can_configure_colors:
                if widget_id not in self._widget_attributes:
                    # Store original colors if not already stored
                    self._widget_attributes[widget_id] = {
                        'bg_original': widget.cget('background'),
                        'fg_original': widget.cget('foreground')
                    }
                # Restore original colors
                try:
                    widget.configure(background=self._widget_attributes[widget_id]['bg_original'], foreground=self._widget_attributes[widget_id]['fg_original'])
                except tk.TclError: pass # Ignore if widget destroyed during config
            # Always remove tooltip if valid
            self._remove_tooltip(widget) # Pass the actual widget
        else:
            # Highlight in red if possible
            if can_configure_colors:
                try:
                    widget.configure(background='#ffebeb', foreground='black')
                except tk.TclError: pass # Ignore if widget destroyed
            # Always show tooltip for invalid state
            self._set_tooltip(widget, error_msg) # Pass the actual widget

    def _set_tooltip(self, widget: tk.Widget, text: str) -> None:
        """Set tooltip text for widget"""
        widget_id = str(widget)
        if widget_id in self._tooltips:
            self._tooltips[widget_id].text = text
            self._tooltips[widget_id].showtip() # show the tip
        else:
            self._tooltips[widget_id] = ToolTip(widget, text)
            self._tooltips[widget_id].showtip() # show the tip after creation

    def _remove_tooltip(self, widget: tk.Widget) -> None:
        """Safely remove tooltip from a specific widget"""
        widget_id = str(widget)
        if widget_id in self._tooltips:
            try:
                tooltip = self._tooltips.pop(widget_id) # Remove and get
                tooltip.hidetip()
                # Optionally call destroy if ToolTip class requires it
                # tooltip.destroy()
            except Exception as e:
                 logger.warning(f"Error removing tooltip for widget {widget_id}: {e}")

    def _remove_tooltip_widget_info(self, widget_info: Union[tk.Widget, Dict[str, Any]]):
        """Helper to remove tooltip, handling the Union type."""
        widget: Optional[tk.Widget] = None
        if isinstance(widget_info, tk.Widget):
            widget = widget_info
        elif isinstance(widget_info, dict) and 'entry' in widget_info and isinstance(widget_info['entry'], tk.Widget):
            widget = widget_info['entry'] # Target the entry part of the color picker

        if widget:
            self._remove_tooltip(widget)
        else:
            logger.warning(f"Could not determine widget to remove tooltip from: {widget_info}")

    def _handle_entry_focus_in(self, event, widget: tk.Entry):
        """Handle focus in event for validated entry.
           (Round 11: Remove foreground color change)
           (Round 10: Ensure black text on focus)
           (Round 9: Keep original background, ensure black text)
           (Round 8: Removed background color change)"""
        # --- Keep original background ---
        # --- REMOVED: Foreground color change ---
        # widget['foreground'] = 'black'
        # ---
        pass # No visual change needed on focus in now

    def _handle_entry_focus_out(self, event, widget: tk.Entry, param_name: Optional[str],
                                column_index: Optional[int] = None, table_type: Optional[str] = None,
                                param_info: Optional[Dict[str, Any]] = None):
        """
        Handle focus out event. Validates parameters or rule table cells.
        Triggers rule-specific contextual validation via validate_parameter_context.
        (Round 7: Call validate_parameter_context correctly)
        """
        # --- Basic Widget Check ---
        if not widget or not widget.winfo_exists():
            logger.warning("FocusOut: Widget is None or destroyed. Aborting.")
            return
        # ---

        value_str = widget.get()
        log_prefix = f"FocusOut (Widget={widget}, param_name={param_name}, value='{value_str}' R7): "
        logger.debug(f"{log_prefix}Entering focus out handler.")

        is_rule_table_cell = table_type is not None and column_index is not None

        if is_rule_table_cell:
            # --- Rule Table Cell Validation & Update ---
            # [ Logic remains the same as Round 4 ]
            logger.debug(f"{log_prefix}Handling as Rule Table Cell")
            is_valid = False
            if table_type is not None and column_index is not None:
                is_valid = self._validate_rule_table_cell(table_type, column_index, value_str, widget)
            else:
                is_valid = False # Should not happen

            if is_valid:
                self._highlight_field(widget, True)
                self._remove_tooltip(widget)
                self._update_rule_table_data() # Update immediately for rule tables
            # Invalid highlighting is handled by _validate_rule_table_cell
            logger.debug(f"{log_prefix}End (Rule Table Cell): Valid={is_valid}")

        elif param_name is not None:
            # --- Parameter Field Validation ---
            logger.debug(f"{log_prefix}Handling as Parameter Field '{param_name}'.")

            # --- Check Controller and Rule ---
            if not hasattr(self, 'controller') or self.controller is None:
                logger.error(f"{log_prefix}Controller is None. Cannot validate parameter.")
                return
            current_rule = self.controller.rule
            if current_rule is None:
                logger.error(f"{log_prefix}Controller rule is None. Cannot validate parameter.")
                return
            # ---

            # --- Check param_info ---
            if param_info is None:
                # Attempt to retrieve it if missing (should have been passed by lambda)
                # Try dynamic first, then static
                dynamic_meta = None
                if hasattr(current_rule, 'get_dynamic_parameter_metadata'):
                    # Need to parse param_name to get base, metric, agg
                    parts = param_name.split('_')
                    base_name_parts = []
                    metric_part = None
                    agg_part = None
                    # Heuristic parsing (might need refinement for complex names)
                    if len(parts) > 2:
                        if parts[-1] in ["SUM", "AVG"]: agg_part = parts[-1]; metric_part = parts[-2]; base_name_parts = parts[:-2]
                        else: metric_part = parts[-1]; base_name_parts = parts[:-1]
                        base_name = "_".join(base_name_parts)
                        if base_name and metric_part:
                            dynamic_meta = current_rule.get_dynamic_parameter_metadata(base_name, metric_part, agg_part)
                if dynamic_meta:
                    param_info = dynamic_meta
                    logger.debug(f"{log_prefix}Retrieved dynamic param_info for '{param_name}'.")
                else: # Fallback to static
                    param_info = current_rule.PARAMETER_METADATA.get(param_name, {})
                    if not param_info:
                        logger.error(f"{log_prefix}param_info is None and not found in rule metadata for '{param_name}'. Cannot validate.")
                        return
                    else:
                        logger.warning(f"{log_prefix}param_info was None, retrieved static metadata.")
            # ---

            # --- Get Last Valid Value Safely ---
            last_valid_value_str = ''
            last_valid_value_raw = current_rule.params.get(param_name)
            default_val = param_info.get('default')
            last_valid_value_str = str(last_valid_value_raw if last_valid_value_raw is not None else default_val if default_val is not None else '')
            logger.debug(f"    Last Valid Value (str): '{last_valid_value_str}'")
            # ---

            # --- Perform Basic Validation ---
            is_valid = False
            error_msg = "Invalid value"
            try:
                is_valid = self._validate_entry_value(value_str, param_name, param_info, widget=None)
                if not is_valid:
                    try: self._convert_parameter_value(param_name, value_str)
                    except ValueError as ve: error_msg = str(ve)
                    except: error_msg = "Invalid format or out of range."
                logger.debug(f"    Basic Validation Result: {'Valid' if is_valid else 'Invalid'}")
            except Exception as e:
                is_valid = False; error_msg = f"Validation error: {e}"
                logger.error(f"    Unexpected basic validation error for {param_name}: {e}")
            # ---

            # --- Apply Highlighting and Trigger Update/Revert ---
            if is_valid:
                value_changed = (value_str != last_valid_value_str)
                logger.debug(f"    Change Check: New Str='{value_str}', Last Valid Str='{last_valid_value_str}', Changed={value_changed}")

                if value_changed:
                    logger.debug(f"    Value for {param_name} is VALID and CHANGED. Triggering update.")
                    update_success = self._on_parameter_change(param_name, tk.StringVar(value=value_str))
                    if update_success:
                        self._highlight_field(widget, True)
                        self._remove_tooltip(widget)

                        # --- MODIFIED: Call Rule's Contextual Validation ---
                        tracker = self._get_change_tracker()
                        if tracker and hasattr(tracker, 'current_state') and isinstance(tracker.current_state, dict):
                            current_params_for_check = tracker.current_state.get('params', {})
                            if isinstance(current_params_for_check, dict):
                                # Check if the method exists before calling
                                if hasattr(current_rule, 'validate_parameter_context') and callable(current_rule.validate_parameter_context):
                                    context_warning_msg = current_rule.validate_parameter_context(param_name, current_params_for_check)
                                    if context_warning_msg:
                                        messagebox.showwarning(
                                            "Potential Rule Conflict",
                                            f"Warning for Rule '{current_rule.name}':\n\n{context_warning_msg}\n\nCheck rule logic if behavior is unexpected.",
                                            parent=self
                                        )
                                        logger.warning(f"Rule '{current_rule.name}': Contextual validation warning for '{param_name}' - {context_warning_msg}")
                                else:
                                    logger.debug(f"{log_prefix}Rule instance does not have the 'validate_parameter_context' method.")
                            else:
                                logger.warning(f"{log_prefix}Change tracker 'params' is not a dictionary, cannot perform contextual validation.")
                        else:
                            logger.warning(f"{log_prefix}Change tracker not found or invalid, cannot perform contextual validation.")
                        # --- END MODIFIED ---

                    else: # Update failed
                        logger.error(f"    _on_parameter_change reported failure for {param_name}. Reverting widget.")
                        try:
                            if widget.winfo_exists():
                                widget.delete(0, tk.END); widget.insert(0, last_valid_value_str)
                                self._highlight_field(widget, False, "Update Failed")
                        except tk.TclError: logger.warning(f"{log_prefix}TclError reverting widget (likely destroyed).")
                else: # Value valid but unchanged
                    logger.debug(f"    Value for {param_name} is VALID but UNCHANGED. Clearing highlights.")
                    self._highlight_field(widget, True)
                    self._remove_tooltip(widget)
            else: # Value invalid
                logger.warning(f"    Invalid value '{value_str}' for {param_name}. Reverting to '{last_valid_value_str}'. Error: {error_msg}")
                try:
                    if widget.winfo_exists():
                        widget.delete(0, tk.END); widget.insert(0, last_valid_value_str)
                        self._highlight_field(widget, False, error_msg) # Highlight invalid field
                except tk.TclError: logger.warning(f"{log_prefix}TclError reverting widget (likely destroyed).")

            logger.debug(f"{log_prefix}End (Parameter Field): Valid={is_valid}")
            # --- END Parameter Field Validation ---
        else:
            logger.warning(f"{log_prefix}FocusOut event on unknown widget type or context.")

    def _process_focus_out(self, widget: tk.Entry, param_name: Optional[str],
                           column_index: Optional[int], table_type: Optional[str],
                           param_info: Optional[Dict[str, Any]] = None): # ADDED param_info argument with default
        """The actual validation and update logic, called after a short delay."""
        # --- Now get the value *after* the delay ---
        value_str = widget.get()
        logger.debug(f"--- Process FocusOut Start: Widget={widget}, param_name={param_name}, value='{value_str}' ---")

        is_valid = False
        error_msg = "Invalid value"

        is_rule_table_cell = table_type is not None and column_index is not None

        if is_rule_table_cell:
            # --- Rule Table Cell Validation ---
            logger.debug("Handling as Rule Table Cell")
            if table_type is not None and column_index is not None:
                is_valid = self._validate_rule_table_cell(table_type, column_index, value_str, widget)
            else:
                is_valid = False # Should not happen

            if is_valid:
                self._highlight_field(widget, True)
                self._remove_tooltip(widget)
                self._update_rule_table_data()
            # Invalid highlighting is handled by _validate_rule_table_cell
            logger.debug(f"--- Process FocusOut End (Rule Table Cell): Valid={is_valid} ---")

        elif param_name is not None:
            # --- Parameter Field Validation ---
            logger.debug(f"Handling as Parameter Field: {param_name}")
            # --- MODIFIED: Use the passed param_info ---
            if param_info is None:
                # Attempt to get it if not passed (should not happen with correct lambda)
                if hasattr(self, 'controller') and self.controller and hasattr(self.controller, 'rule') and self.controller.rule:
                    param_info = self.controller.rule.PARAMETER_METADATA.get(param_name, {})
                else:
                    param_info = {} # Fallback to empty dict
                logger.warning(f"param_info was None in _process_focus_out for '{param_name}', retrieved/defaulted.")
            # --- END MODIFIED ---

            last_valid_value_str = ''
            # Get last valid value safely
            if hasattr(self, 'controller') and self.controller and hasattr(self.controller, 'rule') and self.controller.rule:
                 last_valid_value_raw = self.controller.rule.params.get(param_name)
                 if last_valid_value_raw is not None:
                     last_valid_value_str = str(last_valid_value_raw)
                 else:
                     default_val = param_info.get('default')
                     last_valid_value_str = str(default_val) if default_val is not None else ''
                 logger.debug(f"    Last Valid Value (str): '{last_valid_value_str}'")
            else:
                 logger.error("    Controller/Rule not available to get param info/last value.")
                 last_valid_value_str = '' # Fallback

            # Step 1: Validate the entered string value's format and range
            param_type = param_info.get('type')
            if not value_str and param_type in [int, float]:
                is_valid = False
                error_msg = "Value cannot be empty."
                logger.debug(f"    Validation Result: Invalid (Empty numeric field)")
            else:
                try:
                    # Pass param_info to validation helper
                    is_valid = self._validate_entry_value(value_str, param_name, param_info, widget=None)
                    if not is_valid:
                        try: self._convert_parameter_value(param_name, value_str)
                        except ValueError as ve: error_msg = str(ve)
                        except: error_msg = "Invalid format or out of range."
                    logger.debug(f"    Validation Result: {'Valid' if is_valid else 'Invalid'} (Value: '{value_str}')")
                except Exception as e:
                    is_valid = False
                    error_msg = f"Validation error: {e}"
                    logger.error(f"    Unexpected validation error for {param_name}: {e}")

            # Step 2: Apply Highlighting and Trigger Update if Valid and Changed
            if is_valid:
                value_changed = (value_str != last_valid_value_str)
                logger.debug(f"    Change Check: New Str='{value_str}', Last Valid Str='{last_valid_value_str}', Changed={value_changed}")

                if value_changed:
                    logger.debug(f"    Value for {param_name} is VALID and CHANGED. Triggering update.")
                    update_success = self._on_parameter_change(param_name, tk.StringVar(value=value_str))
                    if update_success:
                        self._highlight_field(widget, True)
                        self._remove_tooltip(widget)
                    else:
                        logger.error(f"    _on_parameter_change reported failure for {param_name}. Reverting widget.")
                        widget.delete(0, tk.END)
                        widget.insert(0, last_valid_value_str)
                        self._highlight_field(widget, False, "Update Failed")
                else:
                    logger.debug(f"    Value for {param_name} is VALID but UNCHANGED. Clearing highlights.")
                    self._highlight_field(widget, True)
                    self._remove_tooltip(widget)
            else:
                logger.warning(f"    Invalid value '{value_str}' for {param_name}. Reverting to '{last_valid_value_str}'. Error: {error_msg}")
                widget.delete(0, tk.END)
                widget.insert(0, last_valid_value_str)
                self._highlight_field(widget, False, error_msg)

            logger.debug(f"--- Process FocusOut End (Parameter Field): Valid={is_valid} ---")

        else:
            logger.warning("FocusOut event on unknown widget type or context.")

    def _handle_entry_validation(self, event, param_name: str, param_info: Dict[str, Any], widget: tk.Entry):
        """Handle validation and update on entry events"""
        value = widget.get()

        try:
            # Get the rule class
            if self.controller and self.controller.rule:
                rule_class = self.controller.rule.__class__
            else:
                logger.error("Controller or rule is not available.")
                return

            # Get the parameter info from the rule class
            parameter_metadata = getattr(rule_class, 'PARAMETER_METADATA', {})

            # Get the appropriate validator function based on the column and table type
            if param_name not in parameter_metadata:
                logger.warning(f"No metadata found for parameter '{param_name}' in rule '{self.controller.rule.name}'.")
                return

            # Get the original value, defaulting to an empty string if not found
            original_value = self.controller.rule.params.get(param_name, '')

            if str(value) != str(original_value): # VALUE CHANGED
                if self._validate_entry_value(value, param_name, param_info, widget):
                    # Valid value - update parameter and highlight field
                    self._on_parameter_change(param_name, tk.StringVar(value=value))

                    # Store original colors in our dictionary
                    widget_id = str(widget)
                    self._widget_attributes[widget_id] = {
                        'bg_original': 'yellow',
                        'fg_original': 'black'
                    }

                    # Highlight field with yellow background and black text
                    widget["background"] = 'yellow'
                    widget["foreground"] = 'black'  # Always keep text black
                else:
                    # Invalid value - restore last valid value and highlight in light red
                    widget.delete(0, tk.END)
                    widget.insert(0, str(original_value))
                    widget["background"] = '#ffebeb'
                    widget["foreground"] = 'black'  # Always keep text black
                    self._set_tooltip(widget, "Invalid value") # Ensure tooltip is set for invalid input
            else: # VALUE NOT CHANGED - Don't change the background color
                # Only remove tooltip if value hasn't changed
                self._remove_tooltip(widget)
        except Exception as e:
            # Log error but don't crash
            logger.error(f"Error handling entry validation: {e}")
            messagebox.showerror("Error", f"Error handling entry validation: {e}")

    def _validate_entry_value(self, value: str, param_name: str, param_info: Dict[str, Any], widget: Optional[Union[tk.Entry, ValidatedEntry]] = None) -> bool:
        """Validate entry value based on parameter info. Returns True/False, NO HIGHLIGHTING."""
        try:
            is_valid = False
            # error_msg = "" # Error message generation moved to _apply_parameters

            param_type = param_info.get('type') if isinstance(param_info, dict) else None
            if param_type is None:
                # Fallback type detection (less reliable)
                current_value = None
                if self.controller and self.controller.rule:
                    current_value = self.controller.rule.params.get(param_name)
                param_type = type(current_value) if current_value is not None else str
                logger.warning(f"Parameter '{param_name}' not in PARAMETER_METADATA. Inferring type as {param_type}.")

            # --- MODIFIED: Skip validation for OptionMenu and Combobox widgets ---
            if isinstance(widget, tk.OptionMenu) or isinstance(widget, ttk.Combobox):
                logger.debug(f"Skipping validation for OptionMenu '{param_name}'. Assuming valid selection.")
                return True
            # ---

            # --- Validation Logic (No Highlighting) ---
            if not value and param_type in [int, float]:
                is_valid = False # Empty numeric is invalid on apply
            elif param_type == float:
                try:
                    val = float(value)
                    min_val = param_info.get('min'); max_val = param_info.get('max')
                    if (min_val is None or val >= min_val) and (max_val is None or val <= max_val): is_valid = True
                except ValueError: is_valid = False
            elif param_type == int:
                if value in ["-", "+", ""]: is_valid = False # Invalid if empty or just sign on apply
                else:
                    try:
                        val = int(float(value)) # Allow float strings like "5.0"
                        min_val = param_info.get('min'); max_val = param_info.get('max')
                        if (min_val is None or val >= min_val) and (max_val is None or val <= max_val): is_valid = True
                    except ValueError: is_valid = False
            elif param_type == bool:
                is_valid = value.lower() in ('true', 'false', '1', '0', 'yes', 'no', 'on', 'off') # Empty string is invalid bool
            elif param_type == list:
                 try:
                     parsed_value = ast.literal_eval(value)
                     if isinstance(parsed_value, list): is_valid = True
                     else: # Try comma-separated
                         parts = [x.strip() for x in value.split(',') if x.strip()]
                         is_valid = True
                 except (ValueError, SyntaxError, TypeError):
                     try: # Fallback comma split
                         parts = [x.strip() for x in value.split(',') if x.strip()]
                         is_valid = True
                     except: is_valid = False
            elif param_type == tuple:
                 try:
                     parsed_value = ast.literal_eval(value)
                     is_valid = isinstance(parsed_value, tuple)
                 except (ValueError, SyntaxError, TypeError): is_valid = False
            # --- MODIFIED: Allow "None" for string with allowed_values, specifically for colormaps ---
            elif param_type == str:
                allowed = param_info.get('allowed_values') if isinstance(param_info, dict) else None
                if allowed:
                    if param_name in ('node_colormap', 'edge_colormap') and value == "(None)":
                        is_valid = True  # Allow "(None)" for colormaps
                    else:
                        is_valid = value in allowed  # Check if the exact string is in the allowed list
                else:
                    is_valid = True # Allow any string if no allowed_values specified
            # --- END MODIFIED ---
            else: # Default to valid for other types
                is_valid = True

            # --- REMOVED Highlighting ---

            return is_valid

        except Exception as e:
            logger.error(f"Error validating entry value for '{param_name}': {e}")
            return False
         
    def _on_parameter_change(self, param_name: str, var: Union[tk.StringVar, tk.BooleanVar]):
        """
        Handles changes to parameters, including conversion and validation.
        Tracks changes using ChangeTracker. Updates button states.
        (Round 21: Add _is_recreating_tab guard)
        """
        # --- ADDED: Guard against execution during recreation ---
        if hasattr(self, '_is_recreating_tab') and self._is_recreating_tab:
            logger.debug(f"_on_parameter_change: Skipping for '{param_name}' because tab is recreating.")
            return False # Indicate no action taken
        # ---

        log_prefix = f"_on_parameter_change: START for {param_name} ---"
        logger.debug(log_prefix)

        current_value = None
        if tracker := self._get_change_tracker():
            current_value = tracker.current_state.get('params', {}).get(param_name)
        logger.debug(f"    Current tracked value for {param_name}: {current_value} (type: {type(current_value)})")

        try:
            new_value = None
            value_str = "" # For logging/reverting entry

            if isinstance(var, tk.BooleanVar):
                new_value = var.get()
                value_str = str(new_value)
                logger.debug(f"    Got boolean value directly from BooleanVar: {new_value}")
            elif isinstance(var, tk.StringVar):
                value_str = var.get()
                logger.debug(f"    Got string value from StringVar: '{value_str}'")
                new_value = self._convert_parameter_value(param_name, value_str)
                logger.debug(f"    Converted string value for {param_name}: {new_value} (type: {type(new_value)})")
            else:
                logger.error(f"    Unhandled variable type: {type(var)}")
                return False

            if new_value != current_value:
                if tracker := self._get_change_tracker():
                    tracker.track_change('param', param_name, current_value, new_value)
                    logger.debug(f"    Tracked change for param '{param_name}': {current_value} -> {new_value}")
                else:
                    logger.warning("    Change tracker not found, cannot track change.")
                self._update_editor_buttons()
                return True
            else:
                logger.debug(f"    No change for {param_name}, skipping tracking.")
                return True

        except ValueError as e:
            logger.error(f"    Invalid value or conversion error for parameter {param_name}: {e}")
            self._show_message(f"Invalid value for {param_name}: {e}", error=True)
            widget_info = self.parameter_entries.get(param_name)
            widget = widget_info if isinstance(widget_info, tk.Widget) else (widget_info.get('entry') if isinstance(widget_info, dict) else None)

            if tracker := self._get_change_tracker():
                revert_value = tracker.current_state.get('params', {}).get(param_name)
                if isinstance(widget, tk.Entry):
                    widget.delete(0, tk.END); widget.insert(0, str(revert_value) if revert_value is not None else "")
                elif isinstance(var, tk.StringVar):
                    var.set(str(revert_value) if revert_value is not None else "")
                elif isinstance(var, tk.BooleanVar):
                    revert_bool = False
                    if isinstance(revert_value, bool): revert_bool = revert_value
                    elif isinstance(revert_value, (str, int)): revert_bool = str(revert_value).lower() in ('true', '1', 'yes', 'on')
                    var.set(revert_bool)
                logger.debug(f"    Reverting UI widget for {param_name} to tracked value '{revert_value}'")
            else:
                 logger.warning("    Cannot revert UI: Change tracker not found.")
            logger.debug(f"--- _on_parameter_change: END (Validation Error) for {param_name} ---")
            return False
        except Exception as e:
            logger.error(f"    Unexpected error for parameter {param_name}: {e}")
            logger.error(traceback.format_exc())
            self._show_message(f"Unexpected error for {param_name}: {e}", error=True)
            if tracker := self._get_change_tracker():
                revert_value = tracker.current_state.get('params', {}).get(param_name)
                if isinstance(var, tk.StringVar): var.set(str(revert_value) if revert_value is not None else "")
                elif isinstance(var, tk.BooleanVar):
                    revert_bool = False
                    if isinstance(revert_value, bool): revert_bool = revert_value
                    elif isinstance(revert_value, (str, int)): revert_bool = str(revert_value).lower() in ('true', '1', 'yes', 'on')
                    var.set(revert_bool)
            logger.debug(f"--- _on_parameter_change: END (Exception) for {param_name} ---")
            return False
           
    def _on_edge_coloring_mode_change(self, *args):
        """Callback when the edge_coloring_mode dropdown changes.
           Enables/disables related edge visualization widgets.
           (Round 21: Add _is_recreating_tab guard)"""
        # --- ADDED: Guard against execution during recreation ---
        if hasattr(self, '_is_recreating_tab') and self._is_recreating_tab:
            logger.debug("_on_edge_coloring_mode_change: Skipping because tab is recreating.")
            return
        # ---
        log_prefix = f"RuleEditorWindow._on_edge_coloring_mode_change (Rule: {self.rule_name} R10): " # Updated round
        logger.debug(f"{log_prefix}Callback triggered.")

        # Get the selected mode
        selected_mode = ""
        # --- MODIFIED: Get value from stored variable ---
        mode_var = self._viz_vars.get('edge_coloring_mode')
        if isinstance(mode_var, tk.StringVar):
            selected_mode = mode_var.get()
        # ---
        logger.debug(f"{log_prefix}Selected mode: '{selected_mode}'")

        # Determine the state for dependent widgets
        new_state = tk.NORMAL if selected_mode != "Default" else tk.DISABLED

        # Update dependent widgets
        widgets_to_toggle = [
            'use_state_coloring_edges',
            'edge_colormap',
            'edge_color_norm_vmin',
            'edge_color_norm_vmax'
        ]

        for param_name in widgets_to_toggle:
            widget = self.parameter_entries.get(param_name)
            if isinstance(widget, (tk.Checkbutton, ttk.Combobox, tk.Entry, ValidatedEntry)):
                try:
                    if widget.winfo_exists():
                        widget.config(state=new_state)
                        logger.debug(f"{log_prefix}Set state of '{param_name}' to {new_state}")
                except tk.TclError:
                    logger.warning(f"{log_prefix}TclError configuring widget '{param_name}' (likely destroyed).")
            elif isinstance(widget, dict) and param_name.endswith('_color'): # Handle color picker dict
                 for sub_widget_key, sub_widget in widget.items():
                     if sub_widget_key != 'var' and isinstance(sub_widget, (tk.Entry, tk.Canvas, tk.Button)):
                         try:
                             if sub_widget.winfo_exists(): sub_widget.config(state=new_state)
                         except tk.TclError: pass
                 logger.debug(f"{log_prefix}Set state of color picker '{param_name}' components to {new_state}")
            elif widget is not None:
                logger.warning(f"{log_prefix}Widget for '{param_name}' is of unexpected type: {type(widget)}")

        # --- Optionally reset vmin/vmax to defaults when switching modes ---
        # [ Logic remains the same ]
        if selected_mode != "Default":
            if self.controller and self.controller.rule:
                rule = self.controller.rule
                vmin_entry = self.parameter_entries.get('edge_color_norm_vmin')
                vmax_entry = self.parameter_entries.get('edge_color_norm_vmax')
                vmin_default = rule.PARAMETER_METADATA.get('edge_color_norm_vmin', {}).get('default', 0.0)
                vmax_default = rule.PARAMETER_METADATA.get('edge_color_norm_vmax', {}).get('default', 1.0)

                # Update defaults based on mode if necessary (e.g., DegreeSum)
                if selected_mode == 'DegreeSum':
                    vmax_default = rule.PARAMETER_METADATA.get('edge_color_norm_vmax', {}).get('default', 16.0) # Use DegreeSum default
                elif selected_mode == 'ActiveNeighbors':
                     vmax_default = rule.PARAMETER_METADATA.get('edge_color_norm_vmax', {}).get('default', 8.0) # Use ActiveNeighbors default

                if isinstance(vmin_entry, tk.Entry) and not vmin_entry.get(): # Only set if empty
                    vmin_entry.delete(0, tk.END); vmin_entry.insert(0, str(vmin_default))
                    logger.debug(f"{log_prefix}Set vmin entry to default: {vmin_default}")
                if isinstance(vmax_entry, tk.Entry) and not vmax_entry.get(): # Only set if empty
                    vmax_entry.delete(0, tk.END); vmax_entry.insert(0, str(vmax_default))
                    logger.debug(f"{log_prefix}Set vmax entry to default: {vmax_default}")

        logger.debug(f"{log_prefix}Finished updating dependent widget states.")

    def _on_node_coloring_mode_change(self, *args):
        """Callback when any node coloring checkbox changes.
           Enables/disables related node visualization widgets.
           (Round 21: Add _is_recreating_tab guard)"""
        # --- ADDED: Guard against execution during recreation ---
        if hasattr(self, '_is_recreating_tab') and self._is_recreating_tab:
            logger.debug("_on_node_coloring_mode_change: Skipping because tab is recreating.")
            return
        # ---
        log_prefix = f"RuleEditorWindow._on_node_coloring_mode_change (Rule: {self.rule_name} R10): " # Updated round
        logger.debug(f"{log_prefix}Callback triggered.")

        # Determine the active coloring mode based on checkboxes
        use_state = False; use_degree = False; use_neighbors = False

        # --- MODIFIED: Get values from stored variables ---
        if state_var := self._viz_vars.get('use_state_coloring'):
            if isinstance(state_var, tk.BooleanVar): use_state = state_var.get()
        if degree_var := self._viz_vars.get('color_nodes_by_degree'):
            if isinstance(degree_var, tk.BooleanVar): use_degree = degree_var.get()
        if neighbors_var := self._viz_vars.get('color_nodes_by_active_neighbors'):
            if isinstance(neighbors_var, tk.BooleanVar): use_neighbors = neighbors_var.get()
        # ---

        # Determine if *any* state-based coloring is active
        is_state_coloring_active = use_state or use_degree or use_neighbors
        logger.debug(f"{log_prefix}State coloring active flags: State={use_state}, Degree={use_degree}, Neighbors={use_neighbors} -> Active={is_state_coloring_active}")

        # Determine the state for dependent widgets
        new_state = tk.NORMAL if is_state_coloring_active else tk.DISABLED

        # Update dependent widgets
        widgets_to_toggle = [
            'node_colormap',
            'node_color_norm_vmin',
            'node_color_norm_vmax'
        ]

        for param_name in widgets_to_toggle:
            widget = self.parameter_entries.get(param_name)
            if isinstance(widget, (ttk.Combobox, tk.Entry, ValidatedEntry)): # Check for Combobox too
                try:
                    if widget.winfo_exists():
                        widget.config(state=new_state)
                        logger.debug(f"{log_prefix}Set state of '{param_name}' to {new_state}")
                except tk.TclError:
                    logger.warning(f"{log_prefix}TclError configuring widget '{param_name}' (likely destroyed).")
            elif widget is not None:
                logger.warning(f"{log_prefix}Widget for '{param_name}' is of unexpected type: {type(widget)}")

        # --- Optionally reset vmin/vmax to defaults when switching modes ---
        if is_state_coloring_active:
            if self.controller and self.controller.rule:
                rule = self.controller.rule
                vmin_entry = self.parameter_entries.get('node_color_norm_vmin')
                vmax_entry = self.parameter_entries.get('node_color_norm_vmax')
                vmin_default = rule.PARAMETER_METADATA.get('node_color_norm_vmin', {}).get('default', 0.0)
                vmax_default = rule.PARAMETER_METADATA.get('node_color_norm_vmax', {}).get('default', 1.0)

                # Update defaults based on active mode if necessary
                if use_state: # Use rule's state range
                    vmin_default = getattr(rule, 'min_node_state', 0.0)
                    vmax_default = getattr(rule, 'max_node_state', 1.0)
                elif use_degree or use_neighbors: # Use degree/neighbor count defaults
                    vmax_default = rule.PARAMETER_METADATA.get('node_color_norm_vmax', {}).get('default', 8.0)

                if isinstance(vmin_entry, tk.Entry) and not vmin_entry.get(): # Only set if empty
                    vmin_entry.delete(0, tk.END); vmin_entry.insert(0, str(vmin_default))
                    logger.debug(f"{log_prefix}Set vmin entry to default: {vmin_default}")
                if isinstance(vmax_entry, tk.Entry) and not vmax_entry.get(): # Only set if empty
                    vmax_entry.delete(0, tk.END); vmax_entry.insert(0, str(vmax_default))
                    logger.debug(f"{log_prefix}Set vmax entry to default: {vmax_default}")

        logger.debug(f"{log_prefix}Finished updating dependent node widget states.")

    def _on_favorite_change(self):
        """Callback when the favorite checkbox state changes."""
        # This is primarily for tracking the change immediately if needed.
        # The actual value is read during _get_current_rule_data.
        if tracker := self._get_change_tracker():
            old_value = tracker.current_state.get('favorite', False)
            new_value = self.favorite_var.get()
            if old_value != new_value:
                tracker.track_change('meta', 'favorite', old_value, new_value)
                self._update_editor_buttons() # Update button states (e.g., if Save depends on modified)
        logger.debug(f"Favorite checkbox changed to: {self.favorite_var.get()}")

    def _get_change_tracker(self) -> Optional[ChangeTracker]:
        """Get the change tracker for this window"""
        return self.change_tracker

    def _update_editor_buttons(self):
        """Update the state of the editor buttons (undo/redo/save/delete) based on change tracker and rule type, manually setting foreground color. Save and Apply buttons are always enabled. Checks widget existence.
           (Round 9: Handle Checkbutton type for 'favorite')
           (Round 1: Always enable Save and Apply)"""
        if not hasattr(self, '_editor_buttons') or not self.winfo_exists():
            logger.warning("_update_editor_buttons called but editor window or buttons dict doesn't exist.")
            return

        tracker = self._get_change_tracker()
        can_undo = tracker.can_undo() if tracker else False
        can_redo = tracker.can_redo() if tracker else False

        is_default = False
        try:
            if hasattr(self, 'rule_name') and self.rule_name:
                rule_data = RuleLibraryManager.get_rule(self.rule_name)
                is_default = (self.rule_name in RuleLibrary.RULES) or ('default' in rule_data.get('tags', []))
            else:
                logger.warning("Rule name not available in editor, cannot determine if default.")
        except ValueError: logger.warning(f"Could not find rule '{getattr(self, 'rule_name', 'N/A')}' to check if default.")
        except Exception as e: logger.error(f"Error checking if rule is default: {e}")

        def set_button_state(button_key, enabled):
            if button_key in self._editor_buttons:
                widget = self._editor_buttons[button_key] # Use generic 'widget' name
                # --- MODIFIED: Check for Button OR Checkbutton ---
                if isinstance(widget, (tk.Button, tk.Checkbutton)) and widget.winfo_exists():
                # ---
                    new_state = tk.NORMAL if enabled else tk.DISABLED
                    new_fg = 'black' if enabled else 'grey50'
                    try:
                        # --- MODIFIED: Only set relief for Buttons ---
                        if isinstance(widget, tk.Button):
                            new_relief = tk.RAISED if enabled else tk.FLAT
                            widget.config(state=new_state, relief=new_relief, fg=new_fg)
                        else: # Checkbutton
                            widget.config(state=new_state, fg=new_fg) # Don't set relief for Checkbutton
                        # ---
                    except tk.TclError as e:
                        logger.warning(f"TclError configuring widget '{button_key}' (likely destroyed): {e}")
                elif not isinstance(widget, (tk.Button, tk.Checkbutton)):
                     logger.warning(f"Widget for button key '{button_key}' is not a tk.Button or tk.Checkbutton.")

        set_button_state('undo', can_undo)
        set_button_state('redo', can_redo)
        set_button_state('save', True) # Always enabled
        set_button_state('delete', not is_default)
        set_button_state('apply', True) # Always enabled
        set_button_state('reset', True)
        set_button_state('close', True)
        # --- ADDED: Handle favorite checkbox state (always enabled) ---
        set_button_state('favorite', True)
        # ---

    def _undo_parameter_change(self, parameter_entries: Mapping[str, Union[tk.Widget, Dict[str, Any]]]):
        """Handle undo button click for editor changes.
           (Round 4: Update parameter_entries type hint)"""
        log_prefix = "RuleEditorWindow._undo_parameter_change: "
        logger.debug(f"{log_prefix}Undo requested.")
        try:
            if tracker := self._get_change_tracker():
                change = tracker.undo()
            else:
                logger.warning(f"{log_prefix}Change tracker not found.")
                change = None

            if change:
                field_type = change['field_type']
                name = change['name']
                old_value = change['old']
                logger.info(f"{log_prefix}Undoing change to {field_type} '{name}' back to value: {old_value}")

                # --- Update UI based on field_type ---
                if field_type == 'param':
                    widget_info = parameter_entries.get(name) # Use the passed mapping
                    if widget_info:
                        widget = widget_info if isinstance(widget_info, tk.Widget) else widget_info.get('entry')
                        if widget:
                            self._update_widget_value(widget, old_value) # Pass the actual widget
                        # Highlight/tooltip clear needs the actual widget
                        widget = widget_info if isinstance(widget_info, tk.Widget) else widget_info.get('entry')
                        if widget:
                            self._highlight_field(widget, True)
                            self._remove_tooltip(widget)
                    else: logger.warning(f"{log_prefix}Widget info for parameter '{name}' not found.")
                elif field_type == 'meta':
                    widget = self.metadata_fields.get(name)
                    if widget:
                        self._update_widget_value(widget, old_value)
                    else: logger.warning(f"{log_prefix}Widget for metadata '{name}' not found.")
                elif field_type == 'table':
                    logger.debug(f"{log_prefix}Recreating rule table tab after undo.")
                    if tracker is not None:
                        self._recreate_rule_table_tab_content(tracker.get_current_state())
                    else:
                        logger.warning("Tracker is None. Cannot recreate rule table tab content.")
                else:
                    logger.warning(f"{log_prefix}Unknown field_type '{field_type}' during undo UI update.")

                # Update button states
                self._update_editor_buttons()
            else:
                logger.debug(f"{log_prefix}Nothing to undo.")

        except Exception as e:
            logger.error(f"{log_prefix}Error during undo: {e}")
            logger.error(traceback.format_exc())
            self._show_message(f"Failed to undo change: {e}", error=True)

    def _redo_parameter_change(self, parameter_entries: Mapping[str, Union[tk.Widget, Dict[str, Any]]]):
        """Handle redo button click for editor changes.
           (Round 4: Update parameter_entries type hint)"""
        log_prefix = "RuleEditorWindow._redo_parameter_change: "
        logger.debug(f"{log_prefix}Redo requested.")
        try:
            if tracker := self._get_change_tracker():
                change = tracker.redo()
            else:
                logger.warning(f"{log_prefix}Change tracker not found.")
                change = None

            if change:
                field_type = change['field_type']
                name = change['name']
                new_value = change['new']
                logger.info(f"{log_prefix}Redoing change to {field_type} '{name}' to value: {new_value}")

                # --- Update UI based on field_type ---
                if field_type == 'param':
                    widget_info = parameter_entries.get(name) # Use the passed mapping
                    if widget_info:
                        widget = widget_info if isinstance(widget_info, tk.Widget) else widget_info.get('entry')
                        if widget:
                            self._update_widget_value(widget, new_value) # Pass the actual widget
                        # Highlight/tooltip clear needs the actual widget
                        widget = widget_info if isinstance(widget_info, tk.Widget) else widget_info.get('entry')
                        if widget:
                            self._highlight_field(widget, True)
                            self._remove_tooltip(widget)
                    else: logger.warning(f"{log_prefix}Widget info for parameter '{name}' not found.")
                elif field_type == 'meta':
                    widget = self.metadata_fields.get(name)
                    if widget:
                        self._update_widget_value(widget, new_value)
                    else: logger.warning(f"{log_prefix}Widget for metadata '{name}' not found.")
                elif field_type == 'table':
                    logger.debug(f"{log_prefix}Recreating rule table tab after redo.")
                    if tracker is not None:
                        self._recreate_rule_table_tab_content(tracker.get_current_state())
                    else:
                        logger.warning("Tracker is None. Cannot recreate rule table tab content.")
                else:
                    logger.warning(f"{log_prefix}Unknown field_type '{field_type}' during redo UI update.")

                # Update button states
                self._update_editor_buttons()
            else:
                logger.debug(f"{log_prefix}Nothing to redo.")

        except Exception as e:
            logger.error(f"{log_prefix}Error during redo: {e}")
            logger.error(traceback.format_exc())
            self._show_message(f"Failed to redo change: {e}", error=True)

    def _reset_parameters_to_defaults(self, rule_name: str, parameter_entries: Mapping[str, Union[tk.Widget, Dict[str, Any]]]):
        """Reset parameters and metadata in the editor to their default values
           as defined in the rule's JSON file.
           (Round 46: Load defaults from specific rule JSON)"""
        log_prefix = "RuleEditorWindow._reset_parameters_to_defaults (R46 JSON Defaults): " # Updated round
        logger.info(f"{log_prefix}Resetting editor fields to JSON defaults for rule '{rule_name}'.")
        try:
            if not messagebox.askyesno("Confirm Reset",
                                    "Reset all fields in this editor (Parameters, Visualization, Info) to their saved default values?\nUnsaved changes will be lost.",
                                    parent=self):
                logger.debug(f"{log_prefix}User cancelled reset.")
                return

            # --- Get Default Rule Data FROM LIBRARY MANAGER (JSON) ---
            default_rule_data = {}
            try:
                # Load the specific rule data as stored in the library
                default_rule_data = RuleLibraryManager.get_rule(rule_name)
                logger.debug(f"{log_prefix}Successfully loaded default data for '{rule_name}' from library.")
            except Exception as e:
                logger.error(f"{log_prefix}Failed to get default rule data from library: {e}")
                messagebox.showerror("Error", f"Could not retrieve default data for rule '{rule_name}'.", parent=self)
                return
            # ---

            # --- Reset Change Tracker and Update UI ---
            if tracker := self._get_change_tracker():
                # Initialize tracker with the data loaded from JSON
                tracker.initialize(copy.deepcopy(default_rule_data))
                logger.debug(f"{log_prefix}Change tracker re-initialized with JSON defaults.")
            else:
                logger.warning(f"{log_prefix}Change tracker not found, cannot reset.")

            # Update UI elements on ALL tabs using the loaded JSON data
            # --- MODIFIED: Pass the loaded default_rule_data ---
            self._set_tab_widget_values(self.parameter_entries, default_rule_data.get('params', {}))
            self._set_tab_widget_values(self.metadata_fields, default_rule_data) # Pass full dict for metadata
            # Recreate rule table using the default data from JSON
            self._recreate_rule_table_tab_content(default_rule_data)
            # Recreate visualization tab using the default data from JSON
            self._recreate_visualization_tab_content(default_rule_data)
            # --- END MODIFIED ---

            self._update_editor_buttons()
            self._show_message("Editor fields reset to saved default values.", error=False)
            logger.info(f"{log_prefix}Editor reset to JSON defaults.")

        except Exception as e:
            logger.error(f"{log_prefix}Error resetting parameters: {e}")
            logger.error(traceback.format_exc())
            self._show_message(f"Failed to reset parameters: {e}", error=True)

    def _randomize_parameters(self, parameter_entries: Mapping[str, Union[tk.Entry, tk.OptionMenu]]):
        """Randomize all parameters in the rule"""
        try:
            if messagebox.askyesno("Confirm Randomize",
                                    "Are you sure you want to randomize all parameters?"):
                # Get the maximum number of neighbors for the current neighborhood type
                if self.parent.controller.grid is not None:
                    max_neighbors = self.parent.controller.grid._calculate_max_neighbors()
                else:
                    max_neighbors = 0  # Default value or handle the case appropriately

                # --- ADDED: Check if rule exists before accessing metadata ---
                if not (self.parent.controller and self.parent.controller.rule):
                    logger.error("Cannot randomize parameters: Controller or rule is missing.")
                    return
                # ---

                # Iterate through parameters defined in PARAMETER_METADATA
                for param_name, param_info in self.parent.controller.rule.PARAMETER_METADATA.items():
                    if param_name == 'initial_conditions':
                        continue  # Skip initial conditions

                    # Generate a random value based on parameter type
                    if param_name.endswith('_rule_table'):
                        # Handle rule tables separately
                        if param_name == 'state_rule_table':
                            self._randomize_specific_rule_table('state_rule_table')
                        elif param_name == 'edge_rule_table':
                            self._randomize_specific_rule_table('edge_rule_table')
                        continue # Skip to the next parameter

                    elif param_info['type'] == float:
                        min_val = param_info.get('min', 0.0)
                        max_val = param_info.get('max', 1.0)
                        new_value = random.uniform(min_val, max_val)
                    elif param_info['type'] == int:
                        min_val = param_info.get('min', 0)
                        # Use the calculated max_neighbors for relevant parameters
                        if param_name in ("min_neighbors_birth", "max_neighbors_birth",
                                        "min_neighbors_survival", "max_neighbors_survival",
                                        "target_connections_per_node", "connection_increase_threshold",
                                        "connection_decrease_threshold","min_shared_neighbors",
                                        "max_connections", "min_connections",
                                        "connect_min_neighbors", "connect_max_neighbors",
                                        "disconnect_min_neighbors", "disconnect_max_neighbors",
                                        "k_connect", "n_connect", "k_disconnect", "n_disconnect",
                                        "k_birth", "n_birth", "k_death", "n_death"):
                            max_val = max_neighbors
                        else:
                            max_val = param_info.get('max', 10) # Use default if not neighbor-related
                        new_value = random.randint(min_val, max_val)
                    elif param_info['type'] == bool:
                        new_value = random.choice([True, False])
                    elif param_info['type'] == str:
                        if 'allowed_values' in param_info:
                            new_value = random.choice(param_info['allowed_values'])
                        else:
                            continue #skip if no allowed values
                    else:
                        # Skip other types for now
                        continue

                    # Update parameter in controller
                    self.parent.controller.rule.update_parameter(param_name, new_value)

                    # Update UI
                    widget = parameter_entries.get(param_name)
                    if isinstance(widget, tk.Entry):
                        widget.delete(0, tk.END)
                        widget.insert(0, str(new_value))
                    elif isinstance(widget, tk.OptionMenu):
                        # Find the variable associated with the OptionMenu and set it
                        var_name = widget.cget('textvariable')
                        if var_name:
                            self.parent.root.globalsetvar(var_name, str(new_value))

                # --- REMOVED: Obsolete invalidate_cache call ---
                # self.parent.controller.rule.invalidate_cache()
                # ---
                if self.parent.running:
                    self.parent._safe_plot_update()

                logger.info("Randomized all parameters")

        except Exception as e:
            logger.error(f"Error randomizing parameters: {e}")
            messagebox.showerror("Error", f"Failed to randomize parameters: {e}")

    def _toggle_override_widgets_state(self, enable: bool):
        """Enables or disables the 'Configure Rule-Specific Colors...' button.
           (Round 21: Add _is_recreating_tab guard)"""
        # --- ADDED: Guard against execution during recreation ---
        if hasattr(self, '_is_recreating_tab') and self._is_recreating_tab:
            logger.debug("_toggle_override_widgets_state: Skipping because tab is recreating.")
            return
        # ---
        new_state = tk.NORMAL if enable else tk.DISABLED
        logger.debug(f"Toggling configure override button state to: {'NORMAL' if enable else 'DISABLED'}")

        configure_button = self._editor_buttons.get('configure_override_colors')
        if isinstance(configure_button, tk.Button):
            try:
                if configure_button.winfo_exists():
                    configure_button.config(state=new_state)
            except tk.TclError:
                logger.warning("TclError configuring configure_override_colors button (likely destroyed).")
        elif configure_button is not None:
             logger.warning(f"Widget for 'configure_override_colors' is not a tk.Button (Type: {type(configure_button)}).")

    def _open_rule_color_modal(self):
        """Opens the modal window for editing rule-specific color overrides."""
        log_prefix = "RuleEditorWindow._open_rule_color_modal: "
        logger.debug(f"{log_prefix}Opening rule color settings modal.")

        if not hasattr(self, 'change_tracker') or not self.change_tracker:
            logger.error(f"{log_prefix}Change tracker not available.")
            messagebox.showerror("Error", "Cannot open color settings: Internal state error.", parent=self)
            return

        # Define the parameters expected in the modal
        override_param_names = [
            'rule_background_color', 'rule_node_base_color', 'rule_node_color',
            'rule_new_node_color', 'rule_default_edge_color', 'rule_new_edge_color'
        ]

        # Get current values from the change tracker's state
        current_params = self.change_tracker.current_state.get('params', {})
        initial_modal_params: Dict[str, Optional[str]] = {}
        for name in override_param_names:
            value = current_params.get(name)
            # Ensure value is None or a valid hex string for the modal
            if value and isinstance(value, str) and value.startswith('#') and len(value) == 7:
                initial_modal_params[name] = value
            else:
                initial_modal_params[name] = None # Pass None if invalid or not set

        logger.debug(f"{log_prefix}Passing initial params to modal: {initial_modal_params}")

        # Create and display the modal
        try:
            # Pass self (RuleEditorWindow) as the parent
            RuleColorSettingsModal(self, initial_modal_params)
        except Exception as e:
            logger.error(f"{log_prefix}Error creating RuleColorSettingsModal: {e}")
            messagebox.showerror("Error", f"Failed to open color settings: {e}", parent=self)

    def _update_widget_value(self, widget: tk.Widget, value: Any):
        """Helper to update the value of different widget types."""
        log_prefix = "RuleEditorWindow._update_widget_value: "
        try:
            if isinstance(widget, (tk.Entry, ValidatedEntry)):
                widget.delete(0, tk.END)
                widget.insert(0, str(value) if value is not None else "")
            elif isinstance(widget, tk.OptionMenu):
                var_name = widget.cget('textvariable')
                if var_name: self.parent.root.globalsetvar(var_name, str(value) if value is not None else "")
            elif isinstance(widget, ttk.Combobox):
                 # Handle "(None)" for colormaps
                 display_value = "(None)" if value is None and widget.cget('textvariable') in ['node_colormap', 'edge_colormap'] else str(value)
                 widget.set(display_value)
            elif isinstance(widget, tk.Checkbutton):
                var_name = widget.cget('variable')
                if var_name:
                    bool_value = False
                    if isinstance(value, bool): bool_value = value
                    elif isinstance(value, (str, int)): bool_value = str(value).lower() in ('true', '1', 'yes', 'on')
                    self.parent.root.globalsetvar(var_name, bool_value)
            elif isinstance(widget, tk.Text):
                widget.delete("1.0", tk.END)
                widget.insert("1.0", str(value) if value is not None else "")
            elif isinstance(widget, dict) and 'var' in widget: # Color Picker
                 color_var = widget.get('var')
                 if isinstance(color_var, tk.StringVar):
                     hex_value = str(value) if value and isinstance(value, str) and value.startswith('#') else ""
                     color_var.set(hex_value)
                     self._update_rule_color_preview(widget['entry'].cget('textvariable'), hex_value) # Update preview
            else:
                logger.warning(f"{log_prefix}Unhandled widget type for update: {type(widget)}")
        except tk.TclError as e:
             logger.warning(f"{log_prefix}TclError updating widget (likely destroyed): {e}")
        except Exception as e:
            logger.error(f"{log_prefix}Error updating widget value: {e}")

    def _update_contextual_buttons(self, selected_tab_index: int):
        """Show/hide buttons in the top button row based on the selected tab.
           (Round 7: New method)"""
        logger.debug(f"Updating contextual buttons for tab index: {selected_tab_index}")

        # Get button references
        add_row_btn = self._editor_buttons.get('add_rule_row')
        randomize_btn = self._editor_buttons.get('randomize_table')

        # Determine if the rule table tab is active and valid
        is_rule_table_tab_selected = (selected_tab_index == 2)
        is_table_valid = getattr(self, 'is_rule_table_active', False) # Check flag set in __init__

        # Show/Hide Add Row button
        if add_row_btn:
            if is_rule_table_tab_selected and is_table_valid:
                add_row_btn.pack(side=tk.LEFT, padx=5, pady=5) # Show
            else:
                add_row_btn.pack_forget() # Hide

        # Show/Hide and Update Randomize button
        if randomize_btn:
            if is_rule_table_tab_selected and is_table_valid:
                # Update button text based on table type
                table_type = 'State' if 'state_rule_table' in self.rule_data.get('params', {}) else 'Edge'
                randomize_btn.config(text=f"Randomize {table_type} Table")
                randomize_btn.pack(side=tk.LEFT, padx=5, pady=5) # Show
            else:
                randomize_btn.pack_forget() # Hide

    def _on_tab_changed(self, event):
        """Handle tab changes in the Rule Editor.
           (Round 24: Add logging)"""
        log_prefix = "_on_tab_changed: "
        if self.enable_tab_change_event and self.notebook and event.widget == self.notebook:
            selected_tab_index = self.notebook.index(self.notebook.select())
            logger.info(f"{log_prefix}Tab changed to index {selected_tab_index}. Current index: {self.current_tab_index}")
            if selected_tab_index != self.current_tab_index:
                logger.info(f"{log_prefix}Actual tab change detected. Disabling event, recreating content.")
                self.current_tab_index = selected_tab_index
                self.enable_tab_change_event = False # Disable during processing

                # --- Cache values BEFORE recreating ---
                logger.debug(f"{log_prefix}Caching values before recreating tab {selected_tab_index}.")
                self._cache_editor_values()
                # ---

                # --- Recreate content based on NEW index ---
                if selected_tab_index == 0: # Parameters
                    logger.debug(f"{log_prefix}Calling _recreate_parameter_tab_content.")
                    self._recreate_parameter_tab_content(self.rule_data)
                elif selected_tab_index == 1: # Visualization
                    logger.debug(f"{log_prefix}Calling _recreate_visualization_tab_content.")
                    self._recreate_visualization_tab_content(self.rule_data)
                elif selected_tab_index == 2: # Rule Table
                    logger.debug(f"{log_prefix}Calling _recreate_rule_table_tab_content.")
                    self._recreate_rule_table_tab_content(self.rule_data)
                elif selected_tab_index == 3: # Rule Info
                    logger.debug(f"{log_prefix}Calling _recreate_metadata_tab_content.")
                    self._recreate_metadata_tab_content(self.rule_data)
                # ---

                # Update contextual button visibility
                self._update_contextual_buttons(selected_tab_index)

                # Schedule re-enabling the event flag
                self.after(600, self._enable_tab_change)
            else:
                logger.debug(f"{log_prefix}No actual tab index change, ignoring.")
        elif not self.enable_tab_change_event:
             logger.debug(f"{log_prefix}Tab change event ignored because enable_tab_change_event is False.")

    def _enable_tab_change(self):
        """Re-enable tab change event and cache values."""
        self.enable_tab_change_event = True
        self._cache_editor_values()  # Cache values *after* widgets are created

    def _cache_editor_values(self):
        """Cache the parameter and metadata values."""
        try:
            # Check if parameter_entries exists and is not empty
            if hasattr(self, 'parameter_entries') and self.parameter_entries:
                # --- MODIFIED: Pass self.parameter_entries directly ---
                self.cached_parameter_values = self._get_tab_widget_values(self.parameter_entries)
                # ---
            else:
                self.cached_parameter_values = {}
                logger.debug("Initializing empty parameter cache")

            # Check if metadata_fields exists and is not empty
            if hasattr(self, 'metadata_fields') and self.metadata_fields:
                self.cached_metadata_values = self._get_tab_widget_values(self.metadata_fields)
            else:
                self.cached_metadata_values = {}
                logger.debug("Initializing empty metadata cache")

            logger.debug(f"Cached {len(self.cached_parameter_values)} parameter values and {len(self.cached_metadata_values)} metadata values")
        except Exception as e:
            logger.error(f"Error caching editor values: {e}")
            self.cached_parameter_values = {}
            self.cached_metadata_values = {}

    def _get_tab_widget_values(self, widgets: Mapping[str, Union[tk.Widget, Dict[str, Any]]]) -> Dict[str, Any]:
        """Get values from all widgets in a tab.
           (Round 6: Update type hint for widgets parameter)"""
        values = {}
        for name, widget_info in widgets.items(): # Use widget_info to handle dict case
            try:
                # --- Handle different widget types ---
                widget: Optional[tk.Widget] = None
                value_to_store: Any = None

                if isinstance(widget_info, tk.Widget):
                    widget = widget_info
                    if isinstance(widget, (tk.Entry, ValidatedEntry)):
                        value_to_store = widget.get()
                    elif isinstance(widget, tk.OptionMenu):
                        var_name = widget.cget('textvariable')
                        if var_name:
                            try: value_to_store = self.parent.root.globalgetvar(var_name)
                            except Exception as e: logger.warning(f"Error getting value from OptionMenu {name}: {e}")
                        else: logger.warning(f"No textvariable found for OptionMenu: {name}")
                    elif isinstance(widget, ttk.Combobox):
                         value_to_store = widget.get()
                    elif isinstance(widget, tk.Checkbutton):
                        var_name = widget.cget('variable')
                        if var_name:
                            try: value_to_store = self.parent.root.globalgetvar(var_name)
                            except tk.TclError: logger.warning(f"Could not get BooleanVar for Checkbutton '{name}'.")
                        else: logger.warning(f"No variable found for Checkbutton: {name}")
                    elif isinstance(widget, tk.Text):
                        value_to_store = widget.get("1.0", tk.END).strip()
                    else:
                        logger.warning(f"Unhandled widget type: {type(widget)}")

                elif isinstance(widget_info, dict) and 'var' in widget_info: # Color Picker
                    color_var = widget_info.get('var')
                    if isinstance(color_var, tk.StringVar):
                        value_to_store = color_var.get()
                    else:
                        logger.warning(f"Color picker for '{name}' has invalid 'var'.")

                else:
                    logger.warning(f"Unhandled item type in widgets mapping for '{name}': {type(widget_info)}")

                # Store the retrieved value
                if value_to_store is not None:
                    values[name] = value_to_store
                # ---

            except Exception as e:
                logger.error(f"Error getting value for {name}: {e}")
        return values

    def _set_tab_widget_values(self, widgets: Mapping[str, Union[tk.Widget, Dict[str, Any]]], values: Dict[str, Any]) -> None:
        """Set values for all widgets in a tab.
           (Round 45: Correctly set visualization widget values)"""
        log_prefix = "_set_tab_widget_values: " # Added prefix
        logger.info(f"{log_prefix}Setting tab widget values...")
        for name, widget_info in list(widgets.items()): # Use widget_info to handle dict case
            try:
                if name in values:
                    value = values[name]
                    logger.info(f"{log_prefix}Setting '{name}' to {value} (Type: {type(value)})")

                    widget: Optional[tk.Widget] = None
                    is_color_picker = False

                    if isinstance(widget_info, tk.Widget):
                        widget = widget_info
                    elif isinstance(widget_info, dict) and 'entry' in widget_info and 'var' in widget_info: # Color Picker
                        is_color_picker = True
                        widget = widget_info['entry'] # Target entry for general logic, handle var separately
                        color_var = widget_info.get('var')
                        if isinstance(color_var, tk.StringVar):
                            # Ensure value is a valid hex string or empty
                            hex_value = str(value) if value and isinstance(value, str) and value.startswith('#') and len(value) == 7 else ""
                            color_var.set(hex_value)
                            self._update_rule_color_preview(name, hex_value) # Update preview
                            logger.debug(f"  Set color picker var for '{name}' to '{hex_value}'")
                        else:
                            logger.warning(f"  Color picker for '{name}' has invalid 'var'.")
                    else:
                        logger.warning(f"{log_prefix}Could not determine widget to update for '{name}' from widget_info: {widget_info}")
                        continue # Skip if widget cannot be determined

                    if widget is None and not is_color_picker: continue # Skip if widget is still None (unless it was a color picker handled above)

                    # --- Update widget value based on type ---
                    if isinstance(widget, (tk.Entry, ValidatedEntry)):
                        if name == 'category': widget.config(state=tk.NORMAL); widget.delete(0, tk.END); widget.insert(0, str(value) if value is not None else "Uncategorized"); widget.config(state='readonly')
                        else: widget.delete(0, tk.END); widget.insert(0, str(value) if value is not None else "")
                    elif isinstance(widget, tk.OptionMenu):
                        var_name = widget.cget('textvariable')
                        if var_name:
                            if name == 'rating':
                                rating_str = "None";
                                if isinstance(value, int) and 1 <= value <= 5: rating_str = "" * value
                                try: self.parent.root.globalsetvar(var_name, rating_str)
                                except Exception as e: logger.warning(f"Error setting variable for OptionMenu {name}: {e}")
                            else:
                                try: self.parent.root.globalsetvar(var_name, str(value) if value is not None else "")
                                except Exception as e: logger.warning(f"Error setting variable for OptionMenu {name}: {e}")
                        else: logger.warning(f"No textvariable found for OptionMenu: {name}")
                    elif isinstance(widget, ttk.Combobox):
                         # --- MODIFIED: Handle "(None)" for colormaps ---
                         if name in ['node_colormap', 'edge_colormap']:
                             display_value = "(None)" if value is None else str(value)
                             widget.set(display_value)
                             logger.debug(f"  Set colormap combobox '{name}' display to '{display_value}'")
                         # --- END MODIFIED ---
                         elif name == 'rating':
                             rating_str = "None"
                             if isinstance(value, int) and 1 <= value <= 5: rating_str = "" * value
                             widget.set(rating_str)
                         else:
                             widget.set(str(value) if value is not None else "")
                    elif isinstance(widget, tk.Checkbutton):
                        var_name = widget.cget('variable')
                        if var_name:
                            bool_value = False
                            if isinstance(value, bool): bool_value = value
                            elif isinstance(value, (str, int)): bool_value = str(value).lower() in ('true', '1', 'yes', 'on')
                            try: self.parent.root.globalsetvar(var_name, bool_value)
                            except Exception as e: logger.warning(f"Error setting variable for Checkbutton {name}: {e}")
                        else: logger.warning(f"No variable found for Checkbutton: {name}")
                    elif isinstance(widget, tk.Text):
                        widget.delete("1.0", tk.END)
                        widget.insert("1.0", str(value) if value is not None else "")
                    elif is_color_picker:
                        pass # Already handled above by setting the StringVar
                    else:
                        logger.warning(f"{log_prefix}Unhandled widget type during set value: {type(widget)}")
            except Exception as e:
                logger.error(f"{log_prefix}Error setting value for {name}: {e}")

    def _create_visualization_tab(self) -> tk.Frame:
        """Creates the content for the new Visualization tab.
           (Round 12 Fix: Set correct background for override LabelFrame)"""
        frame = tk.Frame(self.notebook, bg="#404040")
        scrollable = ScrollableFrame(frame, self.parent, bg="#404040")
        scrollable.pack(fill=tk.BOTH, expand=True)
        content_frame = scrollable.scrolled_frame
        content_frame.columnconfigure(0, weight=1)

        try:
            # [ Get Rule Instance and Merged Metadata - Unchanged ]
            if not self.controller or not self.controller.rule or self.controller.rule.name != self.rule_name:
                try: temp_rule_data = RuleLibraryManager.get_rule(self.rule_name); temp_metadata_dict = {k: v for k, v in temp_rule_data.items() if k != 'params' and k != '_ignored_params'}; temp_metadata_dict.setdefault('position', 1); temp_metadata = RuleMetadata(**temp_metadata_dict); rule_instance = RuleLibrary.create_rule(self.rule_name, temp_metadata); rule_instance.params = copy.deepcopy(temp_rule_data.get('params', {}))
                except Exception as e: logger.error(f"Failed to create temporary rule instance for '{self.rule_name}': {e}"); return frame
            else: rule_instance = self.controller.rule
            base_metadata = getattr(Rule, 'PARAMETER_METADATA', {}); subclass_metadata = getattr(rule_instance, 'PARAMETER_METADATA', {}); merged_metadata = RuleEditorWindow._merge_metadata(base_metadata, subclass_metadata); exclude_set = getattr(rule_instance, 'EXCLUDE_EDITOR_PARAMS', set())

            # [ Group visualization parameters - Unchanged ]
            viz_groups: Dict[str, List[str]] = defaultdict(list)
            use_override_toggle_param: Optional[str] = None
            for param_name, param_info in merged_metadata.items():
                if param_name in exclude_set: continue
                group = param_info.get('parameter_group', 'Other Settings')
                if group.startswith("Visualization"):
                    if group == "Visualization Overrides":
                        if param_name == 'use_rule_specific_colors': use_override_toggle_param = param_name
                    else:
                        viz_groups[group].append(param_name)

            # --- Create Sections ---
            inner_frame_bg = '#404040' # Define standard background

            # 1. Standard Visualization Groups (Nodes, Edges)
            preferred_viz_order = ["Visualization: Nodes", "Visualization: Edges"]
            for group_name in preferred_viz_order:
                if group_name in viz_groups:
                    # --- Use standard background ---
                    group_label_frame = tk.LabelFrame(content_frame, text=group_name, bg=inner_frame_bg, fg="white", bd=2, relief=tk.GROOVE)
                    group_label_frame.pack(fill=tk.X, padx=5, pady=5)
                    inner_content_frame = tk.Frame(group_label_frame, bg=inner_frame_bg)
                    inner_content_frame.pack(fill=tk.X, expand=True)
                    param_names_in_group = sorted(viz_groups[group_name], key=lambda p: 0 if 'mode' in p else 1)
                    for param_name in param_names_in_group:
                        param_info = merged_metadata[param_name]
                        self._create_single_parameter_widget(inner_content_frame, param_name, param_info, self.rule_data, cast(MutableMapping[str, Union[tk.Entry, tk.OptionMenu, ttk.OptionMenu, ttk.Combobox, tk.Checkbutton, ttk.Checkbutton, ValidatedEntry, Dict[str, Any]]], self.parameter_entries))

            # 2. Override Control Section (Checkbox + Button)
            # --- FIX: Explicitly set bg=inner_frame_bg for the LabelFrame ---
            override_control_frame = tk.LabelFrame(content_frame, text="Rule Color Override", bg=inner_frame_bg, fg="white", bd=2, relief=tk.GROOVE)
            override_control_frame.pack(fill=tk.X, padx=5, pady=10)
            override_control_content = tk.Frame(override_control_frame, bg=inner_frame_bg)
            override_control_content.pack(fill=tk.X, expand=True)
            # ---

            if use_override_toggle_param:
                param_info = merged_metadata[use_override_toggle_param]
                self._create_single_parameter_widget(override_control_content, use_override_toggle_param, param_info, self.rule_data, cast(MutableMapping[str, Union[tk.Entry, tk.OptionMenu, ttk.OptionMenu, ttk.Combobox, tk.Checkbutton, ttk.Checkbutton, ValidatedEntry, Dict[str, Any]]], self.parameter_entries))
            else:
                logger.warning("Parameter 'use_rule_specific_colors' not found in metadata!")

            self.configure_override_button = tk.Button(
                override_control_content,
                text="Configure Rule-Specific Colors...",
                command=self._open_rule_color_modal,
                state=tk.DISABLED
            )
            self.configure_override_button.pack(pady=5, padx=5)
            self._editor_buttons['configure_override_colors'] = self.configure_override_button

            # [ Rest of the method remains the same ]
            self._on_edge_coloring_mode_change()
            self._on_node_coloring_mode_change()
            self._toggle_override_widgets_state(self.use_override_var.get())
            self._bind_mouse_wheel_to_all_widgets(content_frame, scrollable)
            self.after(100, lambda c=scrollable.canvas: c.configure(scrollregion=c.bbox("all")))
        except Exception as e:
            logger.error(f"Error creating visualization tab content: {e}")
            logger.error(traceback.format_exc())
            tk.Label(frame, text="Error loading visualization parameters.").pack()
        return frame

    def _create_color_picker_widget(self, parent_frame: tk.Frame, param_name: str, current_value_str: Optional[str], widget_state: str) -> Tuple[tk.StringVar, tk.Frame]:
        """Creates a composite color picker widget (Label, Entry, Canvas, Button).
           (Round 22: New method)"""
        picker_frame = tk.Frame(parent_frame, bg=parent_frame.cget('bg')) # Match parent bg
        picker_frame.pack(fill=tk.X, pady=2)

        # Use the display name logic from _create_single_parameter_widget
        display_name = ' '.join(word.capitalize() for word in param_name.split('_'))
        if display_name.startswith("Rule "): display_name = display_name[5:] # Remove "Rule " prefix
        tk.Label(picker_frame, text=f"{display_name}:", width=20, anchor="w", bg=parent_frame.cget('bg'), fg='white').pack(side=tk.LEFT, padx=(5, 2)) # Adjusted width

        color_var = tk.StringVar(value=current_value_str if current_value_str else "") # Default to empty string if None

        # Entry for hex code
        entry = ValidatedEntry(picker_frame, textvariable=color_var, width=10, state=widget_state)
        entry.pack(side=tk.LEFT, padx=2)

        # Color preview canvas
        preview_bg = current_value_str if current_value_str and current_value_str.startswith('#') and len(current_value_str) == 7 else parent_frame.cget('bg')
        canvas = tk.Canvas(picker_frame, width=30, height=20, bg=preview_bg, highlightthickness=1)
        if widget_state in ('normal', 'disabled'): canvas.config(state=widget_state)
        else: raise ValueError(f"Invalid widget_state: {widget_state}. Expected 'normal' or 'disabled'.")
        canvas.pack(side=tk.LEFT, padx=2)

        # Choose button
        button = tk.Button(picker_frame, text="Choose...", state=widget_state,
                           command=lambda p=param_name, v=color_var, c=canvas: self._open_rule_color_picker(p, v, c))
        button.pack(side=tk.LEFT, padx=2)

        # Bind validation to entry focus out/return
        def create_handler(w, name, p_info):
            def handler(event): self.after(100, lambda w=w, name=name, col_idx=None, tbl_type=None, p_info=p_info: self._process_focus_out(w, name, col_idx, tbl_type, p_info))
            return handler

        param_info = {}
        if self.parent.controller and self.parent.controller.rule:
             param_info = self.parent.controller.rule.PARAMETER_METADATA.get(param_name, {})

        focus_out_handler = create_handler(entry, param_name, param_info)
        entry.bind('<FocusOut>', focus_out_handler)
        entry.bind('<Return>', focus_out_handler)
        entry.bind("<FocusIn>", lambda event, w=entry: self._handle_entry_focus_in(event, w))

        # Store widgets associated with this parameter (use a dict)
        # Store the detailed components in a separate dictionary
        if not hasattr(self, 'parameter_entry_details'):
            self.parameter_entry_details = {}
        self.parameter_entry_details[param_name] = {'var': color_var, 'entry': entry, 'canvas': canvas, 'button': button}

        # Keep parameter_entries consistent with its expected type
        self.parameter_entries[param_name] = entry

        return color_var, picker_frame # Return var and the container frame


    def _create_parameter_fields(self, parent_frame: tk.Frame, rule_name: str,
                                editor_window: 'RuleEditorWindow', rule_data: Dict[str, Any],
                                parameter_entries: MutableMapping[str, Union[tk.Entry, tk.OptionMenu, ttk.OptionMenu, ttk.Combobox, tk.Checkbutton, ttk.Checkbutton, ValidatedEntry, Dict[str, Any]]]):
        """
        Create parameter fields, dynamically generating metadata for permutations.
        (Round 7: Implement dynamic metadata generation call)
        """
        log_prefix = f"RuleEditorWindow._create_parameter_fields (R7 Dynamic): "
        logger.debug(f"{log_prefix}--- ENTRY --- Creating fields in parent: {parent_frame}")
        logger.debug(f"{log_prefix}parameter_entries keys at START: {list(parameter_entries.keys())}")

        # --- Clear existing dynamic widget containers ---
        if not hasattr(self, 'permutation_widget_containers'): self.permutation_widget_containers = {}
        for container in self.permutation_widget_containers.values():
            if container and container.winfo_exists(): container.destroy()
        self.permutation_widget_containers.clear()
        if not hasattr(self, 'sub_frames'): self.sub_frames = {}
        self.sub_frames.clear()
        # ---

        try:
            # --- Get Rule Instance and Static Metadata ---
            rule_instance = None
            if self.controller and self.controller.rule and self.controller.rule.name == rule_name:
                rule_instance = self.controller.rule
            else: # Fallback if controller rule doesn't match (e.g., during init)
                try:
                    temp_rule_data = RuleLibraryManager.get_rule(rule_name)
                    temp_metadata_dict = {k: v for k, v in temp_rule_data.items() if k != 'params' and k != '_ignored_params'}
                    temp_metadata_dict.setdefault('position', 1)
                    temp_metadata = RuleMetadata(**temp_metadata_dict)
                    rule_instance = RuleLibrary.create_rule(rule_name, temp_metadata)
                    rule_instance.params = copy.deepcopy(temp_rule_data.get('params', {}))
                except Exception as e:
                    logger.error(f"{log_prefix}Failed to create temporary rule instance for '{rule_name}' to get metadata: {e}")
                    return
            if rule_instance is None:
                logger.error(f"{log_prefix}Could not obtain rule instance for '{rule_name}'.")
                return

            base_metadata = getattr(Rule, 'PARAMETER_METADATA', {})
            subclass_metadata = getattr(rule_instance, 'PARAMETER_METADATA', {})
            # Use the merged static metadata ONLY for non-permutation params
            static_merged_metadata = RuleEditorWindow._merge_metadata(base_metadata, subclass_metadata)
            exclude_set = getattr(rule_instance, 'EXCLUDE_EDITOR_PARAMS', set())
            # ---

            # --- Group Static Parameters ---
            grouped_static_params: Dict[str, List[str]] = defaultdict(list)
            for param_name, param_info in static_merged_metadata.items():
                # Skip excluded and permutation templates/bases
                if param_name in exclude_set or param_name.endswith('_BASE') or param_name.endswith('_TEMPLATE'):
                    continue
                # Skip parameters handled by dynamic generation logic (even if they exist statically by mistake)
                if param_name.startswith("birth_eligibility_") or \
                   param_name.startswith("survival_eligibility_") or \
                   param_name.startswith("final_death_metric_") or \
                   param_name.startswith("final_life_metric_"):
                    logger.warning(f"{log_prefix}Found static definition for potential dynamic param '{param_name}'. Ignoring static definition.")
                    continue
                # Skip parameters handled elsewhere
                if param_name in ('dimension_type', 'neighborhood_type', 'initial_conditions', 'chunk_size') or param_name.endswith('_rule_table'):
                    continue
                group = param_info.get('parameter_group', 'Other Settings')
                if group.startswith("Visualization"): continue # Skip viz params
                grouped_static_params[group].append(param_name)
            # ---

            # [ Sort groups - Unchanged ]
            preferred_primary_order = ["Initialization", "Node Eligibility", "Final State Check", "Perturbations", "Core", "Other Settings"]
            def group_sort_key(group_name_tuple):
                group_name = group_name_tuple[0]; primary_category = "Other Settings"
                for preferred_cat in preferred_primary_order:
                    if group_name.startswith(preferred_cat): primary_category = preferred_cat; break
                try: primary_key = preferred_primary_order.index(primary_category)
                except ValueError: primary_key = len(preferred_primary_order)
                return (primary_key, group_name)
            sorted_grouped_params = sorted(grouped_static_params.items(), key=group_sort_key)

            # --- Create UI elements group by group ---
            group_frame_bg = parent_frame.cget('bg')

            for group_name, param_names_in_group in sorted_grouped_params:
                group_label_frame = ttk.LabelFrame(parent_frame, text=group_name, padding=(5, 5))
                group_label_frame.pack(fill=tk.X, padx=5, pady=10)
                group_label_frame.columnconfigure(0, weight=1)
                inner_content_frame = tk.Frame(group_label_frame, bg=group_frame_bg)
                inner_content_frame.grid(row=0, column=0, sticky="nsew")
                inner_content_frame.columnconfigure(0, weight=1)

                # [ Sort parameters within group - Unchanged ]
                def param_sort_key(param_name):
                    param_info = static_merged_metadata.get(param_name, {})
                    sort_key = param_info.get('editor_sort_key', float('inf'))
                    return (sort_key, param_name)
                sorted_param_names = sorted(param_names_in_group, key=param_sort_key)

                # [ Create Sub-frames for Dynamic Groups - Unchanged ]
                if group_name == "Node Eligibility":
                    self.sub_frames['birth_selectors'] = tk.Frame(inner_content_frame, bg=group_frame_bg); self.sub_frames['birth_selectors'].pack(fill=tk.X, pady=2)
                    self.sub_frames['birth_criteria'] = tk.Frame(inner_content_frame, bg=group_frame_bg); self.sub_frames['birth_criteria'].pack(fill=tk.X, pady=2)
                    ttk.Separator(inner_content_frame, orient=tk.HORIZONTAL).pack(fill=tk.X, pady=10, padx=5)
                    self.sub_frames['survival_selectors'] = tk.Frame(inner_content_frame, bg=group_frame_bg); self.sub_frames['survival_selectors'].pack(fill=tk.X, pady=2)
                    self.sub_frames['survival_criteria'] = tk.Frame(inner_content_frame, bg=group_frame_bg); self.sub_frames['survival_criteria'].pack(fill=tk.X, pady=2)
                    ttk.Separator(inner_content_frame, orient=tk.HORIZONTAL).pack(fill=tk.X, pady=10, padx=5)
                    self.sub_frames['clustering_config'] = tk.Frame(inner_content_frame, bg=group_frame_bg); self.sub_frames['clustering_config'].pack(fill=tk.X, pady=2)
                elif group_name == "Final State Check":
                    self.sub_frames['check_metric'] = tk.Frame(inner_content_frame, bg=group_frame_bg); self.sub_frames['check_metric'].pack(fill=tk.X, pady=2)
                    self.sub_frames['life_criteria'] = tk.Frame(inner_content_frame, bg=group_frame_bg); self.sub_frames['life_criteria'].pack(fill=tk.X, pady=2)
                    ttk.Separator(inner_content_frame, orient=tk.HORIZONTAL).pack(fill=tk.X, pady=10, padx=5)
                    self.sub_frames['death_criteria'] = tk.Frame(inner_content_frame, bg=group_frame_bg); self.sub_frames['death_criteria'].pack(fill=tk.X, pady=2)

                # --- Create Static Widgets ---
                for param_name in sorted_param_names:
                    if param_name in parameter_entries: continue # Skip if already created (e.g., by dynamic logic)
                    param_info = static_merged_metadata.get(param_name)
                    if not param_info: continue # Skip if no metadata found

                    # Determine target frame (selectors go in specific sub-frames)
                    target_sub_frame = inner_content_frame # Default
                    if group_name == "Node Eligibility":
                        if param_name.startswith("birth_metric_"): target_sub_frame = self.sub_frames.get('birth_selectors', inner_content_frame)
                        elif param_name.startswith("survival_metric_"): target_sub_frame = self.sub_frames.get('survival_selectors', inner_content_frame)
                        elif param_name == "clustering_denominator_type": target_sub_frame = self.sub_frames.get('clustering_config', inner_content_frame)
                    elif group_name == "Final State Check":
                        if param_name == "final_check_metric": target_sub_frame = self.sub_frames.get('check_metric', inner_content_frame)

                    logger.debug(f"{log_prefix}Creating STATIC widget for '{param_name}' in frame '{type(target_sub_frame).__name__}'")
                    self._create_single_parameter_widget(target_sub_frame, param_name, param_info, rule_data, parameter_entries)

            # --- Trigger dynamic widget update AFTER static widgets (especially selectors) are created ---
            logger.debug(f"{log_prefix}Triggering initial dynamic widget visibility update.")
            self._update_permutation_widgets_visibility()
            # ---

        except Exception as e:
            logger.error(f"{log_prefix}Error creating parameter fields: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Error", f"Failed to create parameter fields: {e}")
        finally:
            logger.debug(f"{log_prefix}parameter_entries keys at EXIT: {list(parameter_entries.keys())}")

    def _create_single_parameter_widget(self, content_parent_frame: Union[tk.Frame, ttk.LabelFrame],
                                        param_name: str, param_info: Dict[str, Any],
                                        rule_data: Dict[str, Any],
                                        # --- MODIFIED: Update type hint to match actual dictionary content ---
                                        parameter_entries: MutableMapping[str, Union[tk.Entry, tk.OptionMenu, ttk.OptionMenu, ttk.Combobox, tk.Checkbutton, ttk.Checkbutton, ValidatedEntry, Dict[str, Any]]]) -> Optional[tk.Frame]:
                                        # --- END MODIFIED ---
        """
        Helper function to create the UI elements for a single parameter
        within its own container frame using grid layout. Stores the primary input widget or color picker dict
        in parameter_entries. Stores the container frame in permutation_widget_containers
        if it's a permutation parameter. Returns the created container frame.
        (Round 27 Fix: Correct type hint for parameter_entries)
        """
        container_bg = '#404040'
        widget_entry_bg = "#000000"; text_color = "white" # Standard dark theme

        param_container_frame = tk.Frame(content_parent_frame, bg=container_bg)
        param_container_frame.columnconfigure(0, weight=0) # Label column
        param_container_frame.columnconfigure(1, weight=1) # Widget column (expand)
        param_container_frame.columnconfigure(2, weight=0) # For color picker canvas
        param_container_frame.columnconfigure(3, weight=0) # For color picker button

        display_name = ' '.join(word.capitalize() for word in param_name.split('_'))
        is_permutation_param = False
        base_name = param_name
        if param_name.startswith("birth_eligibility_") or \
           param_name.startswith("survival_eligibility_") or \
           param_name.startswith("final_death_metric_") or \
           param_name.startswith("final_life_metric_"):
            is_permutation_param = True
            parts = param_name.split('_')
            base_name = "_".join(parts[:3]) if parts[0] in ['birth', 'survival'] else "_".join(parts[:4])
            display_name = ' '.join(word.capitalize() for word in base_name.split('_'))
        elif param_name == "clustering_denominator_type":
            is_permutation_param = True

        name_label = tk.Label(param_container_frame, text=display_name, font=("TkDefaultFont", GlobalSettings.Visualization.RULE_EDITOR_FIELD_FONT_SIZE, "bold"), anchor="w", bg=container_bg, fg='white')
        name_label.grid(row=0, column=0, sticky="w", padx=5, pady=(5,2))

        widget_frame = tk.Frame(param_container_frame, bg=container_bg)
        widget_frame.grid(row=0, column=1, sticky="ew", padx=2)
        widget_frame.columnconfigure(0, weight=1)

        widget = None
        current_value = rule_data['params'].get(param_name, param_info.get('default'))
        current_value_str = "" if current_value is None else str(current_value)
        widget_state = tk.NORMAL
        is_override_param = param_info.get('parameter_group') == "Visualization Overrides"
        if is_override_param and param_name != 'use_rule_specific_colors': widget_state = tk.NORMAL if self.use_override_var.get() else tk.DISABLED
        edge_viz_dependents = ['use_state_coloring_edges', 'edge_colormap', 'edge_color_norm_vmin', 'edge_color_norm_vmax']
        if param_name in edge_viz_dependents:
            edge_mode_val = rule_data['params'].get('edge_coloring_mode', 'Default')
            if edge_mode_val == "Default": widget_state = tk.DISABLED
        if param_name != 'use_state_coloring_edges' and param_name in ['edge_colormap', 'edge_color_norm_vmin', 'edge_color_norm_vmax']:
            use_state_coloring_edges_val = rule_data['params'].get('use_state_coloring_edges', False)
            if not use_state_coloring_edges_val: widget_state = tk.DISABLED
        node_viz_dependents = ['node_colormap', 'node_color_norm_vmin', 'node_color_norm_vmax']
        if param_name in node_viz_dependents:
            use_state = rule_data['params'].get('use_state_coloring', False); use_degree = rule_data['params'].get('color_nodes_by_degree', False); use_neighbors = rule_data['params'].get('color_nodes_by_active_neighbors', False)
            if not (use_state or use_degree or use_neighbors): widget_state = tk.DISABLED

        param_type = param_info.get('type')
        is_color_param = param_name.endswith('_color') or param_name == 'background'
        widget_created = False
        widget_row_index = 0

        if is_color_param and param_type == str:
            widget_frame.columnconfigure(0, weight=1)
            widget_frame.columnconfigure(1, weight=0)
            widget_frame.columnconfigure(2, weight=0)

            color_var = tk.StringVar(value=current_value_str if current_value_str else "")
            self._viz_vars[param_name] = color_var

            entry = ValidatedEntry(widget_frame, textvariable=color_var, width=10, state=widget_state,
                                   bg=widget_entry_bg, fg=text_color, insertbackground=text_color)
            entry.grid(row=widget_row_index, column=0, sticky="ew", padx=(0, 2))

            preview_bg = current_value_str if current_value_str and current_value_str.startswith('#') and len(current_value_str) == 7 else 'SystemButtonFace'
            canvas = tk.Canvas(widget_frame, width=30, height=20, bg=preview_bg, highlightthickness=1, highlightbackground="grey50")
            canvas.config(state=widget_state)
            canvas.grid(row=widget_row_index, column=1, padx=2)

            button = tk.Button(widget_frame, text="Choose...", state=widget_state,
                               command=lambda p=param_name, v=color_var, c=canvas: self._open_rule_color_picker(p, v, c))
            button.grid(row=widget_row_index, column=2, padx=2)

            def create_handler(w, name, p_info):
                def handler(event): self.after(100, lambda w=w, name=name, col_idx=None, tbl_type=None, p_info=p_info: self._process_focus_out(w, name, col_idx, tbl_type, p_info))
                return handler
            focus_out_handler = create_handler(entry, param_name, param_info)
            entry.bind('<FocusOut>', focus_out_handler)
            entry.bind('<Return>', focus_out_handler)
            entry.bind("<FocusIn>", lambda event, w=entry: self._handle_entry_focus_in(event, w))

            widget_details = {'entry': entry, 'var': color_var, 'canvas': canvas, 'button': button}
            parameter_entries[param_name] = widget_details # Store dict for color picker
            if not hasattr(self, 'parameter_entry_details'): self.parameter_entry_details = {}
            self.parameter_entry_details[param_name] = widget_details
            widget_created = True

        elif param_name in ['node_colormap', 'edge_colormap']:
            allowed_values_from_meta = param_info.get('allowed_values', _standard_colormaps)
            display_options = ["(None)"] + [v for v in allowed_values_from_meta if v != "(None)"]
            initial_display_value = "(None)" if current_value is None else current_value_str
            if initial_display_value not in display_options: initial_display_value = "(None)"
            var = tk.StringVar(value=initial_display_value)
            self._viz_vars[param_name] = var
            combobox = ttk.Combobox(widget_frame, textvariable=var, values=display_options, width=25, state=widget_state)
            combobox.grid(row=widget_row_index, column=0, sticky="ew", pady=2) # Grid in widget_frame
            parameter_entries[param_name] = combobox
            combobox.bind('<<ComboboxSelected>>', lambda event, name=param_name, v=var: self._on_colormap_selected(name, v))
            widget_created = True

        elif 'allowed_values' in param_info:
            allowed_values = param_info['allowed_values']
            var = tk.StringVar(value=current_value_str)
            self._viz_vars[param_name] = var
            if current_value_str not in allowed_values:
                if allowed_values: var.set(allowed_values[0])
                else: var.set("")
            dropdown = tk.OptionMenu(widget_frame, var, *allowed_values)
            dropdown.config(bg=container_bg, fg=text_color, activebackground=container_bg, activeforeground=text_color, highlightthickness=0, relief=tk.FLAT, borderwidth=1, state=widget_state)
            dropdown["menu"].config(bg=container_bg, fg=text_color)
            dropdown.grid(row=widget_row_index, column=0, sticky="ew", pady=2) # Grid in widget_frame
            parameter_entries[param_name] = dropdown
            var.trace_add("write", lambda *args, name=param_name, v=var: self._on_parameter_change(name, v))
            if param_name in ['birth_metric_type', 'survival_metric_type', 'birth_metric_aggregation', 'survival_metric_aggregation', 'final_check_metric']:
                var.trace_add("write", self._on_eligibility_metric_change)
            if param_name == 'edge_coloring_mode': var.trace_add("write", self._on_edge_coloring_mode_change)
            widget_created = True

        elif param_info.get('type') == bool:
            current_bool_value = str(current_value).lower() in ('true', '1', 'yes', 'on')
            var = tk.BooleanVar(value=current_bool_value)
            self._viz_vars[param_name] = var
            def checkbox_command_wrapper(*args):
                if hasattr(self, '_is_recreating_tab') and self._is_recreating_tab: return
                if param_name == 'use_rule_specific_colors': self._toggle_override_widgets_state(var.get())
                self._on_parameter_change(param_name, var)
            checkbutton = tk.Checkbutton(widget_frame, variable=var, onvalue=True, offvalue=False, anchor=tk.W, bg=container_bg, fg=text_color, selectcolor=widget_entry_bg, state=widget_state, command=checkbox_command_wrapper)
            checkbutton.grid(row=widget_row_index, column=0, sticky="w", pady=2) # Grid in widget_frame
            parameter_entries[param_name] = checkbutton
            if param_name in ['use_state_coloring', 'color_nodes_by_degree', 'color_nodes_by_active_neighbors']: var.trace_add("write", self._on_node_coloring_mode_change)
            if param_name == 'use_state_coloring_edges': var.trace_add("write", self._on_edge_coloring_mode_change)
            widget_created = True

        else: # Default to Entry
            entry = ValidatedEntry(widget_frame, width=20, state=widget_state, bg=widget_entry_bg, fg=text_color, insertbackground=text_color)
            entry.insert(0, current_value_str)
            entry.grid(row=widget_row_index, column=0, sticky="ew", pady=2) # Grid in widget_frame
            parameter_entries[param_name] = entry
            def create_handler(w, name, p_info):
                def handler(event): self.after(100, lambda w=w, name=name, col_idx=None, tbl_type=None, p_info=p_info: self._process_focus_out(w, name, col_idx, tbl_type, p_info))
                return handler
            focus_out_handler = create_handler(entry, param_name, param_info)
            entry.bind('<FocusOut>', focus_out_handler)
            entry.bind('<Return>', focus_out_handler)
            entry.bind("<FocusIn>", lambda event, w=entry: self._handle_entry_focus_in(event, w))
            widget_created = True

        # Description label (row 1, spanning columns 0 and 1 of param_container_frame)
        if isinstance(param_info, dict) and 'description' in param_info:
            desc_label = tk.Label(param_container_frame, text=param_info['description'], wraplength=600-60, justify=tk.LEFT, font=("TkDefaultFont", GlobalSettings.Visualization.RULE_EDITOR_FIELD_FONT_SIZE), bg=container_bg, fg=text_color)
            desc_label.grid(row=1, column=0, columnspan=2, sticky="ew", padx=5, pady=2) # Span 2 columns

        if is_permutation_param:
            if not hasattr(self, 'permutation_widget_containers'):
                self.permutation_widget_containers = {}
            self.permutation_widget_containers[param_name] = param_container_frame

        param_container_frame.pack(fill=tk.X, pady=1)
        return param_container_frame


    def _create_metadata_fields(self, metadata_frame: tk.Frame, rule_name: str,
                                        editor_window: 'RuleEditorWindow', rule_data: Dict[str, Any],
                                        metadata_fields: Dict[str, tk.Widget]) -> Tuple[tk.Frame, Dict[str, tk.Widget]]:
        """Create metadata fields with enhanced display and value tracking.
           (Round 2: Make name read-only, add Rename button)"""
        if rule_data is None:
            logger.error(f"No rule data found for {rule_name}")
            return metadata_frame, metadata_fields

        # --- Order adjusted, Favorite removed ---
        metadata_names = [
            'name', 'category', 'author', 'version', 'dimension_compatibility',
            'neighborhood_compatibility', 'description', 'tags', 'email', 'url',
            'date_created', 'date_modified', 'rating', 'notes' # Removed 'favorite'
        ]

        for i, field_name in enumerate(metadata_names):
            # --- Skip fields not present in data (except category which we add) ---
            if field_name not in rule_data and field_name != 'category':
                # logger.debug(f"Skipping metadata field {field_name} as it is not in rule data") # Reduce noise
                continue
            # ---

            display_name = ' '.join(word.capitalize() for word in field_name.split('_'))
            name_label = tk.Label(metadata_frame,
                                text=display_name,
                                font=("TkDefaultFont", GlobalSettings.Visualization.RULE_EDITOR_FIELD_FONT_SIZE, "bold"),
                                anchor="w")
            name_label.pack(fill=tk.X, padx=5, pady=(5,2))

            if field_name == 'name':
                # --- MODIFIED: Make name read-only, add Rename button ---
                name_frame = tk.Frame(metadata_frame)
                name_frame.pack(fill=tk.X, pady=2, padx=5)
                entry = tk.Entry(name_frame, textvariable=self.name_var, state='readonly',
                                 readonlybackground='white', fg='black',
                                 selectbackground="grey50",
                                 selectforeground="white")
                entry.pack(side=tk.LEFT, fill=tk.X, expand=True)
                rename_button = tk.Button(name_frame, text="Rename...", command=self._prompt_rename_rule)
                rename_button.pack(side=tk.LEFT, padx=(5, 0))
                metadata_fields[field_name] = entry # Store the entry widget
                # --- END MODIFIED ---
            elif field_name == 'description':
                # --- Wrap Text widget in a Frame with Scrollbar ---
                desc_outer_frame = tk.Frame(metadata_frame)
                # --- MODIFIED: Allow vertical expansion ---
                desc_outer_frame.pack(fill=tk.BOTH, expand=True, pady=2, padx=5) # Fill BOTH and expand

                desc_scrollbar = tk.Scrollbar(desc_outer_frame, orient=tk.VERTICAL)
                # --- Increased height ---
                entry = tk.Text(desc_outer_frame, height=10, wrap=tk.WORD, # Increased height to 10
                                yscrollcommand=desc_scrollbar.set,
                                selectbackground="grey50",
                                selectforeground="white")
                # ---
                entry.insert(tk.END, str(rule_data.get(field_name, "")))
                entry.config(insertbackground='black') # Keep black cursor
                desc_scrollbar.config(command=entry.yview)

                desc_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
                entry.pack(side=tk.LEFT, fill=tk.BOTH, expand=True) # Fill BOTH and expand
                metadata_fields[field_name] = entry
            elif field_name == 'category':
                # --- Add Category Field (Read-only, opens manager on click) ---
                category_var = tk.StringVar(value=str(rule_data.get(field_name, "Uncategorized")))
                entry = tk.Entry(metadata_frame, textvariable=category_var, state='readonly',
                                 readonlybackground='white', fg='black',
                                 selectbackground="grey50",
                                 selectforeground="white")
                entry.pack(fill=tk.X, pady=2, padx=5) # Add padx
                # --- Bind click to open category manager ---
                entry.bind("<Button-1>", lambda e: self._open_category_manager())
                ToolTip(entry, "Click to manage categories")
                # ---
                metadata_fields[field_name] = entry
            elif field_name == 'rating':
                 # --- Add Rating Dropdown ---
                 rating_options = ["None", "", "", "", "", ""]
                 rating_value = rule_data.get(field_name)
                 if isinstance(rating_value, int) and 1 <= rating_value <= 5: rating_str = "" * rating_value
                 else: rating_str = "None"
                 rating_var = tk.StringVar(value=rating_str)
                 # --- Use ttk.Combobox for better appearance ---
                 rating_menu = ttk.Combobox(metadata_frame, textvariable=rating_var, values=rating_options, state="readonly", width=10)
                 # ---
                 rating_menu.pack(fill=tk.X, pady=2, padx=5) # Add padx
                 metadata_fields[field_name] = rating_menu # Store the Combobox
                 # Store the variable separately if needed elsewhere
                 self.rating_var = rating_var # Store the variable if needed
            else: # Standard Entry field
                entry = tk.Entry(metadata_frame,
                                 selectbackground="grey50",
                                 selectforeground="white")
                entry.insert(0, str(rule_data.get(field_name, "")))
                entry.config(insertbackground='black')
                entry.pack(fill=tk.X, pady=2, padx=5) # Add padx
                metadata_fields[field_name] = entry

        return metadata_frame, metadata_fields

    def _get_widget_value_safe(self, param_name: str, default_value: Any) -> Any:
        """Safely get value from parameter_entries, handling OptionMenu."""
        widget_info = self.parameter_entries.get(param_name)
        if isinstance(widget_info, tk.OptionMenu):
            var_name = widget_info.cget('textvariable')
            if var_name and hasattr(self.parent, 'root') and self.parent.root:
                try:
                    return self.parent.root.globalgetvar(var_name)
                except tk.TclError:
                    logger.warning(f"TclError getting var '{var_name}' for {param_name}. Returning default.")
                    return default_value
            else:
                logger.warning(f"Could not get textvariable for OptionMenu '{param_name}'. Returning default.")
                return default_value
        elif isinstance(widget_info, tk.Widget): # Handle other widget types if needed later
             pass # Add logic for Entry, Checkbutton etc. if necessary
        # Fallback or if widget not found
        return default_value

    def _on_colormap_selected(self, param_name: str, var: tk.StringVar):
        """Handles selection change in colormap comboboxes."""
        selected_display_value = var.get()
        logger.debug(f"_on_colormap_selected: Param='{param_name}', Selected Display='{selected_display_value}'")

        # Convert "(None)" string to actual None value for the parameter change handler
        value_to_apply = None if selected_display_value == "(None)" else selected_display_value

        # Create a temporary StringVar to pass the potentially modified value
        temp_var = tk.StringVar(value=str(value_to_apply) if value_to_apply is not None else "") # Pass empty string if None

        # Call the standard parameter change handler
        self._on_parameter_change(param_name, temp_var)

    def _open_rule_color_picker(self, param_name: str, color_var: tk.StringVar, preview_canvas: tk.Canvas):
        """Opens color chooser and updates variable, entry, and preview.
           (Round 22: New method)"""
        current_color = color_var.get()
        initial_color_hex = current_color if current_color and current_color.startswith('#') and len(current_color) == 7 else None # Check if valid hex

        color_info = colorchooser.askcolor(initialcolor=initial_color_hex or "", title=f"Choose Color for {param_name}", parent=self)

        if color_info and color_info[1]: # Check if a color was selected and hex is available
            new_color_hex = color_info[1]
            color_var.set(new_color_hex) # Update variable FIRST
            self._update_rule_color_preview(param_name, new_color_hex) # Update preview
            self._on_parameter_change(param_name, color_var) # Trigger change handler

    def _update_rule_color_preview(self, param_name: str, hex_color: Optional[str]):
        """Updates the background color of the preview canvas for a color picker.
           (Round 22: New method)
           (Round 7: Corrected dictionary key access for canvas)"""
        # --- MODIFIED: Access parameter_entry_details directly ---
        widget_details = getattr(self, 'parameter_entry_details', {}).get(param_name)
        # --- END MODIFIED ---

        if isinstance(widget_details, dict):
            # --- MODIFIED: Use correct key 'canvas' ---
            canvas = widget_details.get('canvas')
            # --- END MODIFIED ---
            if isinstance(canvas, tk.Canvas):
                try:
                    # Use parent background if hex_color is None or invalid
                    valid_color = hex_color if hex_color and hex_color.startswith('#') and len(hex_color) == 7 else canvas.master.cget('bg')
                    canvas.config(bg=valid_color)
                except tk.TclError:
                    # Handle cases where the color string might be invalid temporarily
                    # or widget destroyed during update
                    try:
                        if canvas.winfo_exists():
                             canvas.config(bg=canvas.master.cget('bg')) # Fallback to parent bg
                    except tk.TclError: pass # Ignore if widget destroyed during fallback
                except Exception as e:
                    logger.warning(f"Error updating color preview for {param_name}: {e}")
            # --- ADDED: Log if canvas widget not found ---
            elif canvas is None:
                 logger.warning(f"Could not find 'canvas' widget in details for param '{param_name}'")
            else:
                 logger.warning(f"Widget found for 'canvas' key is not a tk.Canvas (Type: {type(canvas)}) for param '{param_name}'")
            # --- END ADDED ---
        # --- ADDED: Log if widget details not found or not dict ---
        elif widget_details is None:
             logger.warning(f"No widget details found in parameter_entry_details for param '{param_name}'")
        else:
             logger.warning(f"Widget details for param '{param_name}' is not a dictionary (Type: {type(widget_details)})")
        # --- END ADDED ---

    def _create_standard_settings_section(self, parent_frame: tk.Frame, rule_name: str) -> tk.LabelFrame:
        """Create the standard settings section in the Rule Editor window"""
        settings_frame = tk.LabelFrame(parent_frame, text="Standard Settings")
        settings_frame.pack(fill=tk.X, padx=5, pady=5)

        # Dimension selection
        dimension_label = tk.Label(settings_frame, text="Dimension:")
        dimension_label.pack(anchor="w")
        dimension_var = tk.StringVar(value=self.parent.controller.dimension_type.name)
        dimension_menu = tk.OptionMenu(settings_frame, dimension_var, *[dim.name for dim in Dimension],
                                        command=lambda value: self.parent._on_dimension_change(value.get()))
        dimension_menu.pack(fill=tk.X, padx=5, pady=2)
        self.widgets['dimension_menu'] = dimension_menu  # Store in self.widgets

        # Neighborhood selection
        neighborhood_label = tk.Label(settings_frame, text="Neighborhood Type:")
        neighborhood_label.pack(anchor="w")
        neighborhood_var = tk.StringVar(value=self.parent.controller.neighborhood_type.name)
        neighborhood_menu = tk.OptionMenu(settings_frame, neighborhood_var, *[n.name for n in NeighborhoodType],
                                            command=lambda value: self.parent._on_neighborhood_change(value.get()))
        neighborhood_menu.pack(fill=tk.X, padx=5, pady=2)
        self.widgets['neighborhood_menu'] = neighborhood_menu  # Store in self.widgets

        # Initial Conditions selection
        initial_conditions_label = tk.Label(settings_frame, text="Initial Conditions:")
        initial_conditions_label.pack(anchor="w")
        # self.initial_conditions_var already initialized in __init__
        initial_conditions_menu = tk.OptionMenu(
            settings_frame,
            self.initial_conditions_var,
            "Random",  # Default option
            "2D - Circle", "2D - Square", "3D - Sphere", "3D - Cube", "ShapeShifting",
            command=lambda value: self.parent._on_initial_conditions_change(self.initial_conditions_var.get())
        )
        initial_conditions_menu.pack(fill=tk.X, padx=5, pady=2)
        self.widgets['initial_conditions_menu'] = initial_conditions_menu  # Store in self.widgets

        return settings_frame

    def _get_current_rule_data(self) -> Dict[str, Any]:
        """
        Get current rule data including changes from UI widgets across ALL tabs,
        ensuring correct types. Handles color pickers and rule tables.
        (Round 45: Correctly read visualization widget values)
        """
        try:
            log_prefix = f"RuleEditorWindow._get_current_rule_data (Rule: {self.rule_name} R45): " # Updated round
            logger.info(f"{log_prefix}--- START Gathering Data ---")

            # Start with original metadata, update specific fields later
            base_metadata = {k: v for k, v in self.rule_data.items() if k != 'params' and k != '_ignored_params'}

            current_data = {
                'name': self.name_var.get() if hasattr(self, 'name_var') else self.rule_name,
                'type': base_metadata.get('type', 'Unknown'),
                'category': base_metadata.get('category', 'Unknown'), # Will be updated from metadata_fields
                'author': base_metadata.get('author', ''), 'url': base_metadata.get('url', ''),
                'email': base_metadata.get('email', ''), 'date_created': base_metadata.get('date_created', ''),
                'date_modified': datetime.now().strftime("%Y-%m-%d"), # Always update modified date
                'version': base_metadata.get('version', '1.0'),
                'description': base_metadata.get('description', ''), # Will be updated
                'tags': base_metadata.get('tags', []), # Will be updated
                'dimension_compatibility': base_metadata.get('dimension_compatibility', []), # Will be updated
                'neighborhood_compatibility': base_metadata.get('neighborhood_compatibility', []), # Will be updated
                'parent_rule': base_metadata.get('parent_rule'),
                'rating': base_metadata.get('rating'), # Will be updated
                'notes': base_metadata.get('notes'), # Will be updated
                'allowed_initial_conditions': base_metadata.get('allowed_initial_conditions', []), # Will be updated
                'allow_rule_tables': base_metadata.get('allow_rule_tables', True), # Will be updated
                'favorite': False, # Will be updated
                'position': base_metadata.get('position', 1),
                'params': {} # Start with empty params
            }

            # --- Get Parameter Values from ALL relevant widgets ---
            logger.debug(f"{log_prefix}Processing {len(self.parameter_entries)} parameter entries...")
            if hasattr(self, 'parameter_entries'):
                logger.debug(f"{log_prefix}Keys in self.parameter_entries: {list(self.parameter_entries.keys())}")
                for param_name, widget_info in self.parameter_entries.items():
                    if param_name.endswith('_rule_table'): continue # Skip rule tables here

                    value_str = ""; value_actual = None; param_info = {}
                    rule_instance = self.controller.rule if self.controller and self.controller.rule else None
                    if rule_instance: param_info = rule_instance.PARAMETER_METADATA.get(param_name, {})
                    param_type = param_info.get('type')

                    # --- Get value based on widget type ---
                    widget_to_get_from: Optional[tk.Widget] = None
                    is_color_picker = False # Flag for color picker

                    if isinstance(widget_info, tk.Widget):
                        widget_to_get_from = widget_info
                    elif isinstance(widget_info, dict) and 'var' in widget_info and 'entry' in widget_info: # Color Picker
                        is_color_picker = True
                        color_var = widget_info.get('var')
                        if isinstance(color_var, tk.StringVar):
                            value_str = color_var.get()
                            # Store the raw hex string (or empty) directly
                            value_actual = value_str if value_str and value_str.startswith('#') else None
                            logger.debug(f"    Got value for COLOR param '{param_name}': '{value_actual}'")
                        else:
                            logger.warning(f"{log_prefix}Color picker for '{param_name}' has invalid 'var'.")
                            continue
                    else:
                        logger.warning(f"{log_prefix}Unhandled item type in parameter_entries for '{param_name}': {type(widget_info)}")
                        continue

                    if widget_to_get_from: # If it's a standard widget
                        if isinstance(widget_to_get_from, (tk.Entry, ValidatedEntry)): value_str = widget_to_get_from.get()
                        elif isinstance(widget_to_get_from, tk.OptionMenu):
                            var_name = widget_to_get_from.cget('textvariable')
                            if var_name: value_str = self.parent.root.globalgetvar(var_name) if self.parent.root else ""
                            else: logger.warning(f"{log_prefix}No textvariable for OptionMenu '{param_name}'."); continue
                        elif isinstance(widget_to_get_from, ttk.Combobox):
                            value_str = widget_to_get_from.get()
                            # --- Handle "(None)" for colormaps ---
                            if param_name in ('node_colormap', 'edge_colormap') and value_str == "(None)":
                                value_actual = None # Store None if "(None)" is selected
                                logger.debug(f"    Got value for COLORMAP param '{param_name}': None (from '(None)')")
                            # ---
                        elif isinstance(widget_to_get_from, tk.Checkbutton):
                            var_name = widget_to_get_from.cget('variable')
                            if var_name:
                                try: value_actual = bool(self.parent.root.globalgetvar(var_name))
                                except tk.TclError: value_actual = None
                            else: logger.warning(f"{log_prefix}No variable for Checkbutton '{param_name}'."); continue
                        else: logger.warning(f"{log_prefix}Unhandled widget type '{type(widget_to_get_from)}' for param '{param_name}'."); continue
                        # Log only if value_actual wasn't already set (by bool or colormap)
                        if value_actual is None and not is_color_picker:
                             logger.debug(f"    Got value for param '{param_name}': '{value_str}' (Type: {type(widget_to_get_from).__name__})")

                    # --- Convert and Store ---
                    try:
                        converted_value = None
                        if value_actual is not None: # Use directly if already processed (bool, colormap None, color hex)
                            converted_value = value_actual
                        else: # Convert other types from string
                            converted_value = self._convert_parameter_value(param_name, value_str)

                        current_data['params'][param_name] = converted_value
                        logger.debug(f"    Stored param '{param_name}' = {converted_value} (Type: {type(converted_value)})")
                    except ValueError as e:
                        logger.warning(f"{log_prefix}Could not convert value for param '{param_name}' ('{value_str}'): {e}. Storing raw string.")
                        current_data['params'][param_name] = value_str # Store raw on error
                    except Exception as e:
                        logger.error(f"{log_prefix}Unexpected error getting/converting param '{param_name}': {e}")
                        current_data['params'][param_name] = self.rule_data.get('params', {}).get(param_name) # Fallback to original

            else: # parameter_entries missing
                logger.warning(f"{log_prefix}parameter_entries attribute not found.")
                current_data['params'] = copy.deepcopy(self.rule_data.get('params', {}))

            # [ Get Rule Table Values - Unchanged ]
            if hasattr(self, 'table_name') and self.table_name:
                current_data['params'][self.table_name] = self.get_table_data()
            else:
                if 'state_rule_table' in self.rule_data.get('params', {}): current_data['params']['state_rule_table'] = self.rule_data['params']['state_rule_table']
                if 'edge_rule_table' in self.rule_data.get('params', {}): current_data['params']['edge_rule_table'] = self.rule_data['params']['edge_rule_table']

            # [ Get Metadata Values - Unchanged ]
            if hasattr(self, 'metadata_fields'):
                logger.debug(f"{log_prefix}Processing {len(self.metadata_fields)} metadata fields.")
                for field_name, widget in self.metadata_fields.items():
                    if field_name == 'name': continue # Handled above
                    value: Any = ""
                    if isinstance(widget, tk.Text): value = widget.get("1.0", tk.END).strip()
                    elif isinstance(widget, tk.Entry): value = widget.get().strip()
                    elif field_name == 'rating' and isinstance(widget, (tk.OptionMenu, ttk.Combobox)):
                        var_name = widget.cget('textvariable')
                        rating_str = self.parent.root.globalgetvar(var_name) if var_name else "None"
                        if rating_str == "None": value = None
                        else: value = len(rating_str)
                    elif isinstance(widget, tk.Checkbutton):
                        var_name = widget.cget('variable'); value = self.parent.root.globalgetvar(var_name) if var_name else False
                    if field_name in ['tags', 'dimension_compatibility', 'neighborhood_compatibility', 'allowed_initial_conditions'] and isinstance(value, str):
                        try: parsed_value = ast.literal_eval(value); value = list(parsed_value) if isinstance(parsed_value, (list, tuple)) else [x.strip() for x in value.split(',') if x.strip()]
                        except: value = [x.strip() for x in value.split(',') if x.strip()]
                    current_data[field_name] = value
            else:
                logger.warning(f"{log_prefix}metadata_fields attribute not found.")

            # [ Get Favorite Value - Unchanged ]
            if hasattr(self, 'favorite_var') and isinstance(self.favorite_var, tk.BooleanVar):
                current_data['favorite'] = self.favorite_var.get()
                logger.debug(f"{log_prefix}Got favorite value: {current_data['favorite']}")
            else:
                logger.warning(f"{log_prefix}Favorite checkbox variable not found, defaulting favorite to False.")
                current_data['favorite'] = False

            logger.info(f"{log_prefix}--- END Gathering Data --- Returning data for: {current_data.get('name')}")
            return current_data

        except Exception as e:
            logger.error(f"{log_prefix}Error getting current rule data: {e}")
            logger.error(traceback.format_exc())
            return copy.deepcopy(self.rule_data) if hasattr(self, 'rule_data') else {}
                    
    def _convert_parameter_value(self, param_name: str, value_str: str) -> Any:
        """Convert parameter string value to appropriate type, including lists/tuples and None for colormaps."""

        try:
            # --- MODIFIED: Handle None value for colormaps EARLY ---
            if param_name in ('node_colormap', 'edge_colormap') and value_str == "(None)":
                logger.debug(f"Converting '{value_str}' to None for colormap parameter '{param_name}'.")
                return None
            # --- END MODIFIED ---

            param_info = self.parent.controller.rule.PARAMETER_METADATA.get(param_name)
            if param_info is None:
                current_value = self.parent.controller.rule.params.get(param_name)
                param_type = type(current_value) if current_value is not None else str
                logger.warning(f"Parameter '{param_name}' not in PARAMETER_METADATA. Inferring type as {param_type}.")
            else:
                param_type = param_info.get('type')

            # --- Keep existing conversion logic ---
            if param_type == float:
                new_value = float(value_str)
                min_val = param_info.get('min') if param_info else None
                max_val = param_info.get('max') if param_info else None
                if min_val is not None and new_value < min_val: raise ValueError(f"Value must be >= {min_val}")
                if max_val is not None and new_value > max_val: raise ValueError(f"Value must be <= {max_val}")
            elif param_type == int:
                new_value = int(float(value_str))
                min_val = param_info.get('min') if param_info else None
                max_val = param_info.get('max') if param_info else None
                if min_val is not None and new_value < min_val: raise ValueError(f"Value must be >= {min_val}")
                if max_val is not None and new_value > max_val: raise ValueError(f"Value must be <= {max_val}")
            elif param_type == bool:
                value_str_lower = value_str.lower()
                if value_str_lower in ('true', '1', 'yes', 'on'): new_value = True
                elif value_str_lower in ('false', '0', 'no', 'off'): new_value = False
                else: raise ValueError("Boolean must be true/false, 1/0, yes/no, on/off")
            elif param_type == list:
                try:
                    parsed_value = ast.literal_eval(value_str)
                    if not isinstance(parsed_value, list): raise ValueError("Input does not evaluate to a list.")
                    element_type = param_info.get('element_type') if param_info else None
                    if element_type == tuple:
                        converted_list = []
                        for item in parsed_value:
                            if isinstance(item, list): converted_list.append(tuple(item))
                            elif isinstance(item, tuple): converted_list.append(item)
                            else: raise TypeError(f"Inner element '{item}' is not a list or tuple")
                        new_value = converted_list
                    elif element_type and not all(isinstance(item, element_type) for item in parsed_value):
                         raise ValueError(f"All list elements must be of type {element_type}.")
                    else: new_value = parsed_value
                except (ValueError, SyntaxError, TypeError) as e:
                    raise ValueError(f"Invalid list format: {e}. Use Python list syntax (e.g., [1, 2, 3] or [[1,2],[3,4]])") from e
            elif param_type == tuple:
                try:
                    parsed_value = ast.literal_eval(value_str)
                    if not isinstance(parsed_value, tuple): raise ValueError("Input does not evaluate to a tuple.")
                    new_value = parsed_value
                except (ValueError, SyntaxError, TypeError) as e:
                    raise ValueError(f"Invalid tuple format: {e}. Use Python tuple syntax (e.g., (1, 5))") from e
            else: # Default to string
                new_value = value_str
                allowed = param_info.get('allowed_values') if isinstance(param_info, dict) else None
                # --- MODIFIED: Allow None if "(None)" was handled earlier ---
                if allowed and new_value is not None and new_value not in allowed:
                # ---
                    raise ValueError(f"Value must be one of: {', '.join(map(str, allowed))}")

            return new_value

        except ValueError as e: raise ValueError(f"{str(e)}") from e
        except Exception as e: raise ValueError(f"Invalid value '{value_str}' for {param_name}: {str(e)}") from e

    def _apply_parameters_from_shortcut(self, event=None):
        """Wrapper for Shift+Return shortcut to add logging."""
        logger.info("Shift+Return detected, calling _apply_parameters.")
        self._apply_parameters()

    def _prompt_rename_rule(self):
        """Prompts the user for a new rule name and initiates the rename process."""
        log_prefix = "RuleEditorWindow._prompt_rename_rule: "
        logger.debug(f"{log_prefix}Prompting for new rule name.")

        current_name = self.rule_name
        new_name = simpledialog.askstring(
            "Rename Rule",
            f"Enter new name for rule '{current_name}':",
            initialvalue=current_name,
            parent=self
        )

        if not new_name or not new_name.strip():
            logger.debug(f"{log_prefix}Rename cancelled (no name entered).")
            return

        new_name = new_name.strip()

        if new_name == current_name:
            logger.debug(f"{log_prefix}New name is the same as the current name. No action needed.")
            return

        # Check for conflicts with existing rule names
        manager = RuleLibraryManager.get_instance()
        if new_name in manager.rules:
            messagebox.showerror("Name Conflict", f"A rule named '{new_name}' already exists. Please choose a different name.", parent=self)
            logger.warning(f"{log_prefix}Rename failed: Name '{new_name}' already exists.")
            return

        # Proceed with the rename
        self._execute_rename_rule(new_name)

    def _execute_rename_rule(self, new_name: str):
        """Executes the rule rename operation, saves the change, and updates the GUI."""
        log_prefix = f"RuleEditorWindow._execute_rename_rule(NewName='{new_name}'): "
        logger.info(f"{log_prefix}Executing rename from '{self.rule_name}' to '{new_name}'.")

        old_name = self.rule_name
        manager = RuleLibraryManager.get_instance()

        try:
            # 1. Get the current rule data under the OLD name
            # Use deepcopy to avoid modifying the manager's cache directly
            rule_data_to_modify = copy.deepcopy(manager.get_rule(old_name))

            # 2. Update the name within the data
            rule_data_to_modify['name'] = new_name
            rule_data_to_modify['date_modified'] = datetime.now().strftime("%Y-%m-%d")

            # 3. Save the modified data under the NEW name
            # The manager's save_rule should handle overwriting if the new name somehow exists
            # (though we checked earlier) and potentially removing the old entry if needed.
            # For safety, explicitly delete the old rule first.
            try:
                manager.delete_rule(old_name)
                logger.debug(f"{log_prefix}Deleted old rule entry '{old_name}'.")
            except ValueError:
                logger.warning(f"{log_prefix}Old rule '{old_name}' not found for deletion (might be intended if saving as new).")
            except Exception as del_err:
                logger.error(f"{log_prefix}Error deleting old rule '{old_name}': {del_err}")
                # Continue attempting to save the new one

            if manager.save_rule(new_name, rule_data_to_modify):
                logger.info(f"{log_prefix}Rule successfully saved with new name '{new_name}'.")

                # 4. Update the Editor's internal state
                self.rule_name = new_name
                self.rule_data = rule_data_to_modify # Update editor's data reference
                self.title(f"Rule Editor - {new_name}")
                self.name_var.set(new_name) # Update UI variable

                # 5. Reset Change Tracker for the renamed rule
                if tracker := self._get_change_tracker():
                    tracker.initialize(self.rule_data)
                self._update_editor_buttons()

                # 6. Trigger Main GUI Update (Crucial)
                # This tells the main GUI to switch to the newly named rule
                logger.info(f"{log_prefix}Triggering main GUI update to switch to rule '{new_name}'.")
                if self.parent and hasattr(self.parent, 'set_rule'):
                    # Schedule the call to ensure Tkinter updates are processed first
                    self.parent.root.after(50, lambda name=new_name: self.parent.set_rule(name))
                else:
                    logger.error(f"{log_prefix}Cannot trigger main GUI update: Parent or set_rule method missing.")

                self._show_message(f"Rule renamed to '{new_name}' and saved.", error=False)

            else:
                logger.error(f"{log_prefix}Failed to save rule with new name '{new_name}' via manager.")
                messagebox.showerror("Save Error", f"Failed to save rule with new name '{new_name}'. Check logs.", parent=self)
                # Attempt to restore the old rule data if save failed? Complex, maybe just log.

        except Exception as e:
            logger.error(f"{log_prefix}Error executing rename: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Rename Error", f"An unexpected error occurred during rename: {e}", parent=self)

    def _check_unsaved_changes(self) -> bool:
        """Check for unsaved changes and prompt user"""
        try:
            if self.change_tracker and self.change_tracker.is_modified():
                response = messagebox.askyesnocancel(
                    "Unsaved Changes",
                    "There are unsaved changes to the current rule. Would you like to save them before closing?",
                    icon='warning'
                )

                if response is None:  # Cancel
                    return False
                elif response:  # Yes, save
                    current_rule_data = self._get_current_rule_data()
                    return self._save_rule_with_confirmation(self.rule_name, current_rule_data, self)

                # No, don't save
                return True

            return True  # No unsaved changes

        except Exception as e:
            logger.error(f"Error checking unsaved changes: {e}")
            return False  # On error, prevent action to be safe

    def _on_rule_editor_close(self):
        """Handle closing of the rule editor window, including checking for unsaved changes."""
        try:
            # Check if the editor window still exists
            if not tk.Toplevel.winfo_exists(self):
                logger.warning("Rule editor window already destroyed, skipping close actions")
                return

            # Check for changes using the local method
            if not self._check_unsaved_changes():
                return

            logger.info(f"Closing Rule Editor for rule: {self.rule_name}")

            # Unbind tab change event
            if hasattr(self, 'tab_change_binding') and self.tab_change_binding:
                try:
                    if self.notebook is not None:
                        self.notebook.unbind("<<NotebookTabChanged>>", self.tab_change_binding)
                except Exception as e:
                    logger.warning(f"Error unbinding tab change event: {e}")
                self.tab_change_binding = None  # Clear the binding ID

            # Destroy the editor window
            try:
                self.destroy()
            except Exception as e:
                logger.warning(f"Error destroying editor window: {e}")

            # Clear pending rule data
            if hasattr(self, '_pending_rule_data'):
                self._pending_rule_data = None

            # IMPORTANT: Make sure the rule instance selector shows the correct rule
            # This ensures the dropdown stays in sync with the actual selected rule
            current_rule = self.parent.rule_instance_var.get()
            logger.info(f"Ensuring rule selector shows: {current_rule}")
            self.parent._update_rule_instance_selector()

        except Exception as e:
            logger.error(f"Error closing Rule Editor: {e}")
            messagebox.showerror("Error", f"Failed to close editor: {e}")

    def _open_category_manager(self):
        """Opens the category manager window."""
        # Check if already open
        if hasattr(self, 'category_manager_window') and self.category_manager_window and self.category_manager_window.winfo_exists():
            self.category_manager_window.lift()
            logger.info("Category manager window already open, bringing to front.")
            return

        try:
            self.category_manager_window = CategoryManagerWindow(self.parent) # Pass the main GUI as parent
            logger.info("Opened Category Manager window.")
        except Exception as e:
            logger.error(f"Error opening category manager window: {e}")
            messagebox.showerror("Error", f"Could not open Category Manager: {e}", parent=self)

    def _show_message(self, message: str, error: bool = False, duration_ms: int = 3000, parent: Optional[tk.Widget] = None):
        """Displays a message in the message bar label.
           (Round 40: Add logging)"""
        log_prefix = "RuleEditorWindow._show_message: " # Added prefix
        logger.debug(f"{log_prefix}Attempting to show message: '{message}', Error={error}") # Added logging

        if not hasattr(self, 'message_bar_label') or not self.message_bar_label:
            logger.warning(f"{log_prefix}Message bar label not found, using messagebox fallback.")
            if parent is None: parent = cast(tk.Widget, self)
            if error: messagebox.showerror("Error", message, parent=parent)
            else: messagebox.showinfo("Info", message, parent=parent)
            return

        try:
            if self.message_bar_label.winfo_exists():
                fg_color = "red" if error else "green"
                self.message_bar_label.config(text=message, fg=fg_color)
                logger.debug(f"{log_prefix}Message displayed in label.") # Added logging
                # Clear the message after a delay
                self.message_bar_label.after(duration_ms, lambda: self.message_bar_label.config(text="") if self.message_bar_label and self.message_bar_label.winfo_exists() else None)
            else:
                logger.warning(f"{log_prefix}Message bar label destroyed, cannot show message.")
        except tk.TclError:
             logger.warning(f"{log_prefix}TclError accessing message bar label (likely destroyed).")
        except Exception as e:
            logger.error(f"{log_prefix}Error showing message in message bar: {e}")

    def _update_gui_after_save(self, saved_rule_name: str, saved_rule_data: Dict[str, Any],
                                   dialog_to_destroy: Optional[tk.Toplevel], verified: bool, save_mode: str):
        """
        Updates editor state after save and triggers main GUI update via set_rule.
        Main GUI update (selectors, etc.) is now handled entirely within set_rule.
        (Round 7: Simplify callback, rely on set_rule for GUI updates)
        """
        log_prefix_cb = f"RuleEditorWindow._update_gui_after_save(Rule='{saved_rule_name}', Mode='{save_mode}' R7): " # Updated round
        logger.debug(f"{log_prefix_cb}Starting GUI update trigger.")
        try:
            # Destroy the confirmation dialog
            if dialog_to_destroy and dialog_to_destroy.winfo_exists(): dialog_to_destroy.destroy()

            # Check if editor window still exists
            editor_exists = self.winfo_exists()
            if not editor_exists:
                logger.warning(f"{log_prefix_cb}Editor window destroyed before GUI update callback executed.")
                return

            # Check if parent GUI still exists
            parent_gui = self.parent
            parent_exists = isinstance(parent_gui, tk.Widget) and parent_gui.winfo_exists()

            # --- Update Editor Window State FIRST (if 'Save As') ---
            if save_mode == "new":
                logger.info(f"{log_prefix_cb}'Save As' detected. Updating editor window state to rule '{saved_rule_name}'.")
                self.rule_name = saved_rule_name
                self.rule_data = copy.deepcopy(saved_rule_data) # Use deepcopy
                self.title(f"Rule Editor - {saved_rule_name}")
                self.name_var.set(saved_rule_name) # Update name variable in editor UI

                # Reset change tracker for the NEW rule state
                if hasattr(self, 'change_tracker') and self.change_tracker:
                    self.change_tracker.initialize(self.rule_data)
                    logger.debug(f"{log_prefix_cb}Reset change tracker for editor window (New Rule: {saved_rule_name}).")
            elif save_mode == "overwrite":
                 # For overwrite, ensure editor's internal data matches saved data
                 self.rule_data = copy.deepcopy(saved_rule_data)
                 if hasattr(self, 'change_tracker') and self.change_tracker:
                     self.change_tracker.initialize(self.rule_data) # Re-init tracker
                     logger.debug(f"{log_prefix_cb}Reset change tracker for editor window (Overwrite: {saved_rule_name}).")
            # ---

            # --- Trigger Main GUI Update (if parent exists) ---
            if parent_exists:
                logger.debug(f"{log_prefix_cb}Reloading RuleLibraryManager in main GUI.")
                RuleLibraryManager.get_instance().reload_library()

                # --- Trigger set_rule on the parent GUI ---
                logger.info(f"{log_prefix_cb}Calling parent_gui.set_rule for '{saved_rule_name}'.")
                set_rule_success = parent_gui.set_rule(saved_rule_name) # Apply the rule change
                # ---

                if not set_rule_success:
                    logger.error(f"{log_prefix_cb}parent_gui.set_rule FAILED for '{saved_rule_name}'.")
                    # Show error in editor if it still exists
                    if self.winfo_exists():
                        self._show_message(f"Error applying rule '{saved_rule_name}' to main GUI.", error=True)
                    return # Stop if set_rule failed
            else:
                logger.error(f"{log_prefix_cb}Parent GUI destroyed, cannot trigger rule update.")
                return # Stop if parent is gone
            # ---

            # --- Recreate Editor Window UI AFTER main GUI update (if editor exists) ---
            # Check existence again as set_rule might take time or cause issues
            if self.winfo_exists():
                logger.debug(f"{log_prefix_cb}Recreating editor tab content for rule '{self.rule_name}'...")
                self._recreate_parameter_tab_content()
                self._recreate_visualization_tab_content()
                self._recreate_rule_table_tab_content()
                self._recreate_metadata_tab_content()
                logger.debug(f"{log_prefix_cb}Editor tab content recreated.")

                # Update editor buttons
                self._update_editor_buttons()

                # Show success message in EDITOR'S message bar
                if verified: self._show_message(f"Rule '{saved_rule_name}' saved successfully!", error=False)
                else: self._show_message(f"Rule '{saved_rule_name}' saved, but verification failed. Check logs.", error=True)
            else:
                logger.warning(f"{log_prefix_cb}Editor window destroyed during parent GUI update. Skipped editor UI recreation.")
            # ---

        except Exception as e:
            logger.error(f"{log_prefix_cb}Error updating GUI after save: {e}")
            logger.error(traceback.format_exc())
            # Show error in editor if it exists, otherwise in parent
            target_parent = self if self.winfo_exists() else parent_gui.root if parent_exists else None
            if target_parent:
                # Use lambda to ensure cast happens in the main thread if needed
                self.parent.root.after(0, lambda: self._show_message(f"Error updating GUI after save: {e}", error=True, parent=cast(tk.Widget, target_parent)))

    def _check_save_result(self, result_queue: queue.Queue):
        """Checks the result queue from the save thread and updates GUI accordingly.
           (Round 9: Fix missing argument and parent window check)"""
        log_prefix = "RuleEditorWindow._check_save_result (R9 Fix): " # Updated round
        try:
            result = result_queue.get_nowait()
            logger.debug(f"{log_prefix}Received result from save thread: {result}")

            if result['success']:
                # Call the simplified update method for the editor
                # Pass None for dialog_to_destroy as it's already destroyed
                self._update_gui_after_save(
                    result['rule_name'],
                    result['rule_data'],
                    dialog_to_destroy=None, # Pass None
                    verified=result['verified'],
                    save_mode=result['save_mode']
                )
                # Trigger the main GUI update
                # --- MODIFIED: Check parent.root.winfo_exists() ---
                if self.parent and hasattr(self.parent, 'root') and self.parent.root and self.parent.root.winfo_exists():
                # ---
                    logger.info(f"{log_prefix}Calling parent_gui.set_rule for '{result['rule_name']}'")
                    set_rule_success = self.parent.set_rule(result['rule_name'])
                    if not set_rule_success:
                        logger.error(f"{log_prefix}parent_gui.set_rule FAILED for '{result['rule_name']}'.")
                        self._show_message(f"Error applying rule '{result['rule_name']}' to main GUI.", error=True)
                else:
                    logger.error(f"{log_prefix}Parent GUI or its root window destroyed, cannot trigger rule update.")
            else:
                error_msg = result.get('error', 'Unknown error')
                self._show_message(f"Error saving rule: {error_msg}", error=True)

        except queue.Empty:
            # Result not ready yet, check again
            # --- MODIFIED: Check self.winfo_exists() before scheduling ---
            if self.winfo_exists():
                self.after(100, self._check_save_result, result_queue)
            else:
                logger.warning(f"{log_prefix}Editor destroyed, stopping check.")
            # ---
        except Exception as e:
            logger.error(f"{log_prefix}Error checking save result: {e}")
            self._show_message(f"Error checking save result: {e}", error=True)

    def _save_rule_with_confirmation(self, rule_name: str, rule_data: Dict[str, Any], window: Optional[tk.Toplevel] = None) -> bool:
        """Save rule with current parameters and metadata, using a thread for file I/O. Keeps editor open on save.
           Provides feedback via message bar. Includes save verification.
           Updates editor state and triggers main GUI update after successful save.
           (Round 8: Trigger parent update synchronously after save thread)"""
        log_prefix = f"RuleEditorWindow._save_rule_with_confirmation (Rule: {rule_name} R8): " # Updated round
        logger.info(f"{log_prefix}Initiating save process.")
        try:
            # Get current data
            rule_data_to_save = self._get_current_rule_data()
            if not rule_data_to_save:
                logger.error(f"{log_prefix}Failed to get current rule data. Aborting save.")
                self._show_message("Error: Could not retrieve current rule data.", error=True)
                return False

            # Validate rule tables before saving
            params = rule_data_to_save.get('params', {})
            if 'state_rule_table' in params:
                try: self._validate_rule_table(params['state_rule_table'], 'state')
                except ValueError as e: self._show_message(f"Invalid State Rule Table: {e}", error=True); return False
            if 'edge_rule_table' in params:
                try: self._validate_rule_table(params['edge_rule_table'], 'edge')
                except ValueError as e: self._show_message(f"Invalid Edge Rule Table: {e}", error=True); return False

            parent_gui_ref = self.parent
            dialog = tk.Toplevel(window if window and window.winfo_exists() else parent_gui_ref.root)
            dialog.title("Save Rule"); dialog_width = 600; dialog.geometry(f"{dialog_width}x200"); dialog.resizable(False, False)
            dialog.transient(window if window and window.winfo_exists() else parent_gui_ref.root); dialog.grab_set()
            tk.Label(dialog, text="How would you like to save the rule?").pack(pady=10, padx=10)
            save_choice = tk.StringVar(value="overwrite")
            overwrite_rb = tk.Radiobutton(dialog, text=f"Overwrite existing rule '{self.rule_name}'", variable=save_choice, value="overwrite", wraplength=dialog_width-40, justify=tk.LEFT)
            overwrite_rb.pack(anchor="w", padx=10)
            new_rb = tk.Radiobutton(dialog, text="Save as new rule", variable=save_choice, value="new", wraplength=dialog_width-40, justify=tk.LEFT)
            new_rb.pack(anchor="w", padx=10)
            new_name_frame = tk.Frame(dialog); new_name_frame.pack(fill="x", padx=10, pady=5)
            tk.Label(new_name_frame, text="New rule name:").pack(side="left")
            new_name_entry = tk.Entry(new_name_frame); new_name_entry.pack(side="left", fill="x", expand=True, padx=5)
            new_name_entry.insert(0, rule_data_to_save['name'] + "_copy"); new_name_entry.config(state=tk.DISABLED)
            def toggle_new_name_entry(*args): new_name_entry.config(state=tk.NORMAL if save_choice.get() == "new" else tk.DISABLED)
            save_choice.trace_add("write", toggle_new_name_entry)

            # --- Use a queue to get results back from the thread ---
            save_result_queue: queue.Queue[Dict[str, Any]] = queue.Queue(maxsize=1)
            # ---

            def on_save():
                final_rule_name = self.rule_name
                final_rule_data = copy.deepcopy(rule_data_to_save)
                save_mode = save_choice.get() # Store save mode ('overwrite' or 'new')

                if save_mode == "new":
                    new_name = new_name_entry.get().strip()
                    if not new_name: self._show_message("Error: New rule name cannot be empty.", error=True, parent=cast(tk.Widget, dialog)); return # Fixed: cast dialog to Widget before passing it.
                    if new_name in RuleLibraryManager.get_instance().rules:
                        if not messagebox.askyesno("Confirm Overwrite", f"A rule named '{new_name}' already exists. Overwrite?", icon='warning', parent=dialog): return
                    final_rule_name = new_name; final_rule_data['name'] = new_name; final_rule_data['date_created'] = datetime.now().strftime("%Y-%m-%d"); final_rule_data['version'] = '1.0'
                    if 'tags' in final_rule_data and isinstance(final_rule_data['tags'], list): final_rule_data['tags'] = [t for t in final_rule_data['tags'] if t != 'default']

                logger.debug(f"{log_prefix}Data being passed to manager.save_rule for '{final_rule_name}':")
                logger.debug(f"  Metadata Keys: {list(k for k in final_rule_data if k != 'params')}")
                logger.debug(f"  Params Keys: {list(final_rule_data.get('params', {}).keys())}")
                viz_params_to_log = ['use_rule_specific_colors', 'node_colormap', 'background_color']
                for vp in viz_params_to_log:
                    if vp in final_rule_data.get('params', {}):
                        logger.debug(f"    Param '{vp}': {final_rule_data['params'][vp]}")

                # --- Close the dialog BEFORE starting the thread ---
                dialog.destroy()
                # ---

                def save_in_thread():
                    save_successful = False
                    verification_passed = False
                    error_message = None
                    try:
                        manager = RuleLibraryManager.get_instance()
                        manager.save_rule(final_rule_name, final_rule_data)
                        logger.info(f"Rule saved successfully via manager as: {final_rule_name}")
                        save_successful = True

                        try:
                            reloaded_data = manager.get_rule(final_rule_name)
                            if final_rule_data.get('params') == reloaded_data.get('params'):
                                verification_passed = True
                                logger.info(f"Save verification passed for '{final_rule_name}'.")
                            else:
                                logger.error(f"SAVE VERIFICATION FAILED for '{final_rule_name}'. Saved params differ from intended params.")
                                logger.debug(f"  Intended Params: {final_rule_data.get('params')}")
                                logger.debug(f"  Reloaded Params: {reloaded_data.get('params')}")
                        except Exception as verify_err:
                            logger.error(f"Error during save verification for '{final_rule_name}': {verify_err}")
                    except Exception as e:
                        logger.error(f"Error saving rule in thread: {e}")
                        error_message = str(e)
                    finally:
                        # --- Put result onto queue ---
                        save_result_queue.put({
                            'success': save_successful,
                            'verified': verification_passed,
                            'rule_name': final_rule_name,
                            'rule_data': final_rule_data,
                            'save_mode': save_mode,
                            'error': error_message
                        })
                        # ---

                threading.Thread(target=save_in_thread, daemon=True).start()
                # --- Schedule check for result ---
                self.after(100, self._check_save_result, save_result_queue)
                # ---

            def on_cancel(): dialog.destroy()
            button_frame = tk.Frame(dialog); button_frame.pack(fill="x", pady=10)
            tk.Button(button_frame, text="Save", command=on_save).pack(side="left", padx=10)
            tk.Button(button_frame, text="Cancel", command=on_cancel).pack(side="right", padx=10)
            dialog.update_idletasks()
            parent_win = window if window and window.winfo_exists() else parent_gui_ref.root
            x = parent_win.winfo_x() + (parent_win.winfo_width() - dialog_width) // 2
            y = parent_win.winfo_y() + (parent_win.winfo_height() - 200) // 2
            dialog.geometry(f"{dialog_width}x200+{x}+{y}")
            return True # Indicate dialog was shown
        except Exception as e:
            logger.error(f"Error initiating save dialog: {e}")
            logger.error(traceback.format_exc())
            self._show_message(f"Error initiating save: {e}", error=True)
            return False
                               
    def delete_rule(self):
        """Delete the current rule after confirmation."""
        if messagebox.askyesno("Delete Rule", f"Are you sure you want to delete the rule '{self.rule_name}'?", icon='warning'):
            try:
                RuleLibraryManager.get_instance().delete_rule(self.rule_name)
                messagebox.showinfo("Rule Deleted", f"The rule '{self.rule_name}' has been deleted.")
                
                # Close the editor window
                self.destroy()
                
                # Update the rule list in the main window
                # Use a safer approach that doesn't rely on type checking
                try:
                    # Attempt to call the method on the master window
                    if hasattr(self.parent, '_update_rule_instance_selector'):
                        self.parent._update_rule_instance_selector()
                        
                        # Try to select a new rule
                        if hasattr(self.parent, 'rule_type_var') and hasattr(self.parent, '_on_rule_instance_change'):
                            # Get available rules for the current category
                            current_rule_type = self.parent.rule_type_var.get()
                            available_rules = [rule for rule in RuleLibraryManager.get_instance().rules 
                                            if RuleLibraryManager.get_instance().rules[rule]['category'] == current_rule_type]
                            
                            # If there are rules available, select the first one
                            if available_rules:
                                self.parent._on_rule_instance_change(available_rules[0])
                                logger.info(f"Selected new rule after deletion: {available_rules[0]}")
                            else:
                                # If no rules are available in the current category, try to find any rule
                                all_rules = list(RuleLibraryManager.get_instance().rules.keys())
                                if all_rules and hasattr(self.parent, '_on_rule_type_change'):
                                    # Get the category of the first available rule
                                    new_category = RuleLibraryManager.get_instance().rules[all_rules[0]]['category']
                                    # Update the rule type dropdown
                                    self.parent.rule_type_var.set(new_category)
                                    # Update the rule instance dropdown
                                    self.parent._on_rule_type_change(new_category)
                                    # Select the first rule
                                    self.parent._on_rule_instance_change(all_rules[0])
                                    logger.info(f"Selected new rule after deletion: {all_rules[0]}")
                                else:
                                    logger.warning("No rules available after deletion")
                                    messagebox.showwarning("Warning", "No rules available after deletion. Please create a new rule.")
                except Exception as e:
                    logger.error(f"Error updating rule selection after deletion: {e}")
                    
            except Exception as e:
                logger.error(f"Error deleting rule: {e}")
                messagebox.showerror("Error", f"Failed to delete rule: {e}")

    def _validate_rule_table_completeness(self, table_data: dict, table_type: str) -> bool:
        """Validate that the rule table covers all necessary cases"""
        try:
            if table_type == 'state':
                # Check for required state transitions
                required_states = [-1, 0, 1]
                for current_state in required_states:
                    # Check basic transitions
                    for neighbor_pattern in itertools.product(['0', '1'], repeat=8):
                        for connection_pattern in itertools.product(['0', '1'], repeat=8):
                            key = f"({current_state}, {''.join(neighbor_pattern)}, {''.join(connection_pattern)})"
                            if key not in table_data and 'default' not in table_data:
                                raise ValueError(f"Missing rule for case: {key}")
                            
            else:  # edge table
                # Check for required edge rules
                required_states = [0, 1]
                for self_state in required_states:
                    for neighbor_state in required_states:
                        for connection_pattern in itertools.product(['0', '1'], repeat=8):
                            key = f"({self_state}, {neighbor_state}, {''.join(connection_pattern)})"
                            if key not in table_data and 'default' not in table_data:
                                raise ValueError(f"Missing rule for case: {key}")
                                
            return True
            
        except ValueError as e:
            logger.error(f"Completeness error: {e}")
            return False

    def _validate_rule_table_consistency(self, table_data: dict, table_type: str) -> bool:
        """Validate consistency across all rule table entries"""
        try:
            if table_type == 'state':
                # Check for required state transitions
                required_states = [-1, 0, 1]
                for current_state in required_states:
                    # Check basic transitions
                    for neighbor_pattern in itertools.product(['0', '1'], repeat=8):
                        for connection_pattern in itertools.product(['0', '1'], repeat=8):
                            key = f"({current_state}, {''.join(neighbor_pattern)}, {''.join(connection_pattern)})"
                            if key not in table_data and 'default' not in table_data:
                                raise ValueError(f"Missing rule for case: {key}")
                            
            else:  # edge table
                # Check for required edge rules
                required_states = [0, 1]
                for self_state in required_states:
                    for neighbor_state in required_states:
                        for connection_pattern in itertools.product(['0', '1'], repeat=8):
                            key = f"({self_state}, {neighbor_state}, {''.join(connection_pattern)})"
                            if key not in table_data and 'default' not in table_data:
                                raise ValueError(f"Missing rule for case: {key}")
                                
            return True
            
        except ValueError as e:
            logger.error(f"Consistency error: {e}")
            return False

    def _validate_state_rule_table(self, table_data: Dict[str, Any]) -> None:
        """Validate state rule table data"""
        if not isinstance(table_data, dict):
            raise ValueError("State rule table must be a dictionary")
            
        if "default" not in table_data:
            raise ValueError("State rule table must have a default value")
            
        for key, value in table_data.items():
            if key == "default":
                if not isinstance(value, int) or value not in [-1, 0, 1]:
                    raise ValueError("Default value must be -1, 0, or 1")
                continue
                
            # Validate key format
            try:
                components = key.strip("()").split(",")
                if len(components) != 3:
                    raise ValueError(f"Invalid key format: {key}")
                current_state = int(components[0])
                neighbor_pattern = components[1].strip()
                connection_pattern = components[2].strip()
                if current_state not in [-1,0, 1] or not all(c in '01IN' for c in neighbor_pattern) or not all(c in '01I' for c in connection_pattern) :
                    raise ValueError(f"Invalid values in key: {key}")
            except (ValueError, IndexError):
                raise ValueError(f"Invalid key format: {key}")
                
            # Validate value
            if not isinstance(value, int) or value not in [-1, 0, 1]:
                raise ValueError(f"Invalid value for key {key}: {value}")

    def _validate_edge_rule_table(self, table_data: Dict[str, Any]) -> None:
        """Validate edge rule table data"""
        if not isinstance(table_data, dict):
            raise ValueError("Edge rule table must be a dictionary")
            
        if "default" not in table_data:
            raise ValueError("Edge rule table must have a default value")
            
        valid_actions = {"add", "remove", "maintain"}
        
        for key, value in table_data.items():
            if key == "default":
                if value not in valid_actions:
                    raise ValueError(f"Default value must be one of: {valid_actions}")
                continue
                
            # Validate key format
            try:
                components = key.strip("()").split(",")
                if len(components) != 3:  # self_state, neighbor_state, connection_pattern
                    raise ValueError(f"Invalid key format: {key}")
                self_state = int(components[0])
                neighbor_state = int(components[1])
                connection_pattern = components[2].strip()
                if (self_state not in [0, 1] or neighbor_state not in [0, 1] or
                    not all(c in '01' for c in connection_pattern) or len(connection_pattern) != 8):
                    raise ValueError(f"Invalid values in key: {key}")
            except (ValueError, IndexError):
                raise ValueError(f"Invalid key format: {key}")
                
            # Validate value
            if value not in valid_actions:
                raise ValueError(f"Invalid value for key {key}: {value}")

    def _validate_rule_table(self, table_data: Dict[str, Any], table_type: str) -> None:
        """Validate rule table data, dynamically handling different neighborhood sizes."""
        rule_name = self.parent.controller.rule.name
        if not isinstance(table_data, dict):
            raise ValueError(f"Rule {rule_name}: Rule table must be a dictionary")

        if "default" not in table_data:
            raise ValueError(f"Rule {rule_name}: Rule table must have a default value")

        # Get the expected pattern length based on the rule type and neighborhood.
        # Access rule data directly from the passed rule_data dictionary.
        try:
            rule_type_str = self.parent.controller.rule.__class__.__name__

            # Get neighborhood type from parameters, use Moore as default
            neighborhood_type_str = self.parent.controller.rule.get_param("neighborhood_type", "MOORE")
            neighborhood_type = NeighborhoodType[neighborhood_type_str]

            # Get dimension type from parameters, use 2D as default
            dimension_type_str = self.parent.controller.rule.get_param("dimension_type", "TWO_D")
            dimension_type = Dimension[dimension_type_str]

            # Get neighborhood size
            if neighborhood_type == NeighborhoodType.MOORE:
                if dimension_type == Dimension.TWO_D:
                    neighborhood_size = 8
                elif dimension_type == Dimension.THREE_D:
                    neighborhood_size = 26
                else:
                    raise ValueError(f"Unsupported dimension type: {dimension_type_str}")
            elif neighborhood_type == NeighborhoodType.VON_NEUMANN:
                if dimension_type == Dimension.TWO_D:
                    neighborhood_size = 4
                elif dimension_type == Dimension.THREE_D:
                    neighborhood_size = 6
                else:
                    raise ValueError(f"Unsupported dimension type: {dimension_type_str}")
            elif neighborhood_type == NeighborhoodType.HEX:
                if dimension_type == Dimension.TWO_D:
                    neighborhood_size = 6
                else:
                    raise ValueError(f"Unsupported dimension type: {dimension_type_str}")
            elif neighborhood_type == NeighborhoodType.HEX_PRISM:
                if dimension_type == Dimension.THREE_D:
                    neighborhood_size = 12 # 6 on the same plane, 6 above, 6 below
                else:
                    raise ValueError(f"Unsupported dimension type: {dimension_type_str}")
            else:
                raise ValueError(f"Unsupported neighborhood type: {neighborhood_type_str}")

        except Exception as e:
            logger.error(f"Error getting neighborhood size for rule {rule_name}: {e}")
            raise ValueError(f"Could not determine neighborhood size for rule {rule_name}") from e

        for key, value in table_data.items():
            if key == "default":
                continue

            # Validate key format
            try:
                components = key.strip("()").split(",")
                if table_type == 'state':
                    if len(components) != 3:
                        raise ValueError(f"Rule {rule_name}: Invalid state rule key format: {key}")
                    current_state = int(components[0].strip())
                    neighbor_pattern = components[1].strip()
                    connection_pattern = components[2].strip()

                    if current_state not in [-1, 0, 1]:
                        raise ValueError(f"Rule {rule_name}: Current state must be -1, 0, or 1, but is {current_state}")
                    # Dynamically check pattern length
                    if len(neighbor_pattern) != neighborhood_size or not all(c in '01IN' for c in neighbor_pattern):
                        raise ValueError(f"Rule {rule_name}: Neighbor pattern must be {neighborhood_size} bits of 0, 1, I, or N, but is {neighbor_pattern}")
                    if len(connection_pattern) != neighborhood_size or not all(c in '01I' for c in connection_pattern):
                        raise ValueError(f"Rule {rule_name}: Connection pattern must be {neighborhood_size} bits of 0, 1, or I, but is {connection_pattern}")
                    if value not in [-1, 0, 1]:
                        raise ValueError(f"Rule {rule_name}: Invalid value for state rule key {key}: {value}")

                elif table_type == 'edge':
                    if len(components) != 3:
                        raise ValueError(f"Rule {rule_name}: Invalid edge rule key format: {key}")

                    self_state = int(components[0].strip())
                    neighbor_state = int(components[1].strip())
                    connection_pattern = components[2].strip()

                    if self_state not in [0, 1] or neighbor_state not in [0, 1]:
                        raise ValueError(f"Rule {rule_name}: Self state and neighbor state must be 0 or 1, but are {self_state} and {neighbor_state}")
                    # Dynamically check pattern length
                    if len(connection_pattern) != neighborhood_size or not all(c in '01I' for c in connection_pattern):
                        raise ValueError(f"Rule {rule_name}: Connection pattern must be {neighborhood_size} bits of 0, 1, or I, but is {connection_pattern}")
                    if value not in ["add", "remove", "maintain"]:
                        raise ValueError(f"Rule {rule_name}: Invalid value for edge rule key {key}: {value}")
            except (ValueError, IndexError) as e:
                raise ValueError(f"Rule {rule_name}: Invalid rule table format: {e}")

    def destroy(self):
        """Destroy the window and unbind events"""
        # Unbind the tab change event if it exists
        if self.notebook and self.tab_change_binding:
            try:
                self.notebook.unbind("<<NotebookTabChanged>>", self.tab_change_binding)
            except Exception as e:
                logger.warning(f"Error unbinding tab change event: {e}")

        # Destroy tooltips
        for tooltip in self._tooltips.values():
            tooltip.destroy()
        self._tooltips.clear()

        # Call the superclass destroy method
        super().destroy()

    def _bind_mouse_wheel_to_all_widgets(self, frame, scrollable):
        """Bind mouse wheel events to all widgets in a frame for scrolling."""
        if not frame or not scrollable:
            return
            
        def _bind_recursive(widget):
            # Bind mouse wheel events to this widget
            widget.bind("<MouseWheel>", lambda event: self._on_mouse_wheel(event, scrollable), add="+")
            widget.bind("<Button-4>", lambda event: self._on_mouse_wheel(event, scrollable), add="+")
            widget.bind("<Button-5>", lambda event: self._on_mouse_wheel(event, scrollable), add="+")
            
            # Recursively bind to all children
            for child in widget.winfo_children():
                _bind_recursive(child)
        
        # Start binding from the frame
        _bind_recursive(frame)

    def _on_mouse_wheel(self, event, scrollable):
        """Handle mouse wheel events for scrolling."""
        if not scrollable or not hasattr(scrollable, 'canvas'):
            return
            
        # Determine scroll direction
        if event.num == 4 or event.num == 5:  # Linux
            delta = -1 if event.num == 4 else 1
        else:  # Windows/macOS
            delta = -1 * (event.delta // 120)
        
        # Scroll the canvas
        scrollable.canvas.yview_scroll(delta, "units")
        return "break"  # Prevent event propagation

class RefocusGridModal(tk.Toplevel):
    """Modal dialog for shifting the grid content toroidally."""

    def __init__(self, parent: tk.Tk, gui: 'SimulationGUI'):
        super().__init__(parent)
        self.gui = gui
        self.grid = gui.grid
        self.title("Refocus Grid (Wrap Boundary)")
        self.transient(parent)
        self.geometry("350x300") # Adjusted size
        self.resizable(False, False)
        self.protocol("WM_DELETE_WINDOW", self._on_cancel)

        if self.grid is None or self.grid.rule is None or self.grid.rule.get_param('grid_boundary', 'bounded') != 'wrap':
            messagebox.showerror("Error", "Grid shifting only works with 'wrap' boundary condition.", parent=self)
            self.after(10, self.destroy)
            return

        self.delta_rows_var = tk.StringVar(value="0")
        self.delta_cols_var = tk.StringVar(value="0")
        self.delta_k_var = tk.StringVar(value="0")

        main_frame = tk.Frame(self)
        main_frame.pack(padx=10, pady=10, fill=tk.BOTH, expand=True)

        # --- Shift by Amount ---
        shift_frame = tk.LabelFrame(main_frame, text="Shift by Amount")
        shift_frame.pack(pady=5, fill=tk.X)

        row_frame = tk.Frame(shift_frame)
        row_frame.pack(fill=tk.X, padx=5, pady=2)
        tk.Label(row_frame, text="Rows (Up-/Down+):").pack(side=tk.LEFT, anchor='w', expand=True)
        row_entry = tk.Entry(row_frame, textvariable=self.delta_rows_var, width=5, validate="key")
        row_entry['validatecommand'] = (row_entry.register(self._validate_int), '%P')
        row_entry.pack(side=tk.RIGHT)

        col_frame = tk.Frame(shift_frame)
        col_frame.pack(fill=tk.X, padx=5, pady=2)
        tk.Label(col_frame, text="Cols (Left-/Right+):").pack(side=tk.LEFT, anchor='w', expand=True)
        col_entry = tk.Entry(col_frame, textvariable=self.delta_cols_var, width=5, validate="key")
        col_entry['validatecommand'] = (col_entry.register(self._validate_int), '%P')
        col_entry.pack(side=tk.RIGHT)

        if self.grid.dimension_type == Dimension.THREE_D:
            k_frame = tk.Frame(shift_frame)
            k_frame.pack(fill=tk.X, padx=5, pady=2)
            tk.Label(k_frame, text="Depth (Back-/Fwd+):").pack(side=tk.LEFT, anchor='w', expand=True)
            k_entry = tk.Entry(k_frame, textvariable=self.delta_k_var, width=5, validate="key")
            k_entry['validatecommand'] = (k_entry.register(self._validate_int), '%P')
            k_entry.pack(side=tk.RIGHT)
        else:
            self.delta_k_var.set("0") # Ensure 0 for 2D

        apply_shift_button = tk.Button(shift_frame, text="Apply Shift", command=self._apply_shift)
        apply_shift_button.pack(pady=5)

        # --- Center Shortcuts ---
        center_frame = tk.LabelFrame(main_frame, text="Center Shortcuts")
        center_frame.pack(pady=5, fill=tk.X)

        button_frame_1 = tk.Frame(center_frame)
        button_frame_1.pack(fill=tk.X)
        tk.Button(button_frame_1, text="Center Top-Left", command=lambda: self._center_corner(0, 0)).pack(side=tk.LEFT, expand=True, padx=2, pady=2)
        tk.Button(button_frame_1, text="Center Top-Right", command=lambda: self._center_corner(0, 1)).pack(side=tk.LEFT, expand=True, padx=2, pady=2)

        button_frame_2 = tk.Frame(center_frame)
        button_frame_2.pack(fill=tk.X)
        tk.Button(button_frame_2, text="Center Bottom-Left", command=lambda: self._center_corner(1, 0)).pack(side=tk.LEFT, expand=True, padx=2, pady=2)
        tk.Button(button_frame_2, text="Center Bottom-Right", command=lambda: self._center_corner(1, 1)).pack(side=tk.LEFT, expand=True, padx=2, pady=2)

        # --- Close Button ---
        close_button = tk.Button(main_frame, text="Close", command=self._on_cancel)
        close_button.pack(pady=10)

        self.grab_set() # Make modal
        self.focus_set()
        self.wait_window(self)

    def _validate_int(self, P):
        """Validation command for integer entries."""
        if P == "" or P == "-":
            return True
        try:
            int(P)
            return True
        except ValueError:
            return False

    def _apply_shift(self):
        """Apply the shift specified in the entry fields."""
        try:
            delta_r = int(self.delta_rows_var.get() or "0")
            delta_c = int(self.delta_cols_var.get() or "0")
            delta_k = int(self.delta_k_var.get() or "0")

            if self.grid:
                # --- ADDED: Push undo state BEFORE shifting ---
                self.gui._push_grid_state_to_undo(f"Shift Grid ({delta_r}, {delta_c}, {delta_k})")
                # ---
                self.grid.shift_grid_content(delta_r, delta_c, delta_k)
                # --- ADDED: Force redraw AFTER shifting ---
                self.gui._safe_plot_update(force=True)
                # ---
            # No need to close the dialog after applying shift by amount
        except ValueError:
            messagebox.showerror("Invalid Input", "Shift amounts must be integers.", parent=self)
            # --- ADDED: Pop undo state if shift failed ---
            self.gui._pop_undo_if_match(f"Shift Grid ({delta_r}, {delta_c}, {delta_k})")
            # ---
        except Exception as e:
            logger.error(f"Error applying shift: {e}")
            messagebox.showerror("Error", f"Failed to apply shift: {e}", parent=self)
            # --- ADDED: Pop undo state if shift failed ---
            self.gui._pop_undo_if_match(f"Shift Grid ({delta_r}, {delta_c}, {delta_k})")
            # ---

    def _center_corner(self, row_corner: int, col_corner: int):
        """Calculate shift needed to center a corner and apply it."""
        if not self.grid: return
        dims = self.grid.dimensions
        rows, cols = dims[0], dims[1]
        depth = dims[2] if len(dims) > 2 else 1

        target_r = rows // 2
        target_c = cols // 2
        target_k = depth // 2

        corner_r = 0 if row_corner == 0 else rows - 1
        corner_c = 0 if col_corner == 0 else cols - 1
        corner_k = 0 # Assuming we center the z=0 plane corner for 3D shortcuts

        delta_r = target_r - corner_r
        delta_c = target_c - corner_c
        delta_k = target_k - corner_k if len(dims) > 2 else 0

        logger.info(f"Centering corner ({corner_r},{corner_c},{corner_k}) -> Target ({target_r},{target_c},{target_k}). Calculated shift: ({delta_r},{delta_c},{delta_k})")

        try:
            # --- ADDED: Push undo state BEFORE shifting ---
            self.gui._push_grid_state_to_undo(f"Center Corner ({row_corner}, {col_corner})")
            # ---
            self.grid.shift_grid_content(delta_r, delta_c, delta_k)
            # --- ADDED: Force redraw AFTER shifting ---
            self.gui._safe_plot_update(force=True)
            # ---
            # Optionally close dialog after centering a corner
            # self.destroy()
        except Exception as e:
            logger.error(f"Error applying corner centering shift: {e}")
            messagebox.showerror("Error", f"Failed to center corner: {e}", parent=self)
            # --- ADDED: Pop undo state if shift failed ---
            self.gui._pop_undo_if_match(f"Center Corner ({row_corner}, {col_corner})")
            # ---

    def _on_cancel(self):
        """Handle closing the dialog."""
        self.destroy()

class MoveRuleDialog(simpledialog.Dialog):
    """Custom dialog to select an existing category or enter a new one."""

    def __init__(self, parent, title, current_category, existing_categories):
        self.current_category = current_category
        # Exclude current category and ensure "Uncategorized" is an option
        self.available_categories = sorted([cat for cat in existing_categories if cat != current_category])
        if "Uncategorized" not in self.available_categories:
            self.available_categories.insert(0, "Uncategorized")

        self.target_category = tk.StringVar()
        self.new_category_entry: Optional[tk.Entry] = None
        self.category_combobox: Optional[ttk.Combobox] = None
        self.choice_var = tk.StringVar(value="existing") # Default to selecting existing

        super().__init__(parent, title=title)

    def body(self, master):
        """Create dialog body."""
        main_frame = tk.Frame(master)
        main_frame.pack(padx=10, pady=10)

        tk.Radiobutton(main_frame, text="Move to Existing Category:",
                       variable=self.choice_var, value="existing",
                       command=self._toggle_widgets).pack(anchor="w")

        self.category_combobox = ttk.Combobox(
            main_frame,
            textvariable=self.target_category,
            values=self.available_categories,
            state="readonly",
            width=30
        )
        # Set initial selection if available_categories is not empty
        if self.available_categories:
            self.target_category.set(self.available_categories[0])
        self.category_combobox.pack(anchor="w", padx=20, pady=(0, 5))

        tk.Radiobutton(main_frame, text="Move to New Category:",
                       variable=self.choice_var, value="new",
                       command=self._toggle_widgets).pack(anchor="w", pady=(10, 0))

        self.new_category_entry = tk.Entry(main_frame, width=33, state=tk.DISABLED)
        self.new_category_entry.pack(anchor="w", padx=20)

        return self.category_combobox # Initial focus

    def _toggle_widgets(self):
        """Enable/disable widgets based on radio button selection."""
        if self.choice_var.get() == "existing":
            if self.category_combobox: self.category_combobox.config(state="readonly")
            if self.new_category_entry: self.new_category_entry.config(state=tk.DISABLED)
            if self.available_categories: self.target_category.set(self.available_categories[0]) # Reset selection
        else: # "new"
            if self.category_combobox: self.category_combobox.config(state=tk.DISABLED)
            if self.new_category_entry: self.new_category_entry.config(state=tk.NORMAL)
            self.target_category.set("") # Clear selection

    def validate(self):
        """Validate the input."""
        if self.choice_var.get() == "existing":
            selected = self.target_category.get()
            if not selected or selected not in self.available_categories:
                messagebox.showerror("Error", "Please select a valid existing category.", parent=self)
                return 0
            self.result = selected # Store the selected existing category
            return 1
        else: # "new"
            new_name = self.new_category_entry.get().strip() if self.new_category_entry else ""
            if not new_name:
                messagebox.showerror("Error", "New category name cannot be empty.", parent=self)
                return 0
            normalized_new = new_name.strip().title()
            if normalized_new == self.current_category:
                 messagebox.showerror("Error", "New category name cannot be the same as the current category.", parent=self)
                 return 0
            # Optional: Check if new name conflicts with existing (though manager handles this)
            # if normalized_new in self.available_categories:
            #    messagebox.showerror("Error", f"Category '{normalized_new}' already exists.", parent=self)
            #    return 0
            self.result = normalized_new # Store the new category name
            return 1

    # apply method is inherited and sets self.result

class CategoryManagerWindow(tk.Toplevel):
    """Modal window for managing rule categories."""

    def __init__(self, parent: 'SimulationGUI'):
        super().__init__(parent.root)
        self.parent_gui = parent
        self.manager = RuleLibraryManager.get_instance()
        self.title("Manage Rule Categories")
        self.geometry("600x500")
        self.transient(parent.root)
        self.grab_set()

        self._create_widgets()
        self._load_categories()

        self.protocol("WM_DELETE_WINDOW", self._on_close)

    def _create_widgets(self):
        main_frame = ttk.Frame(self, padding=10)
        main_frame.pack(fill=tk.BOTH, expand=True)

        # Left Pane: Category List
        left_pane = ttk.Frame(main_frame, width=200)
        left_pane.pack(side=tk.LEFT, fill=tk.Y, padx=(0, 10))

        ttk.Label(left_pane, text="Categories:").pack(anchor="w")
        cat_list_frame = ttk.Frame(left_pane)
        cat_list_frame.pack(fill=tk.BOTH, expand=True)
        cat_scrollbar = tk.Scrollbar(cat_list_frame, orient=tk.VERTICAL)
        self.category_listbox = tk.Listbox(cat_list_frame, yscrollcommand=cat_scrollbar.set, exportselection=False)
        cat_scrollbar.config(command=self.category_listbox.yview)
        cat_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        self.category_listbox.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        self.category_listbox.bind("<<ListboxSelect>>", self._on_category_select)

        # Right Pane: Rules in Category & Actions
        right_pane = ttk.Frame(main_frame)
        right_pane.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True)

        ttk.Label(right_pane, text="Rules in Selected Category:").pack(anchor="w")
        rules_list_frame = ttk.Frame(right_pane)
        rules_list_frame.pack(fill=tk.BOTH, expand=True, pady=(0, 10))
        rules_scrollbar = tk.Scrollbar(rules_list_frame, orient=tk.VERTICAL)
        self.rules_listbox = tk.Listbox(rules_list_frame, yscrollcommand=rules_scrollbar.set, exportselection=False, selectmode=tk.EXTENDED)
        rules_scrollbar.config(command=self.rules_listbox.yview)
        rules_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        self.rules_listbox.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)

        # Action Buttons Frame
        action_frame = ttk.Frame(right_pane)
        action_frame.pack(fill=tk.X)

        self.rename_button = tk.Button(action_frame, text="Rename Category...", command=self._rename_category, state=tk.DISABLED)
        self.rename_button.pack(side=tk.LEFT, padx=5)
        self.delete_button = tk.Button(action_frame, text="Delete Category...", command=self._delete_category, state=tk.DISABLED)
        self.delete_button.pack(side=tk.LEFT, padx=5)
        self.move_button = tk.Button(action_frame, text="Move Rule(s) To...", command=self._move_rules, state=tk.DISABLED)
        self.move_button.pack(side=tk.LEFT, padx=5)

        # Close Button (Bottom)
        close_button = tk.Button(self, text="Close", command=self._on_close)
        close_button.pack(pady=10)

    def _load_categories(self):
        """Loads categories into the listbox."""
        self.category_listbox.delete(0, tk.END)
        categories = self.manager.get_all_categories()
        for category in categories:
            self.category_listbox.insert(tk.END, category)
        self._clear_rules_list()
        self._update_action_buttons()

    def _on_category_select(self, event=None):
        """Handles selection of a category."""
        selected_indices = self.category_listbox.curselection()
        if not selected_indices:
            self._clear_rules_list()
            self._update_action_buttons() # Update buttons when category deselected
            return

        selected_category = self.category_listbox.get(selected_indices[0])
        self._load_rules_for_category(selected_category)
        self._update_action_buttons() # Update buttons when category selected

    def _load_rules_for_category(self, category_name: str):
        """Loads rules for the selected category."""
        self.rules_listbox.delete(0, tk.END)
        rules = self.manager.get_rules_in_category(category_name)
        for rule_name in rules:
            self.rules_listbox.insert(tk.END, rule_name)

    def _clear_rules_list(self):
        """Clears the rules listbox."""
        self.rules_listbox.delete(0, tk.END)

    def _update_action_buttons(self):
        """Updates the state of action buttons based on selection.
           (Round 10: Enable Move button if rules listbox has items and a category is selected)
           (Round 9: Enable Move button if ANY rule is selected)
           (Round 8: Always enable Move button if rules are selected)"""
        cat_selected = bool(self.category_listbox.curselection())
        # --- MODIFIED: Check if rules listbox has items, not just if something is selected ---
        rules_available_in_list = self.rules_listbox.size() > 0
        # ---

        self.rename_button.config(state=tk.NORMAL if cat_selected else tk.DISABLED)
        self.delete_button.config(state=tk.NORMAL if cat_selected else tk.DISABLED)
        # --- MODIFIED: Enable Move if a category is selected AND there are rules listed ---
        self.move_button.config(state=tk.NORMAL if cat_selected and rules_available_in_list else tk.DISABLED)
        # ---

    def _rename_category(self):
        """Handles renaming the selected category."""
        selected_indices = self.category_listbox.curselection()
        if not selected_indices: return
        old_name = self.category_listbox.get(selected_indices[0])

        new_name = simpledialog.askstring("Rename Category", f"Enter new name for '{old_name}':", parent=self)
        if not new_name or not new_name.strip(): return
        new_name = new_name.strip().title()

        if new_name == old_name: return
        if new_name in self.manager.get_all_categories():
            messagebox.showerror("Error", f"Category '{new_name}' already exists.", parent=self)
            return

        if messagebox.askyesno("Confirm Rename", f"Rename category '{old_name}' to '{new_name}' for all its rules?", parent=self):
            count = self.manager.rename_category(old_name, new_name)
            if count > 0:
                self._load_categories() # Refresh category list
                # --- MODIFIED: Call correct method ---
                self.parent_gui._update_rule_type_selector() # Update main GUI dropdown
                # ---
                messagebox.showinfo("Success", f"Renamed category for {count} rules.", parent=self)
            else:
                messagebox.showwarning("Rename Failed", f"Could not rename category '{old_name}'.", parent=self)

    def _delete_category(self):
        """Handles deleting the selected category."""
        selected_indices = self.category_listbox.curselection()
        if not selected_indices: return
        category_to_delete = self.category_listbox.get(selected_indices[0])

        if messagebox.askyesno("Confirm Delete", f"Delete category '{category_to_delete}'?\nRules within it will be moved to 'Uncategorized'.", icon='warning', parent=self):
            count = self.manager.delete_category(category_to_delete, "Uncategorized")
            if count >= 0: # Allow deleting empty categories
                self._load_categories() # Refresh category list
                # --- MODIFIED: Call correct method ---
                self.parent_gui._update_rule_type_selector() # Update main GUI dropdown
                # ---
                messagebox.showinfo("Success", f"Deleted category '{category_to_delete}'. {count} rules moved to 'Uncategorized'.", parent=self)
            else:
                messagebox.showerror("Delete Failed", f"Could not delete category '{category_to_delete}'.", parent=self)

    def _move_rules(self):
        """Handles moving selected rules to a different category using a custom dialog.
           (Round 11: Use MoveRuleDialog)
           (Round 10: Add check if any rule is actually selected)"""
        selected_rule_indices = self.rules_listbox.curselection()
        selected_cat_indices = self.category_listbox.curselection()

        if not selected_rule_indices:
            messagebox.showwarning("No Rule Selected", "Please select one or more rules from the list to move.", parent=self)
            return

        if not selected_cat_indices: return

        rules_to_move = [self.rules_listbox.get(i) for i in selected_rule_indices]
        current_category = self.category_listbox.get(selected_cat_indices[0])
        all_categories = self.manager.get_all_categories()

        # --- Use Custom Dialog ---
        dialog = MoveRuleDialog(self, "Move Rules", current_category, all_categories)
        target_category = dialog.result # This will be None if cancelled, or the chosen string
        # ---

        if not target_category: # User cancelled or closed dialog
            logger.info("Rule move cancelled by user.")
            return

        # target_category is already stripped/titled by the dialog's validate method
        if target_category == current_category: return # Should not happen if dialog logic is correct

        logger.info(f"Moving {len(rules_to_move)} rules from '{current_category}' to '{target_category}'.")
        moved_count = 0
        failed_rules = []
        for rule_name in rules_to_move:
            if self.manager.update_rule_category(rule_name, target_category):
                moved_count += 1
            else:
                failed_rules.append(rule_name)

        if moved_count > 0:
            self._load_categories() # Refresh category list
            self.parent_gui._update_rule_type_selector() # Update main GUI dropdown
            message = f"Moved {moved_count} rule(s) to '{target_category}'."
            if failed_rules:
                message += f"\nFailed to move: {', '.join(failed_rules)}"
                messagebox.showwarning("Partial Success", message, parent=self)
            else:
                messagebox.showinfo("Success", message, parent=self)
            # Reselect the original category to refresh the rules list
            try:
                # Find index case-insensitively after potential rename/delete
                cats_after_move = list(self.category_listbox.get(0, tk.END))
                idx = -1
                for i, cat in enumerate(cats_after_move):
                    if cat.lower() == current_category.lower():
                        idx = i
                        break
                if idx != -1:
                    self.category_listbox.select_set(idx)
                    self._load_rules_for_category(cats_after_move[idx]) # Use actual name from listbox
                else: # Original category might have been renamed/deleted
                     self._clear_rules_list()
            except ValueError:
                self._clear_rules_list() # Clear if original category was deleted/renamed
            self._update_action_buttons() # Update button states after move

        elif failed_rules:
             messagebox.showerror("Move Failed", f"Could not move rules: {', '.join(failed_rules)}", parent=self)

    def _on_close(self):
        """Handle window close."""
        self.grab_release()
        self.destroy()

class RuleImportWindow(tk.Toplevel):
    """Modal window for importing parameters from one rule type to another."""

    def __init__(self, parent: 'SimulationGUI'):
        super().__init__(parent.root)
        self.parent_gui = parent
        self.manager = RuleLibraryManager.get_instance()
        self.title("Import Rule Parameters")
        self.geometry("800x700") # Adjust size as needed
        self.transient(parent.root)
        self.grab_set()

        self.source_type_var = tk.StringVar()
        self.destination_type_var = tk.StringVar()
        self.field_mapping_widgets: Dict[str, ttk.Combobox] = {} # {dest_param: combobox_widget}
        self.source_param_names: List[str] = [] # Params available from the selected source type

        self._create_widgets()
        self._load_rule_types() # Populate initial dropdowns

        self.protocol("WM_DELETE_WINDOW", self._on_close)

    def _create_widgets(self):
        main_frame = ttk.Frame(self, padding=10)
        main_frame.pack(fill=tk.BOTH, expand=True)

        # --- Top Selection Frame ---
        selection_frame = ttk.Frame(main_frame)
        selection_frame.pack(fill=tk.X, pady=(0, 10))
        selection_frame.columnconfigure(1, weight=1)
        selection_frame.columnconfigure(3, weight=1)

        ttk.Label(selection_frame, text="Source Type:").grid(row=0, column=0, padx=(0, 5), sticky="w")
        self.source_type_combo = ttk.Combobox(selection_frame, textvariable=self.source_type_var, state="readonly", width=30)
        self.source_type_combo.grid(row=0, column=1, sticky="ew")
        self.source_type_combo.bind("<<ComboboxSelected>>", self._on_source_type_selected)

        ttk.Label(selection_frame, text="Destination Type:").grid(row=0, column=2, padx=(10, 5), sticky="w")
        self.dest_type_combo = ttk.Combobox(selection_frame, textvariable=self.destination_type_var, state="readonly", width=30)
        self.dest_type_combo.grid(row=0, column=3, sticky="ew")
        self.dest_type_combo.bind("<<ComboboxSelected>>", self._on_destination_type_selected)

        # --- Middle Panes (Source Rules & Mapping) ---
        paned_window = tk.PanedWindow(main_frame, orient=tk.HORIZONTAL, sashrelief=tk.RAISED)
        paned_window.pack(fill=tk.BOTH, expand=True, pady=5)

        # Left Pane: Source Rules List
        source_rules_frame = ttk.LabelFrame(paned_window, text="Select Source Rules", padding=5)
        paned_window.add(source_rules_frame, width=250) # Initial width

        source_list_frame = ttk.Frame(source_rules_frame)
        source_list_frame.pack(fill=tk.BOTH, expand=True)
        source_scrollbar = tk.Scrollbar(source_list_frame, orient=tk.VERTICAL)
        self.source_rules_listbox = tk.Listbox(source_list_frame, yscrollcommand=source_scrollbar.set, exportselection=False, selectmode=tk.EXTENDED)
        source_scrollbar.config(command=self.source_rules_listbox.yview)
        source_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        self.source_rules_listbox.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)

        # Right Pane: Field Mapping
        mapping_outer_frame = ttk.LabelFrame(paned_window, text="Map Destination Fields to Source Fields", padding=5)
        paned_window.add(mapping_outer_frame)

        # Use ScrollableFrame for mapping area
        self.mapping_scrollable = ScrollableFrame(mapping_outer_frame, self.parent_gui)
        self.mapping_scrollable.pack(fill=tk.BOTH, expand=True)
        self.mapping_frame = self.mapping_scrollable.scrolled_frame # Frame to add mapping rows to

        # --- Bottom Buttons ---
        button_frame = ttk.Frame(main_frame)
        button_frame.pack(fill=tk.X, pady=(10, 0))

        self.import_button = tk.Button(button_frame, text="Import Selected Rules", command=self._import_rules, state=tk.DISABLED)
        self.import_button.pack(side=tk.LEFT, padx=5)

        close_button = tk.Button(button_frame, text="Close", command=self._on_close)
        close_button.pack(side=tk.RIGHT, padx=5)

    def _load_rule_types(self):
        """Populate source and destination type dropdowns."""
        all_rule_types = sorted(RuleLibrary.RULES.keys()) # Get names of defined classes
        if all_rule_types:
            self.source_type_combo['values'] = all_rule_types
            self.dest_type_combo['values'] = all_rule_types
            # Optionally set initial selections
            # self.source_type_var.set(all_rule_types[0])
            # self.destination_type_var.set(all_rule_types[0])
            # self._on_source_type_selected() # Trigger loading params for default source
            # self._on_destination_type_selected() # Trigger loading params for default dest
        else:
            logger.error("No rule types found in RuleLibrary.RULES.")
            self.source_type_combo['values'] = ["(No Rules Found)"]
            self.dest_type_combo['values'] = ["(No Rules Found)"]

    def _on_source_type_selected(self, event=None):
        """Load rules for the selected source type and update mapping options."""
        source_type_name = self.source_type_var.get()
        if not source_type_name or source_type_name == "(No Rules Found)":
            self.source_rules_listbox.delete(0, tk.END)
            self.source_param_names = []
            self._update_mapping_comboboxes()
            self._update_import_button_state() # Update button state
            return

        logger.debug(f"Source type selected: {source_type_name}")
        # Load rules of this type
        self.source_rules_listbox.delete(0, tk.END)
        rules_of_type = []
        # --- MODIFIED: Iterate through manager rules ---
        for rule_name, rule_data in self.manager.rules.items():
            # Check the 'type' field which should hold the class name string
            if rule_data.get('type') == source_type_name:
                rules_of_type.append(rule_name)
        # ---
        for rule_name in sorted(rules_of_type):
            self.source_rules_listbox.insert(tk.END, rule_name)

        # Get parameters for this source type to populate mapping dropdowns
        self.source_param_names = self._get_parameter_names_for_type(source_type_name)
        # --- MODIFIED: Call populate mapping area if destination is already selected ---
        if self.destination_type_var.get() and self.destination_type_var.get() != "(No Rules Found)":
            self._populate_mapping_area(self.destination_type_var.get())
        else: # Otherwise, just update existing dropdowns if any
            self._update_mapping_comboboxes()
        # ---
        self._update_import_button_state() # Update button state

    def _on_destination_type_selected(self, event=None):
        """Update the mapping area with destination parameters."""
        dest_type_name = self.destination_type_var.get()
        if not dest_type_name or dest_type_name == "(No Rules Found)":
            self._clear_mapping_area()
            self._update_import_button_state() # Update button state
            return

        logger.debug(f"Destination type selected: {dest_type_name}")
        self._populate_mapping_area(dest_type_name)
        self._update_import_button_state() # Update button state

    def _get_parameter_names_for_type(self, rule_type_name: str) -> List[str]:
        """Gets the editable parameter names for a given rule type."""
        try:
            rule_class = RuleLibrary.RULES.get(rule_type_name)
            if not rule_class: return []

            # Need a temporary instance to access combined metadata
            # Create minimal metadata
            temp_metadata = RuleMetadata(name=rule_type_name, parent_rule="", type=rule_type_name, position=0, category="", author="", url="", email="", date_created="", date_modified="", version="", description="", tags=[], dimension_compatibility=[], neighborhood_compatibility=[])
            temp_instance = rule_class(temp_metadata)

            base_meta = getattr(Rule, 'PARAMETER_METADATA', {})
            sub_meta = getattr(temp_instance, 'PARAMETER_METADATA', {})
            merged_meta = RuleEditorWindow._merge_metadata(base_meta, sub_meta) # Use static method
            exclude_set = getattr(temp_instance, 'EXCLUDE_EDITOR_PARAMS', set())

            param_names = [name for name in merged_meta if name not in exclude_set]
            return sorted(param_names)
        except Exception as e:
            logger.error(f"Error getting parameters for type '{rule_type_name}': {e}")
            return []

    def _clear_mapping_area(self):
        """Clears the field mapping area."""
        for widget in self.mapping_frame.winfo_children():
            widget.destroy()
        self.field_mapping_widgets.clear()

    def _populate_mapping_area(self, dest_rule_type_name: str):
        """Populates the mapping area based on the destination rule type."""
        self._clear_mapping_area()
        dest_param_names = self._get_parameter_names_for_type(dest_rule_type_name)
        mapping_options = ["(Ignore)"] + self.source_param_names # Add Ignore option

        logger.debug(f"Populating mapping area for {len(dest_param_names)} destination params.")

        # Create header row
        header_frame = ttk.Frame(self.mapping_frame)
        header_frame.pack(fill=tk.X, pady=(0, 5))
        ttk.Label(header_frame, text="Destination Parameter", width=30, anchor="w", font=('TkDefaultFont', 10, 'bold')).pack(side=tk.LEFT, padx=5)
        ttk.Label(header_frame, text="Source Parameter", width=30, anchor="w", font=('TkDefaultFont', 10, 'bold')).pack(side=tk.LEFT, padx=5)

        # Create mapping rows
        for dest_param in dest_param_names:
            row_frame = ttk.Frame(self.mapping_frame)
            row_frame.pack(fill=tk.X, pady=1)

            ttk.Label(row_frame, text=dest_param, width=30, anchor="w").pack(side=tk.LEFT, padx=5)

            map_var = tk.StringVar(value="(Ignore)") # Default to ignore
            map_combo = ttk.Combobox(row_frame, textvariable=map_var, values=mapping_options, state="readonly", width=28)
            # Try to pre-select if names match
            if dest_param in self.source_param_names:
                map_var.set(dest_param)
            map_combo.pack(side=tk.LEFT, padx=5)
            self.field_mapping_widgets[dest_param] = map_combo

        # Update scroll region after adding widgets
        self.mapping_scrollable.canvas.configure(scrollregion=self.mapping_scrollable.canvas.bbox("all"))

    def _update_mapping_comboboxes(self):
        """Updates the values in the existing mapping comboboxes."""
        mapping_options = ["(Ignore)"] + self.source_param_names
        logger.debug(f"Updating mapping comboboxes with {len(mapping_options)} options.")
        for dest_param, combo in self.field_mapping_widgets.items():
            current_selection = combo.get()
            combo['values'] = mapping_options
            # Try to preserve selection if still valid, else default to Ignore
            if current_selection in mapping_options:
                combo.set(current_selection)
            elif dest_param in mapping_options: # Auto-select if names match
                 combo.set(dest_param)
            else:
                combo.set("(Ignore)")

    def _get_field_mapping(self) -> Dict[str, Optional[str]]:
        """Reads the user's mapping choices from the UI."""
        mapping: Dict[str, Optional[str]] = {}
        for dest_param, combo in self.field_mapping_widgets.items():
            selected_source = combo.get()
            mapping[dest_param] = selected_source if selected_source != "(Ignore)" else None
        logger.debug(f"Generated field mapping: {mapping}")
        return mapping

    def _update_import_button_state(self):
        """Enables the import button if source/dest types and source rules are selected."""
        source_type_ok = bool(self.source_type_var.get() and self.source_type_var.get() != "(No Rules Found)")
        dest_type_ok = bool(self.destination_type_var.get() and self.destination_type_var.get() != "(No Rules Found)")
        rules_selected = bool(self.source_rules_listbox.curselection())

        new_state = tk.NORMAL if source_type_ok and dest_type_ok and rules_selected else tk.DISABLED
        self.import_button.config(state=new_state)

    def _import_rules(self):
        """Performs the rule import based on selections and mapping."""
        log_prefix = "RuleImportWindow._import_rules: "
        selected_indices = self.source_rules_listbox.curselection()
        source_type_name = self.source_type_var.get()
        dest_type_name = self.destination_type_var.get()

        if not selected_indices: messagebox.showerror("Error", "No source rules selected.", parent=self); return
        if not source_type_name or not dest_type_name or source_type_name == "(No Rules Found)" or dest_type_name == "(No Rules Found)":
            messagebox.showerror("Error", "Source and Destination types must be selected.", parent=self); return

        source_rule_names = [self.source_rules_listbox.get(i) for i in selected_indices]
        field_mapping = self._get_field_mapping()
        dest_rule_class = RuleLibrary.RULES.get(dest_type_name)

        if not dest_rule_class: messagebox.showerror("Error", f"Could not find destination rule class '{dest_type_name}'.", parent=self); return

        logger.info(f"{log_prefix}Starting import of {len(source_rule_names)} rules from '{source_type_name}' to '{dest_type_name}'.")
        # --- Get default params for destination type ---
        try:
            temp_metadata_dest = RuleMetadata(name="temp", type=dest_type_name, parent_rule='', position=0, category="", author="", url="", email="", date_created="", date_modified="", version="", description="", tags=[], dimension_compatibility=[], neighborhood_compatibility=[])
            temp_instance_dest = dest_rule_class(temp_metadata_dest)
            base_meta_dest = getattr(Rule, 'PARAMETER_METADATA', {})
            sub_meta_dest = getattr(temp_instance_dest, 'PARAMETER_METADATA', {})
            merged_meta_dest = RuleEditorWindow._merge_metadata(base_meta_dest, sub_meta_dest)
            exclude_set_dest = getattr(temp_instance_dest, 'EXCLUDE_EDITOR_PARAMS', set())
            dest_default_params = {name: info['default'] for name, info in merged_meta_dest.items() if 'default' in info and name not in exclude_set_dest}
        except Exception as e:
            logger.error(f"{log_prefix}Could not get default parameters for destination type '{dest_type_name}': {e}")
            messagebox.showerror("Error", f"Could not get defaults for destination rule '{dest_type_name}'.", parent=self)
            return
        # ---

        imported_count = 0
        failed_imports = []
        newly_created_names = [] # Track names created in this batch

        for source_rule_name in source_rule_names:
            try:
                logger.debug(f"{log_prefix}Processing source rule: {source_rule_name}")
                source_rule_data = self.manager.get_rule(source_rule_name)
                source_params = source_rule_data.get('params', {})

                # 1. Determine New Name (Append "- Imported", add counter if needed)
                base_new_name = f"{source_rule_name} - Imported"
                new_rule_name = base_new_name
                counter = 1
                # Check against existing rules AND names created in this batch
                while new_rule_name in self.manager.rules or new_rule_name in newly_created_names:
                    new_rule_name = f"{base_new_name} ({counter})"
                    counter += 1
                newly_created_names.append(new_rule_name) # Track the name we will use
                logger.debug(f"  New rule name: {new_rule_name}")

                # 2. Create New Metadata (Copy relevant fields, update others)
                new_metadata_dict = {
                    'name': new_rule_name,
                    'type': dest_type_name, # Use destination type name
                    'category': source_rule_data.get('category', 'Imported'), # Keep original category? Or set to Imported?
                    'author': source_rule_data.get('author', GlobalSettings.Defaults.DEFAULT_AUTHOR),
                    'url': source_rule_data.get('url', GlobalSettings.Defaults.DEFAULT_URL),
                    'email': source_rule_data.get('email', GlobalSettings.Defaults.DEFAULT_EMAIL),
                    'date_created': datetime.now().strftime("%Y-%m-%d"), # Set new creation date
                    'date_modified': datetime.now().strftime("%Y-%m-%d"),
                    'version': '1.0', # Reset version
                    'description': f"Imported from '{source_rule_name}' ({source_type_name}).\nOriginal Desc: {source_rule_data.get('description', '')}",
                    'tags': list(set(source_rule_data.get('tags', []) + ['Imported', dest_type_name])), # Add 'Imported' tag
                    # Compatibility: Use destination rule's defaults or keep source? Let's use destination's
                    'dimension_compatibility': merged_meta_dest.get('dimension_type', {}).get('allowed_values', ["TWO_D", "THREE_D"]),
                    'neighborhood_compatibility': merged_meta_dest.get('neighborhood_type', {}).get('allowed_values', []),
                    'parent_rule': source_rule_name, # Link back to original
                    'rating': source_rule_data.get('rating'), # Keep rating
                    'notes': f"Imported from {source_rule_name}.\n{source_rule_data.get('notes', '')}",
                    'allowed_initial_conditions': dest_default_params.get('allowed_initial_conditions', ["Random"]), # Use dest default
                    'allow_rule_tables': dest_default_params.get('allow_rule_tables', True), # Use dest default
                    'favorite': False, # Don't import as favorite
                    'position': 1 # Default position
                }
                # Ensure all required RuleMetadata fields are present
                for field in fields(RuleMetadata):
                    if field.name not in new_metadata_dict and field.default is dataclasses.MISSING and field.default_factory is dataclasses.MISSING:
                         # Handle missing required fields without defaults (shouldn't happen with above code)
                         logger.error(f"Missing required metadata field '{field.name}' for rule '{new_rule_name}'. Skipping.")
                         raise ValueError(f"Missing required metadata field: {field.name}")
                    elif field.name not in new_metadata_dict and field.default is not dataclasses.MISSING:
                         new_metadata_dict[field.name] = field.default
                    elif field.name not in new_metadata_dict and field.default_factory is not dataclasses.MISSING:
                         new_metadata_dict[field.name] = field.default_factory()

                new_metadata = RuleMetadata(**new_metadata_dict)

                # 3. Create Mapped Parameters
                new_params = {}
                logger.debug(f"  Mapping parameters using: {field_mapping}")
                for dest_param, source_param in field_mapping.items():
                    if source_param and source_param in source_params:
                        # Map value from source
                        new_params[dest_param] = source_params[source_param]
                        logger.debug(f"    Mapped '{dest_param}' <- '{source_param}' (Value: {new_params[dest_param]})")
                    else:
                        # Use destination default if mapping is "(Ignore)" or source param missing
                        if dest_param in dest_default_params:
                            new_params[dest_param] = dest_default_params[dest_param]
                            if source_param:
                                logger.debug(f"    Using default for '{dest_param}' (Source '{source_param}' not found). Value: {new_params[dest_param]}")
                            else:
                                logger.debug(f"    Using default for '{dest_param}' (Mapped to Ignore). Value: {new_params[dest_param]}")
                        else:
                            logger.warning(f"    No source mapping or destination default found for '{dest_param}'. Skipping parameter.")

                # 4. Create and Save New Rule Data Structure
                new_rule_data_to_save = asdict(new_metadata) # Convert metadata dataclass to dict
                new_rule_data_to_save['params'] = new_params # Add the mapped params
                # Ensure type is correct string name
                new_rule_data_to_save['type'] = dest_type_name

                # 5. Save using RuleLibraryManager
                self.manager.save_rule(new_rule_name, new_rule_data_to_save)
                imported_count += 1

            except Exception as e:
                logger.error(f"{log_prefix}Failed to import rule '{source_rule_name}': {e}")
                logger.error(traceback.format_exc())
                failed_imports.append(source_rule_name)

        # --- Final Report ---
        if imported_count > 0:
            message = f"Successfully imported {imported_count} rule(s) as type '{dest_type_name}'."
            if failed_imports:
                message += f"\nFailed to import: {', '.join(failed_imports)}"
                messagebox.showwarning("Partial Success", message, parent=self)
            else:
                messagebox.showinfo("Import Complete", message, parent=self)
            # Refresh main GUI selectors
            self.parent_gui._update_rule_type_selector()
            self.parent_gui._update_rule_instance_selector()
        elif failed_imports:
            messagebox.showerror("Import Failed", f"Failed to import selected rules: {', '.join(failed_imports)}", parent=self)
        else:
            messagebox.showinfo("Import Info", "No rules were imported (check logs for details).", parent=self)

        logger.info(f"{log_prefix}Import process finished.")

    def _on_close(self):
        """Handle window close."""
        self.grab_release()
        self.destroy()


################################################
#                    MAIN GUI                  #
################################################

class GridVisualizer(Observer):
    """Visualizes the grid and simulation"""

    def __init__(self, grid, ax, fig, controller, gui): # Added gui
        """
        Initialize GridVisualizer with grid, matplotlib axes, figure, and controller.
        (Round 1: Added _last_rendered_... attributes for state tracking)
        """
        super().__init__()  # Initialize Observer (and GridVisualizer)
        logger.debug(f"GridVisualizer.__init__: Creating instance with ID: {id(self)}")
        self.grid = grid #This will be None initially
        self.ax = ax
        self.fig = fig
        # Create coordinate system using GlobalSettings initially
        self.coord_system = CoordinateSystem(
            grid.dimensions if grid else (10, 10), # Use default if grid is None initially
            GlobalSettings.Visualization.EDGE_SCALE,
            GlobalSettings.Visualization.NODE_SPACING,
            grid.dimension_type if grid else Dimension.TWO_D # Use default if grid is None
        )
        self.controller = controller
        self.gui = gui  # Store the SimulationGUI instance and put in correct order
        logger.debug(f"GridVisualizer.__init__ (ID: {id(self)}): controller = {self.controller}, grid = {self.grid}") # Added logging
        self.blitting_manager = BlittingManager() # ADDED
        self.debug_mode = False
        self.selected_nodes = set()
        self.selection_rect = None
        self.drag_start = None
        self.highlighted_nodes: Set[int] = set()
        self.highlighted_edges: Set[Tuple[Tuple[int, ...], Tuple[int, ...]]] = set()
        self._initialization_complete: bool = False
        self._recalculate_scaling: bool = True # Start True for initial draw

        self._visualization_state = {
            'node_size': GlobalSettings.Visualization.NODE_SIZE * 100, # Initial default
            'node_outline_width': GlobalSettings.Visualization.NODE_OUTLINE_WIDTH,
            'edge_width': GlobalSettings.Visualization.EDGE_WIDTH,
            'zoom_factor': 1.0, # Keep zoom factor
            'highlight_changes': True,
            'background_color': GlobalSettings.Colors.BACKGROUND,
            'node_color': GlobalSettings.Colors.NODE_ACTIVE,
            'node_edge_new': GlobalSettings.Colors.NODE_EDGE_NEW,
            'default_edge_color': GlobalSettings.Colors.NODE_EDGE_OLD,
            'new_edge_color': GlobalSettings.Colors.NODE_EDGE_NEW,
            'x_coords': np.array([]),
            'y_coords': np.array([]),
            'z_coords': np.array([]),
            'states': np.array([]),
            'indices': np.array([], dtype=int), # Added indices
            'segments': [],
            'colors': [],
            'node_outline_old': GlobalSettings.Colors.NODE_EDGE_OLD,
            'node_outline_new': GlobalSettings.Colors.NODE_EDGE_NEW,
            'updated_nodes': set() # Initialize updated_nodes
        }
        logger.debug(f"GridVisualizer.__init__ (ID: {id(self)}): Initial _visualization_state ID: {id(self._visualization_state)}")
        logger.debug(f"GridVisualizer.__init__ (ID: {id(self)}): Initial _visualization_state content (relevant keys): "
                     f"node_size={self._visualization_state.get('node_size')}, "
                     f"zoom_factor={self._visualization_state.get('zoom_factor')}")

        self._cached_base_size_dims: Optional[Tuple[int, ...]] = None
        self._cached_base_node_size: float = GlobalSettings.Visualization.NODE_SIZE * 100 # Keep cache for base size calculation

        # --- Calculate base size and set initial node_size ---
        self._base_node_size = self._calculate_base_node_size()
        self._visualization_state['node_size'] = self._base_node_size
        logger.debug(f"GridVisualizer.__init__ (ID: {id(self)}): Initial _base_node_size: {self._base_node_size}")
        logger.debug(f"GridVisualizer.__init__ (ID: {id(self)}): _visualization_state after setting base size: "
                     f"node_size={self._visualization_state.get('node_size')}")

        if self.grid is not None:
            self.shape_placer = ShapePlacer(self.grid)
        else:
            self.shape_placer = None

        if self.grid is not None:
            self.debugger = VisualizationDebugger(self.grid, self.ax, self.coord_system, self.gui)
        else:
            self.debugger = None

        self.view_manager = ViewManager(self.grid, self.ax, self.fig, self.coord_system, self, self.gui, self.controller)
        self.inspector = CoordinateInspector(self.grid, self.coord_system)

        self._node_scatter = None
        logger.debug(f"Initialized self._node_scatter to None in __init__ (ID: {id(self)})")
        self._node_scatter_3d = None
        self._edge_lines = None
        self._edge_lines_3d = None

        # --- Attributes to store last rendered state ---
        self._last_rendered_node_offsets: Optional[np.ndarray] = None
        self._last_rendered_node_face_colors: Optional[np.ndarray] = None # Store RGBA
        self._last_rendered_node_edge_colors: Optional[np.ndarray] = None # Store HEX or RGBA? Let's use RGBA for consistency
        self._last_rendered_node_size: Optional[float] = None
        self._last_rendered_outline_width: Optional[float] = None
        self._last_rendered_edge_segments: Optional[list] = None
        self._last_rendered_edge_colors: Optional[list] = None # Store HEX strings
        self._last_rendered_edge_width: Optional[float] = None
        # ---

        self._first_update_done = False

        plot_data = self._prepare_plot_data()
        if plot_data:
            self._visualization_state['x_coords'] = plot_data.get('x_coords', np.array([]))
            self._visualization_state['y_coords'] = plot_data.get('y_coords', np.array([]))
            if 'z_coords' in plot_data:
                self._visualization_state['z_coords'] = plot_data['z_coords']
            self._visualization_state['states'] = plot_data.get('states', np.array([]))
            self._visualization_state['indices'] = plot_data.get('indices', np.array([], dtype=int)) # Store indices
            self._visualization_state['segments'] = plot_data.get('segments', [])
            self._visualization_state['colors'] = plot_data.get('colors', [])
            logger.debug(f"Initialized visualization state with {len(self._visualization_state['x_coords'])} nodes (ID: {id(self)})")
        else:
            logger.warning(f"plot_data is None, visualization state may be incomplete (ID: {id(self)})")

        self._initialization_complete = True
        logger.debug(f"GridVisualizer initialization complete (ID: {id(self)})")

    def set_grid(self, grid: 'Grid'):
        """Update the grid reference and re-initialize dependent components."""
        old_grid_id = id(self.grid) if self.grid else None
        logger.debug(f"Setting new grid in GridVisualizer (Old ID: {old_grid_id}, New ID: {id(grid)})") # Enhanced logging

        # --- CRITICAL: Unregister from the old grid before setting the new one ---
        if self.grid:
            logger.debug(f"Unregistering from old grid: {id(self.grid)}")
            try: # Add try-except for robustness
                self.grid.remove_observer(self)
            except ValueError:
                 logger.warning("Observer already removed or not found in old grid.")
            except Exception as e:
                 logger.error(f"Error removing observer from old grid: {e}")
        # --- END CRITICAL FIX ---

        self.grid = grid
        logger.debug(f"New grid set in GridVisualizer: {self.grid._unique_id if self.grid else 'None'}, ID: {id(self.grid) if self.grid else 'None'}")

        # --- ADDED: Always force recalculation when grid changes ---
        self._recalculate_scaling = True
        logger.debug("Set _recalculate_scaling = True in set_grid")
        # ---

        # Reset cached data (already done in self.reset() below)
        # self.reset() # Call reset AFTER updating coord system

        # Update coordinate system with the actual grid dimensions
        if self.coord_system is None:
             self.coord_system = CoordinateSystem(
                 grid_dimensions=grid.dimensions,
                 node_spacing=GlobalSettings.Visualization.NODE_SPACING,
                 dimension_type=grid.dimension_type
             )
        else:
            self.coord_system.update_parameters(
                grid_dimensions=grid.dimensions,
                node_spacing=GlobalSettings.Visualization.NODE_SPACING, # Use global setting
                dimension_type=grid.dimension_type
            )
        logger.debug("Updated coordinate system with new grid parameters")

        # Reset visualizer state AFTER updating coordinate system
        self.reset()

        # Re-register with the new grid
        self.register_with_grid()

        # Re-initialize the debugger with the new grid
        if self.debugger: # Check if debugger exists
            self.debugger.grid = self.grid # Update grid reference
            self.debugger.coord_system = self.coord_system # Update coord system ref
        else:
            self.debugger = VisualizationDebugger(self.grid, self.ax, self.coord_system, self.gui) # Pass self.gui

        logger.debug("Grid updated in GridVisualizer")

    def register_with_grid(self):
        """Register this visualizer with the grid to receive updates"""
        if self.grid:
            logger.debug("Registering GridVisualizer with grid")
            logger.debug(f"GridVisualizer.register_with_grid: controller = {self.controller}, grid = {self.grid}")  # Add logging
            self.grid.add_observer(self)
        else:
            logger.warning("Grid is None in GridVisualizer. Cannot register.")

    def unregister_from_grid(self):
        """Unregister this visualizer from the grid"""
        if self.grid:
            logger.debug("Unregistering GridVisualizer from grid")
            logger.debug(f"GridVisualizer.unregister_from_grid: controller = {self.controller}, grid = {self.grid}")  # Add logging
            self.grid.remove_observer(self)
        else:
            logger.warning("Grid is None in GridVisualizer. Cannot unregister.")

    def update(self, subject):  
        """Handle updates from the observed subject (Grid or Controller)"""
        logger.debug(f"GridVisualizer received update from: {type(subject).__name__}") # Log the type of the subject
        
        # ADDED: Log the Grid ID and active node count
        if self.grid is not None:
            logger.debug(f"  Grid ID in GridVisualizer.update: {id(self.grid)}")
            active_count = np.sum(self.grid.grid_array > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD)
            logger.debug(f"  Grid has {active_count} active nodes")
        else:
            logger.debug("  Grid is None in GridVisualizer.update")
        # --- END ADDED SECTION ---
        
        # CRITICAL: Update the visualization state.  No arguments are passed here.
        self.update_visualization_state()

    def update_visualization_state(self, invalidate_blit_cache: bool = True, **kwargs) -> Dict[str, float]:
        """
        Update the visualization state dictionary (e.g., zoom_factor, colors) based on provided kwargs.
        Handles new coloring keys. Conditionally invalidates blit cache.
        (Round 6: Isolate selection_to_highlight update)
        """
        log_prefix = f"GridVisualizer.update_visualization_state(ID:{id(self)}): "
        state_id_before = id(self._visualization_state) if hasattr(self, '_visualization_state') else 'N/A'
        logger.debug(f"{log_prefix}ENTRY (invalidate_blit_cache={invalidate_blit_cache}) - State ID BEFORE update: {state_id_before}")
        logger.debug(f"{log_prefix}Received kwargs keys: {list(kwargs.keys())}")

        # --- MODIFIED: Isolate selection update ---
        # 1. Extract selection data if present
        selection_data = kwargs.pop('selection_to_highlight', None) # Use pop with default None

        # 2. Update the rest of the kwargs first
        keys_to_update = {k: v for k, v in kwargs.items() if k != 'colors'} # Exclude legacy 'colors' too for now
        self._visualization_state.update(keys_to_update)
        logger.debug(f"{log_prefix}Updated state with {len(keys_to_update)} keys from kwargs (excluding selection/colors).")

        # 3. Explicitly set selection_to_highlight AFTER the main update
        if selection_data is not None:
            if isinstance(selection_data, set):
                self._visualization_state['selection_to_highlight'] = selection_data
                logger.debug(f"{log_prefix}Explicitly SET 'selection_to_highlight' AFTER main update (Size: {len(selection_data)}).")
            else:
                logger.warning(f"{log_prefix}Received invalid type for 'selection_to_highlight': {type(selection_data)}. Setting to empty set.")
                self._visualization_state['selection_to_highlight'] = set()
        else:
            # If selection wasn't passed, ensure the key exists but *don't* overwrite if it already has content
            self._visualization_state.setdefault('selection_to_highlight', set())
            logger.debug(f"{log_prefix}'selection_to_highlight' not in kwargs. Ensured key exists (value: {len(self._visualization_state['selection_to_highlight'])}).")
        # --- END MODIFIED ---

        # 4. Handle legacy 'colors' key (keep previous logic)
        if 'colors' in kwargs:
            new_colors = kwargs['colors']
            self._visualization_state['colors'] = new_colors
            logger.debug(f"{log_prefix}Explicitly updated legacy 'colors' from kwargs (Length: {len(new_colors)}).")
        else:
            self._visualization_state['colors'] = []

        # 5. Set defaults (redundant but safe)
        self._visualization_state.setdefault('x_coords', np.array([]))
        self._visualization_state.setdefault('y_coords', np.array([]))
        self._visualization_state.setdefault('z_coords', np.array([]))
        self._visualization_state.setdefault('indices', np.array([], dtype=int))
        self._visualization_state.setdefault('node_face_colors', [])
        self._visualization_state.setdefault('coloring_values', None)
        self._visualization_state.setdefault('coloring_mode', 'base')
        self._visualization_state.setdefault('cmap_params', {'cmap_name': 'plasma', 'vmin': 0.0, 'vmax': 8.0})
        self._visualization_state.setdefault('segments', [])
        self._visualization_state.setdefault('edge_colors', [])
        self._visualization_state.setdefault('added_nodes_coords', set())
        self._visualization_state.setdefault('added_edges_coords', set())
        self._visualization_state.setdefault('highlight_on', True)
        self._visualization_state.setdefault('zoom_factor', 1.0)
        self._visualization_state.setdefault('node_size', self._calculate_base_node_size())
        self._visualization_state.setdefault('node_outline_width', GlobalSettings.Visualization.NODE_OUTLINE_WIDTH)
        self._visualization_state.setdefault('edge_width', GlobalSettings.Visualization.EDGE_WIDTH)
        self._visualization_state.setdefault('background_color', GlobalSettings.Colors.BACKGROUND)
        self._visualization_state.setdefault('node_color', GlobalSettings.Colors.NODE_ACTIVE)
        self._visualization_state.setdefault('node_base', GlobalSettings.Colors.NODE_INACTIVE)
        self._visualization_state.setdefault('node_outline_old', GlobalSettings.Colors.NODE_EDGE_OLD)
        self._visualization_state.setdefault('node_outline_new', GlobalSettings.Colors.NODE_EDGE_NEW)
        self._visualization_state.setdefault('default_edge_color', GlobalSettings.Colors.NODE_EDGE_OLD)
        self._visualization_state.setdefault('new_edge_color', GlobalSettings.Colors.NODE_EDGE_NEW)

        # --- ADDED LOGGING ---
        logger.debug(f"{log_prefix}State AFTER explicit updates and setdefault:")
        sel_state_after_update = self._visualization_state.get('selection_to_highlight', 'MISSING')
        logger.debug(f"  selection_to_highlight: Size={len(sel_state_after_update) if isinstance(sel_state_after_update, set) else 'N/A'}, Type={type(sel_state_after_update)}")
        state_id_after = id(self._visualization_state) if hasattr(self, '_visualization_state') else 'N/A'
        logger.debug(f"  State ID AFTER update: {state_id_after}")
        # --- END ADDED LOGGING ---

        if invalidate_blit_cache:
            self.blitting_manager.invalidate_cache()

        logger.debug(f"{log_prefix}EXIT")
        return {} # Return empty dict as per original signature

    def _calculate_outline_width(self, zoom_factor):
        """Calculate node outline width based on zoom."""
        base_outline_width = GlobalSettings.Visualization.NODE_OUTLINE_WIDTH
        if zoom_factor < 1.0: # Zooming in
            outline_width = base_outline_width / zoom_factor
            if GlobalSettings.Visualization.NODE_OUTLINE_ZOOM_IN_LIMIT > 0:
                outline_width = min(outline_width, base_outline_width * GlobalSettings.Visualization.NODE_OUTLINE_ZOOM_IN_LIMIT)
        else: # Zooming out or no zoom
            outline_width = base_outline_width / zoom_factor
            if GlobalSettings.Visualization.NODE_OUTLINE_ZOOM_OUT_LIMIT > 0:
                outline_width = max(outline_width, base_outline_width * GlobalSettings.Visualization.NODE_OUTLINE_ZOOM_OUT_LIMIT)
        return outline_width

    def _calculate_edge_width(self, zoom_factor):
        """Calculate edge width based on zoom."""
        base_edge_width = GlobalSettings.Visualization.EDGE_WIDTH
        if zoom_factor < 1.0: # Zooming in
            edge_width = base_edge_width / zoom_factor
            if GlobalSettings.Visualization.EDGE_THICKNESS_ZOOM_IN_LIMIT > 0:
                edge_width = min(edge_width, base_edge_width * GlobalSettings.Visualization.EDGE_THICKNESS_ZOOM_IN_LIMIT)
        else: # Zooming out or no zoom
            edge_width = base_edge_width / zoom_factor
            if GlobalSettings.Visualization.EDGE_THICKNESS_ZOOM_OUT_LIMIT > 0:
                edge_width = max(edge_width, base_edge_width * GlobalSettings.Visualization.EDGE_THICKNESS_ZOOM_OUT_LIMIT)
        return edge_width
    
    def update_camera_position(self):
        """Update the camera position based on the ViewManager"""
        self.view_manager.update_camera_position()

    def set_view(self, view_name):
        """Set the view using the ViewManager"""
        self.view_manager.set_view(view_name)
    
    def rotate_3d(self, delta_azim, delta_elev):
        """Rotate the 3D view"""
        self.view_manager.rotate_3d(delta_azim, delta_elev)

    def undo_view_change(self):
        """Undo the last view change"""
        self.view_manager.undo_view_change()

    def redo_view_change(self):
        """Redo the last undone view change"""
        self.view_manager.redo_view_change()

    def reset(self):
        """Reset the visualizer state, clearing artists and caches.
           (Round 1: Reset _last_rendered_... attributes)"""

        log_prefix = f"GridVisualizer.reset(ID:{id(self)}): "
        logger.debug(f"{log_prefix}Resetting GridVisualizer, Grid ID: {id(self.grid) if self.grid else 'None'}")

        if hasattr(self, 'debugger') and self.debugger:
            self.debugger.clear_debug_visuals()

        artists_to_remove = []
        if hasattr(self, '_node_scatter') and self._node_scatter: artists_to_remove.append(self._node_scatter)
        if hasattr(self, '_edge_lines') and self._edge_lines: artists_to_remove.append(self._edge_lines)
        if hasattr(self, '_node_scatter_3d') and self._node_scatter_3d: artists_to_remove.append(self._node_scatter_3d)
        if hasattr(self, '_edge_lines_3d') and self._edge_lines_3d:
            if isinstance(self._edge_lines_3d, list): artists_to_remove.extend(self._edge_lines_3d)
            else: artists_to_remove.append(self._edge_lines_3d)
        if hasattr(self, '_lasso_line') and self._lasso_line: artists_to_remove.append(self._lasso_line)
        if hasattr(self, '_edge_tool_temp_line') and self._edge_tool_temp_line: artists_to_remove.append(self._edge_tool_temp_line)
        if hasattr(self, 'selection_rect') and self.selection_rect: artists_to_remove.append(self.selection_rect)

        logger.debug(f"{log_prefix}  Attempting to remove {len(artists_to_remove)} artists.")
        for artist in artists_to_remove:
            if artist:
                try:
                    artist.remove()
                    logger.debug(f"{log_prefix}    Removed artist: {artist}")
                except ValueError: logger.debug(f"{log_prefix}    Artist {artist} already removed.")
                except Exception as e: logger.warning(f"{log_prefix}    Error removing artist {artist}: {e}")

        logger.debug(f"{log_prefix}  Setting artist references to None. Current _node_scatter ID: {id(self._node_scatter) if hasattr(self, '_node_scatter') and self._node_scatter else 'None'}")
        self._node_scatter = None
        self._edge_lines = None
        self._node_scatter_3d = None
        self._edge_lines_3d = None
        self._lasso_line = None
        self._edge_tool_temp_line = None
        self.selection_rect = None
        logger.debug(f"{log_prefix}  Cleared plot artist references. _node_scatter is now: {self._node_scatter}")

        # [ Reset tracking sets - Unchanged ]
        if hasattr(self, 'previous_active_nodes'): self.previous_active_nodes = set()
        if hasattr(self, 'previous_edges'): self.previous_edges = set()
        if hasattr(self, 'last_updated_nodes'): self.last_updated_nodes = set()
        if hasattr(self, 'last_updated_edges'): self.last_updated_edges = set()
        if hasattr(self, 'highlighted_nodes'): self.highlighted_nodes = set()
        if hasattr(self, 'highlighted_edges'): self.highlighted_edges = set()
        logger.debug(f"{log_prefix}  Reset tracking sets.")

        # [ Reset visualization state dictionary - Unchanged ]
        current_zoom = self._visualization_state.get('zoom_factor', 1.0)
        current_bg = self._visualization_state.get('background_color', GlobalSettings.Colors.BACKGROUND)
        current_node = self._visualization_state.get('node_color', GlobalSettings.Colors.NODE_ACTIVE)
        current_node_new = self._visualization_state.get('node_edge_new', GlobalSettings.Colors.NODE_EDGE_NEW)
        current_edge_old = self._visualization_state.get('default_edge_color', GlobalSettings.Colors.NODE_EDGE_OLD)
        current_edge_new = self._visualization_state.get('new_edge_color', GlobalSettings.Colors.NODE_EDGE_NEW)
        current_highlight = self._visualization_state.get('highlight_on', True)
        self._visualization_state = {
            'node_size': self._calculate_base_node_size(),
            'node_outline_width': GlobalSettings.Visualization.NODE_OUTLINE_WIDTH,
            'edge_width': GlobalSettings.Visualization.EDGE_WIDTH,
            'zoom_factor': current_zoom, 'highlight_changes': current_highlight,
            'background_color': current_bg, 'node_color': current_node,
            'node_edge_new': current_node_new, 'default_edge_color': current_edge_old,
            'new_edge_color': current_edge_new, 'x_coords': np.array([]),
            'y_coords': np.array([]), 'z_coords': np.array([]),
            'states': np.array([]), 'indices': np.array([], dtype=int),
            'segments': [], 'colors': [], 'node_outline_old': current_edge_old,
            'node_outline_new': current_edge_new, 'updated_nodes': set()
        }
        logger.debug(f"{log_prefix}  Reset visualization state dictionary.")

        # --- Reset last rendered state attributes ---
        self._last_rendered_node_offsets = None
        self._last_rendered_node_face_colors = None
        self._last_rendered_node_edge_colors = None
        self._last_rendered_node_size = None
        self._last_rendered_outline_width = None
        self._last_rendered_edge_segments = None
        self._last_rendered_edge_colors = None
        self._last_rendered_edge_width = None
        logger.debug(f"{log_prefix}  Reset _last_rendered_... attributes.")
        # ---

        # [ Reset flags and invalidate cache - Unchanged ]
        self.debug_mode = False
        self._recalculate_scaling = True
        self._first_update_done = False
        self.blitting_manager.invalidate_cache()
        logger.debug(f"{log_prefix}  Reset flags and invalidated blitting cache.")

        logger.info(f"{log_prefix}GridVisualizer reset complete")

    def reset_view(self):
        """Reset the view to show the entire grid"""
        if hasattr(self, 'view_manager') and self.view_manager:
            self.view_manager.fit_view_to_grid() # Use ViewManager # CHANGED
            # Invalidate blitting cache # ADDED
            self.blitting_manager.invalidate_cache()
            # Trigger a full redraw using _safe_plot_update # CHANGED
            if hasattr(self, 'gui') and self.gui and hasattr(self.gui, '_safe_plot_update'):
                self.gui._safe_plot_update(force=True)
            else:
                logger.warning("gui._safe_plot_update not found, cannot update plot")
            logger.debug("View reset to show entire grid")
        else:
            logger.warning("ViewManager not initialized, cannot reset view")
             
    def toggle_coordinate_labels(self, show=True):
            """Toggle visibility of coordinate labels without affecting debug mode"""
            logger.info("Entering GridVisualizer.toggle_coordinate_labels") # ADDED INFO LOG
            logger.debug(f"### GridVisualizer.toggle_coordinate_labels: START ### show={show}") # ADDED DEBUG LOG
            
            if self.debugger is None:
                logger.warning("Debugger is not initialized, cannot toggle coordinate labels")
                return
            
            logger.debug("Debugger is valid") # ADDED DEBUG LOG
            # Call the debugger method to handle the actual toggling
            if show:
                logger.debug("show is True - calling debugger methods to show coordinates") # ADDED DEBUG LOG
                self.debugger.show_grid_lines(color=None, alpha=1.0, zorder=100)
                self.debugger._add_coordinate_labels()
            else:
                logger.debug("show is False - calling debugger method to clear debug visuals") # ADDED DEBUG LOG
                self.debugger.clear_debug_visuals()
            
            # Invalidate blitting cache
            self.blitting_manager.invalidate_cache()
            
            # Force a redraw - already done in _on_show_coordinates_toggle, but double check here too
            if hasattr(self, 'gui') and self.gui and hasattr(self.gui, '_safe_plot_update'):
                self.gui._safe_plot_update(force=True)
                logger.debug("Forced plot update in GridVisualizer.toggle_coordinate_labels") # ADDED DEBUG LOGx
            logger.debug("### GridVisualizer.toggle_coordinate_labels: END ###") # ADDED DEBUG LOG

    def _update_from_snapshot(self, grid_snapshot: Dict[str, Any]):
        """Update internal state based on a grid snapshot dictionary."""
        # This method is primarily used by _prepare_plot_data now,
        # but we keep it for potential direct use or clarity.
        # The actual data extraction happens within _prepare_plot_data.
        logger.debug(f"GridVisualizer._update_from_snapshot: Processing snapshot for generation {grid_snapshot.get('generation', 'N/A')}")
        # No direct state update needed here as _prepare_plot_data handles it.
        pass

    @timer_decorator
    def update_visualization(self, nodes_to_highlight: Optional[Set[Tuple[int, ...]]] = None,
                             edges_to_highlight: Optional[Set[Tuple[Tuple[int, ...], Tuple[int, ...]]]] = None,
                             grid_snapshot: Optional[Dict[str, Any]] = None, # Keep for potential future direct calls
                             use_blitting: bool = False,
                             selection_to_highlight: Optional[Set[Tuple[int, ...]]] = None):
        """
        Update the visualization based on dimension, deciding between blit/full redraw.
        Assumes plot data is already prepared and stored in self._visualization_state.
        (Round 9: Reverted explicit selection passing)
        (Round 10: Only call draw/update methods)
        """
        try:
            log_prefix = f"GridVisualizer.update_visualization(ID:{id(self)}): "
            # --- REMOVED: Logging received highlights/selection (handled by caller/prep) ---
            # gen = grid_snapshot.get('generation', 'N/A') if grid_snapshot else 'N/A'
            # selection_from_state = self._visualization_state.get('selection_to_highlight', set())
            # logger.info(f"{log_prefix}RECEIVED HIGHLIGHTS (Gen {gen}): Nodes={len(nodes_to_highlight) if nodes_to_highlight else 0}, Edges={len(edges_to_highlight) if edges_to_highlight else 0}, Selection(Internal)={len(selection_from_state)})")

            if self.grid is None: logger.warning(f"{log_prefix}Grid is not initialized"); return
            if self.ax is None: logger.warning(f"{log_prefix}Axes are not initialized"); return

            # --- REMOVED: Data preparation call - assumes data is in _visualization_state ---
            # plot_data = self._prepare_plot_data(...)
            # self.update_visualization_state(...)
            # ---

            # --- Call the appropriate dimension-specific update/draw method ---
            # These methods now read directly from self._visualization_state
            logger.debug(f"{log_prefix}Calling dimension-specific update/draw (use_blitting={use_blitting})")
            if self.grid.dimension_type == Dimension.TWO_D:
                logger.debug(f"{log_prefix} >>> Calling _update_2d_visualization <<<")
                # Pass None for highlights, as they are baked into the state colors now
                self._update_2d_visualization(
                    nodes_to_highlight=None,
                    edges_to_highlight=None,
                    use_blitting=use_blitting
                )
                logger.debug(f"{log_prefix} <<< Returned from _update_2d_visualization <<<")
            else:  # THREE_D
                logger.debug(f"{log_prefix} >>> Calling _update_3d_visualization <<<")
                # Pass None for highlights, as they are baked into the state colors now
                self._update_3d_visualization(
                    nodes_to_highlight=None,
                    edges_to_highlight=None,
                    use_blitting=use_blitting, # Pass the flag (though 3D won't blit)
                    selection_to_highlight=self._visualization_state.get('selection_to_highlight', set()) # Pass current selection state
                )
                logger.debug(f"{log_prefix} <<< Returned from _update_3d_visualization <<<")

        except Exception as e:
            logger.error(f"Error updating visualization: {e}")
            logger.error(traceback.format_exc())

    @timer_decorator
    def _update_2d_visualization(self, nodes_to_highlight: Optional[Set[Tuple[int, ...]]] = None,
                                 edges_to_highlight: Optional[Set[Tuple[Tuple[int, ...], Tuple[int, ...]]]] = None,
                                 use_blitting: bool = False):
                                 # REVERTED: Removed explicit selection param
        """
        Update the 2D visualization, handling artist creation if needed.
        Applies color precedence and respects highlight_on flag.
        Reads selection from internal state.
        Conditionally draws artists during blitting based on update flags.
        (Round 3: Add logging for data read from state)
        (Round 9: Reverted explicit selection passing)
        (Round 4: Implement conditional artist drawing for blitting)
        (Round 26: Add detailed logging for conditional drawing)
        """
        log_prefix = f"_update_2d_visualization(ID:{id(self)} R3 Log): " # Updated round
        selection_from_state = self._visualization_state.get('selection_to_highlight', set())
        # logger.info(f"{log_prefix}ENTRY (use_blitting={use_blitting}, Selection(Internal)={len(selection_from_state)})") # Reduce noise
        detailed_logging_enabled = LogSettings.Performance.ENABLE_DETAILED_LOGGING # Check flag

        try:
            plot_data = self._visualization_state
            if not plot_data or plot_data.get('x_coords') is None:
                logger.warning(f"{log_prefix}Internal plot_data invalid, cannot update 2D visualization.")
                return

            highlight_on = self._visualization_state.get('highlight_on', True)
            # logger.debug(f"{log_prefix}Extracted highlight_on from _visualization_state: {highlight_on}") # Reduce noise

            # --- ADDED: Log data read from state ---
            indices = plot_data.get('indices', np.array([], dtype=int))
            node_face_colors = plot_data.get('node_face_colors')
            x_coords = plot_data.get('x_coords')
            y_coords = plot_data.get('y_coords')
            segments = plot_data.get('segments')
            colors = plot_data.get('edge_colors', []) # Use pre-calculated HEX colors
            if colors is None: colors = []; logger.warning(f"{log_prefix}plot_data['edge_colors'] was None, defaulting to empty list.")

            logger.debug(f"{log_prefix}--- Data Read from State ---")
            logger.debug(f"  x_coords: Shape={x_coords.shape if x_coords is not None else 'None'}, Dtype={x_coords.dtype if x_coords is not None else 'None'}")
            logger.debug(f"  y_coords: Shape={y_coords.shape if y_coords is not None else 'None'}, Dtype={y_coords.dtype if y_coords is not None else 'None'}")
            logger.debug(f"  indices: Shape={indices.shape if indices is not None else 'None'}, Dtype={indices.dtype if indices is not None else 'None'}")
            logger.debug(f"  node_face_colors: Type={type(node_face_colors)}, Length={len(node_face_colors) if node_face_colors is not None else 'None'}")
            logger.debug(f"  segments: Type={type(segments)}, Length={len(segments) if segments is not None else 'None'}")
            logger.debug(f"  edge_colors: Type={type(colors)}, Length={len(colors)}")
            # --- END ADDED ---

            if use_blitting and self.blitting_manager.is_valid():
                if detailed_logging_enabled: logger.debug(f"{log_prefix}Using blitting for update.")
                # --- Blitting Path ---
                if self._node_scatter is None:
                    logger.warning(f"{log_prefix}Blitting requested but _node_scatter is None. Forcing full redraw.")
                    if hasattr(self.gui, '_safe_plot_update'):
                        self.gui._safe_plot_update(force=True, nodes_to_highlight=nodes_to_highlight, edges_to_highlight=edges_to_highlight) # Pass original highlights
                    return
                # Edge lines can be None if there are no edges, that's okay for blitting.

                bg_buffer = self.blitting_manager.background
                self.fig.canvas.restore_region(bg_buffer)

                # --- Call update methods and capture flags ---
                nodes_updated = self._update_nodes_2d(x_coords, y_coords, node_face_colors, indices, nodes_to_highlight)
                edges_updated = self._update_edges_2d(segments, colors) # Pass colors list
                if detailed_logging_enabled: logger.debug(f"{log_prefix}Update flags: nodes_updated={nodes_updated}, edges_updated={edges_updated}")
                # ---

                # --- Conditionally draw artists ---
                artists_drawn_count = 0
                if nodes_updated and self._node_scatter:
                    if detailed_logging_enabled: logger.debug(f"{log_prefix}Blit: Nodes updated, drawing node scatter artist.")
                    self.ax.draw_artist(self._node_scatter)
                    artists_drawn_count += 1
                # else: # Reduce noise
                    # if detailed_logging_enabled: logger.debug(f"{log_prefix}Blit: Nodes not updated, skipping node draw_artist.")

                if edges_updated and self._edge_lines: # Check if edge lines exist after update
                    if detailed_logging_enabled: logger.debug(f"{log_prefix}Blit: Edges updated, drawing edge lines artist.")
                    self.ax.draw_artist(self._edge_lines)
                    artists_drawn_count += 1
                # else: # Reduce noise
                    # if detailed_logging_enabled: logger.debug(f"{log_prefix}Blit: Edges not updated or no edges exist, skipping edge draw_artist.")
                # ---

                # --- Blit changes ---
                if artists_drawn_count > 0:
                    self.fig.canvas.blit(self.ax.bbox)
                    if detailed_logging_enabled: logger.debug(f"{log_prefix}Blitting update complete ({artists_drawn_count} artists drawn).")
                else:
                    if detailed_logging_enabled: logger.debug(f"{log_prefix}No artists updated, skipping blit.")
                # --- End Blitting Path ---

            else: # --- Full Redraw Path ---
                logger.info(f"{log_prefix}Performing full redraw (blitting disabled/invalid or forced).")
                if self.blitting_manager.background is not None:
                    logger.debug(f"{log_prefix}Invalidating existing blitting background for full redraw.")
                    self.blitting_manager.invalidate_cache()

                # [ Reset Axes Properties - Unchanged ]
                bg_color = self._visualization_state.get('background_color', GlobalSettings.Colors.BACKGROUND)
                self.fig.set_facecolor(bg_color); self.ax.set_facecolor(bg_color)
                self.ax.patch.set_facecolor(bg_color); self.ax.patch.set_alpha(1.0); self.ax.patch.set_visible(True) # type: ignore [reportAttributeAccessIssue]
                self.ax.grid(False); self.ax.set_xticks([]); self.ax.set_yticks([]);
                for spine in self.ax.spines.values(): spine.set_visible(False)
                self.ax.set_axis_off()

                # [ Restore Limits - Unchanged ]
                if hasattr(self.gui, '_view_state'):
                    if 'xlim' in self.gui._view_state and self.gui._view_state['xlim']: self.ax.set_xlim(self.gui._view_state['xlim'])
                    if 'ylim' in self.gui._view_state and self.gui._view_state['ylim']: self.ax.set_ylim(self.gui._view_state['ylim'])
                    if self.grid and self.grid.dimension_type == Dimension.TWO_D: self.ax.set_aspect('equal', adjustable='box')
                    elif self.grid and self.grid.dimension_type == Dimension.THREE_D:
                         if 'zlim' in self.gui._view_state and self.gui._view_state['zlim']: self.ax.set_zlim(self._view_state['zlim']) # type: ignore
                         self.ax.set_box_aspect([1, 1, 1]) # type: ignore [reportArgumentType]
                else: logger.warning(f"{log_prefix}Cannot restore limits: self.gui._view_state not found.")

                # 3. Call DRAW methods, WITHOUT passing selection
                logger.debug(f"{log_prefix}Calling _draw_nodes_2d with explicit highlight_on={highlight_on}")
                self._draw_nodes_2d(x_coords, y_coords, node_face_colors, indices, nodes_to_highlight)
                log_limit = min(10, len(colors))
                logger.debug(f"{log_prefix}Calling _draw_edges_2d with {len(colors)} colors (First {log_limit}): {colors[:log_limit]}")
                self._draw_edges_2d(segments, colors) # Pass colors list

                # 4. Final Canvas Draw
                if self.fig and self.fig.canvas:
                    logger.info(f"{log_prefix}Drawing canvas with content.")
                    draw_start_content = time.time()
                    self.fig.canvas.draw()
                    draw_end_content = time.time()
                    logger.info(f"{log_prefix}Content canvas draw took {(draw_end_content - draw_start_content)*1000:.2f} ms.")
                # --- End Full Redraw Path ---

        except Exception as e:
            logger.error(f"Error in _update_2d_visualization: {e}")
            logger.error(traceback.format_exc())
            self.blitting_manager.invalidate_cache()

    @timer_decorator
    def _update_3d_visualization(self, nodes_to_highlight: Optional[Set[Tuple[int, ...]]] = None,
                                 edges_to_highlight: Optional[Set[Tuple[Tuple[int, ...], Tuple[int, ...]]]] = None,
                                 use_blitting: bool = False,
                                 selection_to_highlight: Optional[Set[Tuple[int, ...]]] = None): # ADDED selection_to_highlight
                                 # REMOVED selection_to_highlight parameter from docstring (it's now explicit)
        """Update the 3D visualization, ensuring background and axes properties match initial draw.
           Uses explicitly passed selection set.
           (Round 8: Accept selection_to_highlight explicitly)"""

        log_prefix = f"_update_3d_visualization(ID:{id(self)}): "
        # --- MODIFIED: Log received selection ---
        logger.info(f"{log_prefix}ENTRY (Blitting Decision: {use_blitting}, Selection Received={len(selection_to_highlight) if selection_to_highlight else 'None'})")
        # ---
        logger.info(f"{log_prefix}Highlights Received: Nodes={len(nodes_to_highlight) if nodes_to_highlight else 0}, Edges={len(edges_to_highlight) if edges_to_highlight else 0}")

        try:
            plot_data = self._visualization_state
            if not plot_data or plot_data.get('x_coords') is None:
                logger.warning(f"{log_prefix}Internal plot_data invalid, cannot update 3D visualization.")
                return

            # --- Blitting is disabled for 3D ---
            if use_blitting:
                 logger.warning(f"{log_prefix}Blitting requested for 3D, but it's disabled. Performing full redraw.")
            # ---

            # --- Full redraw ---
            logger.info(f"{log_prefix}Performing full redraw (3D or blit disabled/invalid).")
            if self.blitting_manager.background is not None:
                logger.debug(f"{log_prefix}Invalidating blitting background for full redraw.")
                self.blitting_manager.invalidate_cache() # Logged inside invalidate

            # [ Reset Axes Properties - Unchanged ]
            bg_color = self._visualization_state.get('background_color', GlobalSettings.Colors.BACKGROUND)
            self.fig.set_facecolor(bg_color)
            self.ax.set_facecolor(bg_color)
            self.ax.patch.set_facecolor(bg_color)
            self.ax.patch.set_alpha(1.0)
            self.ax.patch.set_visible(True)
            self.ax.grid(False)
            self.ax.set_xticks([])
            self.ax.set_yticks([])
            self.ax.set_zticks([]) # type: ignore
            self.ax.set_axis_off()
            # [ Restore Limits and View - Unchanged ]
            if hasattr(self.gui, '_view_state'):
                if 'xlim' in self.gui._view_state and self.gui._view_state['xlim']: self.ax.set_xlim(self.gui._view_state['xlim'])
                if 'ylim' in self.gui._view_state and self.gui._view_state['ylim']: self.ax.set_ylim(self.gui._view_state['ylim'])
                if 'zlim' in self.gui._view_state and self.gui._view_state['zlim']: self.ax.set_zlim(self.gui._view_state['zlim']) # type: ignore
                if 'elev' in self.gui._view_state and 'azim' in self.gui._view_state:
                    elev = self.gui._view_state.get('elev', 30)
                    azim = self.gui._view_state.get('azim', 45)
                    self.ax.view_init(elev=elev, azim=azim) # type: ignore
            else: logger.warning(f"{log_prefix}Cannot restore limits/view: self.gui._view_state not found.")
            self.ax.set_box_aspect([1, 1, 1])

            # [ Prepare data args ]
            indices = plot_data.get('indices', np.array([], dtype=int))
            node_face_colors = plot_data.get('node_face_colors')

            # [ Call draw methods, PASSING selection ]
            logger.debug(f"{log_prefix}Calling _draw_nodes_3d")
            # --- MODIFIED: Pass selection_to_highlight ---
            self._draw_nodes_3d(plot_data['x_coords'], plot_data['y_coords'], plot_data['z_coords'],
                                node_face_colors, indices, nodes_to_highlight, selection_to_highlight)
                                # selection_to_highlight passed here
            # --- END MODIFIED ---
            logger.debug(f"{log_prefix}Calling _draw_edges_3d")
            self._draw_edges_3d(plot_data['segments'], plot_data['edge_colors']) # Use pre-calculated edge colors

            if self.fig and self.fig.canvas:
                logger.info(f"{log_prefix}Drawing canvas for full redraw.")
                draw_start = time.time()
                self.fig.canvas.draw()
                draw_end = time.time()
                logger.info(f"{log_prefix}Canvas draw took {(draw_end - draw_start)*1000:.2f} ms.")

                # --- Capture background AFTER drawing ---
                if self.blitting_manager.enabled: # Only capture if blitting is globally enabled
                    logger.debug(f"{log_prefix}Capturing background for blitting AFTER full draw.")
                    try:
                        if self.fig.canvas.get_renderer() is None:
                            logger.warning(f"{log_prefix}Renderer not available after draw, cannot capture background.")
                        else:
                            self.blitting_manager.background = self.fig.canvas.copy_from_bbox(self.fig.bbox)
                            if self.blitting_manager.background is not None:
                                logger.info(f"{log_prefix}Background captured successfully (type: {type(self.blitting_manager.background)}).")
                            else:
                                logger.error(f"{log_prefix}Background capture FAILED (result is None).")
                    except Exception as e_bg:
                        logger.error(f"{log_prefix}Error capturing background: {e_bg}")
                        self.blitting_manager.invalidate_cache() # Logged inside invalidate
                else:
                    logger.debug(f"{log_prefix}Blitting disabled, not capturing background.")
                # --- END ADDED ---

        except Exception as e:
            logger.error(f"Error in _update_3d_visualization: {e}")
            logger.error(traceback.format_exc())
            self.blitting_manager.invalidate_cache() # Logged inside invalidate

    @timer_decorator
    def _update_with_blitting(self, plot_data,
                              nodes_to_highlight: Optional[Set[Tuple[int, ...]]] = None,
                              edges_to_highlight: Optional[Set[Tuple[Tuple[int, ...], Tuple[int, ...]]]] = None):
        """
        Update the plot using blitting, following the standard efficient pattern.
        Always draws both node and edge artists if they exist.
        (Round 15: Always draw artists during blit)
        (Round 4 Fix: Pass correct arguments to _update_nodes_2d)
        """
        log_prefix = f"_update_with_blitting(ID:{id(self)} R15 Draw All): " # Updated round
        logger.debug(f"{log_prefix}Entering _update_with_blitting")

        if not self.blitting_manager.is_valid():
            logger.warning(f"{log_prefix}Blitting cache invalid or background missing, cannot blit.")
            if hasattr(self, 'gui') and self.gui:
                 self.gui._safe_plot_update(force=True, nodes_to_highlight=nodes_to_highlight, edges_to_highlight=edges_to_highlight)
            return

        try:
            # --- 1. Restore background ---
            bg_buffer = self.blitting_manager.background
            # logger.info(f"{log_prefix}Attempting to restore background (Buffer type: {type(bg_buffer)})...") # Reduce noise
            self.fig.canvas.restore_region(bg_buffer)
            # logger.info(f"{log_prefix}Background restored successfully.") # Reduce noise

            # --- 2. Update Artist DATA ---
            indices = self._visualization_state.get('indices', np.array([], dtype=int))
            node_face_colors = self._visualization_state.get('node_face_colors')
            x_coords = self._visualization_state.get('x_coords')
            y_coords = self._visualization_state.get('y_coords')
            segments = self._visualization_state.get('segments')
            colors_list = self._visualization_state.get('edge_colors') # Use pre-calculated edge colors

            # Call update methods (these should ONLY update data, not draw)
            nodes_updated_flag = False
            edges_updated_flag = False
            if hasattr(self, '_node_scatter') and self._node_scatter is not None:
                nodes_updated_flag = self._update_nodes_2d(x_coords, y_coords, node_face_colors, indices, nodes_to_highlight)
            if hasattr(self, '_edge_lines') and self._edge_lines is not None:
                edges_updated_flag = self._update_edges_2d(segments, colors_list if colors_list is not None else []) # Pass pre-calculated edge colors

            # --- 3. Draw updated artists ---
            # --- MODIFIED: Always draw artists if they exist ---
            artists_to_draw = []
            if self._node_scatter: artists_to_draw.append(self._node_scatter)
            if self._edge_lines: artists_to_draw.append(self._edge_lines)
            logger.debug(f"{log_prefix}Drawing {len(artists_to_draw)} artists for blit (Nodes Updated: {nodes_updated_flag}, Edges Updated: {edges_updated_flag}).")
            # --- END MODIFIED ---

            for artist in artists_to_draw:
                if artist is not None:
                    try:
                        self.ax.draw_artist(artist)
                    except Exception as draw_err:
                        logger.error(f"{log_prefix}Error drawing artist {artist}: {draw_err}")

            # --- 4. ADDED: Draw Idle ---
            # logger.info(f"{log_prefix}Calling canvas.draw_idle() before blit.") # Reduce noise
            self.fig.canvas.draw_idle()
            # ---

            # --- 5. Blit changes ---
            # logger.info(f"{log_prefix}Calling canvas.blit.") # Reduce noise
            blit_start = time.time()
            self.fig.canvas.blit(self.ax.bbox) # Use ax.bbox
            blit_end = time.time()
            # logger.info(f"{log_prefix}Canvas blit took {(blit_end - blit_start)*1000:.2f} ms.") # Reduce noise

        except Exception as e:
            logger.error(f"Error during blitting update: {e}")
            logger.error(traceback.format_exc())
            self.blitting_manager.invalidate_cache() # Invalidate cache on error
            if hasattr(self, 'gui') and self.gui:
                 # Fallback to full redraw on error
                 self.gui._safe_plot_update(force=True, nodes_to_highlight=nodes_to_highlight, edges_to_highlight=edges_to_highlight)

    def _draw_initial_frame(self):
        """Set up axes properties, capture clean background, then fit view and draw."""
        log_prefix = f"_draw_initial_frame(ID:{id(self)}): "
        logger.debug(f"{log_prefix}Entering (Setup + Capture Clean BG + Fit View)")

        if not hasattr(self.gui, '_color_scheme_loaded') or not self.gui._color_scheme_loaded:
            logger.debug(f"{log_prefix}Skipping - color scheme not loaded yet")
            return

        grid_id_at_draw = id(self.grid) if self.grid else "None"
        logger.info(f"{log_prefix}Setting up initial frame for grid ID {grid_id_at_draw}.")

        if self.grid is None or self.grid.grid_array is None:
            logger.warning(f"{log_prefix}Grid is None or has no grid_array attribute")
            return

        # --- 1. Reset Axes Properties ---
        bg_color = self._visualization_state.get('background_color', GlobalSettings.Colors.BACKGROUND)
        self.fig.set_facecolor(bg_color)
        self.ax.set_facecolor(bg_color)
        self.ax.patch.set_facecolor(bg_color) # type: ignore [reportAttributeAccessIssue]
        self.ax.patch.set_alpha(1.0) # type: ignore [reportAttributeAccessIssue]
        self.ax.patch.set_visible(True) # type: ignore [reportAttributeAccessIssue]
        self.ax.grid(False)
        self.ax.set_axisbelow(True)
        self.ax.tick_params(colors='gray')
        for spine in self.ax.spines.values(): spine.set_visible(False)
        self.ax.set_xticks([]); self.ax.set_yticks([])
        if hasattr(self.ax, 'set_zticks'): self.ax.set_zticks([]) # type: ignore
        self.ax.set_axis_off()
        if self.grid.dimension_type == Dimension.THREE_D:
            self.ax.set_box_aspect([1, 1, 1]) # type: ignore [reportArgumentType]
        else:
            self.ax.set_aspect('equal', adjustable='box')
        logger.debug(f"{log_prefix}Axes properties set.")

        # --- 2. Force Draw of EMPTY Axes and Capture CLEAN Background ---
        # This happens BEFORE fit_view_to_grid draws anything
        if self.blitting_manager.enabled:
            logger.info(f"{log_prefix}Drawing EMPTY canvas for background capture.")
            # Set temporary minimal limits to ensure canvas is valid for drawing
            self.ax.set_xlim(-1, 1); self.ax.set_ylim(-1, 1)
            if hasattr(self.ax, 'set_zlim'): self.ax.set_zlim(-1, 1) # type: ignore
            draw_start_empty = time.time()
            self.fig.canvas.draw() # Draw the empty axes
            self.fig.canvas.flush_events()
            draw_end_empty = time.time()
            logger.info(f"{log_prefix}Empty canvas draw took {(draw_end_empty - draw_start_empty)*1000:.2f} ms.")

            logger.debug(f"{log_prefix}Capturing CLEAN background for blitting.")
            try:
                if self.fig.canvas.get_renderer() is None:
                    logger.warning(f"{log_prefix}Renderer not available, cannot capture background.")
                else:
                    self.blitting_manager.background = self.fig.canvas.copy_from_bbox(self.ax.bbox) # type: ignore [reportAttributeAccessIssue]
                    if self.blitting_manager.background is not None:
                        logger.info(f"{log_prefix}CLEAN background captured successfully.")
                    else:
                        logger.error(f"{log_prefix}CLEAN background capture FAILED (result is None).")
            except Exception as e_bg:
                logger.error(f"{log_prefix}Error capturing clean background: {e_bg}")
                self.blitting_manager.invalidate_cache()
        else:
            logger.debug(f"{log_prefix}Blitting disabled, not capturing background.")
        # --- END BACKGROUND CAPTURE ---

        # --- 3. Fit View (Sets Limits and Draws Initial State) ---
        # This will now draw Gen 0 onto the canvas for the user, but the
        # clean background is already saved.
        if hasattr(self, 'view_manager') and self.view_manager:
            logger.debug(f"{log_prefix}Calling view_manager.fit_view_to_grid() to set limits and draw Gen 0.")
            # --- MODIFIED: Removed capture_background argument ---
            self.view_manager.fit_view_to_grid(called_from="_draw_initial_frame_step3")
            # --- END MODIFIED ---
            logger.debug(f"{log_prefix}Returned from fit_view_to_grid (limits set, Gen 0 drawn).")
        else:
            logger.error(f"{log_prefix}ViewManager not available, cannot fit view or draw.")
            return
        # ---

        self._first_update_done = True
        logger.debug(f"{log_prefix}Set _first_update_done = True")
        logger.debug(f"{log_prefix}EXIT")

    def _calculate_base_node_size(self):
        """Calculate the base node size based on grid dimensions, using cache."""
        # (Keep calculation from Round 21 - based on reference size and grid dimension)
        log_prefix = f"_calculate_base_node_size(ID:{id(self)}): "
        logger.debug(f"{log_prefix}ENTRY")

        if self.grid:
            current_dims = tuple(self.grid.dimensions) # Ensure it's a tuple
            logger.debug(f"{log_prefix}Current Grid Dims: {current_dims}, Cached Dims: {self._cached_base_size_dims}") # Log dims

            if self._cached_base_size_dims != current_dims:
                logger.info(f"{log_prefix}Recalculating base node size for dimensions: {current_dims}") # Use INFO level
                reference_dimension = 50 # Or use a GlobalSetting if preferred
                base_reference_size = GlobalSettings.Visualization.BASE_NODE_SIZE_REFERENCE # e.g., 100

                max_dim = max(current_dims) if current_dims else reference_dimension
                scale_factor = reference_dimension / max(1, max_dim) # Avoid division by zero
                self._cached_base_node_size = base_reference_size * scale_factor

                self._cached_base_size_dims = current_dims # Update cached dimensions
                logger.info(f"{log_prefix}New calculated base node size: {self._cached_base_node_size:.4f} (MaxDim={max_dim}, RefDim={reference_dimension}, RefSize={base_reference_size})") # Use INFO level
            else:
                logger.debug(f"{log_prefix}Using cached base node size: {self._cached_base_node_size:.4f}") # Log cached value
            return self._cached_base_node_size
        else:
            logger.warning(f"{log_prefix}Grid not available, returning default/last cached base node size: {getattr(self, '_cached_base_node_size', GlobalSettings.Visualization.NODE_SIZE * 100):.4f}")
            return getattr(self, '_cached_base_node_size', GlobalSettings.Visualization.NODE_SIZE * 100) # Fallback
                  
    def _calculate_node_size(self, zoom_factor=1.0):
        """
        Calculate the appropriate node size in points^2 for scatter plot,
        applying the NODE_SIZE setting and zoom factor to the base size.
        """
        # log_prefix = f"_calculate_node_size(ID:{id(self)}): "
        # logger.debug(f"{log_prefix}ENTRY - Received zoom_factor = {zoom_factor:.4f}")

        base_node_size = self._calculate_base_node_size()
        # logger.debug(f"{log_prefix}Base node size used: {base_node_size:.4f}")

        # Apply NODE_SIZE setting as a multiplier
        node_size_setting_multiplier = GlobalSettings.Visualization.NODE_SIZE
        size_after_setting = base_node_size * node_size_setting_multiplier
        # logger.debug(f"{log_prefix}Size after applying NODE_SIZE setting ({node_size_setting_multiplier:.2f}): {size_after_setting:.4f}")

        node_size = size_after_setting # Start with size adjusted by setting

        # Apply zoom scaling using global settings directly
        if abs(zoom_factor - 1.0) < 1e-6:
            # node_size remains size_after_setting
            # logger.debug(f"{log_prefix}Zoom is ~1.0, size remains {node_size:.4f}")
            pass # Add pass to make the empty if block valid
        elif zoom_factor < 1.0:  # Zooming in
            exponent = GlobalSettings.Visualization.NODE_DIAMETER_ZOOM_IN_AMP
            node_size = size_after_setting * (1.0 / zoom_factor) ** exponent
            # logger.debug(f"{log_prefix}Zooming IN - Using exponent: {exponent:.4f}")
        else:  # Zooming out (zoom_factor > 1.0)
            exponent = -GlobalSettings.Visualization.NODE_DIAMETER_ZOOM_OUT_AMP
            node_size = size_after_setting * (zoom_factor ** exponent)
            # logger.debug(f"{log_prefix}Zooming OUT - Using exponent: {exponent:.4f}")

        # logger.debug(f"{log_prefix}Size after zoom scaling: {node_size:.4f}")

        # Apply limits (relative to the size *after* applying the NODE_SIZE setting)
        limit_in = GlobalSettings.Visualization.NODE_DIAMETER_ZOOM_IN_LIMIT
        limit_out = GlobalSettings.Visualization.NODE_DIAMETER_ZOOM_OUT_LIMIT
        if limit_in > 0:
            max_size = limit_in * size_after_setting # Limit relative to size after setting
            if node_size > max_size:
                node_size = max_size
                # logger.debug(f"{log_prefix}Applied IN limit ({limit_in:.2f} * setting_adjusted_base). Size capped at: {node_size:.4f}")
        if limit_out > 0:
            min_size = limit_out * size_after_setting # Limit relative to size after setting
            if node_size < min_size:
                node_size = min_size
                # logger.debug(f"{log_prefix}Applied OUT limit ({limit_out:.2f} * setting_adjusted_base). Size floored at: {node_size:.4f}")

        # Ensure node size is not negative
        final_node_size = max(node_size, 0.1) # Keep a tiny minimum
        if final_node_size != node_size:
             # logger.debug(f"{log_prefix}Applied minimum size clamp (0.1).")
             pass # Add pass to make the empty if block valid

        # logger.debug(f"{log_prefix}EXIT - Final calculated node_size = {final_node_size:.4f}")
        return final_node_size

    @staticmethod
    @timer_decorator
    def _prepare_plot_data_static(
        grid_array: Optional[np.ndarray],
        edges: Optional[Set[Tuple[Tuple[int, ...], Tuple[int, ...]]]],
        edge_states: Optional[Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float]],
        generation: int,
        visualization_params: Dict[str, Any],
        coord_system: CoordinateSystem,
        nodes_to_highlight: Optional[Set[Tuple[int, ...]]] = None,
        edges_to_highlight: Optional[Set[Tuple[Tuple[int, ...], Tuple[int, ...]]]] = None,
        previous_degree_array: Optional[np.ndarray] = None,
        previous_active_neighbor_array: Optional[np.ndarray] = None
    ) -> Optional[Dict[str, Any]]:
        """
        Static helper to prepare plot data. Accepts individual grid data arrays/values
        and visualization parameters. Uses parameters from the passed
        visualization_params dictionary. Vectorizes edge color calculation.
        Adds robust checks for coloring value arrays using safe_numeric_array.
        Ensures vmin/vmax values are floats.
        (Round 18: Add robust checks for coloring value arrays)
        (Round 10: Vectorize edge color calculation)
        (Round 5: Add dtype logging)
        (Round 6: Re-implement safe_numeric_array fix)
        (Round 7: Add detailed internal dtype logging)
        (Round 8: Ensure vmin/vmax are floats)
        """
        log_prefix = f"_prepare_plot_data_static (Gen {generation} R8 Vmin/Vmax Fix): " # Updated round
        logger.debug(f"{log_prefix}Preparing plot data statically using provided visualization_params.")
        detailed_logging_enabled = LogSettings.Performance.ENABLE_DETAILED_LOGGING

        # --- Log dtype of received arrays ---
        logger.debug(f"{log_prefix}Received previous_degree_array: Type={type(previous_degree_array)}, Dtype={previous_degree_array.dtype if isinstance(previous_degree_array, np.ndarray) else 'N/A'}")
        logger.debug(f"{log_prefix}Received previous_active_neighbor_array: Type={type(previous_active_neighbor_array)}, Dtype={previous_active_neighbor_array.dtype if isinstance(previous_active_neighbor_array, np.ndarray) else 'N/A'}")
        # ---

        def safe_numeric_array(arr, fallback_value=np.nan):
            """Convert arr to a float64 numpy array, replacing non-numeric values with fallback_value."""
            if arr is None: return np.array([], dtype=np.float64) # Handle None input
            # Ensure input is a numpy array first
            if not isinstance(arr, np.ndarray):
                try: arr = np.array(arr)
                except Exception as e: logger.error(f"safe_numeric_array: Failed to convert input to numpy array: {e}"); return np.array([], dtype=np.float64)

            # Check if already numeric
            if np.issubdtype(arr.dtype, np.number):
                return arr.astype(np.float64) # Ensure float64

            # If not numeric, attempt conversion using pd.to_numeric
            logger.warning(f"safe_numeric_array: Input array dtype is {arr.dtype}, attempting conversion with errors='coerce'.")
            try:
                # Use pandas for robust conversion, coercing errors to NaN
                import pandas as pd
                # Ensure input to pd.to_numeric is 1D
                original_shape = arr.shape
                numeric_flat = pd.to_numeric(arr.ravel(), errors='coerce')
                # Convert pandas Series back to NumPy array and reshape
                numeric_arr = numeric_flat.reshape(original_shape).astype(np.float64)
                # Replace NaN with the specified fallback value
                numeric_arr[np.isnan(numeric_arr)] = fallback_value
                logger.debug(f"safe_numeric_array: Conversion successful. Result dtype: {numeric_arr.dtype}")
                return numeric_arr
            except ImportError:
                logger.error("safe_numeric_array: pandas is not installed. Cannot perform robust conversion. Falling back.")
                # Fallback without pandas (less robust)
                converted = []
                for x in arr.ravel():
                    try: converted.append(float(x))
                    except (ValueError, TypeError): converted.append(fallback_value)
                return np.array(converted, dtype=np.float64).reshape(arr.shape)
            except Exception as e:
                logger.error(f"safe_numeric_array: Error during conversion: {e}")
                return np.full(arr.shape, fallback_value, dtype=np.float64) # Return array of fallbacks

        try:
            # --- Data Source Logic ---
            grid_array_local = grid_array
            edges_local = edges if edges is not None else set()
            edge_states_local = edge_states if edge_states is not None else {}
            if grid_array_local is None: raise ValueError("Received grid_array is None")
            if not isinstance(grid_array_local, np.ndarray): raise TypeError("'grid_array' must be a NumPy array")
            if not isinstance(edges_local, set): raise TypeError("'edges' must be a set")
            if not isinstance(edge_states_local, dict): raise TypeError("'edge_states' must be a dict")

            grid_dims = grid_array_local.shape
            dimension_type = Dimension.TWO_D if len(grid_dims) == 2 else Dimension.THREE_D
            total_nodes = np.prod(grid_dims)

            # --- Get Visible Nodes and Positions ---
            visibility_threshold = GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD
            visible_mask = grid_array_local > visibility_threshold
            visible_indices = np.where(visible_mask.ravel())[0]
            node_positions = {}
            x_coords_list, y_coords_list, z_coords_list = [], [], []
            states_list, indices_list = [], []
            for idx in visible_indices:
                try:
                    display_coords = coord_system.index_to_display(idx, grid_dims)
                    node_positions[idx] = display_coords
                    x_coords_list.append(display_coords[0]); y_coords_list.append(display_coords[1])
                    if dimension_type == Dimension.THREE_D and len(display_coords) > 2: z_coords_list.append(display_coords[2])
                    states_list.append(grid_array_local.ravel()[idx]); indices_list.append(idx)
                except Exception as pos_err: logger.warning(f"{log_prefix}Error getting display position for index {idx}: {pos_err}"); continue

            # --- Determine Node Coloring Mode ---
            coloring_values = None; coloring_mode = 'base'; node_cmap_name = 'plasma'; node_vmin = 0.0; node_vmax = 1.0
            use_state_color = visualization_params.get('use_state_coloring', False)
            color_by_degree = visualization_params.get('color_nodes_by_degree', False)
            color_by_neighbors = visualization_params.get('color_nodes_by_active_neighbors', False)
            if use_state_color:
                if color_by_degree: coloring_mode = 'degree'
                elif color_by_neighbors: coloring_mode = 'neighbor_count'
                else: coloring_mode = 'state'
            else: coloring_mode = 'base'
            if coloring_mode != 'base':
                node_cmap_name = visualization_params.get('node_colormap', 'plasma')
                # --- FIX: Ensure node_vmin/vmax are floats ---
                node_vmin_raw = visualization_params.get('node_color_norm_vmin', 0.0)
                node_vmax_raw = visualization_params.get('node_color_norm_vmax', 1.0)
                try: node_vmin = float(node_vmin_raw)
                except (ValueError, TypeError): logger.warning(f"{log_prefix}Invalid node_vmin '{node_vmin_raw}', using 0.0."); node_vmin = 0.0
                try: node_vmax = float(node_vmax_raw)
                except (ValueError, TypeError): logger.warning(f"{log_prefix}Invalid node_vmax '{node_vmax_raw}', using 1.0."); node_vmax = 1.0
                # ---
                if coloring_mode == 'state':
                     rule_min_state = visualization_params.get('min_node_state', 0.0)
                     rule_max_state = visualization_params.get('max_node_state', 1.0)
                     # --- FIX: Ensure rule min/max are floats ---
                     try: node_vmin = float(rule_min_state)
                     except (ValueError, TypeError): logger.warning(f"{log_prefix}Invalid rule min_node_state '{rule_min_state}', using 0.0."); node_vmin = 0.0
                     try: node_vmax = float(rule_max_state)
                     except (ValueError, TypeError): logger.warning(f"{log_prefix}Invalid rule max_node_state '{rule_max_state}', using 1.0."); node_vmax = 1.0
                     # ---

            # --- Get and Validate Coloring Values ---
            source_array = None
            source_name = "N/A"
            expected_dtype = np.number # General numeric type

            if coloring_mode == 'degree':
                source_array = previous_degree_array; source_name = "previous_degree_array"; expected_dtype = np.int32
            elif coloring_mode == 'neighbor_count':
                source_array = previous_active_neighbor_array; source_name = "previous_active_neighbor_array"; expected_dtype = np.int32
            elif coloring_mode == 'state':
                source_array = np.array(states_list); source_name = "states_list"; expected_dtype = np.float64 # States are float

            coloring_values = None
            if source_array is not None:
                logger.debug(f"{log_prefix}Validating source array '{source_name}' for coloring mode '{coloring_mode}'.")
                is_valid_source = True
                # Convert to NumPy array if not already
                if not isinstance(source_array, np.ndarray):
                    try:
                        logger.debug(f"{log_prefix}Source array '{source_name}' is not a numpy array (Type: {type(source_array)}). Attempting conversion.")
                        source_array = np.array(source_array)
                    except Exception as conv_err:
                        logger.error(f"{log_prefix}Failed to convert source array '{source_name}' to numpy array: {conv_err}")
                        is_valid_source = False
                # Use safe_numeric_array for robust conversion
                if is_valid_source:
                    try:
                        logger.debug(f"{log_prefix}Source array '{source_name}' dtype is {source_array.dtype}, attempting safe_numeric_array conversion.")
                        source_array = safe_numeric_array(source_array, fallback_value=node_vmin) # Use vmin as fallback
                        if not np.issubdtype(source_array.dtype, np.number):
                             logger.error(f"{log_prefix}safe_numeric_array failed to return numeric array for '{source_name}'. Dtype: {source_array.dtype}")
                             is_valid_source = False
                    except Exception as safe_conv_err:
                        logger.error(f"{log_prefix}Error during safe_numeric_array conversion for '{source_name}': {safe_conv_err}")
                        is_valid_source = False
                # Check length only if source is valid so far and there are visible nodes
                if is_valid_source and len(visible_indices) > 0 and source_array.size != total_nodes:
                    if np.max(visible_indices) >= source_array.size:
                        logger.error(f"{log_prefix}Source array '{source_name}' size ({source_array.size}) is too small for visible indices (max: {np.max(visible_indices)}). Total nodes: {total_nodes}.")
                        is_valid_source = False
                    else:
                        logger.warning(f"{log_prefix}Source array '{source_name}' size ({source_array.size}) doesn't match total nodes ({total_nodes}), but seems indexable.")
                if is_valid_source and source_array.size > 0:
                    try:
                        # Extract values for visible nodes
                        coloring_values = source_array[visible_indices]
                        # Ensure coloring_values is always float64 before nan_to_num
                        coloring_values = safe_numeric_array(coloring_values, fallback_value=node_vmin) # Use vmin as fallback
                        logger.debug(f"{log_prefix}Successfully extracted coloring_values from '{source_name}' (Shape: {coloring_values.shape}, Dtype: {coloring_values.dtype}).")
                    except Exception as e:
                        logger.error(f"{log_prefix}Error extracting/casting coloring values from '{source_name}': {e}")
                        coloring_values = None
                elif not is_valid_source:
                    logger.warning(f"{log_prefix}Source array '{source_name}' invalid. Using base coloring.")
                    coloring_mode = 'base'
                    coloring_values = None
                else: # Source array is empty (and no visible nodes)
                    coloring_values = np.array([], dtype=np.float64)
            elif coloring_mode != 'base':
                logger.warning(f"{log_prefix}Coloring mode is '{coloring_mode}', but required source array ('{source_name}') is None. Using base coloring.")
                coloring_mode = 'base'
                coloring_values = None
            # --- END FIX ---

            # --- Vectorized Node Face Color Calculation ---
            node_face_colors_rgba = []; node_base_color_hex = visualization_params.get('node_base_color', GlobalSettings.Colors.NODE_INACTIVE)
            logger.debug(f"{log_prefix}Calculating node face colors (Mode: {coloring_mode}).")
            if coloring_mode == 'base' or coloring_values is None or coloring_values.size == 0: # Check size
                node_face_colors_rgba = [colors.to_rgba(node_base_color_hex)] * len(indices_list)
                if detailed_logging_enabled and len(indices_list) > 0: logger.detail(f"  NodeColorDebug: Using base color {node_base_color_hex} for all {len(indices_list)} visible nodes (Reason: mode='{coloring_mode}', values_valid={coloring_values is not None}, values_len={coloring_values.size if coloring_values is not None else 'N/A'}).") # type: ignore [attr-defined]
            else:
                try:
                    logger.debug(f"{log_prefix}Applying '{coloring_mode}' coloring using cmap '{node_cmap_name}' (vmin={node_vmin}, vmax={node_vmax}).")
                    if node_cmap_name is None or node_cmap_name == "(None)":
                        logger.warning(f"{log_prefix}Node colormap is None, using base node color: {node_base_color_hex}")
                        node_face_colors_rgba = [colors.to_rgba(node_base_color_hex)] * len(indices_list)
                    else:
                        state_cmap, state_norm = GridVisualizer._get_cached_cmap_norm(node_cmap_name, node_vmin, node_vmax)
                        if state_cmap is None or state_norm is None: raise ValueError("Cmap/norm cache failed")
                        if coloring_values is None or coloring_values.size == 0:
                            logger.warning(f"{log_prefix}Coloring values are empty/None despite mode being '{coloring_mode}'. Using base color.")
                            node_face_colors_rgba = [colors.to_rgba(node_base_color_hex)] * len(indices_list)
                        else:
                            # Ensure coloring_values is float64 before nan_to_num
                            coloring_values = safe_numeric_array(coloring_values, fallback_value=node_vmin)
                            logger.debug(f"{log_prefix}coloring_values Dtype BEFORE nan_to_num (node coloring): {coloring_values.dtype if isinstance(coloring_values, np.ndarray) else type(coloring_values)}")
                            valid_values = np.nan_to_num(coloring_values, nan=node_vmin, posinf=node_vmax, neginf=node_vmin)
                            normalized_values = state_norm(valid_values)
                            node_face_colors_rgba = state_cmap(normalized_values) # Returns RGBA array
                            if detailed_logging_enabled:
                                log_limit = min(5, len(indices_list)); logger.detail(f"  NodeColorDebug (Vectorized): Calculated {len(node_face_colors_rgba)} RGBA colors. First {log_limit}:") # type: ignore [attr_defined]
                                for i in range(log_limit): logger.detail(f"    Idx={indices_list[i]}, Value({coloring_mode})={valid_values[i]:.3f}, NormVal={normalized_values[i]:.3f}, RGBA={node_face_colors_rgba[i]}") # type: ignore [attr_defined]
                except Exception as e:
                    logger.warning(f"{log_prefix}Error applying node '{coloring_mode}' coloring (vectorized): {e}. Using base color: {node_base_color_hex}")
                    logger.error(traceback.format_exc()); node_face_colors_rgba = [colors.to_rgba(node_base_color_hex)] * len(indices_list)

            # --- Vectorized Edge Color Calculation ---
            segments = []; edge_colors_hex: List[str] = []
            changed_edges_coords_set = edges_to_highlight if edges_to_highlight is not None else set()
            edge_colormap_name = visualization_params.get('edge_colormap', 'viridis')
            # --- FIX: Ensure edge_vmin/vmax are floats ---
            edge_vmin_raw = visualization_params.get('edge_color_norm_vmin', 0.0)
            edge_vmax_raw = visualization_params.get('edge_color_norm_vmax', 1.0)
            try: edge_vmin = float(edge_vmin_raw)
            except (ValueError, TypeError): logger.warning(f"{log_prefix}Invalid edge_vmin '{edge_vmin_raw}', using 0.0."); edge_vmin = 0.0
            try: edge_vmax = float(edge_vmax_raw)
            except (ValueError, TypeError): logger.warning(f"{log_prefix}Invalid edge_vmax '{edge_vmax_raw}', using 1.0."); edge_vmax = 1.0
            # ---
            use_state_coloring_edges = visualization_params.get('use_state_coloring_edges', False)
            edge_coloring_mode = visualization_params.get('edge_coloring_mode', 'Default')
            highlight_on = visualization_params.get('highlight_on', True)
            new_edge_color_hex = visualization_params.get('new_edge_color', GlobalSettings.Colors.NODE_EDGE_NEW)
            default_edge_color_hex = visualization_params.get('default_edge_color', GlobalSettings.Colors.NODE_EDGE_OLD)
            edge_cmap_cache, edge_norm_cache = None, None; can_color_by_endpoint = False
            if use_state_coloring_edges and edge_coloring_mode in ['ActiveNeighbors', 'DegreeSum']:
                if previous_degree_array is not None and edge_coloring_mode == 'DegreeSum': can_color_by_endpoint = True
                elif previous_active_neighbor_array is not None and edge_coloring_mode == 'ActiveNeighbors': can_color_by_endpoint = True
                else: logger.warning(f"{log_prefix}Edge coloring mode '{edge_coloring_mode}' requires previous data which is None. Falling back."); use_state_coloring_edges = False
            valid_edge_indices1 = []; valid_edge_indices2 = []; valid_edge_coords = []; valid_edge_states = []; valid_segments = []; is_changed_edge_mask = []
            wrap_edges_skipped = 0
            for edge_tuple_coords in edges_local:
                node1_coords, node2_coords = edge_tuple_coords; node1_idx = _ravel_multi_index(np.array(node1_coords), grid_dims); node2_idx = _ravel_multi_index(np.array(node2_coords), grid_dims)
                actual_edge_state = edge_states_local.get(edge_tuple_coords, 0.0); is_wrap_edge = False
                for d in range(len(grid_dims)):
                    dist = abs(node1_coords[d] - node2_coords[d])
                    if dist == grid_dims[d] - 1: is_wrap_edge = True; break
                if is_wrap_edge: wrap_edges_skipped += 1; continue
                start_display = node_positions.get(node1_idx); end_display = node_positions.get(node2_idx)
                if start_display is not None and end_display is not None:
                    valid_segments.append([start_display, end_display]); valid_edge_indices1.append(node1_idx); valid_edge_indices2.append(node2_idx)
                    valid_edge_coords.append(edge_tuple_coords); valid_edge_states.append(actual_edge_state)
                    is_changed_edge_mask.append(highlight_on and (edge_tuple_coords in changed_edges_coords_set))
            num_valid_edges = len(valid_segments)
            logger.debug(f"{log_prefix}Gathered data for {num_valid_edges} valid edges (skipped {wrap_edges_skipped} wrap edges).")
            base_colors_rgba = np.full((num_valid_edges, 4), colors.to_rgba(default_edge_color_hex))
            if use_state_coloring_edges and edge_colormap_name is not None and edge_colormap_name != "(None)":
                values_for_coloring_edge = None # Renamed variable
                if edge_coloring_mode == 'Default':
                    values_for_coloring_edge = np.array(valid_edge_states, dtype=float)
                elif can_color_by_endpoint:
                    indices1_np = np.array(valid_edge_indices1, dtype=np.int64); indices2_np = np.array(valid_edge_indices2, dtype=np.int64)
                    source_array_edge = None; source_name_edge = "N/A"
                    if edge_coloring_mode == 'ActiveNeighbors': source_array_edge = previous_active_neighbor_array; source_name_edge = "prev_active_neighbors"
                    elif edge_coloring_mode == 'DegreeSum': source_array_edge = previous_degree_array; source_name_edge = "prev_degrees"

                    if source_array_edge is not None:
                        is_valid_edge_source = True
                        if not isinstance(source_array_edge, np.ndarray): logger.error(f"{log_prefix}Edge source array '{source_name_edge}' is not ndarray."); is_valid_edge_source = False
                        elif source_array_edge.size == 0 and num_valid_edges > 0: logger.warning(f"{log_prefix}Edge source array '{source_name_edge}' is empty."); # Allow empty, will result in default color
                        elif source_array_edge.size > 0 and not np.issubdtype(source_array_edge.dtype, np.number): # Check numeric
                            logger.error(f"{log_prefix}Edge source array '{source_name_edge}' has non-numeric dtype ({source_array_edge.dtype}).")
                            is_valid_edge_source = False
                        elif source_array_edge.size != total_nodes: logger.warning(f"{log_prefix}Edge source array '{source_name_edge}' size ({source_array_edge.size}) mismatch total nodes ({total_nodes})."); # Allow if indexable
                        if is_valid_edge_source and source_array_edge.size > 0:
                            valid_mask1 = indices1_np < source_array_edge.size; valid_mask2 = indices2_np < source_array_edge.size; valid_mask = valid_mask1 & valid_mask2
                            if np.all(valid_mask):
                                # --- FIX: Ensure source array is float before calculation ---
                                source_array_edge_float = safe_numeric_array(source_array_edge, fallback_value=0.0) # Use 0 as fallback
                                # --- END FIX ---
                                if edge_coloring_mode == 'ActiveNeighbors': values_for_coloring_edge = (source_array_edge_float[indices1_np] + source_array_edge_float[indices2_np]) / 2.0
                                elif edge_coloring_mode == 'DegreeSum': values_for_coloring_edge = (source_array_edge_float[indices1_np] + source_array_edge_float[indices2_np])
                            else: logger.warning(f"{log_prefix}Some edge endpoint indices out of bounds for '{source_name_edge}'. Coloring might be incomplete."); values_for_coloring_edge = None
                        elif not is_valid_edge_source: values_for_coloring_edge = None # Fallback if source invalid
                    else: logger.warning(f"{log_prefix}Required source array '{source_name_edge}' is None for edge coloring mode '{edge_coloring_mode}'.")
                if values_for_coloring_edge is not None:
                    try:
                        edge_cmap_cache, edge_norm_cache = GridVisualizer._get_cached_cmap_norm(edge_colormap_name, edge_vmin, edge_vmax)
                        if edge_cmap_cache is None or edge_norm_cache is None: raise ValueError("Cmap/norm cache failed")
                        # --- FIX: Ensure values_for_coloring_edge is float64 before nan_to_num ---
                        values_for_coloring_edge = safe_numeric_array(values_for_coloring_edge, fallback_value=edge_vmin)
                        # --- END FIX ---
                        logger.debug(f"{log_prefix}values_for_coloring_edge Dtype BEFORE nan_to_num (edge coloring): {values_for_coloring_edge.dtype if isinstance(values_for_coloring_edge, np.ndarray) else type(values_for_coloring_edge)}")
                        valid_edge_values = np.nan_to_num(values_for_coloring_edge, nan=edge_vmin, posinf=edge_vmax, neginf=edge_vmin)
                        normalized_values = edge_norm_cache(valid_edge_values)
                        base_colors_rgba = edge_cmap_cache(normalized_values)
                        logger.debug(f"{log_prefix}Calculated state-based edge colors (RGBA) (Mode: {edge_coloring_mode}, Vectorized).")
                    except Exception as e: logger.warning(f"{log_prefix}Error applying edge state coloring (Mode: {edge_coloring_mode}, Cmap: {edge_colormap_name}, Vectorized): {e}. Falling back to default."); base_colors_rgba = np.full((num_valid_edges, 4), colors.to_rgba(default_edge_color_hex))
                else: logger.warning(f"{log_prefix}Could not calculate values for edge coloring mode '{edge_coloring_mode}'. Using default.")
            else:
                 logger.debug(f"{log_prefix}Using default edge color (StateColoringOff={not use_state_coloring_edges} or CmapNone={edge_colormap_name is None or edge_colormap_name == '(None)'}).")
            is_changed_edge_mask_np = np.array(is_changed_edge_mask, dtype=bool)
            new_edge_color_rgba = np.array(colors.to_rgba(new_edge_color_hex))
            final_edge_colors_rgba = np.where(is_changed_edge_mask_np[:, np.newaxis], new_edge_color_rgba, base_colors_rgba)
            try:
                edge_colors_hex = [colors.to_hex(c, keep_alpha=False) for c in final_edge_colors_rgba] # type: ignore
                logger.debug(f"{log_prefix}Converted final edge RGBA to HEX list (Count: {len(edge_colors_hex)}).")
            except Exception as hex_err:
                logger.error(f"{log_prefix}Error converting final edge RGBA to HEX: {hex_err}. Using default.")
                edge_colors_hex = [default_edge_color_hex] * num_valid_edges
            # --- END Vectorized Edge Color Calculation ---

            # --- Prepare final dictionary ---
            plot_data_to_return = {
                'x_coords': np.array(x_coords_list), 'y_coords': np.array(y_coords_list),
                'z_coords': np.array(z_coords_list) if dimension_type == Dimension.THREE_D else None,
                'indices': np.array(indices_list, dtype=int),
                'node_face_colors': node_face_colors_rgba, # Store RGBA array/list
                'segments': valid_segments,
                'edge_colors': edge_colors_hex, # Store final HEX list
                'added_nodes_coords': nodes_to_highlight if nodes_to_highlight is not None else set(),
                'added_edges_coords': edges_to_highlight if edges_to_highlight is not None else set(),
                'grid_array_original': grid_array_local,
                'edges_original': edges_local,
                'edge_states_original': edge_states_local,
                'min_node_state': visualization_params.get('min_node_state', 0.0),
                'max_node_state': visualization_params.get('max_node_state', 1.0),
            }
            plot_data_to_return.update(visualization_params)
            plot_data_to_return.pop('colors', None) # Remove legacy key

            return plot_data_to_return

        except Exception as e:
            logger.error(f"Error in _prepare_plot_data_static: {e}")
            logger.error(traceback.format_exc())
            return None
               
    @timer_decorator
    def _prepare_plot_data(self,
                            nodes_to_highlight: Optional[Set[Tuple[int, ...]]] = None, # Represents ADDED nodes
                            edges_to_highlight: Optional[Set[Tuple[Tuple[int, ...], Tuple[int, ...]]]] = None, # Represents CHANGED edges
                            grid_snapshot: Optional[Dict[str, Any]] = None):
                            # REMOVED selection_to_highlight parameter
        """
        Prepare data for plotting: coords, node face colors, edge segments/colors.
        Uses highlight sets passed as arguments. Reads from grid if snapshot is None.
        Calculates final node face colors (RGBA) and edge colors (HEX) based on CURRENT rule parameters,
        including new edge coloring modes. Vectorizes node color and edge color calculations.
        Filters out wrap-around edges from visualization.
        Stores calculated colors directly in the returned dictionary.
        (Round 16: Use correct vmin/vmax for node state coloring)
        (Round 6: Vectorized node color calculation)
        (Round 7: Vectorized default edge color calculation)
        (Round 8: Correctly filter wrap-around edges)
        (Round 9: Vectorize endpoint-based edge color calculation)
        """
        log_prefix = f"_prepare_plot_data(ID:{id(self)}): "
        received_nodes_highlight_count = len(nodes_to_highlight) if nodes_to_highlight is not None else 0
        received_edges_highlight_count = len(edges_to_highlight) if edges_to_highlight is not None else 0
        # Log selection from internal state
        selection_from_state = self._visualization_state.get('selection_to_highlight', set())
        received_selection_count = len(selection_from_state)
        logger.debug(f"{log_prefix}START (Receiving Highlights: Nodes={received_nodes_highlight_count}, Edges={received_edges_highlight_count}, Selection(Internal)={received_selection_count})")

        detailed_logging_enabled = LogSettings.Performance.ENABLE_DETAILED_LOGGING

        try:
            # [ Data Source Logic - Unchanged ]
            grid_id_source = "Snapshot"
            if grid_snapshot:
                grid_array_local = grid_snapshot.get('grid_array')
                edges_local = grid_snapshot.get('edges', set())
                edge_states_local = grid_snapshot.get('edge_states', {})
                if grid_array_local is None: raise ValueError("Snapshot missing grid_array")
                grid_dims = grid_array_local.shape
                dimension_type = Dimension.TWO_D if len(grid_dims) == 2 else Dimension.THREE_D
                grid_id_source = f"Snapshot (Gen {grid_snapshot.get('generation', 'N/A')})"
            elif self.grid and self.grid.grid_array is not None:
                grid_array_local = self.grid.grid_array.copy()
                edges_local = self.grid.edges.copy()
                edge_states_local = self.grid.edge_states.copy()
                grid_dims = self.grid.dimensions
                dimension_type = self.grid.dimension_type
                grid_id_source = f"Current Grid (ID: {id(self.grid)})"
            else:
                logger.warning(f"{log_prefix}Grid/snapshot or grid_array is None, returning empty plot data")
                return None

            total_nodes = np.prod(grid_dims)

            if grid_array_local is None or edges_local is None or edge_states_local is None:
                logger.warning(f"{log_prefix}Source data missing required arrays/sets, returning empty plot data")
                return None

            # [ Coord System Sync - Unchanged ]
            if self.coord_system and self.coord_system.grid_dimensions != grid_dims:
                logger.warning(f"{log_prefix}Coord system dims {self.coord_system.grid_dimensions} != grid data dims {grid_dims}. Updating coord system.")
                self.coord_system.update_parameters(grid_dimensions=grid_dims, dimension_type=dimension_type)
            elif not self.coord_system:
                 logger.error(f"{log_prefix}Coordinate system is None, cannot proceed."); return None

            # [ Get Visible Nodes and Positions - Unchanged ]
            visibility_threshold = GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD
            visible_mask = grid_array_local > visibility_threshold
            visible_indices = np.where(visible_mask.ravel())[0]
            node_positions = {}
            x_coords_list, y_coords_list, z_coords_list = [], [], []
            states_list, indices_list = [], []

            for idx in visible_indices:
                try:
                    grid_coords = tuple(_unravel_index(idx, grid_dims))
                    display_coords = self.coord_system.index_to_display(idx, grid_dims)
                    node_positions[idx] = display_coords
                    x_coords_list.append(display_coords[0])
                    y_coords_list.append(display_coords[1])
                    if dimension_type == Dimension.THREE_D and len(display_coords) > 2:
                        z_coords_list.append(display_coords[2])
                    states_list.append(grid_array_local.ravel()[idx])
                    indices_list.append(idx)
                except Exception as pos_err:
                    logger.warning(f"{log_prefix}Error getting display position for index {idx}: {pos_err}")
                    continue

            # [ Determine Node Coloring Values and Mode - Unchanged ]
            coloring_values = None
            coloring_mode = 'base' # Default
            node_cmap_name = 'plasma'; node_vmin = 0.0; node_vmax = 1.0
            if self.grid and self.grid.rule:
                rule = self.grid.rule
                color_by_degree = rule.get_param('color_nodes_by_degree', False)
                color_by_neighbors = rule.get_param('color_nodes_by_active_neighbors', False)
                use_state_color = rule.get_param('use_state_coloring', False)
                if color_by_degree: coloring_mode = 'degree'
                elif color_by_neighbors: coloring_mode = 'neighbor_count'
                elif use_state_color: coloring_mode = 'state'
                else: coloring_mode = 'base'
                node_cmap_name = rule.get_param('node_colormap', 'plasma')
                if coloring_mode == 'state':
                    node_vmin = getattr(rule, 'min_node_state', 0.0)
                    node_vmax = getattr(rule, 'max_node_state', 1.0)
                    logger.debug(f"{log_prefix}Using rule's state range for normalization: vmin={node_vmin}, vmax={node_vmax}")
                else:
                    node_vmin = rule.get_param('node_color_norm_vmin', 0.0)
                    default_vmax_for_mode = 8.0 if coloring_mode in ('degree', 'neighbor_count') else 1.0
                    vmax_from_rule = rule.get_param('node_color_norm_vmax', None)
                    node_vmax = vmax_from_rule if vmax_from_rule is not None else default_vmax_for_mode
                if coloring_mode == 'degree':
                    if self.grid and self.grid.previous_degree_array is not None:
                        if len(self.grid.previous_degree_array) == total_nodes: coloring_values = self.grid.previous_degree_array[visible_indices].astype(float)
                        else: logger.warning(f"{log_prefix}previous_degree_array size mismatch. Using base coloring."); coloring_mode = 'base'
                    else: logger.warning(f"{log_prefix}Rule requests degree coloring, but previous_degree_array is None."); coloring_mode = 'base'
                elif coloring_mode == 'neighbor_count':
                    if self.grid and self.grid.previous_active_neighbor_array is not None:
                        if len(self.grid.previous_active_neighbor_array) == total_nodes: coloring_values = self.grid.previous_active_neighbor_array[visible_indices].astype(float)
                        else: logger.warning(f"{log_prefix}previous_active_neighbor_array size mismatch. Using base coloring."); coloring_mode = 'base'
                    else: logger.warning(f"{log_prefix}Rule requests neighbor count coloring, but previous_active_neighbor_array is None."); coloring_mode = 'base'
                elif coloring_mode == 'state': coloring_values = np.array(states_list)
                else: coloring_values = None # Base coloring
            else: logger.warning(f"{log_prefix}Rule not found, using base node coloring."); coloring_mode = 'base'; coloring_values = None
            logger.info(f"{log_prefix}Determined Node Coloring Mode: '{coloring_mode}'")

            # [ Vectorized Node Face Color Calculation - Unchanged ]
            node_face_colors_rgba = [] # Initialize as list
            node_base_color_hex = self._visualization_state.get('node_base', GlobalSettings.Colors.NODE_INACTIVE)
            logger.debug(f"{log_prefix}Calculating node face colors (Mode: {coloring_mode}).")
            if coloring_mode == 'base' or coloring_values is None or len(coloring_values) == 0:
                node_face_colors_rgba = [colors.to_rgba(node_base_color_hex)] * len(indices_list)
                if detailed_logging_enabled and len(indices_list) > 0: logger.detail(f"  NodeColorDebug: Using base color {node_base_color_hex} for all {len(indices_list)} visible nodes (Reason: mode='{coloring_mode}', values_exist={coloring_values is not None}, values_len={len(coloring_values) if coloring_values is not None else 'N/A'}).") # type: ignore [attr-defined]
            else:
                try:
                    logger.debug(f"{log_prefix}Applying '{coloring_mode}' coloring using cmap '{node_cmap_name}' (vmin={node_vmin}, vmax={node_vmax}).")
                    if node_cmap_name is None or node_cmap_name == "(None)":
                        logger.warning(f"{log_prefix}Node colormap is None, using base node color: {node_base_color_hex}")
                        node_face_colors_rgba = [colors.to_rgba(node_base_color_hex)] * len(indices_list)
                        if detailed_logging_enabled and len(indices_list) > 0: logger.detail(f"  NodeColorDebug: Using base color {node_base_color_hex} (cmap was None) for all {len(indices_list)} visible nodes.") # type: ignore [attr-defined]
                    else:
                        state_cmap, state_norm = self._get_cached_cmap_norm(node_cmap_name, node_vmin, node_vmax)
                        if state_cmap is None or state_norm is None: raise ValueError("Cmap/norm cache failed")
                        if not isinstance(coloring_values, np.ndarray): coloring_values = np.array(coloring_values)
                        valid_values = np.nan_to_num(coloring_values, nan=node_vmin, posinf=node_vmax, neginf=node_vmin)
                        normalized_values = state_norm(valid_values)
                        node_face_colors_rgba = state_cmap(normalized_values) # This returns a NumPy array (N, 4)
                        if detailed_logging_enabled:
                             log_limit = min(5, len(indices_list)); logger.detail(f"  NodeColorDebug (Vectorized): Calculated {len(node_face_colors_rgba)} RGBA colors. First {log_limit}:") # type: ignore [attr-defined]
                             for i in range(log_limit): logger.detail(f"    Idx={indices_list[i]}, Value({coloring_mode})={valid_values[i]:.3f}, NormVal={normalized_values[i]:.3f}, RGBA={node_face_colors_rgba[i]}") # type: ignore [attr-defined]
                except Exception as e:
                    logger.warning(f"{log_prefix}Error applying node '{coloring_mode}' coloring (vectorized): {e}. Using base color: {node_base_color_hex}")
                    logger.error(traceback.format_exc()); node_face_colors_rgba = [colors.to_rgba(node_base_color_hex)] * len(indices_list)

            # --- MODIFIED: Vectorized Edge Color Calculation (Round 9) ---
            segments = []
            edge_colors_hex: List[str] = []
            changed_edges_coords_set = edges_to_highlight if edges_to_highlight is not None else set()
            edge_colormap_name = 'viridis'; edge_vmin = 0.0; edge_vmax = 1.0 # Defaults
            use_state_coloring_edges = False
            edge_coloring_mode = 'Default' # Default mode
            if self.grid and self.grid.rule:
                rule = self.grid.rule
                use_state_coloring_edges = rule.get_param('use_state_coloring_edges', False)
                edge_coloring_mode = rule.get_param('edge_coloring_mode', 'Default')
                edge_colormap_name = rule.get_param('edge_colormap', 'viridis')
                if edge_coloring_mode == 'Default': edge_vmin = getattr(rule, 'min_edge_state', 0.0); edge_vmax = getattr(rule, 'max_edge_state', 1.0)
                else: edge_vmin = rule.get_param('edge_color_norm_vmin', 0.0); default_vmax_for_edge_mode = 16.0 if edge_coloring_mode == 'DegreeSum' else 8.0; vmax_from_rule_edge = rule.get_param('edge_color_norm_vmax', None); edge_vmax = vmax_from_rule_edge if vmax_from_rule_edge is not None else default_vmax_for_edge_mode
                logger.debug(f"{log_prefix}Fetched edge color params: UseState={use_state_coloring_edges}, Mode='{edge_coloring_mode}', Cmap='{edge_colormap_name}', Vmin={edge_vmin}, Vmax={edge_vmax}")
            else: logger.warning(f"{log_prefix}Rule not available, using default edge parameters.")

            highlight_on = self._visualization_state.get('highlight_on', True)
            new_edge_color_hex = self._visualization_state.get('new_edge_color', GlobalSettings.Colors.NODE_EDGE_NEW)
            default_edge_color_hex = self._visualization_state.get('default_edge_color', GlobalSettings.Colors.NODE_EDGE_OLD)
            edge_cmap_cache, edge_norm_cache = None, None
            prev_degrees = None; prev_active_neighbors = None
            can_color_by_endpoint = False
            if use_state_coloring_edges and edge_coloring_mode in ['ActiveNeighbors', 'DegreeSum']:
                if self.grid:
                    prev_degrees = self.grid.previous_degree_array
                    prev_active_neighbors = self.grid.previous_active_neighbor_array
                    if prev_degrees is not None and edge_coloring_mode == 'DegreeSum': can_color_by_endpoint = True
                    elif prev_active_neighbors is not None and edge_coloring_mode == 'ActiveNeighbors': can_color_by_endpoint = True
                    else: logger.warning(f"{log_prefix}Edge coloring mode '{edge_coloring_mode}' requires previous data which is None. Falling back."); use_state_coloring_edges = False
                else: logger.warning(f"{log_prefix}Grid is None, cannot fetch previous state arrays for edge coloring. Falling back."); use_state_coloring_edges = False

            # --- Gather Edge Data ---
            valid_edge_indices1 = [] # Store idx1 for valid edges
            valid_edge_indices2 = [] # Store idx2 for valid edges
            valid_edge_coords = [] # Store (coord1, coord2) for valid edges
            valid_edge_states = [] # Store state for valid edges
            valid_segments = [] # Store display segments
            is_changed_edge_mask = [] # Boolean mask for highlighting
            wrap_edges_skipped = 0

            for edge_tuple_coords in edges_local:
                node1_coords, node2_coords = edge_tuple_coords
                node1_idx = _ravel_multi_index(np.array(node1_coords), grid_dims)
                node2_idx = _ravel_multi_index(np.array(node2_coords), grid_dims)
                actual_edge_state = edge_states_local.get(edge_tuple_coords, 0.0)

                # --- Corrected Wrap Check ---
                is_wrap_edge = False
                for d in range(len(grid_dims)):
                    dist = abs(node1_coords[d] - node2_coords[d])
                    if dist == grid_dims[d] - 1: is_wrap_edge = True; break
                if is_wrap_edge: wrap_edges_skipped += 1; continue
                # ---

                start_display = node_positions.get(node1_idx)
                end_display = node_positions.get(node2_idx)
                if start_display is not None and end_display is not None:
                    valid_segments.append([start_display, end_display])
                    valid_edge_indices1.append(node1_idx) # Store index 1
                    valid_edge_indices2.append(node2_idx) # Store index 2
                    valid_edge_coords.append(edge_tuple_coords)
                    valid_edge_states.append(actual_edge_state)
                    is_changed_edge_mask.append(highlight_on and (edge_tuple_coords in changed_edges_coords_set))

            num_valid_edges = len(valid_segments)
            logger.debug(f"{log_prefix}Gathered data for {num_valid_edges} valid edges (skipped {wrap_edges_skipped} wrap edges).")

            # --- Calculate Base Colors (Vectorized) ---
            base_colors_hex = np.full(num_valid_edges, default_edge_color_hex, dtype=object) # Start with default

            if use_state_coloring_edges and edge_colormap_name is not None and edge_colormap_name != "(None)":
                values_for_coloring = None
                if edge_coloring_mode == 'Default':
                    values_for_coloring = np.array(valid_edge_states, dtype=float)
                elif can_color_by_endpoint:
                    # --- Vectorized endpoint data lookup ---
                    indices1_np = np.array(valid_edge_indices1, dtype=int)
                    indices2_np = np.array(valid_edge_indices2, dtype=int)
                    if edge_coloring_mode == 'ActiveNeighbors' and prev_active_neighbors is not None:
                        # Ensure indices are within bounds before accessing
                        valid_mask1 = indices1_np < len(prev_active_neighbors)
                        valid_mask2 = indices2_np < len(prev_active_neighbors)
                        valid_mask = valid_mask1 & valid_mask2
                        if np.all(valid_mask): # If all indices are valid
                            values_for_coloring = (prev_active_neighbors[indices1_np] + prev_active_neighbors[indices2_np]) / 2.0
                        else: # Handle invalid indices if necessary (e.g., fallback or filter)
                            logger.warning(f"{log_prefix}Some edge endpoint indices out of bounds for prev_active_neighbors. Coloring might be incomplete.")
                            # Example fallback: calculate only for valid, leave others default (complex)
                            # For simplicity, we might just fall back to default if any index is bad
                            values_for_coloring = None # Fallback to default if indices are bad
                    elif edge_coloring_mode == 'DegreeSum' and prev_degrees is not None:
                        valid_mask1 = indices1_np < len(prev_degrees)
                        valid_mask2 = indices2_np < len(prev_degrees)
                        valid_mask = valid_mask1 & valid_mask2
                        if np.all(valid_mask):
                            values_for_coloring = (prev_degrees[indices1_np] + prev_degrees[indices2_np]).astype(float)
                        else:
                            logger.warning(f"{log_prefix}Some edge endpoint indices out of bounds for prev_degrees. Coloring might be incomplete.")
                            values_for_coloring = None # Fallback
                    # --- End Vectorized endpoint data lookup ---

                if values_for_coloring is not None:
                    try:
                        edge_cmap_cache, edge_norm_cache = self._get_cached_cmap_norm(edge_colormap_name, edge_vmin, edge_vmax)
                        if edge_cmap_cache is None or edge_norm_cache is None: raise ValueError("Cmap/norm cache failed")
                        valid_edge_values = np.nan_to_num(values_for_coloring, nan=edge_vmin, posinf=edge_vmax, neginf=edge_vmin)
                        normalized_values = edge_norm_cache(valid_edge_values)
                        rgba_colors = edge_cmap_cache(normalized_values)
                        base_colors_hex = [colors.to_hex(c) for c in rgba_colors] # type: ignore
                        logger.debug(f"{log_prefix}Calculated state-based edge colors (Mode: {edge_coloring_mode}, Vectorized).")
                    except Exception as e:
                        logger.warning(f"{log_prefix}Error applying edge state coloring (Mode: {edge_coloring_mode}, Cmap: {edge_colormap_name}, Vectorized): {e}. Falling back to default.");
                        base_colors_hex = np.full(num_valid_edges, default_edge_color_hex, dtype=object) # Ensure fallback
                else:
                    logger.warning(f"{log_prefix}Could not calculate values for edge coloring mode '{edge_coloring_mode}'. Using default.")
            else:
                 logger.debug(f"{log_prefix}Using default edge color (StateColoringOff={not use_state_coloring_edges} or CmapNone={edge_colormap_name is None or edge_colormap_name == '(None)'}).")

            # --- Apply Highlighting ---
            is_changed_edge_mask_np = np.array(is_changed_edge_mask, dtype=bool)
            # Ensure base_colors_hex is a NumPy array for np.where
            if not isinstance(base_colors_hex, np.ndarray):
                base_colors_hex = np.array(base_colors_hex, dtype=object)
            final_edge_colors_hex = np.where(is_changed_edge_mask_np, new_edge_color_hex, base_colors_hex).tolist()
            # --- END MODIFIED ---

            log_limit = min(10, len(final_edge_colors_hex))
            logger.debug(f"{log_prefix}Generated final edge_colors list (Count: {len(final_edge_colors_hex)}, First {log_limit}): {final_edge_colors_hex[:log_limit]}")

            # --- Prepare final dictionary ---
            plot_data_to_return = {
                'x_coords': np.array(x_coords_list),
                'y_coords': np.array(y_coords_list),
                'z_coords': np.array(z_coords_list) if dimension_type == Dimension.THREE_D else None,
                'indices': np.array(indices_list, dtype=int),
                'node_face_colors': node_face_colors_rgba, # Use the calculated RGBA array/list
                'segments': valid_segments, # Use the filtered segments
                'edge_colors': final_edge_colors_hex, # Use the final list of HEX colors
                'added_nodes_coords': nodes_to_highlight if nodes_to_highlight is not None else set(),
                'added_edges_coords': edges_to_highlight if edges_to_highlight is not None else set()
            }
            # Remove intermediate keys if they exist
            plot_data_to_return.pop('coloring_values', None)
            plot_data_to_return.pop('coloring_mode', None)
            plot_data_to_return.pop('cmap_params', None)
            plot_data_to_return.pop('colors', None) # Remove legacy key

            return plot_data_to_return

        except Exception as e:
            logger.error(f"Error in _prepare_plot_data: {e}")
            logger.error(traceback.format_exc())
            return None

        
    def highlight_node(self, node_coords, highlight=True):
        """Highlight or unhighlight a specific node."""
        if highlight:
            self.highlighted_nodes.add(node_coords)
        else:
            if node_coords in self.highlighted_nodes:
                self.highlighted_nodes.remove(node_coords)
        
        # Update the visualization
        self.update_visualization()

    @staticmethod
    @lru_cache(maxsize=32) # Cache up to 32 cmap/norm combinations
    def _get_cached_cmap_norm(cmap_name: str, vmin: float, vmax: float, num_states: Optional[int] = None, base_color_hex: Optional[str] = None, blend_factor: Optional[float] = None, colors_list_tuple: Optional[Tuple[str, ...]] = None):
        """Creates and caches colormap and normalization objects.
           Handles standard names, custom lists, and blending.
           (Round 25: Provided full method definition)
           (Round 14: Made static)"""
        logger = logging.getLogger(__name__) # Get logger instance within static method
        # Use a tuple of sorted color list items if provided, else None, for cache key stability
        colors_key = tuple(sorted(list(colors_list_tuple))) if colors_list_tuple is not None else None
        cache_key_tuple = (cmap_name, vmin, vmax, num_states, base_color_hex, blend_factor, colors_key)
        logger.debug(f"_get_cached_cmap_norm (static): ENTRY for Key={cache_key_tuple}")

        custom_cmap = None
        norm = None

        try:
            # --- Determine Colormap ---
            if colors_list_tuple: # Explicit list provided ('multi' logic)
                logger.debug("  _get_cached_cmap_norm (static): Generating 'multi' cmap from provided list.")
                colors = list(colors_list_tuple)
                custom_cmap = LinearSegmentedColormap.from_list(
                    f"custom_multi_{colors_key}", colors, N=num_states or len(colors)
                )
            elif base_color_hex and blend_factor is not None: # Blending requested
                logger.debug(f"  _get_cached_cmap_norm (static): Generating 'blended' cmap (Base: {base_color_hex}, Factor: {blend_factor}, Cmap: {cmap_name}).")
                base_rgb = to_rgb(base_color_hex)
                try:
                    std_cmap = plt.get_cmap(cmap_name) # type: ignore
                except ValueError:
                    logger.warning(f"Invalid base colormap name '{cmap_name}' for blending. Falling back to 'viridis'.")
                    std_cmap = plt.get_cmap('viridis') # type: ignore

                std_colors = [std_cmap(i) for i in range(256)]
                blended_colors = []
                for color in std_colors:
                    r = color[0] * (1 - blend_factor) + base_rgb[0] * blend_factor
                    g = color[1] * (1 - blend_factor) + base_rgb[1] * blend_factor
                    b = color[2] * (1 - blend_factor) + base_rgb[2] * blend_factor
                    blended_colors.append((r, g, b, color[3]))
                custom_cmap = LinearSegmentedColormap.from_list(f"blended_{cmap_name}", blended_colors)
            else: # Standard colormap requested (no custom list, no blend)
                logger.debug(f"  _get_cached_cmap_norm (static): Getting standard cmap '{cmap_name}'.")
                try:
                    custom_cmap = plt.get_cmap(cmap_name) # type: ignore
                except ValueError:
                    logger.warning(f"Invalid standard colormap name '{cmap_name}'. Falling back to 'viridis'.")
                    custom_cmap = plt.get_cmap('viridis') # type: ignore

            # --- Create Normalization ---
            if num_states is not None and num_states > 0: # Discrete
                 bounds = np.linspace(vmin, vmax, num_states + 1) # Use vmin/vmax for bounds
                 norm = colors.BoundaryNorm(bounds, custom_cmap.N) # type: ignore
                 logger.debug(f"  _get_cached_cmap_norm (static): Generated BoundaryNorm (N={num_states}, Bounds={bounds})")
            else: # Continuous
                 norm = Normalize(vmin=vmin, vmax=vmax)
                 logger.debug(f"  _get_cached_cmap_norm (static): Generated Normalize (vmin={vmin}, vmax={vmax})")

            logger.debug(f"  _get_cached_cmap_norm (static): Generated cmap: {type(custom_cmap).__name__}, norm: {type(norm).__name__}")

        except Exception as e:
            logger.error(f"Error creating cmap/norm in cache function (static): {e}")
            logger.error(traceback.format_exc())
            # Fallback to viridis on error
            custom_cmap = plt.get_cmap('viridis') # type: ignore
            norm = Normalize(vmin=0.0, vmax=1.0)
            logger.warning("  _get_cached_cmap_norm (static): Falling back to viridis/Normalize(0,1).")

        logger.debug(f"_get_cached_cmap_norm (static): EXIT for Key={cache_key_tuple}. Returning cmap={type(custom_cmap).__name__}, norm={type(norm).__name__}")
        return custom_cmap, norm
      
    @timer_decorator
    def _draw_nodes_2d(self, x_coords, y_coords, node_face_colors, indices,
                       nodes_to_highlight: Optional[Set[Tuple[int, ...]]] = None):
        """
        Draw nodes for 2D plots using pre-calculated face colors and applying edge highlights/selection.
        Reads selection from internal state. Ensures face colors are list of RGBA.
        (Round 14: Ensure face colors are list of RGBA tuples)
        (Round 9: Reverted explicit selection passing)
        """
        log_prefix = f"_draw_nodes_2d(ID:{id(self)} R14 Color Fix): " # Updated round
        state_id_at_start = id(self._visualization_state) if hasattr(self, '_visualization_state') else 'N/A'
        selection_at_start = self._visualization_state.get('selection_to_highlight', 'MISSING')
        logger.debug(f"{log_prefix}ENTRY - Reading selection state at start (State ID: {state_id_at_start}): Size={len(selection_at_start) if isinstance(selection_at_start, set) else 'N/A'}, Type={type(selection_at_start)}")
        grid_id_at_draw = id(self.grid) if self.grid else "None"
        logger.info(f"{log_prefix}ENTRY (Grid ID: {grid_id_at_draw}, Nodes: {len(x_coords)})")

        # [ Parameter calculation - Unchanged ]
        node_opacity = GlobalSettings.Visualization.NODE_OPACITY
        current_zoom = self._visualization_state.get('zoom_factor', 1.0)
        size_to_use = self._calculate_node_size(current_zoom)
        outline_width = self._calculate_outline_width(current_zoom)
        background_color = self._visualization_state.get('background_color', GlobalSettings.Colors.BACKGROUND)

        # [ Data Validation - Simplified ]
        if x_coords is None or y_coords is None or indices is None or node_face_colors is None:
            logger.error(f"{log_prefix}Received None for coordinates, indices, or face colors!"); return
        if not (len(x_coords) == len(y_coords) == len(node_face_colors) == len(indices)):
            logger.error(f"{log_prefix}Data array length mismatch! x:{len(x_coords)}, y:{len(y_coords)}, faces:{len(node_face_colors)}, idx:{len(indices)}. Skipping node draw."); return
        if np.any(np.isnan(x_coords)) or np.any(np.isinf(y_coords)): logger.error(f"{log_prefix}NaN values found in node coordinates! Skipping node draw."); return
        if np.any(np.isinf(x_coords)) or np.any(np.isinf(y_coords)): logger.error(f"{log_prefix}Infinite values found in node coordinates! Skipping node draw."); return

        # --- Clear existing scatter plot ---
        if hasattr(self, '_node_scatter') and self._node_scatter:
            try: self._node_scatter.remove()
            except ValueError: pass
            except Exception as e: logger.warning(f"{log_prefix}Error removing previous scatter: {e}")
        self._node_scatter = None
        # ---

        if x_coords is not None and x_coords.size > 0:
            logger.debug(f"{log_prefix}Creating new scatter artist.")

            # --- Determine Final Edge Colors (Logic Unchanged) ---
            final_edge_colors = []
            highlight_applied_count = 0; selection_applied_count = 0
            if indices is not None and len(indices) == len(x_coords):
                highlight_on = self._visualization_state.get('highlight_on', True)
                added_nodes_coords = self._visualization_state.get('added_nodes_coords', set())
                selected_nodes_coords = self._visualization_state.get('selection_to_highlight', set())
                node_outline_old = self._visualization_state.get('default_edge_color', GlobalSettings.Colors.NODE_EDGE_OLD)
                node_outline_new = self._visualization_state.get('node_outline_new', GlobalSettings.Colors.NODE_EDGE_NEW)
                for i, node_idx in enumerate(indices):
                    grid_coords_tuple = tuple(_unravel_index(node_idx, self.grid.dimensions))
                    is_selected = grid_coords_tuple in selected_nodes_coords
                    is_new = highlight_on and (grid_coords_tuple in added_nodes_coords)
                    edge_color_hex = node_outline_old
                    if is_selected:
                        node_face_color_hex = colors.to_hex(node_face_colors[i]) # Use pre-calculated RGBA
                        inverted_color_rgba = _get_contrasting_inverted_color(node_face_color_hex, background_color)
                        edge_color_hex = colors.to_hex(inverted_color_rgba[:3]); selection_applied_count += 1
                    elif is_new:
                        edge_color_hex = node_outline_new; highlight_applied_count += 1
                    final_edge_colors.append(edge_color_hex)
            else: final_edge_colors = [self._visualization_state.get('default_edge_color', GlobalSettings.Colors.NODE_EDGE_OLD)] * len(x_coords)
            logger.debug(f"{log_prefix}Highlight counts: Selection={selection_applied_count}, New={highlight_applied_count}")
            # ---

            # --- MODIFIED: Ensure face colors are list of RGBA ---
            if isinstance(node_face_colors, np.ndarray):
                face_colors_to_use = node_face_colors.tolist()
            elif isinstance(node_face_colors, list):
                face_colors_to_use = node_face_colors
            else:
                logger.error(f"{log_prefix}Unexpected type for node_face_colors: {type(node_face_colors)}. Using default.")
                default_face = colors.to_rgba(self._visualization_state.get('node_base', GlobalSettings.Colors.NODE_INACTIVE))
                face_colors_to_use = [default_face] * len(x_coords)
            # --- END MODIFIED ---

            # --- Create Scatter Plot ---
            self._node_scatter = self.ax.scatter(
                x_coords, y_coords,
                s=size_to_use,
                alpha=node_opacity,
                facecolors=face_colors_to_use, # Use the list of RGBA
                edgecolors=final_edge_colors, # Use HEX list
                linewidths=outline_width,
                zorder=3
            )
            logger.debug(f"{log_prefix}NEW self._node_scatter created: {self._node_scatter} (ID: {id(self._node_scatter)})")
            # ---

        else:
            logger.debug(f"{log_prefix}No nodes to draw.")
            self._node_scatter = None

        logger.debug(f"{log_prefix}EXIT")

    @timer_decorator
    def _update_nodes_2d(self, x_coords, y_coords, node_face_colors, indices,
                         nodes_to_highlight: Optional[Set[Tuple[int, ...]]] = None) -> bool:
        """
        Update node positions, colors, size, and outline for 2D plots using pre-calculated face colors
        and applying edge highlights/selection. Only updates artist properties if data has changed.
        Reads selection from internal state. Returns True if any node property was updated.
        (Round 15: Ensure nodes_updated=True on color change)
        (Round 14: Ensure face colors are list of RGBA tuples)
        """
        log_prefix = f"_update_nodes_2d(ID:{id(self)} R15 Color Update Flag): " # Updated round
        nodes_updated = False # Initialize flag
        detailed_logging_enabled = LogSettings.Performance.ENABLE_DETAILED_LOGGING

        if x_coords is None or y_coords is None or x_coords.size == 0 or node_face_colors is None:
            # [ Clearing logic remains the same ]
            if self._node_scatter is not None:
                current_offsets = self._node_scatter.get_offsets()
                if current_offsets.shape[0] > 0:
                    if detailed_logging_enabled: logger.debug(f"{log_prefix}Input empty, clearing scatter plot data.")
                    self._node_scatter.set_offsets(np.empty((0, 2)))
                    self._node_scatter.set_facecolors([])
                    self._node_scatter.set_edgecolors([])
                    self._node_scatter.set_sizes([])
                    self._node_scatter.set_linewidths([])
                    nodes_updated = True # Mark as updated if cleared
                    self._last_rendered_node_offsets = np.empty((0, 2))
                    self._last_rendered_node_face_colors = np.empty((0, 4))
                    self._last_rendered_node_edge_colors = np.empty((0, 4))
                    self._last_rendered_node_size = None
                    self._last_rendered_outline_width = None
            return nodes_updated

        if self._node_scatter is None:
            logger.warning(f"{log_prefix}_node_scatter is None. Cannot update data. Draw should be called first.")
            self._draw_nodes_2d(x_coords, y_coords, node_face_colors, indices, nodes_to_highlight)
            self._last_rendered_node_offsets = np.column_stack([x_coords, y_coords])
            self._last_rendered_node_face_colors = np.array(node_face_colors)
            self._last_rendered_node_edge_colors = None
            self._last_rendered_node_size = self._calculate_node_size(self._visualization_state.get('zoom_factor', 1.0))
            self._last_rendered_outline_width = self._calculate_outline_width(self._visualization_state.get('zoom_factor', 1.0))
            return True # Mark as updated since it was drawn

        background_color = self._visualization_state.get('background_color', GlobalSettings.Colors.BACKGROUND)
        current_zoom = self._visualization_state.get('zoom_factor', 1.0)
        node_size = self._calculate_node_size(current_zoom)
        outline_width = self._calculate_outline_width(current_zoom)

        # --- Determine Final Edge Colors (Logic Unchanged) ---
        final_edge_colors_hex = []; final_edge_colors_rgba = []
        if indices is not None and len(indices) == len(x_coords):
            highlight_on = self._visualization_state.get('highlight_on', True)
            added_nodes_coords = self._visualization_state.get('added_nodes_coords', set())
            selected_nodes_coords = self._visualization_state.get('selection_to_highlight', set())
            node_outline_old = self._visualization_state.get('default_edge_color', GlobalSettings.Colors.NODE_EDGE_OLD)
            node_outline_new = self._visualization_state.get('node_outline_new', GlobalSettings.Colors.NODE_EDGE_NEW)
            for i, node_idx in enumerate(indices):
                grid_coords_tuple = tuple(_unravel_index(node_idx, self.grid.dimensions))
                is_selected = grid_coords_tuple in selected_nodes_coords
                is_new = highlight_on and (grid_coords_tuple in added_nodes_coords)
                edge_color_hex = node_outline_old; edge_color_rgba = colors.to_rgba(node_outline_old)
                if is_selected:
                    node_face_color_rgba = node_face_colors[i]
                    inverted_color_rgba = _get_contrasting_inverted_color(node_face_color_rgba, background_color)
                    edge_color_hex = colors.to_hex(inverted_color_rgba[:3]); edge_color_rgba = inverted_color_rgba
                elif is_new:
                    edge_color_hex = node_outline_new; edge_color_rgba = colors.to_rgba(node_outline_new)
                final_edge_colors_hex.append(edge_color_hex); final_edge_colors_rgba.append(edge_color_rgba)
        else:
             logger.warning(f"{log_prefix}Index count mismatch. Using default outline.")
             default_hex = self._visualization_state.get('default_edge_color', GlobalSettings.Colors.NODE_EDGE_OLD)
             default_rgba = colors.to_rgba(default_hex)
             final_edge_colors_hex = [default_hex] * len(x_coords); final_edge_colors_rgba = [default_rgba] * len(x_coords)
        final_edge_colors_rgba_np = np.array(final_edge_colors_rgba)
        # ---

        # --- Compare and Update Artist Properties ---
        # Offsets
        new_offsets = np.column_stack([x_coords, y_coords])
        offsets_changed = self._last_rendered_node_offsets is None or not np.array_equal(new_offsets, self._last_rendered_node_offsets)
        if offsets_changed:
            if detailed_logging_enabled: logger.debug(f"{log_prefix}Offsets CHANGED. Calling set_offsets.")
            logger.debug(f"  set_offsets data: Shape={new_offsets.shape}, Dtype={new_offsets.dtype}, First 5: {new_offsets[:5]}")
            self._node_scatter.set_offsets(new_offsets); self._last_rendered_node_offsets = new_offsets; nodes_updated = True

        # Face Colors
        if isinstance(node_face_colors, np.ndarray): new_face_colors_list = node_face_colors.tolist()
        elif isinstance(node_face_colors, list): new_face_colors_list = node_face_colors
        else: logger.error(f"{log_prefix}Unexpected type for node_face_colors: {type(node_face_colors)}. Cannot set."); new_face_colors_list = []
        last_face_colors_list = self._last_rendered_node_face_colors
        if isinstance(last_face_colors_list, np.ndarray): last_face_colors_list = last_face_colors_list.tolist()
        face_colors_changed = last_face_colors_list is None or new_face_colors_list != last_face_colors_list
        if face_colors_changed:
            logger.info(f"{log_prefix}Face colors CHANGED. Calling set_facecolors.")
            logger.debug(f"  set_facecolors data: Type={type(new_face_colors_list)}, Length={len(new_face_colors_list)}, First 5: {new_face_colors_list[:5]}")
            self._node_scatter.set_facecolors(new_face_colors_list)
            self.blitting_manager.invalidate_cache()
            logger.info(f"{log_prefix}Invalidated blit cache because face colors changed.")
            self._last_rendered_node_face_colors = np.array(new_face_colors_list)
            nodes_updated = True # *** Ensure flag is set on color change ***

        # Edge Colors
        edge_colors_changed = self._last_rendered_node_edge_colors is None or not np.array_equal(final_edge_colors_rgba_np, self._last_rendered_node_edge_colors)
        if edge_colors_changed:
            if detailed_logging_enabled: logger.debug(f"{log_prefix}Edge colors CHANGED. Calling set_edgecolors.")
            logger.debug(f"  set_edgecolors data: Type={type(final_edge_colors_hex)}, Length={len(final_edge_colors_hex)}, First 5: {final_edge_colors_hex[:5]}")
            self._node_scatter.set_edgecolors(final_edge_colors_hex); self._last_rendered_node_edge_colors = final_edge_colors_rgba_np; nodes_updated = True # *** Ensure flag is set on color change ***

        # Size
        size_changed = self._last_rendered_node_size is None or not np.isclose(node_size, self._last_rendered_node_size)
        if size_changed:
            if detailed_logging_enabled: logger.debug(f"{log_prefix}Node size CHANGED. Calling set_sizes.")
            logger.debug(f"  set_sizes data: Size={node_size}, Count={len(x_coords)}")
            self._node_scatter.set_sizes([node_size] * len(x_coords)); self._last_rendered_node_size = node_size; nodes_updated = True

        # Linewidth
        width_changed = self._last_rendered_outline_width is None or not np.isclose(outline_width, self._last_rendered_outline_width)
        if width_changed:
            if detailed_logging_enabled: logger.debug(f"{log_prefix}Outline width CHANGED. Calling set_linewidths.")
            logger.debug(f"  set_linewidths data: Width={outline_width}, Count={len(x_coords)}")
            self._node_scatter.set_linewidths([outline_width] * len(x_coords)); self._last_rendered_outline_width = outline_width; nodes_updated = True

        logger.debug(f"{log_prefix}EXIT - Nodes updated flag: {nodes_updated}")
        return nodes_updated

    @timer_decorator
    def _draw_nodes_3d(self, x_coords, y_coords, z_coords, node_face_colors, indices,
                       nodes_to_highlight: Optional[Set[Tuple[int, ...]]] = None,
                       selection_to_highlight: Optional[Set[Tuple[int, ...]]] = None): # ADDED selection_to_highlight
        """Draw or update nodes for 3D plots using pre-calculated face colors and applying edge highlights/selection.
           Uses explicitly passed selection set.
           (Round 12: Accept selection_to_highlight explicitly)"""

        log_prefix = f"_draw_nodes_3d(ID:{id(self)}): "
        # --- MODIFIED: Log received selection ---
        logger.debug(f"{log_prefix}ENTRY - Received selection_to_highlight: Size={len(selection_to_highlight) if selection_to_highlight else 'None'}, Type={type(selection_to_highlight)}")
        # ---
        grid_id_at_draw = id(self.grid) if self.grid else "None"
        logger.info(f"{log_prefix}ENTRY (Grid ID: {grid_id_at_draw}, Nodes: {len(x_coords)})")

        # [ Parameter calculation - Unchanged ]
        node_opacity = GlobalSettings.Visualization.NODE_OPACITY
        current_zoom = self._visualization_state.get('zoom_factor', 1.0)
        size_to_use = self._calculate_node_size(current_zoom)
        outline_width = self._calculate_outline_width(current_zoom)
        background_color = self._visualization_state.get('background_color', GlobalSettings.Colors.BACKGROUND)

        # [ Data Validation - Simplified ]
        if x_coords is None or y_coords is None or z_coords is None or indices is None or node_face_colors is None:
            logger.error(f"{log_prefix}Received None for coordinates, indices, or face colors!"); return
        if not (len(x_coords) == len(y_coords) == len(z_coords) == len(node_face_colors) == len(indices)):
            logger.error(f"{log_prefix}Data array length mismatch! x:{len(x_coords)}, y:{len(y_coords)}, z:{len(z_coords)}, faces:{len(node_face_colors)}, idx:{len(indices)}. Skipping node draw."); return
        if np.any(np.isnan(x_coords)) or np.any(np.isnan(y_coords)) or np.any(np.isnan(z_coords)): logger.error(f"{log_prefix}NaN values found in node coordinates! Skipping node draw."); return
        if np.any(np.isinf(x_coords)) or np.any(np.isinf(y_coords)) or np.any(np.isinf(z_coords)): logger.error(f"{log_prefix}Infinite values found in node coordinates! Skipping node draw."); return

        if x_coords is not None and x_coords.size > 0:
            logger.debug(f"{log_prefix}Preparing to create/update 3D scatter plot.")
            logger.debug(f"{log_prefix}  Current self._node_scatter_3d: {self._node_scatter_3d} (ID: {id(self._node_scatter_3d) if self._node_scatter_3d else 'None'})")
            if self._node_scatter_3d is None:
                logger.debug(f"{log_prefix}Creating new 3D scatter artist.")
                initial_edge_color = self._visualization_state.get('default_edge_color', GlobalSettings.Colors.NODE_EDGE_OLD)
                initial_face_color = self._visualization_state.get('node_base', GlobalSettings.Colors.NODE_INACTIVE)
                self._node_scatter_3d = self.ax.scatter(
                    [], [], [], s=size_to_use, alpha=node_opacity,
                    edgecolors=initial_edge_color,
                    linewidths=outline_width, zorder=3, facecolors=initial_face_color
                )
                logger.debug(f"{log_prefix}  NEW self._node_scatter_3d created: {self._node_scatter_3d} (ID: {id(self._node_scatter_3d)})")

            # [ Set offsets, sizes, linewidths - Unchanged ]
            coords_array = np.column_stack([x_coords, y_coords, z_coords])
            self._node_scatter_3d._offsets3d = (coords_array[:, 0], coords_array[:, 1], coords_array[:, 2]) # type: ignore
            self._node_scatter_3d.set_sizes([size_to_use] * len(x_coords))
            self._node_scatter_3d.set_linewidths([outline_width] * len(x_coords))

            # --- Determine Final Edge Colors (Represents Highlight/Selection) ---
            final_edge_colors = []
            highlight_applied_count = 0; selection_applied_count = 0

            if indices is not None and len(indices) == len(x_coords):
                highlight_on = self._visualization_state.get('highlight_on', True)
                added_nodes_coords = self._visualization_state.get('added_nodes_coords', set())
                # --- MODIFIED: Use the PASSED selection_to_highlight set ---
                selected_nodes_coords = selection_to_highlight if selection_to_highlight is not None else set()
                logger.info(f"{log_prefix}Using PASSED selection set: {len(selected_nodes_coords)} nodes selected.")
                if len(selected_nodes_coords) < 20: logger.debug(f"    Selected Coords (Passed): {selected_nodes_coords}")
                # --- END MODIFIED ---
                node_outline_old = self._visualization_state.get('default_edge_color', GlobalSettings.Colors.NODE_EDGE_OLD)
                node_outline_new = self._visualization_state.get('node_outline_new', GlobalSettings.Colors.NODE_EDGE_NEW)

                for i, node_idx in enumerate(indices):
                    grid_coords_tuple = tuple(_unravel_index(node_idx, self.grid.dimensions))
                    is_selected = grid_coords_tuple in selected_nodes_coords
                    is_new = highlight_on and (grid_coords_tuple in added_nodes_coords)

                    edge_color_hex = node_outline_old

                    if is_selected:
                        node_face_color_hex = colors.to_hex(node_face_colors[i]) # Use pre-calculated RGBA
                        inverted_color_rgba = _get_contrasting_inverted_color(node_face_color_hex, background_color)
                        edge_color_hex = colors.to_hex(inverted_color_rgba[:3])
                        selection_applied_count += 1
                        logger.debug(f"    Node {node_idx} ({grid_coords_tuple}) IS SELECTED. Face={node_face_color_hex}, BG={background_color}, Inverted={inverted_color_rgba}, FinalEdge={edge_color_hex}")
                    elif is_new:
                        edge_color_hex = node_outline_new
                        highlight_applied_count += 1
                        logger.debug(f"    Node {node_idx} ({grid_coords_tuple}) IS NEW. FinalEdge={edge_color_hex}")

                    final_edge_colors.append(edge_color_hex)
            else:
                 logger.warning(f"{log_prefix}Index count mismatch. Using default outline.")
                 final_edge_colors = [self._visualization_state.get('default_edge_color', GlobalSettings.Colors.NODE_EDGE_OLD)] * len(x_coords)

            logger.debug(f"{log_prefix}Highlight counts: Selection={selection_applied_count}, New={highlight_applied_count}")

            # --- Apply final colors ---
            logger.debug(f"{log_prefix}Setting final face colors (Count: {len(node_face_colors)}).")
            if node_face_colors: self._node_scatter_3d.set_facecolors(node_face_colors) # Use pre-calculated RGBA face colors
            logger.debug(f"{log_prefix}Setting final edge colors (Count: {len(final_edge_colors)}).")
            if final_edge_colors: self._node_scatter_3d.set_edgecolors(final_edge_colors)    # Use calculated HEX edge colors
            # ---

        else:
            logger.debug(f"{log_prefix}No nodes to draw, clearing 3D scatter plot.")
            if self._node_scatter_3d is not None:
                self._node_scatter_3d._offsets3d = (np.array([]), np.array([]), np.array([])) # type: ignore
                self._node_scatter_3d.set_facecolors([])
                self._node_scatter_3d.set_edgecolors([])
                self._node_scatter_3d.set_sizes([])
                self._node_scatter_3d.set_linewidths([])
                self._node_scatter_3d.set_array(np.array([]))

    @timer_decorator
    def _update_nodes_3d(self, x_coords, y_coords, z_coords, node_face_colors, indices,
                         nodes_to_highlight: Optional[Set[Tuple[int, ...]]] = None,
                         selection_to_highlight: Optional[Set[Tuple[int, ...]]] = None) -> bool:
        """Update node positions, colors, size, and outline for 3D plots using pre-calculated face colors
           and applying edge highlights/selection. Only updates artist properties if data has changed.
           Uses explicitly passed selection set. Returns True if any node property was updated.
           (Round 51: Invalidate blit cache on face color change for consistency)"""

        log_prefix = f"_update_nodes_3d(ID:{id(self)} R51): " # Updated round
        logger.debug(f"{log_prefix}ENTRY - Received selection_to_highlight: Size={len(selection_to_highlight) if selection_to_highlight else 'None'}, Type={type(selection_to_highlight)}")

        nodes_updated = False # Flag to track if any update occurred

        if x_coords is None or y_coords is None or z_coords is None or x_coords.size == 0 or node_face_colors is None:
            if self._node_scatter_3d is not None:
                current_offsets = self._node_scatter_3d._offsets3d # type: ignore
                if current_offsets is not None and len(current_offsets[0]) > 0:
                    self._node_scatter_3d._offsets3d = (np.array([]), np.array([]), np.array([])) # type: ignore
                    self._node_scatter_3d.set_facecolors([])
                    self._node_scatter_3d.set_edgecolors([])
                    self._node_scatter_3d.set_sizes([])
                    self._node_scatter_3d.set_linewidths([])
                    self._node_scatter_3d.set_array(np.array([]))
                    nodes_updated = True
                    self._last_rendered_node_offsets = np.empty((0, 3))
                    self._last_rendered_node_face_colors = np.empty((0, 4))
                    self._last_rendered_node_edge_colors = np.empty((0, 4))
                    self._last_rendered_node_size = None
                    self._last_rendered_outline_width = None
            return nodes_updated

        if self._node_scatter_3d is None:
            logger.warning(f"{log_prefix}_node_scatter_3d is None. Cannot update data. Draw should be called first.")
            self._draw_nodes_3d(x_coords, y_coords, z_coords, node_face_colors, indices, nodes_to_highlight, selection_to_highlight)
            self._last_rendered_node_offsets = np.column_stack([x_coords, y_coords, z_coords])
            self._last_rendered_node_face_colors = np.array(node_face_colors)
            self._last_rendered_node_edge_colors = None
            self._last_rendered_node_size = self._calculate_node_size(self._visualization_state.get('zoom_factor', 1.0))
            self._last_rendered_outline_width = self._calculate_outline_width(self._visualization_state.get('zoom_factor', 1.0))
            return True

        # --- Calculate current visual properties ---
        background_color = self._visualization_state.get('background_color', GlobalSettings.Colors.BACKGROUND)
        current_zoom = self._visualization_state.get('zoom_factor', 1.0)
        node_size = self._calculate_node_size(current_zoom)
        outline_width = self._calculate_outline_width(current_zoom)

        # --- Determine Final Edge Colors (Represents Highlight/Selection) ---
        final_edge_colors_hex = []; final_edge_colors_rgba = []
        highlight_applied_count = 0; selection_applied_count = 0
        if indices is not None and len(indices) == len(x_coords):
            highlight_on = self._visualization_state.get('highlight_on', True)
            added_nodes_coords = self._visualization_state.get('added_nodes_coords', set())
            selected_nodes_coords = selection_to_highlight if selection_to_highlight is not None else set()
            node_outline_old = self._visualization_state.get('default_edge_color', GlobalSettings.Colors.NODE_EDGE_OLD)
            node_outline_new = self._visualization_state.get('node_outline_new', GlobalSettings.Colors.NODE_EDGE_NEW)
            for i, node_idx in enumerate(indices):
                grid_coords_tuple = tuple(_unravel_index(node_idx, self.grid.dimensions))
                is_selected = grid_coords_tuple in selected_nodes_coords
                is_new = highlight_on and (grid_coords_tuple in added_nodes_coords)
                edge_color_hex = node_outline_old; edge_color_rgba = colors.to_rgba(node_outline_old)
                if is_selected:
                    node_face_color_rgba = node_face_colors[i]
                    inverted_color_rgba = _get_contrasting_inverted_color(node_face_color_rgba, background_color)
                    edge_color_hex = colors.to_hex(inverted_color_rgba[:3]); edge_color_rgba = inverted_color_rgba; selection_applied_count += 1
                elif is_new:
                    edge_color_hex = node_outline_new; edge_color_rgba = colors.to_rgba(node_outline_new); highlight_applied_count += 1
                final_edge_colors_hex.append(edge_color_hex); final_edge_colors_rgba.append(edge_color_rgba)
        else:
             logger.warning(f"{log_prefix}Index count mismatch. Using default outline.")
             default_hex = self._visualization_state.get('default_edge_color', GlobalSettings.Colors.NODE_EDGE_OLD)
             default_rgba = colors.to_rgba(default_hex)
             final_edge_colors_hex = [default_hex] * len(x_coords); final_edge_colors_rgba = [default_rgba] * len(x_coords)
        final_edge_colors_rgba_np = np.array(final_edge_colors_rgba)
        # ---

        # --- Compare and Update Artist Properties ---
        # Offsets
        new_offsets_array = np.column_stack([x_coords, y_coords, z_coords])
        if self._last_rendered_node_offsets is None or not np.array_equal(new_offsets_array, self._last_rendered_node_offsets):
            self._node_scatter_3d._offsets3d = (new_offsets_array[:, 0], new_offsets_array[:, 1], new_offsets_array[:, 2]) # type: ignore
            self._last_rendered_node_offsets = new_offsets_array; nodes_updated = True
            logger.debug(f"{log_prefix}Updated node offsets.")

        # Face Colors
        new_face_colors_np = np.array(node_face_colors)
        if self._last_rendered_node_face_colors is None or not np.array_equal(new_face_colors_np, self._last_rendered_node_face_colors):
            self._node_scatter_3d.set_facecolors(new_face_colors_np)
            # --- ADDED: Invalidate blit cache if face colors changed ---
            self.blitting_manager.invalidate_cache()
            logger.info(f"{log_prefix}Invalidated blit cache because face colors changed (3D).")
            # ---
            self._last_rendered_node_face_colors = new_face_colors_np; nodes_updated = True
            logger.debug(f"{log_prefix}Updated node face colors.")

        # Edge Colors
        if self._last_rendered_node_edge_colors is None or not np.array_equal(final_edge_colors_rgba_np, self._last_rendered_node_edge_colors):
            self._node_scatter_3d.set_edgecolors(final_edge_colors_hex)
            self._last_rendered_node_edge_colors = final_edge_colors_rgba_np; nodes_updated = True
            logger.debug(f"{log_prefix}Updated node edge colors.")

        # Size
        if self._last_rendered_node_size is None or not np.isclose(node_size, self._last_rendered_node_size):
            self._node_scatter_3d.set_sizes([node_size] * len(x_coords))
            self._last_rendered_node_size = node_size; nodes_updated = True
            logger.debug(f"{log_prefix}Updated node size.")

        # Linewidth
        if self._last_rendered_outline_width is None or not np.isclose(outline_width, self._last_rendered_outline_width):
            self._node_scatter_3d.set_linewidths([outline_width] * len(x_coords))
            self._last_rendered_outline_width = outline_width; nodes_updated = True
            logger.debug(f"{log_prefix}Updated node outline width.")

        logger.debug(f"{log_prefix}EXIT - Nodes updated flag: {nodes_updated}")
        return nodes_updated

    @timer_decorator
    def _draw_edges_2d(self, segments, colors: List[str]): # Expecting HEX strings
        """Draw edges for 2D plots by recreating the LineCollection and using the provided colors.
           (Round 1 Fix: Use passed colors)
           (Round 22: Log received colors)"""
        log_prefix = f"_draw_edges_2d(ID:{id(self)} R22): " # Updated round
        log_limit = min(10, len(colors) if colors else 0)
        logger.debug(f"{log_prefix}ENTRY - Drawing {len(segments)} segments. Received Colors (len={len(colors) if colors else 0}, First {log_limit}): {colors[:log_limit] if colors else 'None'}")

        # Clear existing collection if it exists
        if hasattr(self, '_edge_lines') and self._edge_lines:
            try: self._edge_lines.remove()
            except ValueError: pass
            except Exception as e: logger.warning(f"{log_prefix}Error removing previous LineCollection: {e}")
            finally: self._edge_lines = None

        # Calculate width based on current zoom
        current_zoom = self._visualization_state.get('zoom_factor', 1.0)
        width_to_use = self._calculate_edge_width(current_zoom)

        # Filter segments and colors simultaneously (ensure they remain paired)
        valid_segments = []
        valid_colors = [] # Use the provided colors list directly
        if colors is None or len(colors) != len(segments): # Check if colors is None
             logger.error(f"{log_prefix}Color list is None or count ({len(colors) if colors else 'None'}) mismatch segment count ({len(segments)}). Using default color.")
             default_hex = self._visualization_state.get('default_edge_color', GlobalSettings.Colors.NODE_EDGE_OLD)
             colors = [default_hex] * len(segments) # Fallback

        for i, (segment, color) in enumerate(zip(segments, colors)):
            # Basic validation for segment data
            if not isinstance(segment, (list, tuple)) or len(segment) != 2: continue
            start, end = segment
            if not isinstance(start, (list, tuple)) or not isinstance(end, tuple): continue
            if len(start) != 2 or len(end) != 2: continue
            if np.any(np.isnan(start)) or np.any(np.isinf(start)): continue
            if np.any(np.isnan(end)) or np.any(np.isinf(end)): continue
            # Basic validation for color
            if not isinstance(color, str) or not color.startswith('#'):
                logger.warning(f"{log_prefix}Invalid color format '{color}' at index {i}, using default.")
                color = self._visualization_state.get('default_edge_color', GlobalSettings.Colors.NODE_EDGE_OLD) # Use default on error

            valid_segments.append(segment)
            valid_colors.append(color) # Append the pre-calculated or default color

        if valid_segments:
            log_limit_final = min(10, len(valid_colors))
            logger.debug(f"{log_prefix}Creating LineCollection with {len(valid_segments)} segments. Final Colors (First {log_limit_final}): {valid_colors[:log_limit_final]}")
            try:
                self._edge_lines = LineCollection(
                    valid_segments,
                    colors=valid_colors, # Use the validated list of pre-calculated colors
                    alpha=GlobalSettings.Visualization.EDGE_OPACITY,
                    linewidths=width_to_use,
                    zorder=1
                )
                self.ax.add_collection(self._edge_lines)
            except Exception as e:
                logger.error(f"{log_prefix}Error creating LineCollection: {e}")
                self._edge_lines = None
        else:
            logger.debug(f"{log_prefix}No valid segments to draw.")
            self._edge_lines = None

    @timer_decorator
    def _update_edges_2d(self, segments, colors: List[str]) -> bool:
        """
        Update edges for 2D plots using the provided colors list.
        Updates the existing LineCollection data if possible, otherwise recreates it.
        Returns True if the collection data was updated or recreated.
        (Round 6: Update existing LineCollection instead of recreating)
        """
        log_prefix = f"_update_edges_2d(ID:{id(self)} R6 Update): " # Updated round
        log_limit = min(10, len(colors) if colors else 0)
        # logger.debug(f"{log_prefix}ENTRY (Updating data for {len(segments)} segments). Received Colors (len={len(colors) if colors else 0}, First {log_limit}): {colors[:log_limit] if colors else 'None'}") # Reduce noise

        edges_updated = False # Flag to track if update/recreation happened
        detailed_logging_enabled = LogSettings.Performance.ENABLE_DETAILED_LOGGING # Check flag

        # --- Calculate current visual properties ---
        current_zoom = self._visualization_state.get('zoom_factor', 1.0)
        width_to_use = self._calculate_edge_width(current_zoom)

        # --- Filter segments and colors simultaneously ---
        valid_segments = []
        valid_colors = [] # Use the provided colors list directly
        if colors is None or len(colors) != len(segments): # Check if colors is None
             logger.error(f"{log_prefix}Color list is None or count ({len(colors) if colors else 'None'}) mismatch segment count ({len(segments)}). Using default color.")
             default_hex = self._visualization_state.get('default_edge_color', GlobalSettings.Colors.NODE_EDGE_OLD)
             colors = [default_hex] * len(segments) # Fallback

        for i, (segment, color) in enumerate(zip(segments, colors)):
            # Basic validation
            if not isinstance(segment, (list, tuple)) or len(segment) != 2: continue
            start, end = segment
            if not isinstance(start, (list, tuple)) or not isinstance(end, tuple): continue
            if len(start) != 2 or len(end) != 2: continue
            if np.any(np.isnan(start)) or np.any(np.isinf(start)): continue
            if np.any(np.isnan(end)) or np.any(np.isinf(end)): continue
            if not isinstance(color, str) or not color.startswith('#'):
                logger.warning(f"{log_prefix}Invalid color format '{color}' at index {i}, using default.")
                color = self._visualization_state.get('default_edge_color', GlobalSettings.Colors.NODE_EDGE_OLD) # Use default on error

            valid_segments.append(segment)
            valid_colors.append(color) # Append the pre-calculated or default color

        # --- Compare current data with last rendered data ---
        segments_changed = self._last_rendered_edge_segments is None or valid_segments != self._last_rendered_edge_segments
        colors_changed = self._last_rendered_edge_colors is None or valid_colors != self._last_rendered_edge_colors
        width_changed = self._last_rendered_edge_width is None or not np.isclose(width_to_use, self._last_rendered_edge_width)

        # --- MODIFIED: Update existing or recreate ---
        if segments_changed or colors_changed or width_changed:
            edges_updated = True # Mark that an update is happening

            if self._edge_lines is None: # If no collection exists, create it
                if detailed_logging_enabled: logger.debug(f"{log_prefix}Edge data CHANGED and no existing LineCollection. Creating new one.")
                if valid_segments:
                    try:
                        self._edge_lines = LineCollection(
                            valid_segments, colors=valid_colors,
                            alpha=GlobalSettings.Visualization.EDGE_OPACITY,
                            linewidths=width_to_use, zorder=1
                        )
                        self.ax.add_collection(self._edge_lines)
                    except Exception as e:
                        logger.error(f"{log_prefix}Error creating LineCollection: {e}")
                        self._edge_lines = None
                else:
                    self._edge_lines = None # Ensure it's None if no segments
            else: # Collection exists, update its data
                if detailed_logging_enabled: logger.debug(f"{log_prefix}Edge data CHANGED. Updating existing LineCollection.")
                try:
                    if valid_segments:
                        self._edge_lines.set_segments(valid_segments)
                        self._edge_lines.set_colors(valid_colors)
                        self._edge_lines.set_linewidth(width_to_use)
                        self._edge_lines.set_alpha(GlobalSettings.Visualization.EDGE_OPACITY) # Ensure alpha is set
                        self._edge_lines.set_zorder(1) # Ensure zorder is set
                    else: # No valid segments, clear the existing collection
                        self._edge_lines.set_segments([])
                        self._edge_lines.set_colors([])
                        self._edge_lines.set_linewidth(width_to_use)
                except Exception as e:
                    logger.error(f"{log_prefix}Error updating existing LineCollection: {e}. Recreating.")
                    # Fallback to recreation on update error
                    try: self._edge_lines.remove()
                    except: pass
                    self._edge_lines = None
                    if valid_segments:
                        self._edge_lines = LineCollection(valid_segments, colors=valid_colors, alpha=GlobalSettings.Visualization.EDGE_OPACITY, linewidths=width_to_use, zorder=1)
                        self.ax.add_collection(self._edge_lines)

            # Update last rendered state AFTER successful update/creation
            self._last_rendered_edge_segments = valid_segments.copy() # Store copies
            self._last_rendered_edge_colors = valid_colors.copy()
            self._last_rendered_edge_width = width_to_use
        # else: # Reduce noise
            # if detailed_logging_enabled: logger.debug(f"{log_prefix}Edge data UNCHANGED. Skipping LineCollection update/recreation.")
            # edges_updated = False
        # --- END MODIFIED ---

        # logger.debug(f"{log_prefix}EXIT - Edges updated flag: {edges_updated}") # Reduce noise
        return edges_updated

    @timer_decorator
    def _draw_edges_3d(self, segments, colors: List[str]):
        """Draw edges for 3D plots by recreating the Line3DCollection and using the provided colors.
           (Round 10 Fix: Align with 2D color logic - use pre-calculated colors)"""
        log_prefix = f"_draw_edges_3d(ID:{id(self)}): "
        log_limit = min(10, len(colors))
        logger.debug(f"{log_prefix}ENTRY - Drawing {len(segments)} segments. Received Colors (First {log_limit}): {colors[:log_limit]}")

        # Clear existing collection if it exists
        if hasattr(self, '_edge_lines_3d') and self._edge_lines_3d:
            if self._edge_lines_3d is not None:
                for line in self._edge_lines_3d:
                    try: line.remove()
                    except ValueError: pass
                    except Exception as e: logger.warning(f"{log_prefix}Error removing previous Line3DCollection: {e}")
            self._edge_lines_3d = []

        # Calculate width based on current zoom
        current_zoom = self._visualization_state.get('zoom_factor', 1.0)
        width_to_use = self._calculate_edge_width(current_zoom)

        # Filter segments and colors simultaneously
        valid_segments = []
        valid_colors = [] # Use the provided colors list directly
        if len(colors) != len(segments):
             logger.error(f"{log_prefix}Color count ({len(colors)}) mismatch segment count ({len(segments)}). Using default color.")
             default_hex = self._visualization_state.get('default_edge_color', GlobalSettings.Colors.NODE_EDGE_OLD)
             colors = [default_hex] * len(segments) # Fallback

        for i, (segment, color) in enumerate(zip(segments, colors)):
            # Basic validation for segment data
            if not isinstance(segment, (list, tuple)) or len(segment) != 2: continue
            start, end = segment
            if not isinstance(start, (list, tuple)) or not isinstance(end, tuple): continue
            if len(start) != 3 or len(end) != 3: continue # Check for 3D
            if np.any(np.isnan(start)) or np.any(np.isinf(start)): continue
            if np.any(np.isnan(end)) or np.any(np.isinf(end)): continue
            # Basic validation for color
            if not isinstance(color, str) or not color.startswith('#'): continue

            valid_segments.append(segment)
            valid_colors.append(color) # Append the pre-calculated color

        if valid_segments:
            log_limit_final = min(10, len(valid_colors))
            logger.debug(f"{log_prefix}Creating Line3DCollection with {len(valid_segments)} segments. Final Colors (First {log_limit_final}): {valid_colors[:log_limit_final]}")
            line_collection = Line3DCollection(
                valid_segments,
                colors=valid_colors, # Use the validated list of pre-calculated colors
                alpha=GlobalSettings.Visualization.EDGE_OPACITY,
                linewidths=[width_to_use] * len(valid_segments), # Use calculated width
                zorder=1
            )
            self.ax.add_collection(line_collection) # type: ignore
            self._edge_lines_3d = [line_collection]
        else:
            logger.debug(f"{log_prefix}No valid segments to draw.")
            self._edge_lines_3d = []

    @timer_decorator
    def _update_edges_3d(self, segments, colors):
        """Update edges for 3D plots using the provided colors list by recreating the collection
           only if segments, colors, or width change. Returns True if recreated.
           (Round 10 Fix: Align with 2D color logic - use pre-calculated colors)
           (Round 3: Implement conditional recreation based on _last_rendered_... state)"""

        log_prefix = f"_update_edges_3d(ID:{id(self)} R3): " # Updated round
        log_limit = min(10, len(colors) if colors else 0)
        logger.debug(f"{log_prefix}ENTRY (Updating data for {len(segments)} segments). Received Colors (len={len(colors) if colors else 0}, First {log_limit}): {colors[:log_limit] if colors else 'None'}")

        edges_updated = False # Flag to track if recreation happened

        # --- Calculate current visual properties ---
        current_zoom = self._visualization_state.get('zoom_factor', 1.0)
        width_to_use = self._calculate_edge_width(current_zoom)

        # --- Filter segments and colors simultaneously ---
        valid_segments = []
        valid_colors = [] # Use the provided colors list directly
        if colors is None or len(colors) != len(segments): # Check if colors is None
             logger.error(f"{log_prefix}Color list is None or count ({len(colors) if colors else 'None'}) mismatch segment count ({len(segments)}). Using default color.")
             default_hex = self._visualization_state.get('default_edge_color', GlobalSettings.Colors.NODE_EDGE_OLD)
             colors = [default_hex] * len(segments) # Fallback

        for i, (segment, color) in enumerate(zip(segments, colors)):
            # Basic validation
            if not isinstance(segment, (list, tuple)) or len(segment) != 2: continue
            start, end = segment
            if not isinstance(start, (list, tuple)) or not isinstance(end, tuple): continue
            if len(start) != 3 or len(end) != 3: continue # Check for 3D
            if np.any(np.isnan(start)) or np.any(np.isinf(start)): continue
            if np.any(np.isnan(end)) or np.any(np.isinf(end)): continue
            if not isinstance(color, str) or not color.startswith('#'):
                logger.warning(f"{log_prefix}Invalid color format '{color}' at index {i}, using default.")
                color = self._visualization_state.get('default_edge_color', GlobalSettings.Colors.NODE_EDGE_OLD) # Use default on error

            valid_segments.append(segment)
            valid_colors.append(color) # Append the pre-calculated or default color

        # --- Compare current data with last rendered data ---
        # Note: Comparing lists of lists/tuples can be slow for large numbers of segments.
        # If performance becomes an issue here, consider hashing or more optimized comparison.
        segments_changed = self._last_rendered_edge_segments is None or valid_segments != self._last_rendered_edge_segments
        colors_changed = self._last_rendered_edge_colors is None or valid_colors != self._last_rendered_edge_colors
        width_changed = self._last_rendered_edge_width is None or not np.isclose(width_to_use, self._last_rendered_edge_width)

        if segments_changed or colors_changed or width_changed:
            logger.debug(f"{log_prefix}Edge data changed (Segments: {segments_changed}, Colors: {colors_changed}, Width: {width_changed}). Recreating Line3DCollection.")
            edges_updated = True

            # Remove the old collection(s) if they exist
            if hasattr(self, '_edge_lines_3d') and self._edge_lines_3d:
                if self._edge_lines_3d is not None:
                    for line_coll in self._edge_lines_3d: # Iterate through the list
                        try: line_coll.remove()
                        except ValueError: pass
                        except Exception as e: logger.warning(f"{log_prefix}Error removing previous Line3DCollection: {e}")
                self._edge_lines_3d = [] # Reset to empty list

            # Create the new collection if there are segments
            if valid_segments:
                log_limit_final = min(10, len(valid_colors))
                logger.debug(f"{log_prefix}Creating Line3DCollection with {len(valid_segments)} segments. Final Colors (First {log_limit_final}): {valid_colors[:log_limit_final]}")
                try:
                    line_collection = Line3DCollection(
                        valid_segments,
                        colors=valid_colors, # Use the validated list of pre-calculated colors
                        alpha=GlobalSettings.Visualization.EDGE_OPACITY,
                        linewidths=[width_to_use] * len(valid_segments), # Use calculated width
                        zorder=1
                    )
                    self.ax.add_collection(line_collection) # type: ignore
                    self._edge_lines_3d = [line_collection] # Store as a list containing the single collection
                    # Update last rendered state AFTER successful creation
                    self._last_rendered_edge_segments = valid_segments.copy() # Store copies
                    self._last_rendered_edge_colors = valid_colors.copy()
                    self._last_rendered_edge_width = width_to_use
                except Exception as e:
                    logger.error(f"{log_prefix}Error creating Line3DCollection: {e}")
                    self._edge_lines_3d = []
                    # Clear last rendered state on error
                    self._last_rendered_edge_segments = None
                    self._last_rendered_edge_colors = None
                    self._last_rendered_edge_width = None
            else:
                logger.debug(f"{log_prefix}No valid segments to draw, ensuring _edge_lines_3d is empty.")
                self._edge_lines_3d = []
                # Update last rendered state to empty
                self._last_rendered_edge_segments = []
                self._last_rendered_edge_colors = []
                self._last_rendered_edge_width = width_to_use # Store width even if no segments
        else:
            logger.debug(f"{log_prefix}Edge data unchanged, skipping Line3DCollection recreation.")
            edges_updated = False

        logger.debug(f"{log_prefix}EXIT - Edges updated flag: {edges_updated}")
        return edges_updated

    def clear_visualization(self):
        """Clear existing visualization elements"""
        # Clear nodes
        if self.node_artists:
            self.node_artists.remove()
            self.node_artists = None

        # Clear edges
        if self.edge_artists:
            for artist in self.edge_artists:
                artist.remove()
            self.edge_artists = []

    def toggle_debug_mode(self):
        """Toggle debug mode"""
        logger.info("Entering toggle_debug_mode")  # ADDED
        self.debug_mode = not self.debug_mode  # Toggle the attribute
        logger.debug(f"Debug mode set to: {self.debug_mode}")  # ADDED
        if self.debug_mode:
            # Show grid lines and coordinate labels
            if self.gui and hasattr(self.gui, 'color_manager') and self.gui.color_manager:
                if self.debugger is not None:
                    self.debugger.show_grid_lines(color=None, alpha=1.0, zorder=100)
                else:
                    logger.warning("Debugger is not initialized. Cannot show grid lines.")
            else:
                # If color_manager is not available, use white with full opacity
                if self.debugger is not None:
                    self.debugger.show_grid_lines(color='white', alpha=1.0, zorder=100)
                else:
                    logger.warning("Debugger is not initialized. Cannot show grid lines.")
            
            # CRITICAL FIX: Call _add_coordinate_labels only if debugger is initialized
            if self.debugger:
                self.debugger._add_coordinate_labels()
                # Set visibility of coordinate labels to True
                if hasattr(self.debugger, 'debug_artists') and self.debugger.debug_artists:
                    for artist in self.debugger.debug_artists:
                        if hasattr(artist, 'set_visible'):
                            artist.set_visible(True)
            
            # CRITICAL FIX: Fit view to the entire grid, not just active nodes
            if self.gui and hasattr(self.gui, 'view_manager') and self.gui.view_manager:
                self.gui.view_manager.fit_view_to_grid()  # Use ViewManager to fit the entire grid
            
            # Force a redraw to ensure the view is updated
            if self.fig and self.fig.canvas:
                self.fig.canvas.draw_idle()
        else:
            # Clear debug visuals
            if self.debugger:
                # Set visibility of coordinate labels to False
                if hasattr(self.debugger, 'debug_artists') and self.debugger.debug_artists:
                    for artist in self.debugger.debug_artists:
                        if hasattr(artist, 'set_visible'):
                            artist.set_visible(False)
                self.debugger.clear_debug_visuals()
            self.blitting_manager.invalidate_cache()
            
            # CRITICAL: Force a redraw after clearing debug visuals
            if self.gui and hasattr(self.gui, '_safe_plot_update'):
                self.gui._safe_plot_update(force=True)
            
        logger.debug("Debug mode toggled")
        
    def create_random_pattern(self, density=0.3, region=None):
        """Create a random pattern with the given density"""
        # Clear the grid first
        if self.grid is not None:
            self.grid.clear_grid()
        else:
            logger.error("Grid is None, cannot create random pattern")
            return False
        
        # Create random pattern using controller's method
        if self.controller is not None:
            self.controller._initialize_random_state(density)
        else:
            logger.error("Controller is None, cannot create random pattern")
            return False

        # Invalidate blitting cache and force redraw
        self.blitting_manager.invalidate_cache()
        self.update_visualization()

        logger.debug(f"Created random pattern with density {density}")
        return True
    
    def inspect_node(self, node_idx):
        """Inspect a specific node"""
        if self.debugger is not None:  
            return self.debugger.inspect_node(node_idx)
    
    def inspect_coordinates(self, grid_coords=None, display_coords=None, idx=None):
        """Inspect coordinate transformations"""
        return self.inspector.inspect_all_transformations(grid_coords, display_coords, idx)

    def zoom(self, factor):
        """
        Zooms the view using the ViewManager.
        This method primarily delegates the zoom operation to the ViewManager.
        """
        logger.debug(f"GridVisualizer.zoom called with factor: {factor}")

        if hasattr(self, 'view_manager') and self.view_manager:
            # Delegate the actual zoom operation to the ViewManager
            new_zoom_factor = self.view_manager.zoom(factor)
            logger.debug(f"GridVisualizer.zoom: ViewManager returned new zoom factor: {new_zoom_factor}")
            # The ViewManager's zoom method now handles updating the state
            # and triggering the necessary redraw (_safe_plot_update).
        else:
            logger.warning("GridVisualizer.zoom: ViewManager not available, cannot perform zoom.")
            # Optionally return the current zoom factor if no change occurred
            return self._visualization_state.get('zoom_factor', 1.0)

        # Return the potentially updated zoom factor from the state
        return self._visualization_state.get('zoom_factor', 1.0)

    def _update_visual_elements_for_zoom(self, factor):
        """Update visual elements (nodes, edges) for zoom."""
        try:
            logger.info(f"GridVisualizer._update_visual_elements_for_zoom: Starting with factor: {factor}")

            # Log grid state at the start
            if self.grid and self.grid.grid_array is not None:
                active_count = np.sum(self.grid.grid_array > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD)
                logger.debug(f"GridVisualizer._update_visual_elements_for_zoom: START - Grid active nodes: {active_count}")
                logger.debug(f"GridVisualizer._update_visual_elements_for_zoom: START - Grid array ID: {id(self.grid.grid_array)}")
                if active_count > 0:
                    active_indices = np.where(self.grid.grid_array.ravel() > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD)[0]
                    logger.debug(f"GridVisualizer._update_visual_elements_for_zoom: START - First few active indices: {active_indices[:min(5, len(active_indices))]}")

            # Get current zoom factor from visualization state
            zoom_factor = self._visualization_state.get('zoom_factor', 1.0)
            logger.info(f"GridVisualizer._update_visual_elements_for_zoom: Current zoom_factor: {zoom_factor}")

            # Check if node scatter exists - FIXED: use hasattr properly
            has_node_scatter = hasattr(self, '_node_scatter') and self._node_scatter is not None
            logger.info(f"GridVisualizer._update_visual_elements_for_zoom: Has node scatter: {has_node_scatter}")

            # Check if edge lines exist - FIXED: use hasattr properly
            has_edge_lines = hasattr(self, '_edge_lines') and self._edge_lines is not None
            logger.info(f"GridVisualizer._update_visual_elements_for_zoom: Has edge lines: {has_edge_lines}")

            # Calculate node size based on zoom factor
            node_size = self._calculate_node_size(zoom_factor)
            logger.debug(f"Calculated node size for zoom: {node_size}")
            
            # Calculate outline width
            base_outline_width = GlobalSettings.Visualization.NODE_OUTLINE_WIDTH
            
            # Apply zoom-dependent amplification
            if zoom_factor < 1.0:  # Zooming in
                outline_width = base_outline_width / zoom_factor  # Make outlines thicker when zoomed in
                # Apply maximum limit
                if GlobalSettings.Visualization.NODE_OUTLINE_ZOOM_IN_LIMIT > 0:
                    outline_width = min(outline_width, base_outline_width * GlobalSettings.Visualization.NODE_OUTLINE_ZOOM_IN_LIMIT)
            else:  # Zooming out
                outline_width = base_outline_width / zoom_factor  # Make outlines thinner when zoomed out
                # Apply minimum limit
                if GlobalSettings.Visualization.NODE_OUTLINE_ZOOM_OUT_LIMIT > 0:
                    outline_width = max(outline_width, base_outline_width * GlobalSettings.Visualization.NODE_OUTLINE_ZOOM_OUT_LIMIT)
            
            # CRITICAL FIX: Debug visualization state
            logger.debug(f"ZOOM DEBUG: _update_visual_elements_for_zoom - visualization_state keys: {list(self._visualization_state.keys())}")
            
            # CRITICAL FIX: If visualization state doesn't have node coordinates, get them from the grid
            if 'x_coords' not in self._visualization_state or 'y_coords' not in self._visualization_state:
                logger.warning("GridVisualizer._update_visual_elements_for_zoom: x_coords or y_coords not found in visualization state")
                
                # Get the plot data to populate the visualization state
                plot_data = self._prepare_plot_data()
                if plot_data:
                    logger.debug(f"ZOOM DEBUG: plot_data keys: {list(plot_data.keys())}")
                    logger.debug(f"ZOOM DEBUG: plot_data x_coords length: {len(plot_data['x_coords'])}")
                    
                    self._visualization_state['x_coords'] = plot_data.get('x_coords', np.array([]))
                    self._visualization_state['y_coords'] = plot_data.get('y_coords', np.array([]))
                    if 'z_coords' in plot_data:
                        self._visualization_state['z_coords'] = plot_data['z_coords']
                    self._visualization_state['states'] = plot_data.get('states', np.array([]))
                    self._visualization_state['segments'] = plot_data.get('segments', [])
                    self._visualization_state['colors'] = plot_data.get('colors', [])
                    logger.debug(f"GridVisualizer._update_visual_elements_for_zoom: Updated visualization state with {len(self._visualization_state['x_coords'])} nodes")
                    logger.debug(f"ZOOM DEBUG: After storing plot data - visualization_state keys: {list(self._visualization_state.keys())}")
                    logger.debug(f"ZOOM DEBUG: After storing plot data - x_coords length: {len(self._visualization_state['x_coords'])}")
            
            # CRITICAL: Use the visualization state data if available
            if 'x_coords' in self._visualization_state and 'y_coords' in self._visualization_state:
                x_coords = self._visualization_state['x_coords']
                y_coords = self._visualization_state['y_coords']
                
                if x_coords is not None and y_coords is not None and len(x_coords) > 0:
                    logger.debug(f"GridVisualizer._update_visual_elements_for_zoom: Using {len(x_coords)} nodes from visualization state")
                    logger.debug(f"ZOOM DEBUG: First few x_coords: {x_coords[:min(5, len(x_coords))]}")
                    logger.debug(f"ZOOM DEBUG: First few y_coords: {y_coords[:min(5, len(y_coords))]}")
                    
                    if has_node_scatter:
                        # Update node scatter with existing data
                        if self._node_scatter is not None:
                            self._node_scatter.set_offsets(np.column_stack([x_coords, y_coords]))
                            self._node_scatter.set_sizes([node_size] * len(x_coords))
                            self._node_scatter.set_linewidths([outline_width] * len(x_coords))
                            logger.debug(f"GridVisualizer._update_visual_elements_for_zoom: Updated nodes with size={node_size}, outline_width={outline_width}")
                    else:
                        logger.warning("GridVisualizer._update_visual_elements_for_zoom: No node scatter available for update")
                        # CRITICAL FIX: If node scatter doesn't exist, create it
                        self._draw_nodes_2d(
                            x_coords, 
                            y_coords, 
                            self._visualization_state.get('states', np.ones(len(x_coords))), 
                            indices=None,  # Provide appropriate indices if available
                            nodes_to_highlight=None  # Optional, adjust as needed
                        )
                        logger.debug("GridVisualizer._update_visual_elements_for_zoom: Created new node scatter")
                else:
                    logger.warning("GridVisualizer._update_visual_elements_for_zoom: x_coords or y_coords empty in visualization state")
                    logger.debug(f"ZOOM DEBUG: x_coords: {x_coords}")
                    logger.debug(f"ZOOM DEBUG: y_coords: {y_coords}")
            else:
                logger.warning("GridVisualizer._update_visual_elements_for_zoom: x_coords or y_coords not found in visualization state")
                logger.debug(f"ZOOM DEBUG: visualization_state keys: {list(self._visualization_state.keys())}")
            
            # Update edge width based on zoom
            base_width = GlobalSettings.Visualization.EDGE_WIDTH
            if zoom_factor < 1.0:  # Zooming in
                width = base_width / zoom_factor
                if GlobalSettings.Visualization.EDGE_THICKNESS_ZOOM_IN_LIMIT > 0:
                    width = min(width, base_width * GlobalSettings.Visualization.EDGE_THICKNESS_ZOOM_IN_LIMIT)
            else:  # Zooming out
                width = base_width / zoom_factor
                if GlobalSettings.Visualization.EDGE_THICKNESS_ZOOM_OUT_LIMIT > 0:
                    width = max(width, base_width * GlobalSettings.Visualization.EDGE_THICKNESS_ZOOM_OUT_LIMIT)
            
            # Update edge lines
            if has_edge_lines:
                if self._edge_lines is not None:
                    self._edge_lines.set_linewidth(width)
                    logger.debug(f"Updated 2D edges with width={width}")
            else:
                logger.warning("No edge lines available for update")

            # Force a redraw
            self.ax.figure.canvas.draw_idle()
            logger.info("GridVisualizer._update_visual_elements_for_zoom: Completed")

        except Exception as e:
            logger.error(f"Error updating visual elements for zoom: {e}")
            logger.error(traceback.format_exc())
             
    def _on_node_click(self, event):
        """Handle mouse clicks on nodes (for selection)."""
        if event.inaxes != self.ax:
            return  # Not a click on our axes

        # Convert display coordinates to grid coordinates
        grid_coords = self.coord_system.display_to_grid((event.xdata, event.ydata))
        if len(grid_coords) == 2:
            grid_x, grid_y = grid_coords
        elif len(grid_coords) == 3:
            grid_x, grid_y, _ = grid_coords  # Ignore the third coordinate for 2D
        grid_coords = (int(round(grid_x)), int(round(grid_y)))

        # Find the nearest node (within a tolerance)
        if self.grid.dimension_type == Dimension.THREE_D:
            tolerance = self.coord_system.scale_factor * 0.5 # Example tolerance
        else:
            tolerance = self.coord_system.scale_factor * 0.5 # Example tolerance
        
        nearest_node_idx = None
        min_dist_sq = float('inf')

        for node_idx in self.grid.get_node_positions():
            node_coords = _unravel_index(node_idx, self.grid.dimensions)
            
            if self.grid.dimension_type == Dimension.THREE_D:
                if len(node_coords) != 3:
                    continue
                dist_sq = (node_coords[0] - grid_coords[0])**2 + (node_coords[1] - grid_coords[1])**2 + (node_coords[2] - 0)**2 # Assuming z=0 for click
            else:
                if len(node_coords) != 2:
                    continue
                dist_sq = (node_coords[0] - grid_coords[0])**2 + (node_coords[1] - grid_coords[1])**2

            if dist_sq < min_dist_sq and dist_sq <= tolerance**2:
                min_dist_sq = dist_sq
                nearest_node_idx = node_idx

        if nearest_node_idx is not None:
            # Toggle selection state
            if nearest_node_idx in self.selected_nodes:
                self.selected_nodes.remove(nearest_node_idx)
                logger.debug(f"Node deselected: {nearest_node_idx}")
            else:
                self.selected_nodes.add(nearest_node_idx)
                logger.debug(f"Node selected: {nearest_node_idx}")

            # Update visualization to reflect selection
            self.update_visualization()


####################################################################################################



    class BlittingManager:
        """Manages the blitting cache and blitting status."""

        def __init__(self):
            self.enabled = GlobalSettings.ENABLE_BLITTING
            self.background = None

        def set_enabled(self, enabled: bool):
            """Set the blitting status."""
            self.enabled = enabled
            GlobalSettings.ENABLE_BLITTING = enabled  # Update global setting
            self.invalidate_cache()

        def invalidate_cache(self):
            """Invalidate the blitting cache."""
            # --- ADDED Logging ---
            logger = logging.getLogger(__name__) # Get logger instance
            current_frame = inspect.currentframe()
            caller_frame = current_frame.f_back if current_frame is not None else None
            caller_func = caller_frame.f_code.co_name if caller_frame is not None else "Unknown"
            caller_line = caller_frame.f_lineno if caller_frame is not None else "Unknown"
            logger.debug(f"BlittingManager.invalidate_cache() called by {caller_func} at line {caller_line}. Setting background to None.")
            # ---
            self.background = None

        def is_valid(self) -> bool:
            """Check if the blitting cache is valid."""
            # --- ADDED Logging ---
            # logger = logging.getLogger(__name__) # Get logger instance
            # is_valid_result = self.enabled and self.background is not None
            # logger.debug(f"BlittingManager.is_valid() check: enabled={self.enabled}, background_is_None={self.background is None} -> Result={is_valid_result}")
            # --- (Reduce noise for now)
            return self.enabled and self.background is not None

class ControlPanelUI:
    
    def __init__(self, parent_frame: tk.Frame, gui_reference: 'SimulationGUI', initial_preset_obj: Optional[GridPreset] = None): # ADDED initial_preset_obj
        """
        Initialize the ControlPanelUI.
        (Round 14: Use initial_preset_obj for slider init)
        """
        logger.info(f"--- ControlPanelUI __init__ called (Instance ID: {id(self)}) ---")
        self.parent_frame = parent_frame
        self.gui = gui_reference
        self.widgets: Dict[str, tk.Widget] = {}
        logger.debug(f"ControlPanelUI.__init__: Initialized self.widgets as empty dict (ID: {id(self.widgets)}) for Instance ID: {id(self)}")

        # --- Store initial preset object ---
        self.initial_preset_obj = initial_preset_obj
        # ---

        # --- Initialize Tkinter Variables needed by Control Panel Widgets ---
        # Ensure required variables exist on the gui object
        if not hasattr(self.gui, 'preset_var'): self.gui.preset_var = tk.StringVar(value="")
        if not hasattr(self.gui, 'rule_type_var'): self.gui.rule_type_var = tk.StringVar()
        if not hasattr(self.gui, 'rule_instance_var'): self.gui.rule_instance_var = tk.StringVar()
        if not hasattr(self.gui, 'neighborhood_var'): self.gui.neighborhood_var = tk.StringVar(value=self.gui.neighborhood_type.name)
        if not hasattr(self.gui, 'dimension_var'): self.gui.dimension_var = tk.StringVar(value=self.gui.dimension_type.name)
        if not hasattr(self.gui, 'new_grid_size_var'): self.gui.new_grid_size_var = tk.StringVar(value=",".join(map(str, self.gui.dimensions)))
        if not hasattr(self.gui, 'initial_conditions_var'): self.gui.initial_conditions_var = tk.StringVar(value="Random")
        if not hasattr(self.gui, 'enable_tiebreakers_var'): self.gui.enable_tiebreakers_var = tk.BooleanVar(value=GlobalSettings.ENABLE_TIEBREAKERS)
        if not hasattr(self.gui, 'tiebreaker_type_var'): self.gui.tiebreaker_type_var = tk.StringVar(value='RANDOM')
        if not hasattr(self.gui, 'grid_boundary_var'): self.gui.grid_boundary_var = tk.StringVar(value='bounded')
        if not hasattr(self.gui, 'run_continuously'): self.gui.run_continuously = tk.BooleanVar(value=True)
        if not hasattr(self.gui, 'num_steps_var'): self.gui.num_steps_var = tk.StringVar(value=str(GlobalSettings.Simulation.NUM_STEPS))
        if not hasattr(self.gui, 'stability_detection_var'): self.gui.stability_detection_var = tk.BooleanVar(value=False)
        # These are likely specific to ControlPanelUI or initialized reliably elsewhere in GUI
        self.highlight_var = tk.BooleanVar(value=True)
        self.blitting_var = tk.BooleanVar(value=GlobalSettings.ENABLE_BLITTING)
        self.show_coordinates_var = tk.BooleanVar(value=False)
        self.periodic_reporting_var = tk.BooleanVar(value=LogSettings.Performance.ENABLE_PERIODIC_REPORTING)
        self.deep_profiling_var = tk.BooleanVar(value=LogSettings.Performance.ENABLE_DEEP_PROFILING)
        self.reporting_interval_var = tk.StringVar(value=str(LogSettings.Performance.REPORTING_INTERVAL))
        self.detailed_logging_var = tk.BooleanVar(value=LogSettings.Performance.ENABLE_DETAILED_LOGGING)
        self.rotation_enabled_var = tk.BooleanVar(value=False)
        self.common_sizes_map: Dict[str, str] = {}
        # REMOVED parallel_var initialization
        # ---

        # --- Create the scrollable frame ---
        self.scrollable_frame = ScrollableFrame(parent_frame, self.gui, bg='#404040')
        self.scrollable_frame.pack(side=tk.TOP, fill=tk.BOTH, expand=True)
        self.inner_frame = self.scrollable_frame.scrolled_frame
        logger.debug(f"ControlPanelUI: ScrollableFrame created and packed.")
        # ---

        # --- Create all control sections ---
        self._setup_controls_content(self.inner_frame, self.widgets)
        # ---

        logger.info(f"ControlPanelUI.__init__: AFTER _setup_controls_content, self.widgets keys: {list(self.widgets.keys())}")

        # --- Create _widgets_copy AFTER setup ---
        self._widgets_copy = self.widgets.copy()
        logger.info(f"ControlPanelUI.__init__: Created _widgets_copy with {len(self._widgets_copy)} items.")
        # ---

        # --- Call _post_setup_controls directly ---
        self._post_setup_controls()
        logger.debug(f"ControlPanelUI.__init__: Called _post_setup_controls directly.")
        # ---

        logger.info(f"ControlPanelUI initialized successfully (Instance ID: {id(self)}).")
   
    def _pack_control_widgets(self, parent_frame, widgets: Dict[str, tk.Widget]):
        """Pack all control widgets into the scrollable frame"""
        # Pack control sections
        widgets['control_section'].pack(in_=parent_frame, fill=tk.X, padx=5, pady=5)
        widgets['status_section'].pack(in_=parent_frame, fill=tk.X, padx=5, pady=5)
        widgets['viz_section'].pack(in_=parent_frame, fill=tk.X, padx=5, pady=5)
        widgets['rule_section'].pack(in_=parent_frame, fill=tk.X, padx=5, pady=5)
        widgets['density_section'].pack(in_=parent_frame, fill=tk.X, padx=5, pady=5)
        widgets['initial_conditions_section'].pack(in_=parent_frame, fill=tk.X, padx=5, pady=5)
        widgets['io_section'].pack(in_=parent_frame, fill=tk.X, padx=5, pady=5)
        widgets['neighborhood_section'].pack(in_=parent_frame, fill=tk.X, padx=5, pady=5)
        widgets['dimension_section'].pack(fill=tk.X, padx=5, pady=5)
        widgets['grid_size_section'].pack(fill=tk.X, padx=5, pady=5)
        widgets['speed_section'].pack(fill=tk.X, padx=5, pady=5)
        widgets['spacing_section'].pack(fill=tk.X, padx=5, pady=5)
        widgets['rotation_section'].pack(fill=tk.X, padx=5, pady=5)
        widgets['scroll_speed_section'].pack(fill=tk.X, padx=5, pady=5)
        widgets['color_settings_section'].pack(fill=tk.X, padx=5, pady=5)

        # Pack labels
        widgets['step_label'].pack(in_=parent_frame, pady=2)
        widgets['perf_label'].pack(in_=parent_frame, pady=2)
        widgets['grid_size_label'].pack(in_=parent_frame, pady=2)

        # Pack checkbutton
        widgets['highlight_checkbox'].pack(in_=parent_frame, pady=2)

        # Pack buttons
        widgets['start_button'].pack(in_=parent_frame, pady=2)
        widgets['pause_button'].pack(in_=parent_frame, pady=2)
        widgets['step_button'].pack(in_=parent_frame, pady=2)
        widgets['reset_button'].pack(in_=parent_frame, pady=2)
        widgets['edit_rule_button'].pack(in_=parent_frame, fill=tk.X)
        widgets['zoom_in_button'].pack(in_=parent_frame, pady=2)
        widgets['zoom_out_button'].pack(in_=parent_frame, pady=2)
        widgets['save_button'].pack(in_=parent_frame, pady=2)
        widgets['load_button'].pack(in_=parent_frame, pady=2)

        # Pack selectors
        widgets['initial_conditions_selector'].pack(in_=parent_frame, fill=tk.X, padx=5, pady=2)
        widgets['rule_type_selector'].pack(in_=parent_frame, fill=tk.X, padx=5, pady=2)
        widgets['rule_instance_selector'].pack(in_=parent_frame, fill=tk.X, padx=5, pady=2)

        # Pack scales
        widgets['grid_size_scale'].pack(in_=parent_frame, fill=tk.X, padx=5, pady=2)
        widgets['speed_scale'].pack(in_=parent_frame, fill=tk.X, padx=5, pady=2)
        widgets['spacing_scale'].pack(in_=parent_frame, fill=tk.X, padx=5, pady=2)
        widgets['node_density_scale'].pack(in_=parent_frame, fill=tk.X, padx=5, pady=2)
        widgets['edge_density_scale'].pack(in_=parent_frame, fill=tk.X, padx=5, pady=2)
        widgets['scroll_speed_scale'].pack(in_=parent_frame, fill=tk.X, padx=5, pady=2)
            
    def _setup_controls_content(self, parent_frame, widgets_dict: Dict[str, tk.Widget]): # Added widgets_dict argument
        """Setup all control panel content within the provided parent frame.
           (Round 13: Added Analytics section)
           """
        logger.info(f"--- ControlPanelUI _setup_controls_content called (Parent Frame ID: {id(parent_frame)}) ---") # Log call

        # --- Pass widgets_dict to all creation methods ---
        self._create_grid_preset_management_section(parent_frame, widgets_dict)
        self._create_rule_selection_section(parent_frame, widgets_dict)
        self._create_neighborhood_section(parent_frame, widgets_dict)
        self._create_dimension_section(parent_frame, widgets_dict)
        self._create_grid_size_section(parent_frame, widgets_dict)
        self._create_initial_conditions_section(parent_frame, widgets_dict)
        self._create_tiebreaker_section(parent_frame, widgets_dict)
        self._create_status_section(parent_frame, widgets_dict)
        self._create_control_section(parent_frame, widgets_dict)
        self._create_step_control_section(parent_frame, widgets_dict)
        self._create_visualization_section(parent_frame, widgets_dict)
        self._create_view_control_section(parent_frame, widgets_dict)
        self._create_density_section(parent_frame, widgets_dict)
        self._create_node_size_section(parent_frame, widgets_dict)
        self._create_spacing_section(parent_frame, widgets_dict)
        self._create_color_settings_section(parent_frame, widgets_dict)
        self._create_analytics_section(parent_frame, widgets_dict)
        self._create_save_load_section(parent_frame, widgets_dict)
        self._create_performance_section(parent_frame, widgets_dict)
        self._create_debug_section(parent_frame, widgets_dict)
        # --- End passing widgets_dict ---

        logger.debug("Control panel content setup complete.")

    def _create_grid_preset_management_section(self, parent_frame, widgets_dict: Dict[str, tk.Widget]): # Added widgets_dict argument
        """Create grid preset selection section"""
        preset_section = tk.LabelFrame(parent_frame, text="Grid Presets", bg='#404040', fg='white')
        preset_section.pack(fill=tk.X, padx=5, pady=5)
        widgets_dict['preset_section'] = preset_section # Store the section frame

        preset_names = list(self.gui.grid_preset_manager.presets.keys())
        sorted_preset_names = sorted(preset_names)
        display_names = ["None"] + sorted_preset_names

        preset_selector = tk.OptionMenu(
            preset_section,
            self.gui.preset_var,
            *display_names,
            command=lambda value: self.gui._on_preset_selected(self.gui.preset_var.get())
        )
        preset_selector.pack(fill=tk.X, padx=5, pady=2)
        # --- Store the OptionMenu widget with the correct key ---
        widgets_dict['preset_selector'] = preset_selector # Use passed dictionary
        # --- ADDED: Log after storing ---
        logger.debug(f"_create_grid_preset_management_section: Stored widget '{preset_selector}' under key 'preset_selector'. widgets_dict now contains: {list(widgets_dict.keys())}")
        # ---

        manage_preset_button = tk.Button(
            preset_section,
            text="Manage Presets",
            command=self.gui._open_grid_preset_management_modal
        )
        manage_preset_button.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['manage_preset_button'] = manage_preset_button # Use passed dictionary

    def _create_rule_selection_section(self, parent_frame, widgets_dict: Dict[str, tk.Widget]): # Added widgets_dict argument
        """Create rule selection section"""
        # CORRECTED: Use parent_frame instead of self.control_panel
        rule_section = tk.LabelFrame(parent_frame, text="Rule Selection", bg='#404040', fg='white')
        rule_section.pack(fill=tk.X, padx=5, pady=5)
        widgets_dict['rule_section'] = rule_section # Store the section frame

        # --- MODIFIED: Access initial rule name from controller ---
        initial_rule_name = self.gui.controller.rule_name if self.gui.controller else GlobalSettings.Defaults.DEFAULT_RULE
        # --- END MODIFIED ---
        initial_rule_category = RuleLibrary.get_rule_category(initial_rule_name)

        # Normalize, Deduplicate, and Sort Categories
        all_categories_dict = RuleLibrary.get_rule_categories()
        all_category_names = list(all_categories_dict.keys())  # Extract keys from all_categories_dict
        normalized_categories = [cat.strip().title() for cat in all_category_names]
        unique_sorted_categories = sorted(list(set(normalized_categories)))
        if "Favorites" in unique_sorted_categories:
            unique_sorted_categories.remove("Favorites")
            unique_sorted_categories.insert(0, "Favorites")
        logger.debug(f"Final sorted categories for dropdown: {unique_sorted_categories}")

        # Normalize initial category for setting the variable
        normalized_initial_category = initial_rule_category.strip().title()
        # self.gui.rule_type_var is initialized in __init__

        # Ensure the initial category is valid before setting
        if normalized_initial_category not in unique_sorted_categories and unique_sorted_categories:
            logger.warning(f"Initial category '{normalized_initial_category}' not found, defaulting to '{unique_sorted_categories[0]}'")
            normalized_initial_category = unique_sorted_categories[0]
        elif not unique_sorted_categories:
             logger.error("No categories found for rule type selector!")
             normalized_initial_category = ""
        self.gui.rule_type_var.set(normalized_initial_category)

        # Create the OptionMenu correctly
        if unique_sorted_categories:
            rule_type_selector = tk.OptionMenu(
                rule_section,
                self.gui.rule_type_var,
                *unique_sorted_categories,
                # CORRECTED: Pass the selected value using .get()
                command=lambda value: self.gui._on_rule_type_change(self.gui.rule_type_var.get())
            )
        else:
            rule_type_selector = tk.OptionMenu(rule_section, self.gui.rule_type_var, "(No Categories)")
            rule_type_selector.config(state=tk.DISABLED)
        rule_type_selector.configure(width=25)
        rule_type_selector['menu'].configure(font=('TkDefaultFont', 10))
        rule_type_selector.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['rule_type_selector'] = rule_type_selector # Store the type selector

        # Rule instance selector
        # self.gui.rule_instance_var is initialized in __init__
        initial_category_for_instances = self.gui.rule_type_var.get()
        initial_available_rules = sorted(list(dict.fromkeys(RuleLibrary.get_rules_in_category(initial_category_for_instances))))

        if initial_available_rules:
            rule_instance_selector = tk.OptionMenu(
                rule_section, self.gui.rule_instance_var,
                *initial_available_rules,
                # CORRECTED: Pass the selected value using .get()
                command=lambda value: self.gui._on_rule_instance_change(self.gui.rule_instance_var.get())
            )
            if initial_rule_name not in initial_available_rules:
                 self.gui.rule_instance_var.set(initial_available_rules[0])
            else:
                 self.gui.rule_instance_var.set(initial_rule_name) # Set to the actual initial rule
        else:
            rule_instance_selector = tk.OptionMenu(rule_section, self.gui.rule_instance_var, "(No rules)")
            self.gui.rule_instance_var.set("(No rules)")
            rule_instance_selector.config(state=tk.DISABLED)
        rule_instance_selector.configure(width=25)
        rule_instance_selector['menu'].configure(font=('TkDefaultFont', 10))
        rule_instance_selector.pack(fill=tk.X, padx=5, pady=2)
        # --- CORRECTED: Store the instance selector in widgets_dict ---
        widgets_dict['rule_instance_selector'] = rule_instance_selector
        # --- END CORRECTION ---

        # Add parameter editing button
        param_button_frame = tk.Frame(rule_section, bg='#404040')
        param_button_frame.pack(fill=tk.X, padx=5, pady=5)

        def open_rule_editor():
            current_rule = self.gui.rule_instance_var.get()
            if current_rule and current_rule != "(No rules)":
                self.gui.create_rule_editor_window(current_rule) # Call GUI method
            else:
                messagebox.showwarning("No Rule Selected", "Please select a rule instance before editing.")

        edit_rule_button = tk.Button(param_button_frame, text="Edit Rule", command=open_rule_editor)
        edit_rule_button.pack(fill=tk.X)
        widgets_dict['edit_rule_button'] = edit_rule_button

    def _create_neighborhood_section(self, parent_frame, widgets_dict: Dict[str, tk.Widget]): # Added widgets_dict argument
        """Create neighborhood selection section"""
        # CORRECTED: Use parent_frame instead of self.control_panel
        neighborhood_section = tk.LabelFrame(parent_frame, text="Neighborhood Type", bg='#404040', fg='white')
        neighborhood_section.pack(fill=tk.X, padx=5, pady=5)
        widgets_dict['neighborhood_section'] = neighborhood_section

        # Get valid neighborhood types for current dimension
        valid_neighborhoods = self.gui._get_valid_neighborhoods() # Call GUI helper

        # self.gui.neighborhood_var is initialized in __init__

        # Create the OptionMenu
        neighborhood_selector = tk.OptionMenu(
            neighborhood_section,
            self.gui.neighborhood_var,
            *valid_neighborhoods,
            # CORRECTED: Pass the selected value using .get()
            command=lambda value: self.gui._on_neighborhood_change(self.gui.neighborhood_var.get())
        )
        neighborhood_selector.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['neighborhood_selector'] = neighborhood_selector

    def _create_dimension_section(self, parent_frame, widgets_dict: Dict[str, tk.Widget]): # Added widgets_dict argument
        """Create dimension selection section"""
        # CORRECTED: Use parent_frame instead of self.control_panel
        dimension_section = tk.LabelFrame(parent_frame, text="Dimension", bg='#404040', fg='white')
        dimension_section.pack(fill=tk.X, padx=5, pady=5)
        widgets_dict['dimension_section'] = dimension_section

        # self.gui.dimension_var is initialized in __init__

        # Get unique dimension names without duplicates
        dimension_names = sorted(list(set(dim.name for dim in Dimension)))

        # Create the OptionMenu
        dimension_selector = tk.OptionMenu(
            dimension_section,
            self.gui.dimension_var,
            *dimension_names,
            # CORRECTED: Pass the selected value using .get()
            command=lambda value: self.gui._on_dimension_change(self.gui.dimension_var.get())
        )
        dimension_selector.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['dimension_selector'] = dimension_selector

    def _create_grid_size_section(self, parent_frame: tk.Frame, widgets_dict: Dict[str, tk.Widget]): # Added widgets_dict argument
        """Create grid size control section with Combobox and Apply button."""
        # CORRECTED: Use parent_frame instead of self.control_panel
        grid_size_section = tk.LabelFrame(parent_frame, text="Grid Size", bg='#404040', fg='white')
        grid_size_section.pack(fill=tk.X, padx=5, pady=5)
        widgets_dict['grid_size_section'] = grid_size_section

        # Frame for new size input
        new_size_frame = tk.Frame(grid_size_section, bg='#404040')
        new_size_frame.pack(fill=tk.X, padx=5, pady=2)

        new_size_label = tk.Label(new_size_frame, text="Select Size:", bg='#404040', fg='white')
        new_size_label.pack(side=tk.LEFT, padx=(0, 5))
        widgets_dict['new_grid_size_label'] = new_size_label

        # Define common sizes
        common_sizes_display = [
            "5x5", "10x10", "20x20", "30x30", "50x50", "80x80", "100x100", "150x150",
            "200x200", "300x300", "400x400", "500x500", "1000x1000", "Custom..."
        ]
        common_sizes_internal = [
            "5,5", "10,10", "20,20", "30,30", "50,50", "80,80", "100,100", "150,150",
            "200,200", "300,300", "400,400", "500,500", "1000,1000", "Custom..."
        ]
        self.common_sizes_map = dict(zip(common_sizes_display, common_sizes_internal))

        # Initialize StringVar - find initial value based on current dimensions from GUI
        current_dims_str_internal = ",".join(map(str, self.gui.dimensions))
        initial_display_value = "Custom..." # Default if not found
        for display, internal in self.common_sizes_map.items(): # Use self.common_sizes_map
            if internal == current_dims_str_internal:
                initial_display_value = display
                break

        # Store the internal format (e.g., "50,50") in the GUI's variable
        self.gui.new_grid_size_var = tk.StringVar(value=current_dims_str_internal)

        # Create Combobox
        grid_size_combobox = ttk.Combobox(
            new_size_frame,
            textvariable=self.gui.new_grid_size_var, # Link to the variable holding internal format
            values=common_sizes_display,
            state="readonly", # User selects or chooses Custom
            width=8 # Adjusted width
        )
        # Set the *display* text initially
        grid_size_combobox.set(initial_display_value if initial_display_value != "Custom..." else current_dims_str_internal)

        grid_size_combobox.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=5)
        widgets_dict['grid_size_combobox'] = grid_size_combobox

        # Bind selection event to GUI method
        grid_size_combobox.bind("<<ComboboxSelected>>", self.gui._on_grid_size_selected)

        # Apply Button
        apply_size_button = tk.Button(new_size_frame, text="Apply", command=self.gui._apply_new_grid_size) # Callback to GUI
        apply_size_button.pack(side=tk.LEFT, padx=5)
        widgets_dict['apply_grid_size_button'] = apply_size_button

        logger.debug("Created grid size section with Combobox and Apply button.")

    def _create_initial_conditions_section(self, parent_frame: tk.Frame, widgets_dict: Dict[str, tk.Widget]): # Added widgets_dict argument
        """Create initial conditions selection section"""
        initial_conditions_section = tk.LabelFrame(parent_frame, text="Initial Conditions", bg='#404040', fg='white')
        initial_conditions_section.pack(fill=tk.X, padx=5, pady=5)
        widgets_dict['initial_conditions_section'] = initial_conditions_section

        manager = InitialConditionManager.get_instance()
        condition_names = manager.get_all_names() # Get names from manager
        if not condition_names: condition_names = ["(None)"] # Add placeholder if empty

        current_var_value = self.gui.initial_conditions_var.get()
        logger.debug(f"ControlPanelUI._create_initial_conditions_section: Value of self.gui.initial_conditions_var BEFORE OptionMenu: '{current_var_value}'")

        # --- MODIFIED: Prevent resetting if value is "Pattern" ---
        # Ensure the variable's current value is valid *unless* it's "Pattern"
        if current_var_value not in condition_names and current_var_value != "Pattern":
            logger.warning(f"Initial condition '{current_var_value}' from GUI var not in options {condition_names}. Resetting var to '{condition_names[0]}'.")
            self.gui.initial_conditions_var.set(condition_names[0])
        elif current_var_value == "Pattern":
            logger.debug(f"Initial condition is 'Pattern' (likely from preset), keeping it but dropdown will show first valid option.")
            # Keep the internal variable as "Pattern", but set the *display* of the OptionMenu
            # to the first available user-selectable option initially. The internal var retains "Pattern".
            # We need a temporary variable for the OptionMenu display in this specific case.
            display_var = tk.StringVar(value=condition_names[0])
            initial_conditions_selector = tk.OptionMenu(
                initial_conditions_section,
                display_var, # Use display var for OptionMenu
                *condition_names,
                # Command still uses the *main* variable, which might still be "Pattern"
                command=lambda value: self.gui._on_initial_conditions_change(self.gui.initial_conditions_var.get())
            )
        else:
            # Value is valid and not "Pattern", create OptionMenu normally
            initial_conditions_selector = tk.OptionMenu(
                initial_conditions_section,
                self.gui.initial_conditions_var, # Use the main variable
                *condition_names,
                command=lambda value: self.gui._on_initial_conditions_change(self.gui.initial_conditions_var.get())
            )
        # --- END MODIFIED ---

        initial_conditions_selector.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['initial_conditions_selector'] = initial_conditions_selector

    def _create_tiebreaker_section(self, parent_frame: tk.Frame, widgets_dict: Dict[str, tk.Widget]): # Added widgets_dict argument
        """Create tiebreaker settings section"""
        tiebreaker_section = tk.LabelFrame(parent_frame, text="Tiebreaker Settings", bg='#404040', fg='white')
        tiebreaker_section.pack(fill=tk.X, padx=5, pady=5)
        widgets_dict['tiebreaker_section'] = tiebreaker_section

        # Tiebreaker enable checkbox
        # self.gui.enable_tiebreakers_var is initialized in __init__
        enable_tiebreakers_checkbox = tk.Checkbutton(
            tiebreaker_section,
            text="Enable Tiebreakers",
            variable=self.gui.enable_tiebreakers_var,
            bg='#404040',
            fg='white',
            selectcolor='#404040',
            command=self.gui._on_enable_tiebreakers_change # Callback to GUI
        )
        enable_tiebreakers_checkbox.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['enable_tiebreakers_checkbox'] = enable_tiebreakers_checkbox

        # Tiebreaker type selector
        # Access rule via self.gui.controller
        initial_tiebreaker = 'RANDOM' # Default
        if self.gui.controller and self.gui.controller.rule:
            initial_tiebreaker = self.gui.controller.rule.get_param('tiebreaker_type', 'RANDOM')
        # self.gui.tiebreaker_type_var is initialized in __init__
        tiebreaker_type_selector = tk.OptionMenu(
            tiebreaker_section,
            self.gui.tiebreaker_type_var,
            *TieBreaker.__members__.keys(),
            # CORRECTED: Pass the selected value using .get()
            command=lambda value=self.gui.tiebreaker_type_var.get(): self.gui._on_tiebreaker_type_change(value)
        )
        tiebreaker_type_selector.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['tiebreaker_type_selector'] = tiebreaker_type_selector

    def _create_control_section(self, parent_frame: tk.Frame, widgets_dict: Dict[str, tk.Widget]): # Added widgets_dict argument
        """Create main control buttons section"""
        control_section = tk.LabelFrame(parent_frame, text="Controls", bg='#404040', fg='white')
        control_section.pack(fill=tk.X, padx=5, pady=5)
        widgets_dict['control_section'] = control_section

        # Grid boundary dropdown
        boundary_label = tk.Label(control_section, text="Grid Boundary:", bg='#404040', fg='white')
        boundary_label.pack(fill=tk.X, padx=5, pady=2)

        boundary_options = ["bounded", "wrap"]
        default_boundary = 'bounded'
        if hasattr(self.gui, 'controller') and self.gui.controller and hasattr(self.gui.controller, 'rule') and self.gui.controller.rule:
            default_boundary = self.gui.controller.rule.get_param('grid_boundary', 'bounded')

        if not hasattr(self.gui, 'grid_boundary_var'):
            self.gui.grid_boundary_var = tk.StringVar(value=default_boundary)

        boundary_menu = tk.OptionMenu(
            control_section,
            self.gui.grid_boundary_var,
            *boundary_options,
            command=lambda value=self.gui.grid_boundary_var.get(): self.gui._on_grid_boundary_change(self.gui.grid_boundary_var.get())
        )
        boundary_menu.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['grid_boundary_menu'] = boundary_menu

        button_width = 15
        # Button configurations
        button_configs = [
            ("Start", self.gui.toggle_simulation),
            ("Stop", self.gui._stop_simulation),
            ("Step", self.gui.step_button_clicked),
            ("Reset", self.gui.reset_simulation),
            ("Clear", self.gui.clear_grid)
        ]

        for text, command in button_configs:
            # --- MODIFIED: Added disabledforeground='black' ---
            btn = tk.Button(control_section, text=text, width=button_width, command=command, disabledforeground='black')
            # --- END MODIFIED ---
            btn.pack(fill=tk.X, padx=5, pady=2)
            button_key = text.lower().replace(" ", "_") + "_button"
            widgets_dict[button_key] = btn

        # Speed Slider
        speed_label = tk.Label(control_section, text="Simulation Speed:", bg='#404040', fg='white')
        speed_label.pack(fill=tk.X, padx=5, pady=(10, 2)) # Add some top padding
        widgets_dict['speed_label'] = speed_label

        initial_delay = 50 # Default step_delay if not set elsewhere
        if hasattr(self.gui, 'step_delay'):
            initial_delay = self.gui.step_delay
        initial_speed = max(10, min(1000, (1001 - initial_delay) / 0.99))

        speed_scale = tk.Scale(
            control_section,
            from_=10, # Corresponds to ~991ms delay (fastest practical)
            to=1000, # Corresponds to ~11ms delay (slowest)
            resolution=10, # Adjust resolution as needed
            orient=tk.HORIZONTAL,
            label="Speed (Faster ->)", # Add label to slider
            troughcolor='#555555', # Darker trough
            sliderrelief=tk.RAISED,
            highlightthickness=0,
            bg='#404040', fg='white',
            command=self.gui._on_speed_change # Callback to GUI method in SimulationGUI
        )
        speed_scale.set(initial_speed) # Set initial value
        speed_scale.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['speed_scale'] = speed_scale
        logger.debug("Added speed slider to control section.")

    def _create_step_control_section(self, parent_frame: tk.Frame, widgets_dict: Dict[str, tk.Widget]): # Added widgets_dict argument
        """Create step control section"""
        # CORRECTED: Use parent_frame instead of self.control_panel
        step_section = tk.LabelFrame(parent_frame, text="Step Control", bg='#404040', fg='white')
        step_section.pack(fill=tk.X, padx=5, pady=5)
        widgets_dict['step_section'] = step_section

        # Run continuously checkbox
        # self.gui.run_continuously is initialized in __init__
        run_continuously_check = tk.Checkbutton(
            step_section,
            text="Run Continuously",
            variable=self.gui.run_continuously,
            bg='#404040',
            fg='white',
            selectcolor='#404040',
            command=self.update_num_steps_entry_state # Callback to own method
        )
        run_continuously_check.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['run_continuously_check'] = run_continuously_check

        # Number of steps entry
        steps_label = tk.Label(step_section, text="     Number of Steps:", bg='#404040', fg='white')
        steps_label.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['steps_label'] = steps_label

        # self.gui.num_steps_var is initialized in __init__
        num_steps_entry = tk.Entry(
            step_section,
            textvariable=self.gui.num_steps_var,
            state=tk.DISABLED if self.gui.run_continuously.get() else tk.NORMAL
        )
        num_steps_entry.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['num_steps_entry'] = num_steps_entry

        # Stability Detection Checkbox
        # self.gui.stability_detection_var is initialized in __init__
        stability_detection_checkbox = tk.Checkbutton(
            step_section,
            text="Detect Stability",
            variable=self.gui.stability_detection_var,
            bg='#404040',
            fg='white',
            selectcolor='#404040',
            command=self.gui._on_stability_detection_toggle # Callback to GUI
        )
        stability_detection_checkbox.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['stability_detection_checkbox'] = stability_detection_checkbox

        # Bind the run_continuously variable change to the update method
        self.gui.run_continuously.trace_add("write", lambda *args: self.update_num_steps_entry_state())

    def _create_status_section(self, parent_frame: tk.Frame, widgets_dict: Dict[str, tk.Widget]): # Added widgets_dict argument
        """Create status display section, including buffering status and FPS.
           """
        # CORRECTED: Use parent_frame instead of self.control_panel
        status_section = tk.LabelFrame(parent_frame, text="Status", bg='#404040', fg='white')
        status_section.pack(fill=tk.X, padx=5, pady=5)
        widgets_dict['status_section'] = status_section

        # Step Label
        step_label = tk.Label(status_section, text="Step: 0", bg='#404040', fg='white')
        step_label.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['step_label'] = step_label # Store label

        # Grid Size Label
        grid_size_label = tk.Label(status_section, text=f"Size: {'x'.join(map(str, self.gui.dimensions))}", bg='#404040', fg='white')
        grid_size_label.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['grid_size_label'] = grid_size_label # Store label

        # Buffering Status Label
        buffering_status_label = tk.Label(status_section, text="", font=("TkDefaultFont", 9), bg='#404040', fg='#FFA500') # Orange text
        buffering_status_label.pack(fill=tk.X, padx=5, pady=(2, 0)) # Reduced bottom padding
        widgets_dict['buffering_status_label'] = buffering_status_label

        # --- ADDED: FPS Label ---
        fps_label = tk.Label(
            status_section,
            textvariable=self.gui.fps_display_var, # Link to GUI variable
            font=("TkDefaultFont", 9),
            bg='#404040',
            fg='lightgrey' # Use a slightly dimmer color for FPS
        )
        fps_label.pack(fill=tk.X, padx=5, pady=(0, 5)) # Add padding below
        widgets_dict['fps_label'] = fps_label
        # ---
        # --- END ADDED ---
    
    def _create_view_control_section(self, parent_frame: tk.Frame, widgets_dict: Dict[str, tk.Widget]): # Added widgets_dict argument
        """Create view control section"""
        view_section = tk.LabelFrame(parent_frame, text="View Controls", bg='#404040', fg='white')
        view_section.pack(fill=tk.X, padx=5, pady=5)
        widgets_dict['view_section'] = view_section

        # Zoom controls
        zoom_frame = tk.Frame(view_section, bg='#404040')
        zoom_frame.pack(fill=tk.X, padx=5, pady=2)

        button_width = 10 # Define a fixed width for the buttons

        zoom_in_button = tk.Button(
            zoom_frame,
            text="Zoom +",
            width=button_width,
            command=self.gui.zoom_in # Callback to GUI method
        )
        zoom_in_button.pack(side=tk.LEFT, padx=2, pady=2)
        widgets_dict['zoom_in_button'] = zoom_in_button

        zoom_out_button = tk.Button(
            zoom_frame,
            text="Zoom -",
            width=button_width,
            command=self.gui.zoom_out # Callback to GUI method
        )
        zoom_out_button.pack(side=tk.RIGHT, padx=2, pady=2)
        widgets_dict['zoom_out_button'] = zoom_out_button

        # Fit view buttons
        fit_view_frame = tk.Frame(view_section, bg='#404040')
        fit_view_frame.pack(fill=tk.X, padx=5, pady=2)

        # Fit to Grid button
        fit_plot_button = tk.Button(
            fit_view_frame,
            text="Fit to Grid",
            width=button_width,
            # Callback to GUI's visualizer reset_view method
            command=lambda: self.gui.grid_visualizer.reset_view() if hasattr(self.gui, 'grid_visualizer') and self.gui.grid_visualizer is not None else None
        )
        fit_plot_button.pack(side=tk.LEFT, padx=2, pady=2)
        widgets_dict['fit_plot_button'] = fit_plot_button

        # Rotation controls for 3D
        if self.gui.dimension_type == Dimension.THREE_D:
            rotation_frame = tk.Frame(view_section, bg='#404040')
            rotation_frame.pack(fill=tk.X, padx=5, pady=2)

            self.gui.rotation_enabled_var = tk.BooleanVar(value=False) # Store var on GUI
            rotation_checkbox = tk.Checkbutton(
                rotation_frame,
                text="Enable Rotation",
                variable=self.gui.rotation_enabled_var,
                bg='#404040',
                fg='white',
                selectcolor='#404040',
                command=self.gui._on_enable_rotation_change # Callback to GUI
            )
            rotation_checkbox.pack(fill=tk.X, pady=2)
            widgets_dict['rotation_checkbox'] = rotation_checkbox

            # Rotation speed control
            speed_label = tk.Label(rotation_frame, text="Rotation Speed:", bg='#404040', fg='white')
            speed_label.pack(fill=tk.X, pady=2)
            widgets_dict['rotation_speed_label'] = speed_label

            rotation_speed_scale = tk.Scale(
                rotation_frame,
                from_=0.0,
                to=2.0,
                resolution=0.1,
                orient=tk.HORIZONTAL,
                command=lambda v: setattr(GlobalSettings.Visualization, 'ROTATION_SPEED', float(v))
            )
            rotation_speed_scale.set(GlobalSettings.Visualization.ROTATION_SPEED)
            rotation_speed_scale.pack(fill=tk.X, pady=2)
            widgets_dict['rotation_speed_scale'] = rotation_speed_scale

    def _create_visualization_section(self, parent_frame: tk.Frame, widgets_dict: Dict[str, tk.Widget]): # Added widgets_dict argument
        """Create visualization options section, including Refocus Grid button.
           """
        logger.debug("Entering _create_visualization_section")
        viz_section = tk.LabelFrame(parent_frame, text="Visualization", bg='#404040', fg='white')
        viz_section.pack(fill=tk.X, padx=5, pady=5)
        widgets_dict['viz_section'] = viz_section

        # Highlight checkbox (Uses self.gui.highlight_var)
        highlight_checkbox = tk.Checkbutton(
            viz_section,
            text="Show Highlights",
            variable=self.gui.highlight_var, # Use self.gui.highlight_var
            bg='#404040',
            fg='white',
            selectcolor='#404040',
            command=self.gui._on_highlight_toggle # Callback to GUI
        )
        highlight_checkbox.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['highlight_checkbox'] = highlight_checkbox

        # Blitting checkbox (Uses self.blitting_var)
        blitting_checkbox = tk.Checkbutton(
            viz_section,
            text="Enable Blitting",
            variable=self.blitting_var, # Use self.blitting_var
            bg='#404040',
            fg='white',
            selectcolor='#404040',
            command=self.gui._on_toggle_blitting # Callback to GUI
        )
        blitting_checkbox.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['blitting_checkbox'] = blitting_checkbox

        # Show Coordinates Checkbox (Uses self.show_coordinates_var)
        show_coordinates_checkbox = tk.Checkbutton(
            viz_section,
            text="Show Coordinates",
            variable=self.show_coordinates_var, # Use self.show_coordinates_var
            bg='#404040',
            fg='white',
            selectcolor='#404040',
            command=self.gui._on_show_coordinates_toggle # Callback to GUI
        )
        show_coordinates_checkbox.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['show_coordinates_checkbox'] = show_coordinates_checkbox

        # --- ADDED: Refocus Grid Button ---
        refocus_button = tk.Button(
            viz_section,
            text="Refocus Grid (Wrap)",
            command=self.gui._open_refocus_grid_modal, # Callback to GUI method
            disabledforeground='grey50' # Set disabled color
        )
        refocus_button.pack(fill=tk.X, padx=5, pady=5)
        widgets_dict['refocus_grid_button'] = refocus_button
        # --- END ADDED ---

        # Shape Editor Button
        shape_editor_button = tk.Button(
            viz_section,
            text="Shape Editor...",
            command=self.gui._open_shape_editor_window # Callback to GUI method
        )
        shape_editor_button.pack(fill=tk.X, padx=5, pady=5)
        widgets_dict['shape_editor_button'] = shape_editor_button

        logger.debug("Exiting _create_visualization_section")

    def _create_node_size_section(self, parent_frame: tk.Frame, widgets_dict: Dict[str, tk.Widget]): # Added widgets_dict argument
        """Create node size control section."""
        node_size_section = tk.LabelFrame(parent_frame, text="Node Size Multiplier", bg='#404040', fg='white')
        node_size_section.pack(fill=tk.X, padx=5, pady=5)
        widgets_dict['node_size_section'] = node_size_section

        node_size_scale = tk.Scale(
            node_size_section,
            from_=0.1, # Min multiplier
            to=5.0,   # Max multiplier
            resolution=0.1,
            orient=tk.HORIZONTAL,
            label="Size Multiplier", # Add label to slider
            troughcolor='#555555', # Darker trough
            sliderrelief=tk.RAISED,
            highlightthickness=0,
            bg='#404040', fg='white',
            command=self.gui._on_node_size_change # Callback to GUI
        )
        node_size_scale.set(GlobalSettings.Visualization.NODE_SIZE) # Set initial value
        node_size_scale.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['node_size_scale'] = node_size_scale
        logger.debug("Created node size section.")

    def _create_spacing_section(self, parent_frame: tk.Frame, widgets_dict: Dict[str, tk.Widget]): # Added widgets_dict argument
        """Create node spacing control section.
           (Round 15: Temporarily disable command during initial set)"""
        spacing_section = tk.LabelFrame(parent_frame, text="Node Spacing (Edge Length)", bg='#404040', fg='white')
        spacing_section.pack(fill=tk.X, padx=5, pady=5)
        widgets_dict['spacing_section'] = spacing_section

        spacing_scale = tk.Scale(
            spacing_section,
            from_=GlobalSettings.Visualization.MIN_NODE_SPACING,
            to=GlobalSettings.Visualization.MAX_NODE_SPACING,
            resolution=0.5, # Adjust resolution as needed
            orient=tk.HORIZONTAL,
            label="Spacing", # Add label to slider
            troughcolor='#555555', # Darker trough
            sliderrelief=tk.RAISED,
            highlightthickness=0,
            bg='#404040', fg='white',
            # command=self.gui._on_spacing_change # Set command AFTER setting value
        )
        # --- MODIFIED: Set initial value, THEN set command ---
        spacing_scale.set(GlobalSettings.Visualization.NODE_SPACING) # Set initial value
        spacing_scale.config(command=self.gui._on_spacing_change) # Callback to GUI method
        # ---
        spacing_scale.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['spacing_scale'] = spacing_scale
        logger.debug("Created/Updated node spacing section.")

    def _create_density_section(self, parent_frame: tk.Frame, widgets_dict: Dict[str, tk.Widget]): # Added widgets_dict argument
        """Create density control section.
           (Round 15: Temporarily disable command during initial set)"""
        density_section = tk.LabelFrame(parent_frame, text="Density Settings", bg='#404040', fg='white')
        density_section.pack(fill=tk.X, padx=5, pady=5)
        widgets_dict['density_section'] = density_section

        # --- Determine initial densities ---
        initial_node_density = GlobalSettings.Simulation.INITIAL_NODE_DENSITY
        initial_edge_density = GlobalSettings.Simulation.INITIAL_EDGE_DENSITY
        density_source = "Global Defaults" # Track source for logging
        if hasattr(self, 'initial_preset_obj') and self.initial_preset_obj:
            initial_node_density = self.initial_preset_obj.node_density
            initial_edge_density = self.initial_preset_obj.edge_density
            density_source = f"Initial Preset '{self.initial_preset_obj.name}'"
        logger.info(f"ControlPanelUI: Initializing density sliders using source '{density_source}': Node={initial_node_density:.3f}, Edge={initial_edge_density:.3f}")
        # ---

        # Node density
        node_density_label = tk.Label(density_section, text="Node Density:", bg='#404040', fg='white')
        node_density_label.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['node_density_label'] = node_density_label
        logger.debug("Creating node density scale")
        node_density_scale = tk.Scale(
            density_section,
            from_=0.0,
            to=1.0,
            resolution=0.05,
            orient=tk.HORIZONTAL,
            # command=self.gui._on_node_density_change # Set command AFTER setting value
        )
        # --- MODIFIED: Set initial value, THEN set command ---
        node_density_scale.set(initial_node_density)
        node_density_scale.config(command=self.gui._on_node_density_change)
        # ---
        node_density_scale.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['node_density_scale'] = node_density_scale
        logger.debug("Node density scale created and packed")

        # Edge density
        edge_density_label = tk.Label(density_section, text="Edge Density:", bg='#404040', fg='white')
        edge_density_label.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['edge_density_label'] = edge_density_label
        logger.debug("Creating edge density scale")
        edge_density_scale = tk.Scale(
            density_section,
            from_=0.0,
            to=1.0,
            resolution=0.05,
            orient=tk.HORIZONTAL,
            # command=self.gui._on_edge_density_change # Set command AFTER setting value
        )
        # --- MODIFIED: Set initial value, THEN set command ---
        edge_density_scale.set(initial_edge_density)
        edge_density_scale.config(command=self.gui._on_edge_density_change)
        # ---
        edge_density_scale.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['edge_density_scale'] = edge_density_scale
        logger.debug("Edge density scale created and packed")

    def _create_save_load_section(self, parent_frame: tk.Frame, widgets_dict: Dict[str, tk.Widget]): # Added widgets_dict argument
        """Create save/load control section"""
        io_section = tk.LabelFrame(parent_frame, text="Save/Load", bg='#404040', fg='white')
        io_section.pack(fill=tk.X, padx=5, pady=5)
        widgets_dict['io_section'] = io_section

        button_width = 15

        # --- MODIFIED: Added disabledforeground='black' ---
        save_button = tk.Button(
            io_section,
            text="Save State", # Changed text for clarity
            width=button_width,
            command=self.gui.save_state, # Callback to GUI method
            disabledforeground='black'
        )
        # --- END MODIFIED ---
        save_button.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['save_button'] = save_button

        # --- MODIFIED: Added disabledforeground='black' ---
        load_button = tk.Button(
            io_section,
            text="Load State", # Changed text for clarity
            width=button_width,
            command=self.gui.load_state, # Callback to GUI method
            disabledforeground='black'
        )
        # --- END MODIFIED ---
        load_button.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['load_button'] = load_button

    def _create_color_settings_section(self, parent_frame: tk.Frame, widgets_dict: Dict[str, tk.Widget]): # Added widgets_dict argument
        """Create color settings section with a button to launch the modal."""
        color_section = tk.LabelFrame(parent_frame, text="Color Settings", bg='#404040', fg='white')
        color_section.pack(fill=tk.X, padx=5, pady=5)
        widgets_dict['color_settings_section'] = color_section

        # --- MODIFIED: Added disabledforeground='black' ---
        color_settings_button = tk.Button(
            color_section,
            text="Open Color Settings",
            command=self.gui._open_color_settings_modal, # Callback to GUI method
            width=15, # Match other button widths
            disabledforeground='black'
        )
        # --- END MODIFIED ---
        color_settings_button.pack(fill=tk.X, padx=5, pady=2) # Fill horizontally
        widgets_dict['color_settings_button'] = color_settings_button

        # Add a label to show current color scheme
        if not hasattr(self.gui, 'color_scheme_label_var'):
            self.gui.color_scheme_label_var = tk.StringVar(value="Current Scheme: Classic") # Default text
        color_scheme_label = tk.Label(
            color_section,
            textvariable=self.gui.color_scheme_label_var, # Use variable for dynamic updates
            bg='#404040',
            fg='white',
            anchor=tk.W
        )
        color_scheme_label.pack(fill=tk.X, padx=10, pady=(5, 5)) # Add padding
        widgets_dict['color_scheme_label'] = color_scheme_label

    def _create_performance_section(self, parent_frame: tk.Frame, widgets_dict: Dict[str, tk.Widget]):
        """
        Create performance settings section, including queue size controls,
        parallel processing toggle, and chunk size control.
        (Round 11: Added Chunk Size Combobox/Entry/Button)
        (Round 9: Added back Parallel Processing checkbox)
        """
        perf_section = tk.LabelFrame(parent_frame, text="Performance", bg='#404040', fg='white')
        perf_section.pack(fill=tk.X, padx=5, pady=5)
        widgets_dict['performance_section'] = perf_section

        # --- Parallel Processing Checkbox ---
        if not hasattr(self.gui, 'parallel_var'):
            self.gui.parallel_var = tk.BooleanVar(value=GlobalSettings.USE_PARALLEL_PROCESSING)
        parallel_checkbox = tk.Checkbutton(
            perf_section, text="Use Parallel Processing", variable=self.gui.parallel_var,
            bg='#404040', fg='white', selectcolor='#404040', command=self.gui._on_toggle_parallel
        )
        parallel_checkbox.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['parallel_checkbox'] = parallel_checkbox
        ToolTip(parallel_checkbox, "Enable/disable multi-core processing for simulation steps.\nRequires restart if changed while running.")

        # --- Chunk Size Control ---
        chunk_frame = tk.Frame(perf_section, bg='#404040')
        chunk_frame.pack(fill=tk.X, padx=5, pady=5)
        chunk_label = tk.Label(chunk_frame, text="Chunk Size:", bg='#404040', fg='white')
        chunk_label.pack(side=tk.LEFT, padx=(0, 5))
        widgets_dict['chunk_size_label'] = chunk_label
        ToolTip(chunk_label, "Number of nodes processed by each worker in parallel.\n'Auto' calculates based on grid size and workers.\nSmaller values may improve responsiveness for complex rules but increase overhead.\nLarger values reduce overhead but may load balance poorly.")

        # Ensure GUI variable exists
        if not hasattr(self.gui, 'chunk_size_display_var'):
            self.gui.chunk_size_display_var = tk.StringVar(value="Auto") # Variable for Combobox display
        if not hasattr(self.gui, 'custom_chunk_size_var'):
             self.gui.custom_chunk_size_var = tk.StringVar(value="") # Variable for Entry

        chunk_options = ["Auto", "64", "128", "256", "512", "1024", "2048", "4096", "Custom..."]
        chunk_size_combobox = ttk.Combobox(
            chunk_frame, textvariable=self.gui.chunk_size_display_var, values=chunk_options,
            state="readonly", width=10
        )
        chunk_size_combobox.pack(side=tk.LEFT, padx=2)
        chunk_size_combobox.bind("<<ComboboxSelected>>", self.gui._on_chunk_size_selected) # Link to GUI handler
        widgets_dict['chunk_size_combobox'] = chunk_size_combobox

        custom_chunk_entry = tk.Entry(
            chunk_frame, textvariable=self.gui.custom_chunk_size_var, width=8,
            state=tk.DISABLED, validate="key"
        )
        vcmd_chunk = (custom_chunk_entry.register(self.gui._validate_chunk_size_input), '%P')
        custom_chunk_entry.config(validatecommand=vcmd_chunk)
        custom_chunk_entry.pack(side=tk.LEFT, padx=2)
        widgets_dict['custom_chunk_entry'] = custom_chunk_entry

        apply_chunk_button = tk.Button(
            chunk_frame, text="Apply", command=self.gui._apply_custom_chunk_size, # Link to GUI handler
            state=tk.DISABLED
        )
        apply_chunk_button.pack(side=tk.LEFT, padx=2)
        widgets_dict['apply_chunk_button'] = apply_chunk_button
        # --- End Chunk Size Control ---

        # --- Render Queue Size Slider ---
        render_queue_label = tk.Label(perf_section, text="Render Buffer Size (Frames):", bg='#404040', fg='white')
        render_queue_label.pack(fill=tk.X, padx=5, pady=(10, 0)) # Add padding above
        widgets_dict['render_queue_label'] = render_queue_label
        ToolTip(render_queue_label, "Max prepared frames buffered before display.\nControls how far computation can run ahead of rendering.\nIncrease for smoother animation if rendering is fast.")

        render_queue_scale = tk.Scale(
            perf_section, from_=1, to=500, resolution=1, orient=tk.HORIZONTAL,
            variable=self.gui.render_queue_size_var, troughcolor='#555555',
            sliderrelief=tk.RAISED, highlightthickness=0, bg='#404040', fg='white',
            command=self.gui._on_render_queue_size_change
        )
        render_queue_scale.set(GlobalSettings.Simulation.RENDER_QUEUE_SIZE)
        render_queue_scale.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['render_queue_scale'] = render_queue_scale
        # ---

    def _create_analytics_section(self, parent_frame: tk.Frame, widgets_dict: Dict[str, tk.Widget]):
        """Create the Analytics control section.
           (Round 13: New method)"""
        analytics_section = tk.LabelFrame(parent_frame, text="Analytics", bg='#404040', fg='white')
        analytics_section.pack(fill=tk.X, padx=5, pady=5)
        widgets_dict['analytics_section'] = analytics_section

        # Ensure the variable exists on the GUI instance
        if not hasattr(self.gui, 'analytics_enabled_var'):
            self.gui.analytics_enabled_var = tk.BooleanVar(value=False) # Default OFF

        # Enable/Disable Analytics Checkbox
        analytics_enable_checkbox = tk.Checkbutton(
            analytics_section,
            text="Enable Analytics",
            variable=self.gui.analytics_enabled_var, # Link to GUI variable
            bg='#404040',
            fg='white',
            selectcolor='#404040',
            command=self.gui._on_toggle_analytics_enabled # Callback to GUI method
        )
        analytics_enable_checkbox.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['analytics_enable_checkbox'] = analytics_enable_checkbox

        # View Analytics Button
        view_analytics_button = tk.Button(
            analytics_section,
            text="View Analytics",
            command=self.gui._open_analytics_window, # Callback to GUI method
            width=15, # Match other button widths
            disabledforeground='grey50' # Set disabled color
        )
        view_analytics_button.pack(fill=tk.X, padx=5, pady=5)
        widgets_dict['view_analytics_button'] = view_analytics_button

    def _create_debug_section(self, parent_frame: tk.Frame, widgets_dict: Dict[str, tk.Widget]): # Added widgets_dict argument
        """Create debug section at the bottom of the control panel with logging controls.
           """
        debug_section = tk.LabelFrame(parent_frame, text="Debug & Performance", bg='#404040', fg='white')
        debug_section.pack(fill=tk.X, padx=5, pady=5)
        widgets_dict['debug_section'] = debug_section

        # --- Logging Enable Checkbox ---
        log_enable_checkbox = tk.Checkbutton(
            debug_section,
            text="Enable Logging",
            variable=self.gui.logging_enabled_var, # Use new GUI variable
            bg='#404040', fg='white', selectcolor='#404040',
            command=self.gui._on_toggle_logging_enabled # Callback to GUI
        )
        log_enable_checkbox.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['logging_enabled_checkbox'] = log_enable_checkbox

        # --- Logging Level Combobox ---
        log_level_frame = tk.Frame(debug_section, bg='#404040')
        log_level_frame.pack(fill=tk.X, padx=5, pady=2)
        log_level_label = tk.Label(log_level_frame, text="Logging Level:", bg='#404040', fg='white')
        log_level_label.pack(side=tk.LEFT, padx=(0, 5))
        # --- MODIFIED: Added PIPELINE level ---
        log_levels = ["DEBUG", "DETAIL", "INFO", "WARNING", "ERROR", "CRITICAL", "PIPELINE"]
        # ---
        log_level_combobox = ttk.Combobox(
            log_level_frame,
            textvariable=self.gui.log_level_var, # Use new GUI variable
            values=log_levels,
            state="readonly", # User selects from list
            width=10
        )
        # Set initial state based on logging_enabled_var
        initial_log_state = tk.NORMAL if self.gui.logging_enabled_var.get() else tk.DISABLED
        log_level_combobox.config(state=initial_log_state)
        log_level_combobox.pack(side=tk.LEFT, padx=5)
        log_level_combobox.bind("<<ComboboxSelected>>", self.gui._on_logging_level_change) # Callback to GUI
        widgets_dict['log_level_label'] = log_level_label
        widgets_dict['log_level_combobox'] = log_level_combobox

        # --- Detailed Logging Checkbox ---
        detailed_log_checkbox = tk.Checkbutton(
            debug_section,
            text="Enable Detailed File Logging", # Clarified label
            variable=self.detailed_logging_var, # Use existing GUI variable
            bg='#404040', fg='white', selectcolor='#404040',
            command=self.gui._on_toggle_detailed_logging, # Callback to GUI
            state=initial_log_state # Initial state depends on logging enabled
        )
        detailed_log_checkbox.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['detailed_logging_checkbox'] = detailed_log_checkbox

        # --- Periodic Reporting Checkbox ---
        periodic_checkbox = tk.Checkbutton(
            debug_section,
            text="Enable Periodic Reporting",
            variable=self.periodic_reporting_var,
            bg='#404040', fg='white', selectcolor='#404040',
            command=self.gui._on_toggle_periodic_reporting
        )
        periodic_checkbox.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['periodic_reporting_checkbox'] = periodic_checkbox

        # --- Reporting Interval ---
        interval_frame = tk.Frame(debug_section, bg='#404040')
        interval_frame.pack(fill=tk.X, padx=5, pady=2)
        interval_label = tk.Label(interval_frame, text="Reporting Interval (steps):", bg='#404040', fg='white')
        interval_label.pack(side=tk.LEFT, padx=(0, 5))
        interval_entry = tk.Entry(
            interval_frame,
            textvariable=self.reporting_interval_var,
            width=5
        )
        vcmd = (interval_entry.register(self.gui._validate_reporting_interval), '%P')
        interval_entry.config(validate='key', validatecommand=vcmd)
        interval_entry.bind("<FocusOut>", self.gui._on_reporting_interval_change)
        interval_entry.bind("<Return>", self.gui._on_reporting_interval_change)
        interval_entry.pack(side=tk.LEFT)
        widgets_dict['reporting_interval_label'] = interval_label
        widgets_dict['reporting_interval_entry'] = interval_entry

        # --- Deep Profiling Checkbox ---
        profiling_checkbox = tk.Checkbutton(
            debug_section,
            text="Enable Deep Profiling (Every Step)",
            variable=self.deep_profiling_var,
            bg='#404040', fg='white', selectcolor='#404040',
            command=self.gui._on_toggle_deep_profiling
        )
        profiling_checkbox.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['deep_profiling_checkbox'] = profiling_checkbox

        # Original Debug Mode Button (Visuals)
        debug_button = tk.Button(
            debug_section,
            text="Toggle Debug Mode (Visuals)",
            command=lambda: self.gui.grid_visualizer.toggle_debug_mode() if hasattr(self.gui, 'grid_visualizer') and self.gui.grid_visualizer is not None else None,
            disabledforeground='black'
        )
        debug_button.pack(fill=tk.X, padx=5, pady=2)
        widgets_dict['debug_button'] = debug_button

    def _post_setup_controls(self):
        """Perform post-setup tasks that require GUI elements to be initialized.
           """
        try:
            # --- ADDED Instance ID Logging ---
            logger.debug(f"Entering ControlPanelUI._post_setup_controls (Instance ID: {id(self)}, Widgets ID: {id(self.widgets)})")
            # ---
            logger.debug(f"  _post_setup_controls: self.widgets keys BEFORE updates: {list(self.widgets.keys())}")

            # Initialize highlight_var if it doesn't exist on GUI
            if not hasattr(self.gui, 'highlight_var'):
                self.gui.highlight_var = tk.BooleanVar(value=True)

            # Set initial values for GUI elements controlled here (or ensure they reflect GUI state)
            highlight_checkbox = self.widgets.get('highlight_checkbox')
            if isinstance(highlight_checkbox, tk.Checkbutton):
                highlight_checkbox.select() # Default highlight to on

            # Set initial state of buttons using the update method
            self.update_button_states() # Call the update method to set initial states

            # Call update methods to set initial states
            self.update_step_label()
            # --- ADDED Logging before problematic call ---
            logger.debug(f"  _post_setup_controls: self.widgets keys JUST BEFORE update_grid_preset_selector: {list(self.widgets.keys())} (Widgets ID: {id(self.widgets)})")
            # ---
            self.update_grid_preset_selector() # <--- Problem occurs here
            self.update_neighborhood_selector()
            self.update_num_steps_entry_state()
            # Update grid size label initially
            grid_size_label = self.widgets.get('grid_size_label')
            if isinstance(grid_size_label, tk.Label):
                 grid_size_label.config(text=f"Size: {'x'.join(map(str, self.gui.dimensions))}")

            # Explicitly set StringVars for Dimension and Boundary AFTER widgets are created
            if hasattr(self.gui, 'dimension_var'):
                self.gui.dimension_var.set(self.gui.dimension_type.name)
                logger.debug(f"Explicitly set dimension_var to '{self.gui.dimension_type.name}' in _post_setup_controls")
            if hasattr(self.gui, 'grid_boundary_var') and self.gui.controller and self.gui.controller.rule:
                boundary_val = self.gui.controller.rule.get_param('grid_boundary', 'bounded')
                self.gui.grid_boundary_var.set(boundary_val)
                logger.debug(f"Explicitly set grid_boundary_var to '{boundary_val}' in _post_setup_controls")

            logger.debug("ControlPanelUI._post_setup_controls completed successfully")

        except Exception as e:
            logger.error(f"Error in ControlPanelUI._post_setup_controls: {e}")
            logger.error(traceback.format_exc())

    def update_button_states(self): 
        """Update the state of control buttons based on simulation status.
           """
        # --- MODIFIED: Use self.widgets ---
        widgets_dict = self.widgets
        # ---
        # Access GUI state via self.gui
        is_running = self.gui.running
        is_paused = self.gui.paused
        is_fixed_running = getattr(self.gui, '_fixed_steps_running', False) # Check if fixed steps are running

        # Access buttons via widgets_dict dictionary
        start_button = widgets_dict.get('start_button')
        stop_button = widgets_dict.get('stop_button') # Get stop button
        step_button = widgets_dict.get('step_button')
        reset_button = widgets_dict.get('reset_button')

        # --- ADDED: Check widget existence and type ---
        if start_button and isinstance(start_button, tk.Button) and start_button.winfo_exists():
            if is_running and not is_paused:
                start_button.config(text="Pause", state=tk.NORMAL)
            elif is_paused:
                start_button.config(text="Resume", state=tk.NORMAL)
            else: # Stopped
                start_button.config(text="Start", state=tk.NORMAL)
        elif start_button: logger.warning("Start button widget invalid or destroyed in update_button_states.")

        if stop_button and isinstance(stop_button, tk.Button) and stop_button.winfo_exists():
            stop_button.config(state=tk.NORMAL if is_running or is_paused else tk.DISABLED)
        elif stop_button: logger.warning("Stop button widget invalid or destroyed in update_button_states.")

        if step_button and isinstance(step_button, tk.Button) and step_button.winfo_exists():
            step_button.config(state=tk.NORMAL if not is_running or is_paused else tk.DISABLED)
        elif step_button: logger.warning("Step button widget invalid or destroyed in update_button_states.")

        if reset_button and isinstance(reset_button, tk.Button) and reset_button.winfo_exists():
            reset_button.config(state=tk.NORMAL)
        elif reset_button: logger.warning("Reset button widget invalid or destroyed in update_button_states.")
        # --- END ADDED CHECKS ---

    def update_refocus_button_state(self):
        """Enables or disables the Refocus Grid button based on the grid boundary condition."""
        refocus_button = self.widgets.get('refocus_grid_button')
        if not isinstance(refocus_button, tk.Button) or not refocus_button.winfo_exists():
            # logger.warning("Refocus grid button not found or invalid, cannot update state.") # Reduce noise
            return

        is_wrap_boundary = False
        if self.gui.grid and self.gui.grid.rule:
            is_wrap_boundary = self.gui.grid.rule.get_param('grid_boundary', 'bounded') == 'wrap'

        new_state = tk.NORMAL if is_wrap_boundary else tk.DISABLED
        try:
            refocus_button.config(state=new_state)
            # logger.debug(f"Refocus grid button state set to: {new_state}") # Reduce noise
        except tk.TclError:
            logger.warning("TclError configuring refocus grid button state (likely destroyed).")

    def update_step_label(self): 
        """Updates the step counter label in the GUI using the GUI's generation count.
           """
        # --- MODIFIED: Use self.widgets ---
        widgets_dict = self.widgets
        # ---
        step_label = widgets_dict.get('step_label')

        # --- ADDED: Check widget existence and type ---
        if isinstance(step_label, tk.Label) and step_label.winfo_exists():
        # ---
            try:
                # --- MODIFIED: Get generation from the GUI instance ---
                current_generation = 0 # Default
                if hasattr(self.gui, 'generation'): # Check if GUI has the attribute
                    current_generation = self.gui.generation # Use GUI's generation count
                else:
                    logger.warning("GUI generation attribute not available in update_step_label.")
                # --- END MODIFIED ---
                step_label.config(text=f"Step: {current_generation}")
            except tk.TclError as e:
                logger.warning(f"TclError updating step label in ControlPanelUI (likely widget destroyed): {e}")
            except Exception as e:
                logger.error(f"Unexpected error updating step label in ControlPanelUI: {e}")
        # --- ADDED: Else block for logging ---
        else:
            logger.debug(f"Step label widget not found, invalid, or destroyed in ControlPanelUI's self.widgets (Keys: {list(widgets_dict.keys())}).")
        # ---

    def update_rule_instance_selector(self):
        """Update the rule instance selector based on the selected rule type."""
        rule_instance_selector = self.widgets.get('rule_instance_selector')
        rule_type_selector = self.widgets.get('rule_type_selector') # Needed to get current category

        if not isinstance(rule_instance_selector, tk.OptionMenu) or not isinstance(rule_type_selector, tk.OptionMenu):
            logger.error("Rule instance or type selector widget not found or invalid type in ControlPanelUI.")
            return

        try:
            # Get the currently selected category from the GUI's variable
            selected_category = self.gui.rule_type_var.get()
            logger.debug(f"Updating rule instance selector for category: {selected_category}")

            # Get available rule names for this category
            manager = RuleLibraryManager.get_instance() # Get manager instance
            available_rules = []
            if selected_category == "Favorites":
                available_rules = manager.get_favorite_rule_names()
            else:
                available_rules = sorted(list(dict.fromkeys(RuleLibrary.get_rules_in_category(selected_category))))

            # Get the menu widget
            menu = rule_instance_selector['menu']
            if menu is None:
                logger.error("Rule instance selector menu not found.")
                return

            # Clear existing options
            menu.delete(0, 'end')

            # Add new options
            if available_rules:
                # --- ADDED: Check if rule_instance_selector supports config before calling it ---
                if hasattr(rule_instance_selector, 'config') and isinstance(rule_instance_selector, tk.OptionMenu):
                    rule_instance_selector.config(state=tk.NORMAL) # Enable selector
                # ---
                for rule_name in available_rules:
                    # Use functools.partial to correctly bind the rule_name to the GUI's callback
                    menu.add_command(label=rule_name,
                                     command=functools.partial(self.gui._on_rule_instance_change, rule_name))

                # Set the variable to the first available rule if the current one isn't valid for this category
                current_instance = self.gui.rule_instance_var.get()
                if current_instance not in available_rules:
                    self.gui.rule_instance_var.set(available_rules[0])
            else:
                # --- ADDED: Check if rule_instance_selector supports config before calling it ---
                if hasattr(rule_instance_selector, 'config') and isinstance(rule_instance_selector, tk.OptionMenu):
                    rule_instance_selector.config(state=tk.DISABLED) # Disable selector
                # ---
                menu.add_command(label="(No rules)", state="disabled")
                self.gui.rule_instance_var.set("(No rules)")

            # --- ADDED: Check if rule_instance_selector supports config before calling it ---
            if hasattr(rule_instance_selector, 'config') and isinstance(rule_instance_selector, tk.OptionMenu):
                rule_instance_selector.config(width=25)
            # ---
            rule_instance_selector['menu'].configure(font=('TkDefaultFont', 10))

            logger.debug(f"Rule instance selector updated. Selected: {self.gui.rule_instance_var.get()}")

        except Exception as e:
            logger.error(f"Error updating rule instance selector: {e}")
            logger.error(traceback.format_exc())
            # Attempt to reset to a safe state
            if 'rule_instance_selector' in self.widgets and isinstance(self.widgets['rule_instance_selector'], tk.OptionMenu):
                self.widgets['rule_instance_selector'].config(state=tk.DISABLED)

    def update_grid_preset_selector(self): 
        """Update the grid preset selector with available presets and set the current selection.
           """

        log_prefix = "ControlPanelUI._update_grid_preset_selector: "
        # --- MODIFIED: Use self.widgets ---
        widgets_dict = self.widgets
        # ---
        logger.debug(f"{log_prefix}Updating grid preset selector (Instance ID: {id(self)}, Widgets ID: {id(widgets_dict)}).")
        logger.debug(f"{log_prefix}Accessing self.widgets. Keys available: {list(widgets_dict.keys())}")
        preset_selector = widgets_dict.get('preset_selector')
        logger.debug(f"{log_prefix}Result of get('preset_selector'): {preset_selector} (Type: {type(preset_selector)})")

        # --- ADDED: Check widget existence and type ---
        if not isinstance(preset_selector, tk.OptionMenu) or not preset_selector.winfo_exists():
            logger.error(f"{log_prefix}Preset selector widget not found, invalid, or destroyed in self.widgets. Found: {type(preset_selector)}")
            logger.error(f"{log_prefix}Current content of self.widgets: {widgets_dict}")
            return
        # ---

        try:
            preset_names = list(self.gui.grid_preset_manager.presets.keys())
            sorted_preset_names = sorted(preset_names)
            display_names = ["None"] + sorted_preset_names

            menu = preset_selector['menu']
            if menu is None:
                logger.error(f"{log_prefix}Preset selector menu not found.")
                return

            menu.delete(0, "end")

            for name in display_names:
                menu.add_command(label=name, command=functools.partial(self.gui._on_preset_selected, name))

            active_preset = self.gui.active_preset_name
            target_selection = "None"
            if active_preset and active_preset in preset_names:
                target_selection = active_preset
            else:
                logger.debug(f"{log_prefix}Active preset '{active_preset}' is None or invalid, setting selector to 'None'.")
                target_selection = "None"

            self.gui.preset_var.set(target_selection)

            logger.debug(f"{log_prefix}Grid preset selector updated. Selected: {self.gui.preset_var.get()}")

        except Exception as e:
            logger.error(f"{log_prefix}Error updating grid preset selector: {e}")
            logger.error(traceback.format_exc())

    def update_neighborhood_selector(self): 
        """Update the neighborhood selector options based on the current dimension type.
           """
        widgets_dict = self.widgets
        log_prefix = "ControlPanelUI._update_neighborhood_selector: "
        logger.debug(f"{log_prefix}Updating neighborhood selector (Instance ID: {id(self)}, Widgets ID: {id(widgets_dict)}).")

        # --- ADDED: Detailed logging BEFORE accessing the widget ---
        logger.debug(f"{log_prefix}Accessing self.widgets. Keys available: {list(widgets_dict.keys())}")
        neighborhood_selector = widgets_dict.get('neighborhood_selector')
        logger.debug(f"{log_prefix}Result of get('neighborhood_selector'): {neighborhood_selector} (Type: {type(neighborhood_selector)})")
        if neighborhood_selector:
             logger.debug(f"  Widget Exists: {neighborhood_selector.winfo_exists()}")
             logger.debug(f"  Is OptionMenu: {isinstance(neighborhood_selector, tk.OptionMenu)}")
        # --- END ADDED ---

        if not isinstance(neighborhood_selector, tk.OptionMenu) or not neighborhood_selector.winfo_exists():
            logger.error(f"{log_prefix}Neighborhood selector widget not found, invalid, or destroyed in self.widgets. Found: {type(neighborhood_selector)}")
            logger.error(f"{log_prefix}Current content of self.widgets: {widgets_dict}")
            return

        try:
            valid_neighborhoods = self.gui._get_valid_neighborhoods()
            menu = neighborhood_selector['menu']
            if menu is None:
                logger.error(f"{log_prefix}Neighborhood selector menu not found.")
                return

            menu.delete(0, 'end')

            for neighborhood_name in valid_neighborhoods:
                menu.add_command(
                    label=neighborhood_name,
                    command=functools.partial(self.gui._on_neighborhood_change, neighborhood_name)
                )

            current_neighborhood_name = self.gui.neighborhood_type.name
            if current_neighborhood_name in valid_neighborhoods:
                self.gui.neighborhood_var.set(current_neighborhood_name)
            elif valid_neighborhoods:
                self.gui.neighborhood_var.set(valid_neighborhoods[0])
                self.gui.root.after(10, lambda name=valid_neighborhoods[0]: self.gui._on_neighborhood_change(name))
            else:
                self.gui.neighborhood_var.set("")

            logger.debug(f"{log_prefix}Neighborhood selector updated. Selected: {self.gui.neighborhood_var.get()}")

        except KeyError:
            logger.error(f"{log_prefix}Neighborhood selector widget ('neighborhood_selector') not found in widgets_dict.")
        except Exception as e:
            logger.error(f"{log_prefix}Error updating neighborhood selector: {e}")
            logger.error(traceback.format_exc())

    def update_num_steps_entry_state(self): 
        """Update the state of the num_steps_entry based on run_continuously.
           """
        # --- MODIFIED: Use self.widgets ---
        widgets_dict = self.widgets
        # ---
        num_steps_entry = widgets_dict.get('num_steps_entry')
        # --- ADDED: Check widget existence and type ---
        if isinstance(num_steps_entry, tk.Entry) and num_steps_entry.winfo_exists():
        # ---
            try:
                if self.gui.run_continuously.get():
                    if hasattr(num_steps_entry, 'config'): num_steps_entry.config(state=tk.DISABLED)
                else:
                    if hasattr(num_steps_entry, 'config'): num_steps_entry.config(state=tk.NORMAL)
            except tk.TclError as e: logger.warning(f"TclError updating num_steps_entry state (likely widget destroyed): {e}")
            except AttributeError: logger.warning("Could not access self.gui.run_continuously variable.")
            except Exception as e: logger.error(f"Unexpected error updating num_steps_entry state: {e}")
        # --- ADDED: Else block for logging ---
        elif num_steps_entry is not None:
            logger.warning(f"Widget 'num_steps_entry' not found in self.widgets or is not a tk.Entry (Type: {type(num_steps_entry)}). Cannot update state.")
        else:
             logger.debug("num_steps_entry widget not found in self.widgets.")
        # ---

class SimulationGUI(Observer, Observable):
    """
    Main GUI for the simulation.
    """
    # Global application lock
    _app_lock = threading.Lock()
    change_tracker: Optional[ChangeTracker] = None  # Class-level, optional
    _params_modified: bool = False  # Class-level
    loop_thread: Optional[threading.Thread] = None # ADDED
    _is_grid_size_change = False # ADDED
    _show_coords_local = False
    shape_editor_window: Optional['ShapeLibraryEditorWindow'] = None
    DEFAULT_HOTMENU_SHAPES: List[str] = ["Dot", "Block (2x2)", "Glider", "Gosper Glider Gun"]
# Modify __init__ in the SimulationGUI class

    # --- INCREASED QUEUE SIZES ---
    MIN_QUEUE_AHEAD = 10 # Minimum snapshots computation should be aheadf
    MAX_QUEUE_AHEAD = 30 # Allow computation to get further ahead
    # ---

    def __init__(self, root: tk.Tk,
                 controller: 'SimulationController',
                 grid: 'Grid',
                 visualizer: Optional['GridVisualizer'], # Make Optional
                 fig: Figure,
                 ax: Axes,
                 coord_system: CoordinateSystem,
                 app_paths: Dict[str, str],
                 color_manager: 'ColorManager',
                 rule_library_manager: 'RuleLibraryManager',
                 grid_preset_manager: 'GridPresetManager',
                 shape_manager: 'ShapeLibraryManager',
                 initial_rule_name: str,
                 active_preset_name: Optional[str] = None,
                 initial_conditions_name: str = "Random",
                 initial_preset_obj: Optional[GridPreset] = None): # ADDED initial_preset_obj
        """
        Initializes the SimulationGUI with pre-initialized components.
        (Round 13: Add _is_initializing_or_applying_preset flag)
        """
        # ... (previous init code before super().__init__()) ...
        try:
            import collections # Import collections
            import queue # ADDED for queue management refactor
            logger.info("--- SimulationGUI Initializing ---")
            # --- Use Global Settings for Queue Sizes ---
            self.MIN_QUEUE_AHEAD = 10 # Minimum snapshots computation should be ahead
            self.MAX_QUEUE_AHEAD = GlobalSettings.Simulation.MAX_QUEUE_AHEAD # Use global setting
            render_queue_maxsize = GlobalSettings.Simulation.RENDER_QUEUE_SIZE # Use global setting
            logger.info(f"Queue Settings: MIN_AHEAD={self.MIN_QUEUE_AHEAD}, MAX_AHEAD={self.MAX_QUEUE_AHEAD}, RENDER_Q_SIZE={render_queue_maxsize}")
            # ---

            self.root = root # Assign root first
            self._init_tk_variables(initial_conditions_name)
            # --- QUEUE MANAGEMENT REFACTOR: Initialize render_queue_size_var ---
            if not hasattr(self, 'render_queue_size_var'):
                self.render_queue_size_var = tk.IntVar(value=GlobalSettings.Simulation.RENDER_QUEUE_SIZE)
            # ---
            # --- FPS Tracking Attributes ---
            self.fps_history = collections.deque(maxlen=30) # Rolling window for avg FPS (e.g., 30 frames)
            self.last_avg_fps = 0.0
            self._last_render_completion_time = 0.0
            self.fps_display_var = tk.StringVar(value="Avg FPS: N/A | Render Q: N/A")
            # --- ADDED: Step Duration Tracking ---
            self.step_duration_history = collections.deque(maxlen=20) # Store last 20 step durations
            # ---
            logger.info("Tkinter variables initialized.")
            super().__init__() # Initialize Observable
            # self.root = root # Already assigned
            self.controller = controller
            if self.controller:
                self.controller.gui = self
                logger.info(f"Set controller.gui reference to self (GUI ID: {id(self)})")
            else:
                logger.error("Controller object is None during GUI init, cannot set back-reference.")
            self.grid = grid
            self.fig = fig
            self.ax = ax
            self.grid_visualizer: Optional[GridVisualizer] = None
            self.view_manager: Optional[ViewManager] = None
            self.coord_system = coord_system
            self.app_paths = app_paths
            self.color_manager = color_manager
            self.rule_library_manager = rule_library_manager
            self.grid_preset_manager = grid_preset_manager
            self.shape_manager = shape_manager
            self.rule_name = initial_rule_name
            self.active_preset_name = active_preset_name
            self.initial_preset_obj = initial_preset_obj
            logger.info(f"Stored initial_preset_obj: {'Preset ' + initial_preset_obj.name if initial_preset_obj else 'None'}")
            logger.info(f"Received active_preset_name: {self.active_preset_name}")
            self.generation = 0
            self.dimensions = self.grid.dimensions if self.grid else GlobalSettings.Simulation.get_grid_dimensions()
            self.dimension_type = self.grid.dimension_type if self.grid else GlobalSettings.Simulation.DIMENSION_TYPE
            self.neighborhood_type = self.grid.neighborhood_type if self.grid else GlobalSettings.Simulation.NEIGHBORHOOD_TYPE
            self._observers = []
            self._initial_setup_complete = False
            self._pending_color_scheme = None
            self._color_scheme_loaded = False
            self._init_state_tracking()
            self.widgets = {}
            self.control_panel_ui: Optional[ControlPanelUI] = None
            self._tk_destroyed = False
            self._view_state = {
                'xlim': None, 'ylim': None, 'zlim': None,
                'elev': 30, 'azim': 45, 'zoom_factor': 1.0
            }
            self._is_stopping = False
            self._stop_event = threading.Event()
            self._programmatic_change = False
            self._applying_preset = False
            # --- ADDED FLAG ---
            self._is_initializing_or_applying_preset = False
            # ---
            self._is_setting_defaults = False
            self.active_tool: Optional[str] = None
            self.paused = False
            self._user_interaction_active = False
            self._stopped = True
            self._is_shutting_down = False
            self._log_listener_stop_event = threading.Event()
            self._log_listener_thread: Optional[threading.Thread] = None
            self._window_has_focus = True # Assume focus initially
            self._inactive_pool_cleanup_timer: Optional[str] = None # Timer ID for cleanup
            self._render_timer_after_id: Optional[str] = None

            # --- QUEUE MANAGEMENT REFACTOR: Initialize both queues ---
            self.communication_queue = queue.Queue(maxsize=1000) # Or 0 for unbounded
            render_queue_maxsize = self.render_queue_size_var.get() # Get value from Tk var
            self.render_data_queue = queue.Queue(maxsize=max(1, render_queue_maxsize)) # Ensure at least 1
            logger.info(f"Initialized communication_queue (maxsize=1000) and render_data_queue (maxsize={render_queue_maxsize})")

            # Preparation thread and stop event
            self._prep_stop_event = threading.Event()
            self._prep_thread: Optional[threading.Thread] = None
            logger.debug("Initialized prep thread attributes.")
            # --- END QUEUE MANAGEMENT REFACTOR ---

            self._prep_stop_event = threading.Event()
            self._prep_thread: Optional[threading.Thread] = None
            self._last_prepared_snapshot_for_highlight: Optional[Dict[str, Any]] = None

            # --- Prep Thread State Dictionary and Lock ---
            self._prep_params_lock = threading.Lock()
            self._prep_visualization_params: Dict[str, Any] = { # Initialize with defaults
                'zoom_factor': 1.0, 'highlight_on': True,
                'background_color': GlobalSettings.Colors.BACKGROUND, 'node_base_color': GlobalSettings.Colors.NODE_INACTIVE,
                'node_color': GlobalSettings.Colors.NODE_ACTIVE, 'new_node_color': GlobalSettings.Colors.NODE_EDGE_NEW,
                'default_edge_color': GlobalSettings.Colors.NODE_EDGE_OLD, 'new_edge_color': GlobalSettings.Colors.NODE_EDGE_NEW,
                'node_outline_old': GlobalSettings.Colors.NODE_EDGE_OLD, 'node_outline_new': GlobalSettings.Colors.NODE_EDGE_NEW,
                'selection_highlight_nodes': set(), 'node_colormap': 'plasma', 'node_color_norm_vmin': 0.0, 'node_color_norm_vmax': 1.0,
                'edge_colormap': 'viridis', 'edge_color_norm_vmin': 0.0, 'edge_color_norm_vmax': 1.0,
                'use_state_coloring': False, 'use_state_coloring_edges': False, 'color_nodes_by_degree': False,
                'color_nodes_by_active_neighbors': False, 'edge_coloring_mode': 'Default',
            }
            logger.debug("Initialized _prep_visualization_params and lock.")

            self.hide_show_control_panel_text = tk.StringVar(value="Hide Control Panel")

            logger.debug("Added active_tool attribute.")
            logger.debug("Added _applying_preset flag.")
            logger.debug("Initialized _view_state and _stop_event.")
            logger.info("Stored dependencies and initialized core attributes.")

            if self.color_manager and self.color_manager.current_scheme:
                self._latest_color_scheme = copy.deepcopy(self.color_manager.current_scheme)
                logger.info(f"Initialized _latest_color_scheme to '{self._latest_color_scheme.name}'")
                with self._prep_params_lock:
                    self._prep_visualization_params.update({
                        'background_color': self._latest_color_scheme.background, 'node_base_color': self._latest_color_scheme.node_base,
                        'node_color': self._latest_color_scheme.node, 'new_node_color': self._latest_color_scheme.new_node,
                        'default_edge_color': self._latest_color_scheme.default_edge, 'new_edge_color': self._latest_color_scheme.new_edge,
                        'node_outline_old': self._latest_color_scheme.default_edge, 'node_outline_new': self._latest_color_scheme.new_node,
                    })
            else:
                logger.warning("ColorManager or current_scheme missing, initializing _latest_color_scheme to default 'Classic'.")
                self._latest_color_scheme = ColorScheme("Classic", "#ffffff", "#f0f0f0", "#f77b4f", "#ff0000", "#0000ff", "#00ff00", False)
                with self._prep_params_lock:
                    self._prep_visualization_params.update({
                        'background_color': GlobalSettings.Colors.BACKGROUND, 'node_base_color': GlobalSettings.Colors.NODE_INACTIVE,
                        'node_color': GlobalSettings.Colors.NODE_ACTIVE, 'new_node_color': GlobalSettings.Colors.NODE_EDGE_NEW,
                        'default_edge_color': GlobalSettings.Colors.NODE_EDGE_OLD, 'new_edge_color': GlobalSettings.Colors.NODE_EDGE_NEW,
                        'node_outline_old': GlobalSettings.Colors.NODE_EDGE_OLD, 'node_outline_new': GlobalSettings.Colors.NODE_EDGE_NEW,
                    })

            if self.color_manager and self.color_manager.current_scheme:
                self._pending_color_scheme = copy.deepcopy(self.color_manager.current_scheme)
                logger.debug(f"Stored pending color scheme: {self._pending_color_scheme.name}")
                self._color_scheme_loaded = True
            else:
                logger.warning("Color manager or current scheme not available during init.")
                self._pending_color_scheme = copy.deepcopy(self._latest_color_scheme)
                self._color_scheme_loaded = False

            self._init_window_and_frames()
            logger.info("Window and base frames initialized.")
            self._load_hotmenu_shapes()
            logger.info("Hotmenu shapes loaded.")
            self._start_logging_listener()
            self._start_preparation_thread() # Start prep thread here
            self._setup_observers()
            logger.info("Observers set up.")
            self.root.after(50, self._complete_gui_setup)
            logger.info("Scheduled _complete_gui_setup.")
            self.root.after(10000, self._schedule_inactive_pool_cleanup) # Start 10s after init
            logger.info("Scheduled first inactive pool cleanup check.")

            self.analytics_enabled_var = tk.BooleanVar(value=False)  # Initialize with default value

        except Exception as e:
            logger.critical(f"Error during SimulationGUI init: {e}", exc_info=True)
            if hasattr(self, 'root') and self.root:
                try: self.root.destroy()
                except: pass
            raise


    def _init_matplotlib_elements(self):
        """Initialize matplotlib figure, axes, canvas, visualizer, and view manager."""
        logger.debug("--- Entering _init_matplotlib_elements ---")
        try:
            initial_bg = self.color_manager.current_scheme.background if hasattr(self, 'color_manager') and self.color_manager.current_scheme else GlobalSettings.Colors.BACKGROUND
            if self.fig is None or self.ax is None:
                logger.info("Fig/Ax not provided by Initializer, creating new ones.")
                self.fig = Figure(figsize=GlobalSettings.Visualization.FIGURE_SIZE)
                if self.dimension_type == Dimension.THREE_D:
                    self.ax = self.fig.add_subplot(111, projection='3d')
                    elev = getattr(self, '_current_elev', 30); azim = getattr(self, '_current_azim', 45)
                    # Ensure self.ax is an Axes3DType before calling view_init
                    if isinstance(self.ax, Axes3DType):
                        self.ax.view_init(elev=elev, azim=azim)
                    else:
                        logger.warning("self.ax is not an instance of Axes3DType. Skipping view initialization.")
                    self.ax.set_box_aspect(1.0)
                else:
                    self.ax = self.fig.add_subplot(111)
            else:
                 logger.info("Using Fig/Ax provided by Initializer.")

            self.fig.set_facecolor(initial_bg)
            self.ax.set_facecolor(initial_bg)
            self.ax.set_position((0.0, 0.0, 1.0, 1.0))
            logger.debug("Set axes position to [0, 0, 1, 1]")

            self.ax.grid(False)
            self.ax.set_axisbelow(True)
            self.ax.tick_params(colors='gray')
            for spine in self.ax.spines.values(): spine.set_visible(False)
            self.ax.set_xticks([]); self.ax.set_yticks([])
            if hasattr(self.ax, 'set_zticks'): self.ax.set_zticks([]) # type: ignore
            self.ax.set_axis_off()


            if not hasattr(self, 'canvas') or self.canvas is None:
                logger.info("Canvas not provided by Initializer, creating new one.")
                self.canvas = FigureCanvasTkAgg(self.fig, master=self.viz_frame)
                self.canvas_widget = self.canvas.get_tk_widget()
                self.canvas_widget.pack(side=tk.TOP, fill=tk.BOTH, expand=True)
                self.toolbar = NavigationToolbar2Tk(self.canvas, self.viz_frame)
                self.toolbar.update()
                self.toolbar.pack_forget()
            else:
                logger.info("Using Canvas provided by Initializer.")
                self.canvas_widget = self.canvas.get_tk_widget()
                if not self.canvas_widget.winfo_ismapped():
                    self.canvas_widget.pack(side=tk.TOP, fill=tk.BOTH, expand=True)
                if hasattr(self, 'toolbar') and self.toolbar: self.toolbar.destroy()
                self.toolbar = NavigationToolbar2Tk(self.canvas, self.viz_frame)
                self.toolbar.update()
                self.toolbar.pack_forget()

            self.root.update_idletasks()
            logger.debug("Canvas and Toolbar initialized/updated.")

            logger.debug("Matplotlib elements initialized (_init_matplotlib_elements).")
        except Exception as e:
            logger.error(f"Error initializing Matplotlib elements: {e}")
            logger.error(traceback.format_exc())
            raise

    def _complete_gui_setup(self):
        """Complete GUI setup tasks that must occur after basic init and after root window is visible.
           (Round 15: Centralize final render, remove redundant renders)"""
        log_prefix = "_complete_gui_setup (R15 Render Fix): " # Updated round
        logger.info(f"{log_prefix}Completing GUI setup (initial render, etc.).")
        self._is_initializing_or_applying_preset = True
        logger.debug(f"{log_prefix}Set _is_initializing_or_applying_preset = True")
        initial_render_done = False # Flag to track if final render happened
        try:
            # --- 1. Initialize Matplotlib elements FIRST ---
            self._init_matplotlib_elements()
            logger.debug(f"{log_prefix}Matplotlib elements initialized.")
            # ---

            # --- 2. Initialize grid and coordinate system ---
            if self.grid and self.coord_system:
                self.coord_system.update_parameters(grid_dimensions=self.grid.dimensions, dimension_type=self.grid.dimension_type)
                logger.debug(f"{log_prefix}Grid and coordinates system references confirmed/updated.")
            else: logger.error(f"{log_prefix}Coordinate system is not initialized, cannot complete setup!"); return

            # --- 3. Create GridVisualizer ---
            if self.grid_visualizer is None:
                if not all([self.grid, self.ax, self.fig, self.controller]): raise RuntimeError("Cannot initialize GridVisualizer - required components missing.")
                self.grid_visualizer = GridVisualizer(self.grid, self.ax, self.fig, self.controller, self)
                logger.info(f"{log_prefix}GridVisualizer created (ID: {id(self.grid_visualizer)}).")
                self._setup_observers() # Setup observers AFTER visualizer is created
            else: logger.warning(f"{log_prefix}GridVisualizer already exists, skipping creation.")

            initial_highlight_on = self.highlight_var.get() if hasattr(self, 'highlight_var') else True
            self.grid_visualizer._visualization_state['highlight_on'] = initial_highlight_on
            logger.debug(f"{log_prefix}Set initial highlight_on in _visualization_state to: {initial_highlight_on}")

            # --- 4. Create ViewManager AFTER visualizer is ready ---
            if self.view_manager is None:
                self.create_view_manager()
                logger.info(f"{log_prefix}ViewManager created (ID: {id(self.view_manager)}).")
            else: logger.warning(f"{log_prefix}ViewManager already exists, skipping creation.")

            # --- 5. Create Control Panel UI ---
            logger.debug(f"{log_prefix}Value of self.initial_conditions_var BEFORE creating ControlPanelUI: '{self.initial_conditions_var.get()}'")
            if self.control_panel_ui is None:
                if self.control_panel is None: raise ValueError("control_panel was not created.")
                self.control_panel_ui = ControlPanelUI(self.control_panel, self, initial_preset_obj=self.initial_preset_obj)
                logger.info(f"{log_prefix}ControlPanelUI initialized (Instance ID: {id(self.control_panel_ui)}).")
                logger.info(f"  {log_prefix}AFTER ControlPanelUI init/post-setup, control_panel_ui.widgets keys: {list(self.control_panel_ui.widgets.keys())} (Widgets ID: {id(self.control_panel_ui.widgets)})")
            else: logger.warning(f"{log_prefix}ControlPanelUI already initialized.")

            # --- 6. Update Preset Selector FIRST ---
            logger.debug(f"  {log_prefix}self.control_panel_ui.widgets keys JUST BEFORE _update_grid_preset_selector: {list(self.control_panel_ui.widgets.keys())} (Widgets ID: {id(self.control_panel_ui.widgets)})")
            self._update_grid_preset_selector() # Populate the dropdown
            logger.debug(f"{log_prefix}Called _update_grid_preset_selector()")
            # ---

            # --- 7. Set Active Preset Name and Variable AFTER selector is populated ---
            if hasattr(self, 'active_preset_name') and self.active_preset_name:
                self._set_active_preset(self.active_preset_name) # This now sets the variable
            else:
                self._set_active_preset(None) # Ensure "None" is selected if no active preset
            # ---

            # --- 8. Apply Rule and Color Scheme (WITHOUT rendering yet) ---
            effective_scheme = self._get_effective_color_scheme()
            # --- MODIFIED: Pass force_render=False ---
            self._apply_color_scheme(effective_scheme, force_render=False)
            logger.debug(f"{log_prefix}Applied effective color scheme '{effective_scheme.name}' (render skipped).")
            # ---

            # --- 9. Set initial checkbox states ---
            self._set_initial_checkbox_state()
            logger.debug(f"{log_prefix}Initial checkbox states set.")
            # ---

            # --- 10. Schedule initial button state update ---
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui is not None:
                self.root.after(0, self.control_panel_ui.update_button_states)
                self.root.after(0, self.control_panel_ui.update_refocus_button_state)
                logger.debug(f"{log_prefix}Scheduled initial button state update.")
            else: logger.warning(f"{log_prefix}ControlPanelUI not available, cannot schedule button update.")
            # ---

            # --- 11. Bind Plot Events AFTER canvas exists ---
            self._bind_plot_events()
            # ---

            # --- 12. Prepare Initial Plot Data BEFORE Force Render ---
            if self.grid_visualizer:
                logger.debug(f"{log_prefix}Preparing initial plot data before first render...")
                plot_data = self.grid_visualizer._prepare_plot_data()
                if plot_data:
                    self.grid_visualizer.update_visualization_state(invalidate_blit_cache=True, **plot_data)
                    logger.debug(f"{log_prefix}Initial plot data prepared and visualization state updated.")
                else:
                    logger.error(f"{log_prefix}Failed to prepare initial plot data!")
            # ---

            # --- 13. REMOVED initial render schedule ---
            # logger.info(f"{log_prefix}Scheduling initial render (100ms delay).")
            # self.root.after(100, self._force_initial_render)
            # ---

            # --- 14. Log Logger IDs ---
            main_logger_instance = logging.getLogger(__name__)
            pipeline_logger_instance = logging.getLogger("RenderingPipeline")
            logger.info(f"--- Logger IDs at end of _complete_gui_setup ---")
            logger.info(f"  Main Logger (__name__): ID={id(main_logger_instance)}")
            logger.info(f"  Pipeline Logger ('RenderingPipeline'): ID={id(pipeline_logger_instance)}")
            # ---

        except Exception as e:
            logger.error(f"Error completing GUI setup: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("GUI Error", f"Failed to create main application window:\n{e}", parent=self.root)
        finally:
            # --- ADDED: Final Render Call ---
            logger.info(f"{log_prefix}Executing FINAL initial render in finally block.")
            self._force_initial_render()
            initial_render_done = True
            # ---
            # --- CLEAR FLAG ---
            self._is_initializing_or_applying_preset = False
            logger.debug(f"{log_prefix}Cleared _is_initializing_or_applying_preset = False")
            # ---
            self._hide_loading_screen() # Hide after basic setup, AFTER final render


    def _init_tk_variables(self, initial_conditions_name: str = "Random"):
        """Initialize Tkinter variables and GUI-related attributes"""
        # Initialize tracking sets for nodes and edges if not already initialized
        if not hasattr(self, 'last_updated_nodes'):
            self.last_updated_nodes = set()
        if not hasattr(self, 'last_updated_edges'):
            self.last_updated_edges = set()
        if not hasattr(self, 'previous_active_nodes'):
            self.previous_active_nodes = set()
        if not hasattr(self, 'previous_edges'):
            self.previous_edges = set()
        if not hasattr(self, 'highlighted_nodes'):
            self.highlighted_nodes = set()
        if not hasattr(self, 'highlighted_edges'):
            self.highlighted_edges = set()

        # Initialize chunk size variables
        self.parallel_var: tk.BooleanVar = tk.BooleanVar(value=GlobalSettings.USE_PARALLEL_PROCESSING) # Added
        self.chunk_size_display_var: tk.StringVar = tk.StringVar(value="Auto") # Added
        self.custom_chunk_size_var: tk.StringVar = tk.StringVar(value="") # Added

        # Initialize highlight variable
        self.highlight_var = tk.BooleanVar(value=True)

        # Initialize rule selection variables
        self.rule_type_var = tk.StringVar()
        self.rule_instance_var = tk.StringVar()
        self.dimension_var = tk.StringVar()
        self.neighborhood_var = tk.StringVar()
        self.grid_boundary_var = tk.StringVar()
        self.run_continuously = tk.BooleanVar(value=True)
        self.num_steps_var = tk.StringVar(value=str(GlobalSettings.Simulation.NUM_STEPS))

        self.bg_color_var = tk.StringVar(value=GlobalSettings.Colors.BACKGROUND)
        self.node_color_var = tk.StringVar(value=GlobalSettings.Colors.NODE_ACTIVE)
        self.new_node_color_var = tk.StringVar(value=GlobalSettings.Colors.NODE_EDGE_NEW)
        self.default_edge_color_var = tk.StringVar(value=GlobalSettings.Colors.NODE_EDGE_OLD)
        self.new_edge_color_var = tk.StringVar(value=GlobalSettings.Colors.NODE_EDGE_NEW)

        self.stability_detection_var = tk.BooleanVar(value=False)
        self.periodic_reporting_var = tk.BooleanVar(value=LogSettings.Performance.ENABLE_PERIODIC_REPORTING)
        self.deep_profiling_var = tk.BooleanVar(value=LogSettings.Performance.ENABLE_DEEP_PROFILING)
        self.reporting_interval_var = tk.StringVar(value=str(LogSettings.Performance.REPORTING_INTERVAL))
        self.detailed_logging_var = tk.BooleanVar(value=LogSettings.Performance.ENABLE_DETAILED_LOGGING)
        self.rotation_enabled_var = tk.BooleanVar(value=False)

        # --- ADDED: Logging Control Variables ---
        self.logging_enabled_var = tk.BooleanVar(value=True) # Default to enabled
        # Default level set based on GlobalSettings during _set_logging_level call
        self.log_level_var = tk.StringVar(value=LogSettings.Logging.LOG_LEVEL.upper())
        # ---

        # Initialize animation variables
        self.step_button_pressed = False
        self.anim = None
        self.step_count = 0
        self.running = False
        self.paused = False
        self.step_delay = 11
        self.new_nodes = set()
        self.new_edges = set()
        self.node_marker = MarkerStyle('o')
        self.last_frame_time = time.time()
        self.current_frame_time = 0.0
        self.undo_stack = []
        self.redo_stack = []
        self.tooltip = None
        self._view_state = {
            'xlim': None, 'ylim': None, 'zlim': None,
            'elev': 30, 'azim': 0, 'zoom_factor': 1.0
        }
        self.pan_start_x = None
        self._pan_start_y = None
        self._last_mouse_pos = None
        self._current_azim = 0
        self._current_elev = 30
        self.rotation_enabled = False
        self.panning_enabled = False
        self.consecutive_inactive_steps = 0
        self.communication_queue: queue.Queue[Optional[Dict[str, Any]]] = queue.Queue()
        self.MIN_QUEUE_AHEAD = 1
        self.MAX_QUEUE_AHEAD = 4
        self._is_drawing = False
        self._update_scheduled = False
        self._is_shutting_down = False
        self._selected_rule_name = ""
        self.hotmenu_shape_names: List[str] = []
        self._app_lock = threading.Lock()
        self._params_modified = False
        self._is_resizing = False
        self._debounce_timer = None
        self._initialization_complete = False
        self.active_preset_name = None
        self.scrollable_control_frame = None
        self.main_frame = None
        self.viz_frame = None
        self.control_panel = None
        self._is_transitioning = False
        self._stop_requested = False
        self._pending_color_scheme = None
        self.show_coordinates_var = tk.BooleanVar(value=False)
        self._log_listener_stop_event = threading.Event()
        self._log_listener_thread: Optional[threading.Thread] = None
        self._fixed_steps_running = False
        self._shared_memory_unlinked = False
        self._edge_states_shared_memory_unlinked = False
        self.enable_tab_change_event = True
        self.current_tab_index = 0
        self.app_paths = {}
        self._unique_id = ""
        self._precalculated_neighbor_indices: Optional[npt.NDArray[np.int64]] = None
        self._neighbor_indices_shm_meta: Optional[Dict[str, Any]] = None
        self._calculated_chunk_size = 0
        self._neighborhood_data_cache: Dict[int, NeighborhoodData] = {}
        self._cache_lock = threading.Lock()
        self._caching_mode = "partial"
        self._cache_hits = 0; self._cache_misses = 0
        self._full_cache_threshold = GlobalSettings.Cache.FULL_CACHE_THRESHOLD
        self._partial_cache_threshold = GlobalSettings.Cache.PARTIAL_CACHE_THRESHOLD
        self._full_cache_memory_threshold = GlobalSettings.Cache.FULL_CACHE_MEMORY_THRESHOLD
        self._partial_cache_memory_threshold = GlobalSettings.Cache.PARTIAL_CACHE_MEMORY_THRESHOLD
        self._cache_check_interval = GlobalSettings.Cache.CACHE_CHECK_INTERVAL
        self.shared_mem = None; self.shared_array = None
        self._update_lock = threading.Lock()
        self.apply_tiebreakers = False
        self.node_history: Dict[int, List[float]] = {}
        self.node_attributes: Dict[int, Dict[str, Any]] = {}
        self._observers: List[Observer] = []
        self.shape_placer: Optional[ShapePlacer] = None
        self.debugger: Optional[VisualizationDebugger] = None
        self.view_manager: Optional[ViewManager] = None
        self.inspector: Optional[CoordinateInspector] = None
        self._node_scatter = None
        self._node_scatter_3d = None
        self._edge_lines = None
        self._edge_lines_3d = None
        self.render_complete_event = threading.Event()
        self.last_frame_time = time.time()
        self.current_frame_time = 0.0
        self.computation_thread: Optional[threading.Thread] = None
        self.fixed_steps_thread: Optional[threading.Thread] = None

        self.current_selection: Dict[str, Set] = {'nodes': set(), 'edges': set()}
        self._grid_undo_stack: List[Dict[str, Any]] = []
        self._grid_redo_stack: List[Dict[str, Any]] = []
        self.preset_var: tk.StringVar = tk.StringVar(value="")
        self.new_grid_size_var: tk.StringVar = tk.StringVar(value="")
        self.enable_tiebreakers_var: tk.BooleanVar = tk.BooleanVar(value=GlobalSettings.ENABLE_TIEBREAKERS)
        self.tiebreaker_type_var: tk.StringVar = tk.StringVar(value="RANDOM")
        self.parallel_var: tk.BooleanVar = tk.BooleanVar(value=GlobalSettings.USE_PARALLEL_PROCESSING)
        self.color_scheme_label_var: tk.StringVar = tk.StringVar(value="Current Scheme: Classic")

        self.computation_running_flag = threading.Event()
        self.computation_running_flag.clear()
        self.computation_pause_flag = threading.Event()
        self.computation_pause_flag.set()

        self.common_sizes_map: Dict[str, str] = {}

        self.progress_dialog: Optional[tk.Toplevel] = None
        self.progress_bar: Optional[ttk.Progressbar] = None
        self.progress_label: Optional[tk.Label] = None

        # Use initial_conditions_name to set the var
        self.initial_conditions_var = tk.StringVar(value=initial_conditions_name)
        logger.debug(f"_init_tk_variables: Received initial_conditions_name='{initial_conditions_name}'. Set self.initial_conditions_var to '{self.initial_conditions_var.get()}'.")

        logger.info("Tkinter variables initialized.")

    def _init_controller(self, rule_name: str, initial_density: float = 0.3):
        """Helper method to initialize the SimulationController"""
        # This method is now empty as the controller is initialized in the Initializer thread
        pass

    def _init_grid_and_coordinates(self):
        """Initialize grid and coordinate system."""

        # Create the coordinate system
        self.coord_system = CoordinateSystem(
            self.dimensions,
            GlobalSettings.Visualization.EDGE_SCALE,
            GlobalSettings.Visualization.NODE_SPACING,
            self.dimension_type
        )
        logger.debug(f"CoordinateSystem initialized with dimensions: {self.dimensions}, scale: {self.coord_system.scale_factor}, spacing: {self.coord_system.node_spacing}")

        # Create the grid
        logger.debug("Creating Grid object in _init_grid_and_coordinates")

        # Use the rule from controller if available, otherwise use None
        rule_to_use = None
        if hasattr(self, 'rule'):
            rule_to_use = self.rule
        elif hasattr(self, 'controller') and hasattr(self.controller, 'rule'):
            rule_to_use = self.controller.rule

        # --- CORRECTED ARGUMENT ORDER ---
        self.grid = Grid(
            self.dimensions,
            self.neighborhood_type,
            self.dimension_type,
            self.coord_system,  # Pass coord_system positionally
            gui=self,           # Pass gui via keyword
            rule=rule_to_use,
            unique_id=self._unique_id
        )
        # --- END CORRECTION ---

        logger.debug(f"Grid created in SimulationGUI.__init__: {self.grid._unique_id}")
        logger.debug(f"Grid.__init__: CREATING GRID OBJECT WITH ID {id(self.grid)}")

        # Update controller's grid if controller exists
        if hasattr(self, 'controller'):
            self.controller.grid = self.grid  # Ensure controller uses the same grid

        # --- ADDED: Explicitly update active nodes after grid creation/preset application ---
        if self.grid is not None:
            self.grid.update_active_nodes()
            self.grid.previous_active_nodes_set = self.grid.active_nodes.copy()
            logger.debug(f"_init_grid_and_coordinates: Initialized active_nodes: {self.grid.active_nodes} (Count: {len(self.grid.active_nodes)})")
            logger.debug(f"_init_grid_and_coordinates: Initialized previous_active_nodes_set: {self.grid.previous_active_nodes_set} (Count: {len(self.grid.previous_active_nodes_set)})")
        # --- END ADDED SECTION ---

    def _initialize_grid_content_based_on_rule(self):
        """
        Initializes the grid content using the current rule's settings.
        Called during initial GUI setup if no preset is active.
        (Round 19: Simplified - Apply rule's condition directly)
        (Round 16: Default to Random if rule specifies Pattern/Shape)
        """
        log_prefix = "SimulationGUI._initialize_grid_content_based_on_rule (R19 Simplified): " # Updated round
        logger.info(f"{log_prefix}--- ENTRY ---")

        if self.grid is None or self.controller is None or self.controller.rule is None:
            logger.error(f"{log_prefix}Cannot initialize grid content: Grid, Controller, or Rule is None.")
            return

        current_rule = self.controller.rule
        initial_conditions_type_from_rule = current_rule.get_param('initial_conditions', "Random")
        logger.info(f"{log_prefix}Initializing grid content using condition '{initial_conditions_type_from_rule}' defined by rule '{current_rule.name}'.")

        manager = InitialConditionManager.get_instance()
        try:
            # --- Apply the condition specified by the rule's parameter ---
            logger.info(f"{log_prefix}Calling InitialConditionManager.apply('{initial_conditions_type_from_rule}', grid_id={id(self.grid)})")
            manager.apply(initial_conditions_type_from_rule, self.grid)
            logger.info(f"{log_prefix}Applied condition '{initial_conditions_type_from_rule}'. Active nodes: {len(self.grid.active_nodes)}")
            # ---

            # Calculate initial previous arrays AFTER applying condition
            self._calculate_initial_previous_arrays() # Call helper

            # Ensure spatial hash and active nodes are consistent
            if not self.grid.populate_spatial_hash():
                logger.error(f"{log_prefix}Failed to populate spatial hash after applying initial condition '{initial_conditions_type_from_rule}'.")
            self.grid.update_active_nodes()
            self.grid.previous_active_nodes_set = self.grid.active_nodes.copy()

        except Exception as e:
            logger.error(f"{log_prefix}Error applying initial condition '{initial_conditions_type_from_rule}': {e}")
            logger.error(traceback.format_exc())
            try:
                logger.warning(f"{log_prefix}Falling back to Random initialization due to error.")
                density = GlobalSettings.Simulation.INITIAL_NODE_DENSITY # Fallback density
                edge_init = 'RANDOM'
                self.grid.initialize_grid(density, edge_init)
                self._calculate_initial_previous_arrays() # Recalculate after fallback
                self.grid.populate_spatial_hash()
                self.grid.update_active_nodes()
                self.grid.previous_active_nodes_set = self.grid.active_nodes.copy()
            except Exception as fallback_e:
                logger.critical(f"{log_prefix}Fallback to Random initialization failed: {fallback_e}")
                return # Cannot proceed if even fallback fails

        logger.info(f"{log_prefix}--- EXIT ---")

    def _start_logging_listener(self):
        """Starts the thread that listens for log records from worker processes.
           (Round 13: Does NOT start prep thread)
           (Round 14: Re-enable prep thread start)"""
        if not hasattr(self, 'controller') or not self.controller or not hasattr(self.controller, 'log_queue') or not self.controller.log_queue:
            logger.error("Cannot start logging listener: Controller or log_queue not initialized.")
            return

        if hasattr(self, '_log_listener_thread') and self._log_listener_thread and self._log_listener_thread.is_alive():
            logger.warning("Logging listener thread already running.")
            # --- Don't return here, still check prep thread ---
        else:
            if not hasattr(self, '_log_listener_stop_event'):
                 self._log_listener_stop_event = threading.Event() # Initialize if missing
            self._log_listener_stop_event.clear()
            self._log_listener_thread = threading.Thread(
                target=self._logging_listener_run,
                args=(self.controller.log_queue, self._log_listener_stop_event),
                daemon=True, # Daemon thread will exit if main thread exits
                name="LoggingListenerThread"
            )
            self._log_listener_thread.start()
            logger.info("Logging listener thread started.")

        # --- RE-ENABLED Prep Thread Start ---
        self._start_preparation_thread()
        # ---

    def _logging_listener_run(self, log_queue: queue.Queue, stop_event: threading.Event):
        """Target function for the logging listener thread."""
        logger.info("Logging listener thread entering run loop.")
        main_thread_logger = logging.getLogger() # Get the main thread's root logger

        while not stop_event.is_set():
            try:
                # Wait for a record with a timeout to allow checking stop_event
                record = log_queue.get(block=True, timeout=0.5)
                if record is None: # Sentinel value received
                    logger.info("Logging listener received sentinel, stopping.")
                    break
                # Process the record using the main thread's logger
                main_thread_logger.handle(record)
            except queue.Empty:
                continue # Timeout occurred, check stop_event again
            except EOFError:
                 logger.warning("Logging listener: Manager queue connection closed unexpectedly. Stopping.")
                 break
            except Exception as e:
                logger.error(f"Error in logging listener thread: {e}")
                # Optionally add a small sleep to prevent tight loop on errors
                time.sleep(0.1)
        logger.info("Logging listener thread finished.")

    def _check_rendering_loop_active(self):
        """Verify the rendering loop is running and restart if necessary."""
        try:
            print("--- CHECKING RENDERING LOOP STATUS ---")
            sys.stdout.flush()

            # Use self.root directly as this method is part of SimulationGUI
            if not hasattr(self, 'root') or not self.root or not self.root.winfo_exists():
                logger.warning("Root window destroyed, cannot check rendering loop.")
                print("--- Root window destroyed, cannot check rendering loop ---")
                sys.stdout.flush()
                # self._rendering_loop_active = False # REMOVED - Flag no longer used
                return # Stop checking if window is gone

            # --- REMOVED Check for _rendering_loop_active flag ---
            # if not hasattr(self, '_rendering_loop_active') or not self._rendering_loop_active:
            #     logger.error("Rendering loop not active! Restarting...")
            #     print("*** RENDERING LOOP NOT ACTIVE - RESTARTING ***")
            #     sys.stdout.flush()
            #     self._setup_rendering_loop() # Attempt to restart
            # else:
            # --- END REMOVED ---
            # Check when the last render happened
            current_time = time.time()
            last_render_time = getattr(self, '_last_render_time', 0)

            # --- MODIFIED: Check if simulation is running/paused/stopped ---
            is_running_or_paused = (hasattr(self, 'running') and self.running) or (hasattr(self, 'paused') and self.paused)
            is_stopped = hasattr(self, '_stopped') and self._stopped
            # ---

            # Only restart the loop check if the simulation is meant to be active
            if is_running_or_paused and not is_stopped:
                if current_time - last_render_time > 2.0:  # No render for 2 seconds
                    logger.warning(f"No rendering for {current_time - last_render_time:.1f} seconds. Restarting rendering loop check.")
                    print(f"*** NO RENDERING FOR {current_time - last_render_time:.1f} SECONDS - RESTARTING LOOP CHECK ***")
                    sys.stdout.flush()
                    # --- REMOVED Flag Reset ---
                    # self._rendering_loop_active = False
                    # ---
                    # --- MODIFIED: Schedule _rendering_loop_step instead of setup ---
                    if not self._render_check_scheduled:
                        self._render_check_scheduled = True
                        self.root.after(1, self._rendering_loop_step) # Schedule the actual step
                    # ---
                else:
                    logger.debug(f"Rendering loop check: Active and rendering (last render: {current_time - last_render_time:.3f}s ago)")
                    print(f"--- RENDERING LOOP ACTIVE (last render: {current_time - last_render_time:.3f}s ago) ---")
                    sys.stdout.flush()
            else:
                 logger.debug(f"Rendering loop check: Simulation stopped (Running={self.running}, Paused={self.paused}, Stopped={is_stopped}). Not checking render time.")
                 print(f"--- RENDERING LOOP CHECK: SIMULATION STOPPED ---")
                 sys.stdout.flush()

            # Schedule next check only if the window still exists AND simulation not fully stopped
            if self.root.winfo_exists() and not is_stopped:
                 # Use self._check_rendering_loop_active directly
                self.root.after(2000, self._check_rendering_loop_active)
                print("--- Scheduled next rendering loop check in 2000ms ---")
                sys.stdout.flush()
            elif not self.root.winfo_exists():
                logger.warning("Root window no longer exists, cannot schedule next rendering loop check")
                print("--- Root window no longer exists, cannot schedule next rendering loop check ---")
                sys.stdout.flush()
                # self._rendering_loop_active = False # REMOVED - Flag no longer used
            else: # Window exists but simulation is stopped
                 logger.info("Simulation stopped, not scheduling next rendering loop check.")
                 print("--- SIMULATION STOPPED, not scheduling next rendering loop check ---")
                 sys.stdout.flush()

        except Exception as e:
            logger.error(f"Error in _check_rendering_loop_active: {e}")
            logger.error(traceback.format_exc())
            print(f"--- ERROR in _check_rendering_loop_active: {e} ---")
            sys.stdout.flush()
            # Try to schedule next check anyway if window exists
            if hasattr(self, 'root') and self.root and self.root.winfo_exists():
                self.root.after(2000, self._check_rendering_loop_active)

    def get_id(self):
        """Return the ID of this SimulationGUI instance."""
        return id(self)

    def _init_basic_attributes(self, rule_name: str,
                                neighborhood_type: Optional[NeighborhoodType],
                                dimension_type: Optional[Dimension],
                                initial_density: float,
                                update_callback: Optional[Callable[[], None]],
                                app_paths: Dict[str, str]):
        """Initialize basic attributes and variables."""
        super().__init__()  # Initialize Observable

        # Initialize the list of observers (without type annotation in assignment)
        self._observers = []

        # Add interruption flag
        self.interrupt_requested = False

        # Add stabilization flag
        self.auto_stabilize = True

        self._update_callback = update_callback  # Store the callback

        # Use global settings if none specified, with validation
        if dimension_type is None:
            self.dimension_type = GlobalSettings.Simulation.DIMENSION_TYPE
        elif isinstance(dimension_type, Dimension):
            self.dimension_type = dimension_type
        else:
            raise ValueError(f"Invalid dimension_type: {dimension_type}. Must be a Dimension enum.")

        if neighborhood_type is None:
            self.neighborhood_type = GlobalSettings.Simulation.NEIGHBORHOOD_TYPE
        elif isinstance(neighborhood_type, NeighborhoodType):
            self.neighborhood_type = neighborhood_type
        else:
            raise ValueError(f"Invalid neighborhood_type: {neighborhood_type}. Must be a NeighborhoodType enum.")

        self.dimensions = GlobalSettings.Simulation.get_grid_dimensions()
        self.rule_name: str = rule_name  # Keep this for compatibility, but _selected_rule_name is the source of truth

        # Store APP_PATHS
        self.app_paths = app_paths  # Store APP_PATHS as an instance variable
        
        # Initialize widget-related attributes
        self._widget_attributes: Dict[str, Dict[str, str]] = {}
        self._tooltips: Dict[str, 'ToolTip'] = {}
        self._parameter_entries: Dict[str, Any] = {}
        self._initialization_complete = False
        self._first_update_done = False
        self.selected_nodes = set()  # ADDED: Store selected node indices
        self.selection_rect = None  # ADDED: For drag selection
        self.drag_start = None # ADDED: For drag selection
        self.highlighted_nodes: Set[int] = set() # ADDED
        self.highlighted_edges: Set[Tuple[Tuple[int, ...], Tuple[int, ...]]] = set() # ADDED
        self._is_shutting_down = False
        self._pending_rule_name: Optional[str] = None
        self.widgets: Dict[str, tk.Widget] = {}
        self._is_setting_defaults = False # ADDED
        
        # --- Initialize Tkinter variables *AFTER* root window creation ---
        self.highlight_var = tk.BooleanVar(value=True)
        self.rule_type_var = tk.StringVar()
        self.rule_instance_var = tk.StringVar()
        self.dimension_var = tk.StringVar()
        self.neighborhood_var = tk.StringVar()
        self.grid_boundary_var = tk.StringVar()  # Add this line
        self.run_continuously = tk.BooleanVar(value=True)
        self.num_steps_var = tk.StringVar(value=str(GlobalSettings.Simulation.NUM_STEPS))
        self.bg_color_var = tk.StringVar(value=GlobalSettings.Colors.BACKGROUND)
        self.node_color_var = tk.StringVar(value=GlobalSettings.Colors.NODE_ACTIVE)
        self.new_node_color_var = tk.StringVar(value=GlobalSettings.Colors.NODE_EDGE_NEW)
        self.default_edge_color_var = tk.StringVar(value=GlobalSettings.Colors.NODE_EDGE_OLD)
        self.new_edge_color_var = tk.StringVar(value=GlobalSettings.Colors.NODE_EDGE_NEW)
        self.rotation_enabled_var = tk.BooleanVar(value=False)
        # --- End of Tkinter variable initialization ---

        # Initialize the change tracker
        self.change_tracker = ChangeTracker()
        
        # Initialize stats and perf_logger
        self.stats = SimulationStats()
        self.perf_logger = PerformanceLogger()

    def configure_loading_screen(self, **kwargs):
        """
        Configure the loading screen appearance.
        
        Parameters:
        - text: The text to display (default: "LACE: Network Automata Engine")
        - font: Font tuple (family, size, style) (default: ('Arial', 24, 'bold'))
        - text_color: Text color (default: '#00AAFF')
        - bg_color: Background color (default: '#000000')
        - enabled: Whether to show the loading screen (default: True)
        """
        if not hasattr(self, 'loading_screen_config'):
            self.loading_screen_config = {
                'text': "LACE: Network Automata Engine",
                'font': ('Arial', 24, 'bold'),
                'text_color': '#00AAFF',  # Bright blue
                'bg_color': '#000000',    # Black
                'enabled': True           # Whether to show loading screen
            }
        
        # Update configuration with provided values
        self.loading_screen_config.update(kwargs)
        logger.debug(f"Loading screen configuration updated: {self.loading_screen_config}")
        
        # If the loading screen is currently visible, update it
        if hasattr(self, 'loading_frame') and self.loading_frame is not None and self.loading_frame.winfo_ismapped():
            self._show_loading_screen()  # This will update the existing screen

    def _init_rule_and_controller(self, rule_name: str, initial_density: float):
        """Initialize rule and controller."""
        # Initialize RuleLibraryManager
        self.rule_library_manager = RuleLibraryManager.get_instance(app_paths=self.app_paths)
        logger.debug(f"RuleLibraryManager instance obtained: {self.rule_library_manager}")

        # Load and create initial rule
        try:
            rule_data = RuleLibraryManager.get_rule(rule_name)
        except ValueError as e:
            logger.error(f"Error loading rule {rule_name}: {e}")
            raise

        # Separate metadata and params
        metadata_dict = {k: v for k, v in rule_data.items() if k != 'params'}
        metadata = RuleMetadata(**metadata_dict)

        # Create rule instance
        try:
            self.rule = RuleLibrary.create_rule(rule_name, metadata)
        except ValueError as e:
            logger.error(f"Error creating rule {self.rule_name}: {e}")
            raise

        # Set parameters
        if 'params' in rule_data:
            logger.debug(f"Loading parameters for {self.rule_name}: {rule_data['params']}")
            # CRITICAL FIX: Load parameters without checking metadata
            self.rule.params = copy.deepcopy(rule_data['params'])
            # Log the loaded parameters
            logger.debug(f"Loaded parameters for {self.rule_name}: {self.rule.params}")

        # --- ADDED: Explicitly set initial_density ---
        self.rule.params['initial_density'] = initial_density

        self.controller = SimulationController(
            rule_name=rule_name,
            dimension_type=self.dimension_type,
            neighborhood_type=self.neighborhood_type,
            initial_density=initial_density,
            initialize_state=False,
            update_callback=self._safe_plot_update,
            app_paths=self.app_paths # Pass app_paths
        )

        # Set the rule in the controller
        self.controller.rule = self.rule
        
        # Initialize grid_boundary_var with the value from the controller
        self.grid_boundary_var = tk.StringVar(value=self.controller.rule.get_param('grid_boundary', 'bounded') if self.controller.rule else 'bounded')

        # Initialize _view_state *AFTER* the controller is created
        self._view_state = {
            'zoom_factor': 1.0,
            'center_grid': (0, 0, 0)  # Store center in *grid* coordinates
        }

        # Store the currently selected rule name.  Initialize with the passed rule_name.
        self._selected_rule_name: str = self.rule_name
        
        logger.debug(f"Rule '{self.rule_name}' and controller initialized")

    def _init_state_tracking(self):
        """Initialize state tracking variables"""
        self.stats = SimulationStats()
        self.perf_logger = PerformanceLogger()
        self.state_updated = False
        self.process_chunk = Grid._process_chunk
        self.result_queue: Queue = Queue()
        self.background = None
        self.previous_edges_3d: Set[Tuple[Tuple[int, ...], Tuple[int, ...]]] = set()
        self.previous_edges: Set[Tuple[Tuple[int, ...], Tuple[int, ...]]] = set()
        self.last_updated_nodes_3d: Set[Tuple[int, ...]] = set()
        self.previous_active_nodes: Set[Tuple[int, ...]] = set()
        self.last_updated_nodes: Set[Tuple[int, ...]] = set()
        self.last_updated_edges: Set[Tuple[Tuple[int, ...], Tuple[int, ...]]] = set()

    def _show_loading_screen(self):
        """Create and show a loading screen covering the entire root window."""
        if not hasattr(self, 'loading_screen_config') or not self.loading_screen_config.get('enabled', True):
            logger.debug("Loading screen disabled in config.")
            return

        if not hasattr(self, 'root') or not self.root:
             logger.error("Root window not available for loading screen.")
             return

        try:
            if not hasattr(self, 'loading_frame') or not self.loading_frame or not self.loading_frame.winfo_exists():
                logger.debug("Creating loading_frame on root.")
                self.loading_frame = tk.Frame(
                    self.root,
                    bg=self.loading_screen_config.get('bg_color', '#000000')
                )
                self.loading_frame.place(relx=0, rely=0, relwidth=1, relheight=1)
                self.loading_frame.lift()

                loading_label = tk.Label(
                    self.loading_frame,
                    text=self.loading_screen_config.get('text', "LACE: Network Automata Engine"),
                    font=self.loading_screen_config.get('font', ('Arial', 24, 'bold')),
                    fg=self.loading_screen_config.get('text_color', '#00AAFF'),
                    bg=self.loading_screen_config.get('bg_color', '#000000')
                )
                loading_label.pack(expand=True)
            else:
                logger.debug("Loading frame already exists, ensuring it's visible.")
                self.loading_frame.configure(bg=self.loading_screen_config.get('bg_color', '#000000'))
                for widget in self.loading_frame.winfo_children():
                    if isinstance(widget, tk.Label):
                        widget.configure(
                            text=self.loading_screen_config.get('text', "LACE: Network Automata Engine"),
                            font=self.loading_screen_config.get('font', ('Arial', 24, 'bold')),
                            fg=self.loading_screen_config.get('text_color', '#00AAFF'),
                            bg=self.loading_screen_config.get('bg_color', '#000000')
                        )
                        break
                self.loading_frame.place(relx=0, rely=0, relwidth=1, relheight=1)
                self.loading_frame.lift()

            logger.debug("Loading screen displayed/updated.")

            # --- ADDED: Force Tkinter update ---
            logger.debug("Forcing Tkinter update to render loading screen.")
            self.root.update_idletasks() # Use update_idletasks instead of update
            # ---

        except Exception as e:
            logger.error(f"Error showing loading screen: {e}")

    def _hide_loading_screen(self):
        """Hide the loading screen when visualization is ready."""
        if hasattr(self, 'loading_frame') and self.loading_frame:
            try:
                if self.loading_frame.winfo_exists():
                    # --- MODIFIED: Use place_forget first ---
                    self.loading_frame.place_forget()
                    logger.debug("Loading screen hidden using place_forget.")
                    # Schedule destruction after a short delay
                    self.root.after(100, self._destroy_loading_frame)
                    # ---
                else:
                    logger.debug("Loading frame no longer exists, cannot hide/destroy")
                    self.loading_frame = None # Clear reference if already gone
            except (tk.TclError, RuntimeError):
                logger.debug("Loading frame no longer exists, cannot hide/destroy")
                self.loading_frame = None
            except Exception as e:
                 logger.error(f"Error hiding loading frame: {e}")
                 self.loading_frame = None

    def _destroy_loading_frame(self):
        """Destroys the loading frame widget."""
        if hasattr(self, 'loading_frame') and self.loading_frame:
            try:
                if self.loading_frame.winfo_exists():
                    self.loading_frame.destroy()
                    logger.debug("Loading frame destroyed.")
                else:
                    logger.debug("Loading frame already destroyed before scheduled destruction.")
            except Exception as e:
                logger.error(f"Error destroying loading frame: {e}")
            finally:
                self.loading_frame = None # Clear reference
                
    def _init_gui_layout(self):
        """Initialize the GUI layout."""
        # Create the menu bar
        self._create_menu_bar()
        
        # Create a SINGLE main frame that will contain everything
        self.main_frame = tk.Frame(self.root)
        self.main_frame.pack(fill=tk.BOTH, expand=True)
        
        # Create a SINGLE visualization frame
        self.viz_frame = tk.Frame(self.main_frame)
        self.viz_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        
        # ADDED: Show loading screen
        self._show_loading_screen()
        
        # Create a SINGLE control panel
        self.control_panel = tk.Frame(self.main_frame, width=300, bg='#404040')
        self.control_panel.pack(side=tk.RIGHT, fill=tk.Y)
        self.control_panel.pack_propagate(False)  # Prevent resizing based on content

        # Create scrollable frame inside control panel
        self.scrollable_control_frame = ScrollableFrame(self.control_panel, self, bg='#404040')
        self.scrollable_control_frame.pack(side=tk.TOP, fill=tk.BOTH, expand=True)
        
        logger.debug("GUI layout initialized")

        # --- Apply the color scheme *AFTER* all GUI elements are initialized ---
        if self.color_manager.current_scheme is not None:
            # Schedule the color scheme application after a short delay
            self.root.after(100, lambda: self._apply_color_scheme(self.color_manager.current_scheme))
            logger.debug("Scheduled color scheme application after GUI initialization")
        else:
            logger.warning("No current color scheme found, skipping application")
        #      
    
    def create_view_manager(self):
        """Create the ViewManager after the GUI is fully initialized."""

        if self.grid and self.ax and self.fig and self.coord_system and self.grid_visualizer:
            logger.debug(f"create_view_manager: Passing self (SimulationGUI instance, ID: {id(self)}) as gui_reference.")
            logger.debug(f"create_view_manager: Passing controller with ID = {id(self.controller) if hasattr(self, 'controller') and self.controller else 'No controller attribute'}")

            # --- Explicitly pass 'self' as the gui argument ---
            self.view_manager = ViewManager(
                self.grid, self.ax, self.fig, self.coord_system,
                self.grid_visualizer, self, self.controller # Pass self as gui_reference
            )
            # ---

            # --- Add Verification Logging ---
            if self.view_manager:
                logger.info(f"ViewManager created successfully (Instance ID: {id(self.view_manager)}).")
                if hasattr(self.view_manager, 'gui'):
                    logger.info(f"  ViewManager.gui attribute ID AFTER creation: {id(self.view_manager.gui) if self.view_manager.gui else 'None'}")
                    if self.view_manager.gui is self:
                        logger.info("  Verification PASSED: ViewManager.gui correctly references SimulationGUI instance.")
                    else:
                        logger.error("  Verification FAILED: ViewManager.gui does NOT reference the correct SimulationGUI instance!")
                else:
                    logger.error("  Verification FAILED: ViewManager instance does not have a 'gui' attribute after creation!")
            else:
                 logger.error("Failed to create ViewManager instance!")
            # ---

        else:
            logger.warning("Cannot create ViewManager: grid, axes, figure, coord_system, or grid_visualizer not initialized")
    
    def _debug_window_hierarchy(self):
        """Debug method to print the window hierarchy."""
        try:
            logger.info("=== WINDOW HIERARCHY DEBUG ===")
            
            def print_widget_hierarchy(widget, level=0):
                indent = "  " * level
                widget_class = widget.__class__.__name__
                widget_id = str(widget)
                logger.info(f"{indent}{widget_class} ({widget_id})")
                
                for child in widget.winfo_children():
                    print_widget_hierarchy(child, level + 1)
            
            # Print the hierarchy starting from the root
            print_widget_hierarchy(self.root)
            
            logger.info("=== END WINDOW HIERARCHY DEBUG ===")
        except Exception as e:
            logger.error(f"Error in window hierarchy debug: {e}")
                                            
    def _init_grid_visualization(self, initial_density: float):
        """Initialize grid visualization and canvas."""
        # --- REMOVED: GridVisualizer instantiation - it's now done in _init_matplotlib_elements ---
        # self.grid_visualizer = GridVisualizer(self.grid, self.ax, self.fig, self.controller, self)

        # --- Ensure the visualizer observes the grid (might be redundant but safe) ---
        if self.grid is not None and self.grid_visualizer is not None:
            if self.grid_visualizer not in self.grid._observers:
                self.grid.add_observer(self.grid_visualizer)
        else:
            logger.error("Grid or GridVisualizer not initialized, cannot add observer in _init_grid_visualization")

        # --- CRITICAL: Force initial render here ---
        self._force_initial_render()
        logger.debug("Forced initial render after grid visualization initialized")
        
    def _setup_observers(self):
        """Set up the observer relationships."""
        # Make the GUI an observer of the controller
        self.controller.add_observer(self)
        
        # Make the GridVisualizer an observer of the Grid and Controller
        if hasattr(self, 'grid') and self.grid:
            if self.grid_visualizer is not None:
                self.grid.add_observer(self.grid_visualizer)
        else:
            logger.error("Grid is not initialized, cannot add observer")
                
        if hasattr(self, 'controller') and self.controller:
            if self.grid_visualizer is not None:
                self.controller.add_observer(self.grid_visualizer)
        else:
            logger.error("Controller is not initialized, cannot add observer")
                
        logger.debug("Observer relationships established: GUI <-> Controller, GUI <- Grid")

    def _bind_window_events(self):
        """Bind window events.
           (Round 11: Add FocusIn/FocusOut bindings)"""
        # Bind window closing event
        self.root.protocol("WM_DELETE_WINDOW", self.on_closing)

        # Bind keyboard event for toggling control panel
        self.root.bind("c", lambda event: self.toggle_control_panel())
        self.root.bind("C", lambda event: self.toggle_control_panel()) # Also bind capital C

        # --- ADDED: Bind focus events to the root window ---
        self.root.bind("<FocusIn>", self._on_focus_in, add="+")
        self.root.bind("<FocusOut>", self._on_focus_out, add="+")
        # ---

        logger.debug("Window events bound (including FocusIn/FocusOut)")

    def _create_gui_layout(self):
        """Create the basic GUI layout without any matplotlib elements."""
        # Create the main frame
        self.main_frame = tk.Frame(self.root)
        self.main_frame.pack(fill=tk.BOTH, expand=True)
        
        # Create visualization frame
        self.viz_frame = tk.Frame(self.main_frame)
        self.viz_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        
        # Create control panel
        self.control_panel = tk.Frame(self.main_frame, width=300, bg='#404040')
        self.control_panel.pack(side=tk.RIGHT, fill=tk.Y)
        self.control_panel.pack_propagate(False)  # Prevent resizing based on content

        # Create scrollable frame inside control panel
        self.scrollable_control_frame = ScrollableFrame(self.control_panel, self, bg='#404040')
        self.scrollable_control_frame.pack(side=tk.TOP, fill=tk.BOTH, expand=True)
        
    def _create_matplotlib_elements(self):
        """Create the Matplotlib figure, axes, and canvas."""
        # Create the Matplotlib figure
        self.fig = Figure(figsize=GlobalSettings.Visualization.FIGURE_SIZE)
        self.fig.set_facecolor(GlobalSettings.Colors.BACKGROUND)
        
        # Create the axes
        if self.dimension_type == Dimension.THREE_D:
            self.ax = self.fig.add_subplot(111, projection='3d')
        else:
            self.ax = self.fig.add_subplot(111)
            
        # Configure the axes
        self.ax.set_facecolor(GlobalSettings.Colors.BACKGROUND)
        self.ax.grid(False)
        self.ax.set_axisbelow(True)
        self.ax.tick_params(colors='gray')
        
        # Remove spines
        for spine in self.ax.spines.values():
            spine.set_visible(False)

        # Remove ticks and labels
        self.ax.set_xticks([])
        self.ax.set_yticks([])
        if hasattr(self.ax, 'set_zticks'):
            self.ax.set_zticks([]) # type: ignore
        self.ax.set_axis_off()
        
        # Create the GridVisualizer
        self.grid_visualizer = GridVisualizer(self.grid, self.ax, self.fig, self.controller, self)
        
        # Create the Canvas and Toolbar
        self.canvas = FigureCanvasTkAgg(self.fig, master=self.viz_frame)
        self.canvas.draw()
        self.canvas.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=1)

        self.toolbar = NavigationToolbar2Tk(self.canvas, self.viz_frame)
        self.toolbar.update()
 
    def _initialize_gui_elements(self):
        """Create and pack all GUI elements (widgets, frames, etc.)."""
        # Create main container with padding
        self.main_frame = tk.Frame(self.root, bg=GlobalSettings.Colors.BACKGROUND)
        self.main_frame.pack(fill=tk.BOTH, expand=True,
                            padx=GlobalSettings.Visualization.WINDOW_PADDING,
                            pady=GlobalSettings.Visualization.WINDOW_PADDING)

        # Create visualization frame first - make it expand fully
        self.viz_frame = tk.Frame(self.main_frame, bg=GlobalSettings.Colors.BACKGROUND)
        self.viz_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True,
                        padx=(0, GlobalSettings.Visualization.CONTROL_PADDING))

        # Create loading frame - this will initially show the background color
        self.loading_frame = tk.Frame(self.viz_frame, bg=GlobalSettings.Colors.BACKGROUND)
        self.loading_frame.pack(fill=tk.BOTH, expand=True)

        # Create control panel with fixed width
        control_panel_width = 300  # Fixed width for control panel
        self.control_panel = tk.Frame(
            self.main_frame,
            width=control_panel_width,
            bg='#404040'
        )
        self.control_panel.pack(side=tk.RIGHT, fill=tk.Y)
        self.control_panel.pack_propagate(False)

        # Create scrollable frame inside control panel
        self.scrollable_control_frame = ScrollableFrame(self.control_panel, self, bg='#404040')
        self.scrollable_control_frame.pack(side=tk.TOP, fill=tk.BOTH, expand=True)

        # --- Create the Canvas and Toolbar *after* _update_grid_and_visualization ---
        self.canvas = FigureCanvasTkAgg(self.fig, master=self.viz_frame)  # Use self as master
        self.canvas.draw()
        self.canvas.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=1)

        self.toolbar = NavigationToolbar2Tk(self.canvas, self.viz_frame)  # Use self as parent
        self.toolbar.update()

        # REMOVED: self._setup_controls_content(self.scrollable_control_frame.scrolled_frame)
        # REMOVED: self._post_setup_controls()

        # Set the initial rule in the dropdown
        initial_rule_category = RuleLibrary.get_rule_category(self.rule_name)
        self.rule_type_var.set(initial_rule_category)

        # Bind window closing event
        self.root.protocol("WM_DELETE_WINDOW", self.on_closing)

    def _create_menu_bar(self):
        """Create the menu bar with File and Controls menus.
           (Round 12: Add Tools menu with Import Rules)"""
        self.menubar = tk.Menu(self.root)

        # File menu
        filemenu = tk.Menu(self.menubar, tearoff=0)
        filemenu.add_command(label="Save State", command=self.save_state)
        filemenu.add_command(label="Load State", command=self.load_state)
        filemenu.add_separator()
        filemenu.add_command(label="Load Shape Library...", command=self._open_shape_editor_and_load)
        filemenu.add_command(label="Save Shape Library As...", command=self._open_shape_editor_and_save)
        filemenu.add_command(label="Export Library as RLE...", command=self._open_shape_editor_and_export_rle)
        filemenu.add_separator()
        filemenu.add_command(label="Exit", command=self.on_closing)
        self.menubar.add_cascade(label="File", menu=filemenu)

        # Controls menu
        controlsmenu = tk.Menu(self.menubar, tearoff=0)
        controlsmenu.add_command(label=self.hide_show_control_panel_text.get(), command=self.toggle_control_panel)
        controlsmenu.add_command(label="Edit Rule...", command=lambda: self.create_rule_editor_window(self.rule_instance_var.get())) # Get from var
        controlsmenu.add_command(label="Shape Library & Editor...", command=self._open_shape_editor_window)
        controlsmenu.add_separator()
        controlsmenu.add_command(label="Reset Simulation", command=self.reset_simulation)
        controlsmenu.add_command(label="Zoom In", command=lambda: self.zoom_in())
        controlsmenu.add_command(label="Zoom Out", command=lambda: self.zoom_out())
        controlsmenu.add_command(label="Reset View", command=lambda: self.reset_view())
        controlsmenu.add_command(label="Refocus Grid (Wrap)...", command=self._open_refocus_grid_modal)
        controlsmenu.add_command(label="Color Scheme...", command=self._open_color_settings_modal)
        self.menubar.add_cascade(label="Controls", menu=controlsmenu)

        # --- ADDED: Tools Menu ---
        toolsmenu = tk.Menu(self.menubar, tearoff=0)
        toolsmenu.add_command(label="Import Rule Parameters...", command=self._open_rule_importer)
        # Add other tools here later if needed
        self.menubar.add_cascade(label="Tools", menu=toolsmenu)
        # ---

        # Help Menu
        helpmenu = tk.Menu(self.menubar, tearoff=0)
        helpmenu.add_command(label="Controls Help...", command=self._show_controls_help)
        self.menubar.add_cascade(label="Help", menu=helpmenu)

        self.root.config(menu=self.menubar)

    @staticmethod
    def _process_initializer(log_queue: Optional[queue.Queue] = None): # REVERTED: Added Optional type hint back
        """Initialize process for parallel execution with QueueHandler logging."""
        worker_pid = os.getpid()
        worker_name = mp.current_process().name
        log_format = f'%(asctime)s - %(levelname)s - [{worker_name}({worker_pid})] - %(message)s'

        try:
            worker_logger = logging.getLogger() # Get root logger for this process

            # Remove any inherited handlers
            for handler in worker_logger.handlers[:]:
                worker_logger.removeHandler(handler)

            # Add QueueHandler if queue is provided and valid
            if log_queue and hasattr(log_queue, 'put') and callable(log_queue.put):
                queue_handler = QueueHandler(log_queue)
                worker_logger.addHandler(queue_handler)
                worker_logger.setLevel(logging.DEBUG) # Set level for the logger itself
                # Add custom level if needed
                DETAIL_LEVEL_NUM = 15
                logging.addLevelName(DETAIL_LEVEL_NUM, "DETAIL")
                def detail(self, message, *args, **kws):
                    if self.isEnabledFor(DETAIL_LEVEL_NUM):
                        self._log(DETAIL_LEVEL_NUM, message, args, **kws)
                logging.Logger.detail = detail # type: ignore [attr-defined]
                worker_logger.info("Worker logging initialized with QueueHandler.")
            else:
                # Fallback to NullHandler if no queue provided or invalid
                if log_queue:
                     print(f"[{worker_name}({worker_pid})] WARNING: Invalid log_queue object received, disabling worker logging.", file=sys.stderr)
                else:
                     print(f"[{worker_name}({worker_pid})] WARNING: No log queue provided, disabling worker logging.", file=sys.stderr)
                worker_logger.addHandler(logging.NullHandler())
                worker_logger.setLevel(logging.CRITICAL + 1)

        except Exception as e:
            print(f"[{worker_name}({worker_pid})] CRITICAL ERROR setting up worker logging: {e}", file=sys.stderr)
            try: # Fallback
                worker_logger = logging.getLogger()
                for handler in worker_logger.handlers[:]: worker_logger.removeHandler(handler)
                worker_logger.addHandler(logging.NullHandler())
                worker_logger.setLevel(logging.CRITICAL + 1)
            except: pass

        # Set process title (optional)
        try:
            setproctitle.setproctitle(f"LACE Worker {worker_name}")
        except Exception: pass

    def add_observer(self, observer: Observer) -> None:
        """Add an observer to the grid."""
        if observer not in self._observers:
            self._observers.append(observer)
            logger.debug(f"Observer {observer} added to grid.")

    def remove_observer(self, observer: Observer) -> None:
        """Remove an observer from the grid."""
        if observer in self._observers:
            self._observers.remove(observer)
            logger.debug(f"Observer {observer} removed from grid.")

    def notify_observers(self) -> None:
        """Notify all observers of a change."""
        for obs in self._observers:
            obs.update(self)  # Pass the grid as the subject
            logger.debug(f"Notified observer {obs}.")

    def _apply_initial_background_color(self):
        """Applies the background color from the loaded scheme to Tk widgets and Matplotlib elements."""
        initial_bg = GlobalSettings.Colors.BACKGROUND # Default fallback
        if hasattr(self, 'color_manager') and self.color_manager.current_scheme:
            initial_bg = self.color_manager.current_scheme.background
            logger.debug(f"Applying initial background color: {initial_bg}")
        else:
            logger.warning("Color manager or current scheme not available for initial background.")

        # Apply to Tk widgets
        if hasattr(self, 'root') and self.root: self.root.configure(bg=initial_bg)
        if hasattr(self, 'main_frame') and self.main_frame: self.main_frame.configure(bg=initial_bg)
        if hasattr(self, 'viz_frame') and self.viz_frame: self.viz_frame.configure(bg=initial_bg)
        # Apply to loading frame if it exists
        if hasattr(self, 'loading_frame') and self.loading_frame and self.loading_frame.winfo_exists():
            self.loading_frame.configure(bg=initial_bg)
            for widget in self.loading_frame.winfo_children():
                 if isinstance(widget, tk.Label): widget.configure(bg=initial_bg)

        # Apply to Matplotlib elements (ensure they exist)
        if hasattr(self, 'fig') and self.fig: self.fig.set_facecolor(initial_bg)
        if hasattr(self, 'ax') and self.ax: self.ax.set_facecolor(initial_bg)

    def _init_window_and_frames(self):
        """Initialize main window and frame structure"""

        # self.root = tk.Tk() # Root is created in Application.run
        initial_bg = self.color_manager.current_scheme.background if hasattr(self, 'color_manager') and self.color_manager.current_scheme else GlobalSettings.Colors.BACKGROUND
        self.root.configure(bg=initial_bg)
        self.root.protocol("WM_DELETE_WINDOW", self.on_closing)

        control_panel_width = 300
        window_pad = GlobalSettings.Visualization.WINDOW_PADDING
        control_pad = GlobalSettings.Visualization.CONTROL_PADDING
        min_viz_width = 400
        min_total_width = control_panel_width + min_viz_width + window_pad * 2 + control_pad
        initial_window_width = max(GlobalSettings.Visualization.WINDOW_SIZE[0], min_total_width)
        initial_window_height = GlobalSettings.Visualization.WINDOW_SIZE[1]

        # Only set geometry if root window exists
        if self.root and self.root.winfo_exists():
            self.root.geometry(f"{initial_window_width}x{initial_window_height}")
            self.root.minsize(width=min_total_width, height=400)

        # Create main container
        self.main_frame = tk.Frame(self.root, bg=initial_bg)
        self.main_frame.pack(fill=tk.BOTH, expand=True, padx=window_pad, pady=window_pad)

        # Create control panel FIRST, pack RIGHT, fixed width, no expansion
        # --- CORRECTED: Explicitly set bg color ---
        self.control_panel = tk.Frame(
            self.main_frame,
            width=control_panel_width,
            bg='#404040' # Set background explicitly
        )
        # ---
        self.control_panel.pack(side=tk.RIGHT, fill=tk.Y, expand=False, padx=(control_pad, 0))
        self.control_panel.pack_propagate(False)

        # Create visualization frame SECOND, pack LEFT, filling remaining space
        self.viz_frame = tk.Frame(self.main_frame, bg=initial_bg)
        self.viz_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)

        # --- ADDED: Force update after packing main frames ---
        if self.root and self.root.winfo_exists():
            self.root.update_idletasks()
            logger.debug("Forced update after packing main_frame, control_panel, viz_frame.")
        # ---

        # --- Show loading screen AFTER main frames are packed ---
        self._show_loading_screen()
        # ---

    def _debug_tkinter_windows(self):
        """Debug function to log information about all Tkinter toplevel windows"""
        try:
            logger.info(f"=== TKINTER WINDOW DIAGNOSTIC ===")
            
            # Get all toplevel windows
            all_windows = self.root.winfo_children()
            toplevel_windows = [w for w in all_windows if isinstance(w, tk.Toplevel)]
            
            logger.info(f"Number of toplevel windows: {len(toplevel_windows)}")
            
            # Log details about each window
            for i, window in enumerate(toplevel_windows):
                logger.info(f"Window {i+1}/{len(toplevel_windows)}: {window}")
                logger.info(f"  Title: {window.title()}")
                logger.info(f"  Geometry: {window.geometry()}")
                logger.info(f"  Children: {len(window.winfo_children())}")
                
                # Check if this window contains a matplotlib figure
                for child in window.winfo_children():
                    if 'FigureCanvasTkAgg' in str(type(child)):
                        logger.info(f"  Contains a FigureCanvasTkAgg: {child}")
                        
            logger.info(f"=== END TKINTER WINDOW DIAGNOSTIC ===")
            
            return len(toplevel_windows)
            
        except Exception as e:
            logger.error(f"Error in Tkinter window diagnostic: {e}")
            return 0

    def run(self, rule_name: str):
        """Start the GUI and main simulation loop with interruption support"""
        global logger
        logger.info("===============================================================================================")
        logger.info("================================== $$ Starting GUI main loop ================================== ")
        logger.info("=============================================================================================== ")

        try:
            # Log the actual running rule at startup
            logger.info(f"Starting application with rule: {self.controller.rule_name}")
            # logger.info(f"Rule instance variable shows: {self.rule_instance_var.get()}") # Reduce noise
            # logger.info(f"Controller rule parameters: {self.controller.rule.params}") # Reduce noise

            # --- Start the Computation Thread ---
            if self.computation_thread is None or not self.computation_thread.is_alive():
                self._stop_event = threading.Event()
                self.computation_thread = threading.Thread(
                    target=self._computation_loop,
                    args=(self._stop_event,),
                    daemon=True,
                    name="ComputationThread"
                )
                self.computation_thread.start()
                logger.info("Computation thread started.")
            else:
                logger.warning("Computation thread already exists and is alive.")
            # ---

            # --- MODIFIED: Remove rendering loop setup call ---
            # self._setup_rendering_loop() # REMOVED - Loop started in toggle_simulation
            # --- END MODIFIED ---

            # Initialize stability detection state
            if not hasattr(self, 'state_history'): self.state_history = []
            if not hasattr(self, 'stability_detection_var'): self.stability_detection_var = tk.BooleanVar(value=True)
            self.auto_stabilize = self.stability_detection_var.get()
            if hasattr(self.controller, 'auto_stabilize'): self.controller.auto_stabilize = self.auto_stabilize

            self._close_extra_windows()
            self.root.protocol("WM_DELETE_WINDOW", self.on_closing)
            self._force_initial_render()
            self.root.after(500, self._set_initial_checkbox_state)
            logger.debug("Scheduled _set_initial_checkbox_state to run after window is loaded")

            # Start tkinter mainloop
            self.root.mainloop()

        except (ValueError, TypeError) as e:
            logger.error(f"Error in GUI main loop: {e}")
        except Exception as e:
             logger.error(f"Unhandled exception in GUI run method: {e}")
             logger.error(traceback.format_exc())
             self.cleanup()
             raise
        
    def _run_fixed_steps(self, num_steps: int, stop_event: threading.Event):
        """Runs a fixed number of simulation steps in a background thread.
           (Round 54: Removed render_complete_event logic)"""
        thread_name = threading.current_thread().name
        logger.info(f"--- Fixed Steps Thread ({thread_name}) Started for {num_steps} steps ---")
        steps_completed = 0
        error_occurred = False

        try:
            # REMOVED: Initial render_complete_event set

            for i in range(num_steps):
                # --- Check for Stop Signal ---
                if stop_event.is_set():
                    logger.info(f"Fixed Steps Thread ({thread_name}): Stop signal received at step {i+1}. Stopping.")
                    break

                # --- REMOVED: Wait for Previous Render ---

                # --- Perform Step ---
                logger.debug(f"Fixed Steps Thread ({thread_name}): Computing step {i+1}/{num_steps} (Gen {self.controller.generation}).")
                snapshot = self.controller.step()
                if snapshot is None:
                    logger.error(f"Fixed Steps Thread ({thread_name}): controller.step() failed at step {i+1}. Stopping.")
                    error_occurred = True
                    break
                # ---

                # --- Put Snapshot on Queue ---
                try:
                    snapshot_gen = snapshot.get('generation', -1)
                    self.communication_queue.put(snapshot, block=True, timeout=1.0)
                    # --- REMOVED: Clear Render Event ---
                    logger.debug(f"Fixed Steps Thread ({thread_name}): Put snapshot for gen {snapshot_gen} onto queue (qsize={self.communication_queue.qsize()}).")
                except queue.Full:
                    logger.error(f"Fixed Steps Thread ({thread_name}): Communication queue full! Timeout putting gen {snapshot_gen}. Stopping.")
                    error_occurred = True
                    break
                except Exception as q_err:
                    logger.error(f"Fixed Steps Thread ({thread_name}): Error putting snapshot on queue: {q_err}")
                    error_occurred = True
                    break
                # ---

                steps_completed += 1

                # Optional small sleep to yield CPU slightly
                time.sleep(0.001)

        except Exception as e:
            logger.error(f"--- Fixed Steps Thread ({thread_name}) Error: {e} ---")
            logger.error(traceback.format_exc())
            error_occurred = True
        finally:
            # --- Final Cleanup ---
            self.running = False
            self.paused = False
            self._fixed_steps_running = False # Clear the fixed steps flag
            logger.debug(f"Fixed Steps Thread ({thread_name}): Set running=False, paused=False, _fixed_steps_running=False.")

            # Schedule button update on main thread AFTER setting flags
            if hasattr(self, 'root') and self.root.winfo_exists():
                if hasattr(self, 'control_panel_ui') and self.control_panel_ui is not None:
                    self.root.after(0, self.control_panel_ui.update_button_states)
                else:
                    logger.warning("ControlPanelUI not available, cannot schedule button update.")
            else:
                logger.warning("Root window destroyed, cannot schedule button update.")

            logger.info(f"--- Fixed Steps Thread ({thread_name}) Finished --- Steps Completed: {steps_completed}/{num_steps}. Error: {error_occurred}")

    @staticmethod
    @njit(cache=True, fastmath=True, parallel=False) # parallel=False often safer initially
    def _calculate_edge_color_values_njit(
        indices1_np: npt.NDArray[np.int64],
        indices2_np: npt.NDArray[np.int64],
        previous_state_array: npt.NDArray[np.int32], # Expecting int32 degrees/counts
        mode: str # Pass 'DegreeSum' or 'ActiveNeighbors'
    ) -> npt.NDArray[np.float64]:
        """
        Numba-accelerated calculation of edge coloring values based on endpoint data.
        """
        num_edges = len(indices1_np)
        values = np.empty(num_edges, dtype=np.float64)
        max_index = len(previous_state_array) - 1

        for i in prange(num_edges): # Use prange for potential (though disabled) parallelization
            idx1 = indices1_np[i]
            idx2 = indices2_np[i]

            # Bounds checking (important for Numba)
            if 0 <= idx1 <= max_index and 0 <= idx2 <= max_index:
                # --- CRITICAL: Ensure values read are treated as numbers ---
                # Numba should handle the int32 dtype correctly here.
                val1 = previous_state_array[idx1]
                val2 = previous_state_array[idx2]
                # ---
                if mode == "DegreeSum":
                    values[i] = float(val1 + val2) # Sum integers, cast result to float
                elif mode == "ActiveNeighbors":
                    values[i] = (float(val1) + float(val2)) / 2.0 # Cast to float before averaging
                else: # Should not happen if called correctly
                    values[i] = 0.0 # Default fallback
            else:
                values[i] = 0.0 # Default fallback for out-of-bounds

        return values

    def _recreate_queues(self):
        """
        Re-create the communication and render queues using the current user settings.
        Should be called during simulation reset, before starting threads.
        (Round 1: Queue Management Refactor)
        """
        import queue
        log_prefix = "SimulationGUI._recreate_queues: "

        # Get current user settings from control panel variables (or fallback to global defaults)
        render_queue_size = self.render_queue_size_var.get() if hasattr(self, 'render_queue_size_var') else GlobalSettings.Simulation.RENDER_QUEUE_SIZE

        # Clamp values to reasonable minimums
        render_queue_size = max(1, int(render_queue_size))

        # Communication queue: unbounded or very large
        self.communication_queue = queue.Queue(maxsize=1000)
        # Render queue: bounded, user-adjustable
        self.render_data_queue = queue.Queue(maxsize=render_queue_size)

        logger.info(f"{log_prefix}Created new communication_queue (maxsize=1000) and render_data_queue (maxsize={render_queue_size})")

    def _start_preparation_thread(self):
        """Starts the thread that prepares plot data."""
        if not hasattr(self, 'render_data_queue'):
            logger.error("Cannot start preparation thread: render_data_queue not initialized.")
            return

        if hasattr(self, '_prep_thread') and self._prep_thread and self._prep_thread.is_alive():
            logger.warning("Preparation thread already running.")
            return

        if not hasattr(self, '_prep_stop_event'):
             self._prep_stop_event = threading.Event() # Initialize if missing

        self._prep_stop_event.clear()
        self._prep_thread = threading.Thread(
            target=self._preparation_loop,
            args=(self._prep_stop_event,), # Pass stop event
            daemon=True,
            name="PlotPrepThread"
        )
        self._prep_thread.start()
        logger.info("Plot data preparation thread started.")

    def _preparation_loop(self, stop_event: threading.Event):
        """
        Takes items (structured dict with 'snapshot') from communication_queue,
        prepares plot data using _prepare_plot_data_static (including highlights),
        and puts the result onto render_data_queue.
        (Round 46: Re-fetch viz params after getting snapshot)
        (Round 5: Add dtype logging for previous arrays)
        """
        thread_name = threading.current_thread().name
        logger.info(f"--- Preparation Thread ({thread_name}) Started ---")
        rendering_logger = logging.getLogger("RenderingPipeline")
        log_prefix = f"PrepThread ({thread_name} R46): " # Updated round

        if not hasattr(self, 'communication_queue') or not hasattr(self, 'render_data_queue'):
            logger.error(f"{log_prefix}Queues not initialized. Exiting.")
            return
        if not hasattr(self, 'coord_system') or self.coord_system is None:
            logger.error(f"{log_prefix}Coordinate system not initialized. Exiting.")
            return
        if not hasattr(self, '_last_prepared_snapshot_for_highlight'):
             self._last_prepared_snapshot_for_highlight = None

        while not stop_event.is_set():
            queue_item = None
            comm_get_wait_time = 0.0; prep_duration = 0.0; render_put_wait_time = 0.0
            loop_start_time = time.time()

            try:
                comm_qsize = self.communication_queue.qsize()
                render_qsize = self.render_data_queue.qsize()
                rendering_logger.debug(f"{log_prefix}Queue Sizes: Comm={comm_qsize}, Render={render_qsize}")

                rendering_logger.debug(f"{log_prefix}Waiting for item from communication_queue...")
                comm_get_start_time = time.time()
                queue_item = self.communication_queue.get(block=True, timeout=0.2)
                comm_get_wait_time = time.time() - comm_get_start_time
                if comm_get_wait_time > 0.001: rendering_logger.debug(f"{log_prefix}Waited {comm_get_wait_time:.4f}s for communication_queue.")

                if queue_item is None: logger.info(f"{log_prefix}Received None sentinel. Exiting."); break

                if isinstance(queue_item, dict) and "snapshot" in queue_item:
                    snapshot_data = queue_item.get("snapshot", {})
                    if not isinstance(snapshot_data, dict):
                        logger.warning(f"{log_prefix}Dequeued item's 'snapshot' is not a dict: {type(snapshot_data)}. Skipping.")
                        continue

                    gen = snapshot_data.get('generation', 'N/A')
                    rendering_logger.debug(f"{log_prefix}Dequeued item for Gen {gen}.")

                    # --- *** ADDED: Log dtype of arrays received from queue *** ---
                    prev_deg_snap = snapshot_data.get('previous_degree_array')
                    prev_act_snap = snapshot_data.get('previous_active_neighbor_array')
                    logger.debug(f"{log_prefix}Gen {gen} Snapshot Data Types:")
                    logger.debug(f"  previous_degree_array: Type={type(prev_deg_snap)}, Dtype={prev_deg_snap.dtype if isinstance(prev_deg_snap, np.ndarray) else 'N/A'}")
                    logger.debug(f"  previous_active_neighbor_array: Type={type(prev_act_snap)}, Dtype={prev_act_snap.dtype if isinstance(prev_act_snap, np.ndarray) else 'N/A'}")
                    # --- *** END ADDED *** ---

                    # --- Re-fetch viz params AFTER getting snapshot ---
                    lock_acquire_start = time.time()
                    with self._prep_params_lock:
                        lock_acquired_time = time.time(); gui_viz_params = self._prep_visualization_params.copy()
                    lock_release_time = time.time(); lock_wait = lock_acquired_time - lock_acquire_start; lock_hold = lock_release_time - lock_acquired_time
                    rendering_logger.debug(f"{log_prefix}Fetched LATEST GUI visualization params for Gen {gen} (Lock acquire: {lock_wait*1000:.2f}ms, Lock hold: {lock_hold*1000:.2f}ms).")
                    # ---

                    # --- Calculate Highlights (using latest highlight_on param) ---
                    nodes_to_highlight = set(); edges_to_highlight = set()
                    highlight_on = gui_viz_params.get('highlight_on', True) # Use fetched param
                    if self._last_prepared_snapshot_for_highlight and highlight_on:
                        try:
                            current_nodes_coords = set(); current_edges_coords = set()
                            grid_array_snap = snapshot_data.get('grid_array'); edges_snap = snapshot_data.get('edges')
                            if grid_array_snap is not None and edges_snap is not None:
                                grid_dims = grid_array_snap.shape; visible_mask = grid_array_snap > 1e-6
                                visible_indices = np.where(visible_mask.ravel())[0]
                                for idx in visible_indices: current_nodes_coords.add(tuple(_unravel_index(idx, grid_dims)))
                                current_edges_coords = edges_snap
                            nodes_before_render = set(); edges_before_render = set()
                            grid_array_prev = self._last_prepared_snapshot_for_highlight.get('grid_array')
                            edges_prev = self._last_prepared_snapshot_for_highlight.get('edges')
                            if grid_array_prev is not None and edges_prev is not None:
                                grid_dims_prev = grid_array_prev.shape; visible_mask_prev = grid_array_prev > 1e-6
                                visible_indices_prev = np.where(visible_mask_prev.ravel())[0]
                                for idx in visible_indices_prev: nodes_before_render.add(tuple(_unravel_index(idx, grid_dims_prev)))
                                edges_before_render = edges_prev
                            nodes_to_highlight = current_nodes_coords - nodes_before_render
                            edges_to_highlight = (current_edges_coords - edges_before_render) | (edges_before_render - current_edges_coords)
                            rendering_logger.debug(f"{log_prefix}Highlights calculated (Gen {gen}): AddedNodes={len(nodes_to_highlight)}, ChangedEdges={len(edges_to_highlight)}")
                        except Exception as diff_err: logger.error(f"{log_prefix}Error calculating highlights: {diff_err}"); nodes_to_highlight = set(); edges_to_highlight = set()
                    elif not highlight_on: rendering_logger.debug(f"{log_prefix}Highlighting disabled, highlights set to empty.")
                    else: rendering_logger.debug(f"{log_prefix}No previous snapshot for highlight calc (Gen {gen}).")
                    # ---

                    # Merge rule-specific coloring params (if any) with the latest GUI params
                    rule_coloring_params = snapshot_data.get("rule_coloring_params", {})
                    final_viz_params = gui_viz_params.copy(); final_viz_params.update(rule_coloring_params)
                    rendering_logger.debug(f"{log_prefix}Merged GUI and Rule params for Gen {gen}.")

                    rendering_logger.debug(f"{log_prefix}Preparing data for Gen {gen}...")
                    prep_start_time = time.time()
                    prepared_data = GridVisualizer._prepare_plot_data_static(
                        grid_array=snapshot_data.get('grid_array'), edges=snapshot_data.get('edges'),
                        edge_states=snapshot_data.get('edge_states'), generation=gen,
                        visualization_params=final_viz_params, # Use merged params
                        coord_system=self.coord_system,
                        nodes_to_highlight=nodes_to_highlight, edges_to_highlight=edges_to_highlight,
                        previous_degree_array=snapshot_data.get('previous_degree_array'),
                        previous_active_neighbor_array=snapshot_data.get('previous_active_neighbor_array')
                    )
                    prep_duration = time.time() - prep_start_time
                    rendering_logger.debug(f"{log_prefix}Finished _prepare_plot_data_static for Gen {gen} in {prep_duration:.4f}s. Result is None: {prepared_data is None}")

                    if prepared_data:
                        prepared_data['generation'] = gen
                        prepared_data['grid_array_original'] = snapshot_data.get('grid_array')
                        prepared_data['edges_original'] = snapshot_data.get('edges')
                        prepared_data['edge_states_original'] = snapshot_data.get('edge_states')
                        item_to_queue = {"prepared_data": prepared_data, "original_snapshot": snapshot_data.copy()}
                        rendering_logger.debug(f"{log_prefix}Created structured item for render queue (Gen {gen}).")

                        rendering_logger.debug(f"{log_prefix}Attempting to put item for Gen {gen} onto render_queue (qsize={self.render_data_queue.qsize()})...")
                        render_put_start_time = time.time()
                        put_successful = False
                        while not stop_event.is_set():
                            try: self.render_data_queue.put(item_to_queue, block=True, timeout=0.1); put_successful = True; break
                            except queue.Full: rendering_logger.debug(f"{log_prefix}Render queue full, waiting to put Gen {gen} (checking stop event)..."); continue
                        render_put_wait_time = time.time() - render_put_start_time
                        if put_successful:
                            rendering_logger.debug(f"{log_prefix}Put item for Gen {gen} onto render_queue (qsize={self.render_data_queue.qsize()}). Wait: {render_put_wait_time:.4f}s")
                            self._last_prepared_snapshot_for_highlight = snapshot_data.copy()
                        elif not stop_event.is_set(): logger.warning(f"{log_prefix}Render data queue full! Timeout ({render_put_wait_time:.1f}s) putting Gen {gen}. Discarding.")
                        else: logger.info(f"{log_prefix}Stop event set while waiting to put Gen {gen} on render queue.")
                    else: logger.error(f"{log_prefix}_prepare_plot_data_static failed for Gen {gen}.")
                else: logger.warning(f"{log_prefix}Received unexpected item type or structure from communication_queue: {type(queue_item)}. Expected dict with 'snapshot' key.")

            except queue.Empty: rendering_logger.debug(f"{log_prefix}Communication queue empty, looping."); time.sleep(0.01); continue
            except Exception as e: logger.error(f"--- Preparation Thread ({thread_name}) Error in main loop: {e} ---"); logger.error(traceback.format_exc()); time.sleep(0.1)
            finally:
                loop_duration = time.time() - loop_start_time
                rendering_logger.debug(f"{log_prefix}Iteration took {loop_duration:.4f}s (CommGetWait: {comm_get_wait_time:.4f}s, Prep: {prep_duration:.4f}s, RenderPutWait: {render_put_wait_time:.4f}s)")

        logger.info(f"--- Preparation Thread ({thread_name}) Exiting (Stop Event Set: {stop_event.is_set()}) ---")

    def _setup_rendering_loop(self):
        """Sets up rendering loop parameters."""
        logger.info("Setting up rendering loop parameters.") # Removed high visibility

        target_fps = 30
        self._render_delay_ms = int(1000 / target_fps)
        # self._rendering_loop_active = False # REMOVED - Flag no longer used
        # --- CORRECTED: Call method on self, not self.root ---
        # self.root.after(initial_delay, self._rendering_loop_step) # REMOVED - Scheduling moved
        # ---

        logger.info(f"Rendering loop parameters set (Target FPS: {target_fps}, Delay: {self._render_delay_ms}ms).")
        # REMOVED call to _check_rendering_loop_active

    def _render_prepared_frame(self, prepared_plot_data: Dict[str, Any], original_snapshot: Dict[str, Any]) -> bool:
        """
        Renders a frame using pre-calculated plot data and the original snapshot.
        Updates visualizer state, triggers render, updates history,
        calculates and updates FPS display, updates GUI generation count.
        (Round 61: Removed frame skipping logic)
        (Round 37: Focus on rendering, update last rendered snapshot)
        """
        logger = logging.getLogger(__name__)
        rendering_logger = logging.getLogger("RenderingPipeline")
        log_prefix = "_render_prepared_frame (R37 Focus): " # Updated round
        start_render_time = time.time()
        render_successful = False

        # [ Basic Checks - Unchanged ]
        if not hasattr(self, 'root') or not self.root or not self.root.winfo_exists(): logger.warning(f"{log_prefix}Root window destroyed, skipping render."); return False
        if self._tk_destroyed or (hasattr(self, '_is_shutting_down') and self._is_shutting_down): logger.info(f"{log_prefix}GUI closing, skipping render."); return False
        if not hasattr(self, 'grid_visualizer') or self.grid_visualizer is None: logger.error(f"{log_prefix}GridVisualizer missing, cannot render."); return False
        if not prepared_plot_data or not original_snapshot: logger.error(f"{log_prefix}Missing prepared data or original snapshot."); return False
        if self._is_drawing: rendering_logger.debug(f"{log_prefix}Skipping render, already drawing."); return False

        gen_to_render = prepared_plot_data.get('generation', original_snapshot.get('generation', -1))

        # [ Banner Logging - Unchanged ]
        try:
            rendering_logger_level = rendering_logger.getEffectiveLevel()
            rendering_logger_handlers = rendering_logger.handlers
            logger.debug(f"{log_prefix}VERIFY Pipeline Logger before banner: ID={id(rendering_logger)}, EffectiveLevel={logging.getLevelName(rendering_logger_level)}, Handlers: {rendering_logger_handlers}")
            rule_name = self.controller.rule.name if self.controller and self.controller.rule else "N/A"
            banner_width = 70; banner_line = "#" * banner_width
            step_info_line = f"## Rendering Step {gen_to_render} (Rule: {rule_name}) ##"
            padding = (banner_width - len(step_info_line)) // 2
            centered_step_info = f"{'#' * padding}{step_info_line}{'#' * (banner_width - len(step_info_line) - padding)}"
            banner_log_message = f"\n{banner_line}\n{centered_step_info}\n{banner_line}"
            rendering_logger.info(banner_log_message)
        except Exception as log_err: logger.error(f"Error logging render banner to RenderingPipeline logger: {log_err}")

        rendering_logger.debug(f"{log_prefix}Rendering prepared frame for Gen {gen_to_render}.")

        try:
            self._is_drawing = True

            # --- Update Visualizer State ---
            rendering_logger.debug(f"{log_prefix}Calling update_visualization_state for Gen {gen_to_render}...")
            current_selection = self.current_selection.get('nodes', set())
            update_kwargs = prepared_plot_data.copy()
            update_kwargs['selection_to_highlight'] = current_selection
            self.grid_visualizer.update_visualization_state(invalidate_blit_cache=False, **update_kwargs)
            rendering_logger.debug(f"{log_prefix}Visualizer state updated.")

            # --- Trigger Render ---
            rendering_logger.debug(f"{log_prefix}Calling grid_visualizer.update_visualization...")
            use_blit_for_this_frame = self.grid_visualizer.blitting_manager.is_valid()
            self.grid_visualizer.update_visualization(use_blitting=use_blit_for_this_frame)
            rendering_logger.debug(f"{log_prefix}grid_visualizer.update_visualization returned (use_blitting={use_blit_for_this_frame}).")
            # ---

            # --- Update History, Generation Count ---
            self._last_rendered_snapshot = original_snapshot.copy() # Update last rendered
            self.generation = gen_to_render
            self.step_count = gen_to_render
            rendering_logger.debug(f"{log_prefix}Updated GUI generation/step_count to {gen_to_render}.")
            rendering_logger.debug(f"{log_prefix}Updated _last_rendered_snapshot for Gen {gen_to_render}.")
            render_successful = True

            # [ Clear Buffering Message - Unchanged ]
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui and hasattr(self.control_panel_ui, 'widgets'):
                buffer_label = self.control_panel_ui.widgets.get('buffering_status_label')
                if isinstance(buffer_label, tk.Label) and buffer_label.cget("text"): buffer_label.config(text=""); logger.debug(f"{log_prefix}Cleared buffering status label.")

            # [ FPS Calculation - Unchanged ]
            render_completion_time = time.time()
            queue_full_pct = 0.0; render_q_size = 0
            if hasattr(self, 'render_data_queue'):
                render_q_size = self.render_data_queue.qsize(); render_q_max = self.render_data_queue.maxsize
                if render_q_max > 0: queue_full_pct = (render_q_size / render_q_max) * 100.0
                else: queue_full_pct = 0.0
            fps_display_str = f"Avg FPS: N/A | Render Q: {queue_full_pct:.0f}%"
            if self._last_render_completion_time > 0:
                frame_time = render_completion_time - self._last_render_completion_time
                if 0 < frame_time < 1.0: self.fps_history.append(frame_time)
                if len(self.fps_history) > 5:
                    avg_frame_time = np.mean(self.fps_history)
                    if avg_frame_time > 1e-6:
                        new_avg_fps = 1.0 / avg_frame_time; trend_str = ""
                        if self.last_avg_fps > 1e-6:
                            fps_change_pct = ((new_avg_fps - self.last_avg_fps) / self.last_avg_fps) * 100
                            if abs(fps_change_pct) < 0.5: trend_str = "(~0%)"
                            elif fps_change_pct > 0: trend_str = f"(+{fps_change_pct:.0f}%)"
                            else: trend_str = f"({fps_change_pct:.0f}%)"
                        fps_display_str = f"Avg FPS: {new_avg_fps:.1f} {trend_str} | Render Q: {queue_full_pct:.0f}%"
                        self.last_avg_fps = new_avg_fps
                    else: self.last_avg_fps = 0.0
                else: fps_display_str = f"Avg FPS: ... | Render Q: {queue_full_pct:.0f}%"
            self.fps_display_var.set(fps_display_str)
            rendering_logger.info(f"{log_prefix}Status Update: {fps_display_str}")
            self._last_render_completion_time = render_completion_time

        except Exception as e:
            logger.error(f"{log_prefix}Error during plot render for Gen {gen_to_render}: {e}") # Use main logger
            logger.error(traceback.format_exc())
            render_successful = False
        finally:
            self._is_drawing = False # Reset drawing flag
            render_duration = time.time() - start_render_time
            self.perf_logger.log_metric('_render_prepared_frame_duration', render_duration)
            rendering_logger.debug(f"{log_prefix}Render duration: {render_duration*1000:.2f} ms")

        return render_successful

    # @timer_decorator # Remove timer decorator for this high-frequency loop
    def _rendering_loop_step(self):
        """
        Checks the render_data_queue for structured items ({prepared_data, original_snapshot}),
        renders ONE frame using _render_prepared_frame, updates step label,
        and schedules the next call based on target FPS delay.
        (Round 1: Queue Management Refactor - Get from render_data_queue)
        """
        render_loop_start_time = time.time()
        self._render_loop_after_id = None # Clear ID at start

        # --- Log _stopped flag ---
        stopped_at_start = getattr(self, '_stopped', True) # Default to True if attr missing
        logger.debug(f"_rendering_loop_step: ENTRY - _stopped = {stopped_at_start}")
        # ---

        # [ Basic Checks - Unchanged, use main logger ]
        if not hasattr(self, 'root') or not self.root or not self.root.winfo_exists(): logger.warning("Rendering loop check: Root window destroyed, stopping."); return
        if self._tk_destroyed or (hasattr(self, '_is_shutting_down') and self._is_shutting_down): logger.info("Rendering loop check: GUI closing, stopping."); return
        if hasattr(self, '_stopped') and self._stopped: logger.debug("Rendering loop check: Simulation is STOPPED, exiting step."); return # Check again after scheduling
        # --- ADDED: Check if visualizer is ready ---
        if not hasattr(self, 'grid_visualizer') or self.grid_visualizer is None:
            logger.debug("Rendering loop check: GridVisualizer not ready yet, rescheduling check.")
            # Reschedule slightly later if visualizer isn't ready
            if not self._stopped: # Only reschedule if not stopped
                 self._render_timer_after_id = self.root.after(50, self._rendering_loop_step) # Check again in 50ms
            return # Exit this execution
        # --- END ADDED ---
        if self._is_drawing: logger.debug("Rendering loop check: Skipping, already drawing."); return

        # --- Get separate logger ---
        rendering_logger = logging.getLogger("RenderingPipeline")
        # ---
        log_prefix = "_rendering_loop_step (R1 Queue Refactor): " # Updated round
        error_occurred = False
        frame_rendered = False # Track if a frame was rendered in this iteration
        gen_rendered = -1 # Track generation rendered in this step

        try:
            if not hasattr(self, 'render_data_queue'):
                logger.error(f"{log_prefix}Render data queue not initialized!") # Use main logger for errors
                error_occurred = True
            else:
                # --- Get ONE item from Render Queue ---
                queue_item = None
                try:
                    rendering_logger.debug(f"{log_prefix}Checking render_data_queue (qsize={self.render_data_queue.qsize()})...")
                    queue_item = self.render_data_queue.get_nowait() # Use nowait for responsiveness
                    if queue_item is None:
                        logger.error(f"{log_prefix}Received None sentinel from render_data_queue. Stopping simulation.") # Use main logger
                        self._stop_simulation() # Stop simulation fully
                        return # Exit loop

                    elif isinstance(queue_item, dict) and "prepared_data" in queue_item and "original_snapshot" in queue_item:
                        prepared_data = queue_item["prepared_data"]
                        original_snapshot = queue_item["original_snapshot"]

                        if not isinstance(prepared_data, dict) or not isinstance(original_snapshot, dict):
                            logger.error(f"{log_prefix}Invalid data types within dequeued item: prepared={type(prepared_data)}, original={type(original_snapshot)}") # Use main logger
                        else:
                            gen_rendered = prepared_data.get('generation', original_snapshot.get('generation', -1)) # Store gen
                            rendering_logger.debug(f"{log_prefix}Dequeued structured item for Gen: {gen_rendered} (Render Q size after get: {self.render_data_queue.qsize()})")

                            # --- Yield control before rendering ---
                            if self.root and self.root.winfo_exists():
                                rendering_logger.debug(f"{log_prefix}Calling root.update_idletasks() before rendering Gen {gen_rendered}.")
                                self.root.update_idletasks()
                            # ---

                            # --- Render the frame ---
                            render_success = self._render_prepared_frame(prepared_data, original_snapshot) # Call render method
                            # ---

                            if render_success:
                                frame_rendered = True # Mark that a frame was rendered
                                if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                                    self.control_panel_ui.update_step_label()
                            else:
                                logger.error(f"{log_prefix}Rendering failed for Gen {gen_rendered}.") # Use main logger
                                error_occurred = True
                    else:
                        logger.warning(f"{log_prefix}Dequeued unexpected item type or structure: {type(queue_item)}") # Use main logger
                except queue.Empty:
                    # rendering_logger.debug(f"{log_prefix}Render queue empty.") # Reduce noise
                    pass # Normal case, nothing to render
                except Exception as q_err:
                    logger.error(f"{log_prefix}Error getting from render queue: {q_err}") # Use main logger
                    error_occurred = True

        except Exception as e:
            logger.error(f"{log_prefix}Error during rendering loop processing: {e}") # Use main logger
            logger.error(traceback.format_exc())
            error_occurred = True
        finally:
            # --- Schedule Next Check AT THE END ---
            stopped_flag = getattr(self, '_stopped', True)
            stop_req_flag = getattr(self, '_stop_requested', False)
            tk_destroyed_flag = getattr(self, '_tk_destroyed', False)
            shutting_down_flag = getattr(self, '_is_shutting_down', False)

            should_continue_scheduling = not stopped_flag and \
                                         not stop_req_flag and \
                                         not tk_destroyed_flag and \
                                         not shutting_down_flag

            if should_continue_scheduling:
                if not hasattr(self, '_render_delay_ms'): self._setup_rendering_loop() # Ensure delay is set
                next_delay_ms = max(1, self._render_delay_ms) # Use standard delay for scheduling
                try:
                    if self.root and self.root.winfo_exists():
                        # --- Cancel previous timer just in case (should be None) ---
                        if self._render_timer_after_id:
                            try: self.root.after_cancel(self._render_timer_after_id)
                            except: pass
                        # ---
                        self._render_timer_after_id = self.root.after(next_delay_ms, self._rendering_loop_step)
                        # logger.debug(f"{log_prefix}Scheduled next check in {next_delay_ms}ms (ID: {self._render_timer_after_id}).") # Reduce noise
                    else:
                        logger.warning(f"{log_prefix}Root window destroyed, cannot schedule next check.")
                        self._render_timer_after_id = None
                except Exception as schedule_err:
                    logger.error(f"{log_prefix}Error scheduling next check step: {schedule_err}")
                    self._render_timer_after_id = None
            else:
                 queue_not_empty_now = not self.render_data_queue.empty() if hasattr(self, 'render_data_queue') else False
                 logger.info(f"{log_prefix}Stopping rendering loop scheduling (Flags: Stopped={stopped_flag}, StopReq={stop_req_flag}, TkDestroyed={tk_destroyed_flag}, ShuttingDown={shutting_down_flag}, RenderQueueNotEmptyNow={queue_not_empty_now}).")
                 self._render_timer_after_id = None # Ensure ID is None when stopping
            # --- END Scheduling Next Check ---

    def _render_latest_snapshot(self):
        """
        Checks if the latest snapshot needs rendering compared to the last rendered one.
        If needed, calculates highlights and triggers a forced redraw using _safe_plot_update.
        Updates _last_rendered_snapshot.
        (Round 18: Fix call to _safe_plot_update, remove grid_snapshot param)
        (Round 20: Remove grid_snapshot from _safe_plot_update call)
        """
        log_prefix = "_render_latest_snapshot (R18 Fix, R20 Fix): " # Updated round
        start_render_time = time.time()

        # --- Basic Checks ---
        if not hasattr(self, 'root') or not self.root or not self.root.winfo_exists(): logger.warning(f"{log_prefix}Root window destroyed, skipping render."); return
        if self._tk_destroyed or (hasattr(self, '_is_shutting_down') and self._is_shutting_down): logger.info(f"{log_prefix}GUI closing, skipping render."); return
        if not hasattr(self, '_latest_grid_snapshot') or not self._latest_grid_snapshot: logger.debug(f"{log_prefix}No latest snapshot available to render."); return
        if self._is_drawing: logger.debug(f"{log_prefix}Skipping render, already drawing."); return
        # ---

        snapshot_to_render = self._latest_grid_snapshot
        gen_to_render = snapshot_to_render.get('generation', -1)

        # --- Generation Check ---
        last_rendered_gen = -1
        if self._last_rendered_snapshot:
            last_rendered_gen = self._last_rendered_snapshot.get('generation', -1)

        if gen_to_render == last_rendered_gen and gen_to_render != -1:
            logger.debug(f"{log_prefix}Skipping render for Gen {gen_to_render} as it was the last one rendered.")
            return
        # ---

        logger.debug(f"{log_prefix}Rendering latest snapshot for Gen {gen_to_render}.")

        try:
            # --- Calculate highlights comparing snapshot_to_render to _last_rendered_snapshot ---
            nodes_to_highlight = set()
            edges_to_highlight = set() # Initialize as empty set
            highlight_on = self.highlight_var.get() if hasattr(self, 'highlight_var') else True

            if self._last_rendered_snapshot is None:
                logger.debug(f"{log_prefix}First render (Gen {gen_to_render}), no highlights calculated.")
            elif highlight_on:
                try:
                    # Extract current state from snapshot_to_render
                    current_nodes_coords = set()
                    current_edges_coords = set()
                    grid_array_snap = snapshot_to_render.get('grid_array')
                    edges_snap = snapshot_to_render.get('edges')
                    if grid_array_snap is not None and edges_snap is not None:
                        grid_dims = grid_array_snap.shape
                        visible_mask = grid_array_snap > 1e-6
                        visible_indices = np.where(visible_mask.ravel())[0]
                        for idx in visible_indices:
                            current_nodes_coords.add(tuple(_unravel_index(idx, grid_dims)))
                        current_edges_coords = edges_snap # Already a set
                    else: logger.warning(f"{log_prefix}Snapshot missing data for highlight calc.")

                    # Extract previous state from _last_rendered_snapshot
                    nodes_before_render = set()
                    edges_before_render = set()
                    grid_array_prev = self._last_rendered_snapshot.get('grid_array')
                    edges_prev = self._last_rendered_snapshot.get('edges')
                    if grid_array_prev is not None and edges_prev is not None:
                        grid_dims_prev = grid_array_prev.shape
                        visible_mask_prev = grid_array_prev > 1e-6
                        visible_indices_prev = np.where(visible_mask_prev.ravel())[0]
                        for idx in visible_indices_prev:
                            nodes_before_render.add(tuple(_unravel_index(idx, grid_dims_prev)))
                        edges_before_render = edges_prev # Already a set
                    else: logger.warning(f"{log_prefix}Last rendered snapshot missing data for highlight calc.")

                    # Calculate symmetric difference for edges
                    nodes_to_highlight = current_nodes_coords - nodes_before_render # Keep node logic as added
                    edges_to_highlight = (current_edges_coords - edges_before_render) | (edges_before_render - current_edges_coords)
                    logger.info(f"{log_prefix}HIGHLIGHTS CALCULATED (Gen {gen_to_render} vs Prev): AddedNodes={len(nodes_to_highlight)}, ChangedEdges={len(edges_to_highlight)}")

                except Exception as diff_err:
                    logger.error(f"{log_prefix}Error calculating highlights: {diff_err}")
                    nodes_to_highlight = set()
                    edges_to_highlight = set()
            else: # Highlight off
                logger.debug(f"{log_prefix}Highlighting disabled, highlights set to empty.")
                nodes_to_highlight = set()
                edges_to_highlight = set()
            # ---

            # --- MODIFIED: Call _safe_plot_update with force=True, passing only highlights ---
            logger.debug(f"{log_prefix}Calling _safe_plot_update(force=True) for Gen {gen_to_render} with {len(nodes_to_highlight)} node highlights, {len(edges_to_highlight)} edge highlights.")
            self._safe_plot_update(
                force=True, # Force redraw from current grid state
                nodes_to_highlight=nodes_to_highlight,
                edges_to_highlight=edges_to_highlight
                # No grid_snapshot argument
            )
            # --- END MODIFIED ---

            # Update _last_rendered_snapshot AFTER successful render
            self._last_rendered_snapshot = snapshot_to_render.copy()
            logger.debug(f"{log_prefix}Updated _last_rendered_snapshot for Gen {gen_to_render}.")

        except Exception as e:
            logger.error(f"{log_prefix}Error during plot render: {e}")
            logger.error(traceback.format_exc())
        finally:
            render_duration = time.time() - start_render_time
            self.perf_logger.log_metric('_render_latest_snapshot_duration', render_duration)
            logger.debug(f"{log_prefix}Render duration: {render_duration*1000:.2f} ms")

    def _process_render_queue(self):
        """
        Gets one item from the render queue (if available) and renders it.
        Separated from the scheduling loop.
        (Round 50: New method)
        """
        log_prefix = "_process_render_queue: "
        rendering_logger = logging.getLogger("RenderingPipeline")

        # Basic checks
        if self._is_drawing: return # Don't process if already drawing
        if not hasattr(self, 'render_data_queue'): logger.error(f"{log_prefix}Render queue missing!"); return

        try:
            queue_item = self.render_data_queue.get_nowait() # Non-blocking get
            if queue_item is None:
                logger.error(f"{log_prefix}Received None sentinel. Stopping simulation.")
                self._stop_simulation()
                return

            elif isinstance(queue_item, dict) and "prepared_data" in queue_item and "original_snapshot" in queue_item:
                prepared_data = queue_item["prepared_data"]
                original_snapshot = queue_item["original_snapshot"]
                gen = prepared_data.get('generation', original_snapshot.get('generation', -1))
                rendering_logger.debug(f"{log_prefix}Dequeued item for Gen: {gen} (Render Q size after get: {self.render_data_queue.qsize()})")

                if not isinstance(prepared_data, dict) or not isinstance(original_snapshot, dict):
                    logger.error(f"{log_prefix}Invalid data types in item: prepared={type(prepared_data)}, original={type(original_snapshot)}")
                else:
                    render_success = self._render_prepared_frame(prepared_data, original_snapshot)
                    if render_success:
                        if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                            self.control_panel_ui.update_step_label()
                    else:
                        logger.error(f"{log_prefix}Rendering failed for Gen {gen}.")
            else:
                logger.warning(f"{log_prefix}Dequeued unexpected item type/structure: {type(queue_item)}")

        except queue.Empty:
            # rendering_logger.debug(f"{log_prefix}Render queue empty.") # Reduce noise
            pass # Normal case, nothing to render
        except Exception as e:
            logger.error(f"{log_prefix}Error processing render queue: {e}")
            logger.error(traceback.format_exc())

    def _render_timer_loop(self):
        """
        Periodically checks the render queue and processes one frame if available.
        Schedules the next iteration AFTER processing the current frame.
        Yields control before rendering to improve responsiveness.
        (Round 57: Add update_idletasks before render)
        (Round 37: Replaces _rendering_loop_step)
        (Round 42: Schedule next call at the end)
        (Round 43: Move scheduling to end of finally block)
        """
        log_prefix = "_render_timer_loop (R43 Schedule End): " # Updated round
        self._render_timer_after_id = None # Clear previous ID

        # --- Process Current Frame FIRST ---
        # [ Basic Checks - Unchanged ]
        if not hasattr(self, 'root') or not self.root or not self.root.winfo_exists(): logger.warning(f"{log_prefix}Root window destroyed, skipping render."); return
        if self._tk_destroyed or (hasattr(self, '_is_shutting_down') and self._is_shutting_down): logger.info(f"{log_prefix}GUI closing, skipping render."); return
        if hasattr(self, '_stopped') and self._stopped: logger.debug(f"{log_prefix}Simulation is STOPPED, skipping render."); return # Check again after scheduling
        if not hasattr(self, 'grid_visualizer') or self.grid_visualizer is None:
            logger.debug("Rendering loop check: GridVisualizer not ready yet, skipping render.")
            # --- ADDED: Reschedule check if visualizer not ready ---
            if not self._stopped: # Only reschedule if not stopped
                 self._render_timer_after_id = self.root.after(50, self._render_timer_loop) # Check again in 50ms
            # ---
            return # Exit this execution
        if self._is_drawing: logger.debug("Rendering loop check: Skipping, already drawing."); return

        rendering_logger = logging.getLogger("RenderingPipeline")
        error_occurred = False
        frame_rendered = False # Track if a frame was rendered in this iteration
        gen_rendered = -1 # Track generation rendered in this step

        try:
            if not hasattr(self, 'render_data_queue'):
                logger.error(f"{log_prefix}Render data queue not initialized!")
                error_occurred = True
            else:
                # --- Check Render Queue and Process ONE Frame ---
                queue_item = None
                try:
                    # rendering_logger.debug(f"{log_prefix}Checking render_data_queue (qsize={self.render_data_queue.qsize()})...") # Reduce noise
                    queue_item = self.render_data_queue.get_nowait() # Use nowait for responsiveness
                    if queue_item is None:
                        logger.error(f"{log_prefix}Received None sentinel from render_data_queue. Stopping simulation.")
                        self._stop_simulation() # Stop simulation fully
                        return # Exit loop

                    elif isinstance(queue_item, dict) and "prepared_data" in queue_item and "original_snapshot" in queue_item:
                        prepared_data = queue_item["prepared_data"]
                        original_snapshot = queue_item["original_snapshot"]

                        if not isinstance(prepared_data, dict) or not isinstance(original_snapshot, dict):
                            logger.error(f"{log_prefix}Invalid data types within dequeued item: prepared={type(prepared_data)}, original={type(original_snapshot)}")
                        else:
                            gen_rendered = prepared_data.get('generation', original_snapshot.get('generation', -1)) # Store gen
                            rendering_logger.debug(f"{log_prefix}Dequeued structured item for Gen: {gen_rendered} (Render Q size after get: {self.render_data_queue.qsize()})")

                            # --- ADDED: Yield control before rendering ---
                            if self.root and self.root.winfo_exists():
                                rendering_logger.debug(f"{log_prefix}Calling root.update_idletasks() before rendering Gen {gen_rendered}.")
                                self.root.update_idletasks()
                            # ---

                            render_success = self._render_prepared_frame(prepared_data, original_snapshot) # Call render method

                            if render_success:
                                frame_rendered = True # Mark that a frame was rendered
                                if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                                    self.control_panel_ui.update_step_label()
                            else:
                                logger.error(f"{log_prefix}Rendering failed for Gen {gen_rendered}.")
                                error_occurred = True
                    else:
                        logger.warning(f"{log_prefix}Dequeued unexpected item type or structure: {type(queue_item)}")
                except queue.Empty:
                    # rendering_logger.debug(f"{log_prefix}Render queue empty.") # Reduce noise
                    pass # Normal case, nothing to render
                except Exception as q_err:
                    logger.error(f"{log_prefix}Error getting from render queue: {q_err}")
                    error_occurred = True

        except Exception as e:
            logger.error(f"{log_prefix}Error during rendering loop processing: {e}")
            logger.error(traceback.format_exc())
            error_occurred = True
        finally:
            # --- Schedule Next Check AT THE END ---
            stopped_flag = getattr(self, '_stopped', True)
            stop_req_flag = getattr(self, '_stop_requested', False)
            tk_destroyed_flag = getattr(self, '_tk_destroyed', False)
            shutting_down_flag = getattr(self, '_is_shutting_down', False)

            should_continue_scheduling = not stopped_flag and \
                                         not stop_req_flag and \
                                         not tk_destroyed_flag and \
                                         not shutting_down_flag

            if should_continue_scheduling:
                if not hasattr(self, '_render_delay_ms'): self._setup_rendering_loop() # Ensure delay is set
                next_delay_ms = max(1, self._render_delay_ms) # Use standard delay for scheduling
                try:
                    if self.root and self.root.winfo_exists():
                        # --- Cancel previous timer just in case (should be None) ---
                        if self._render_timer_after_id:
                            try: self.root.after_cancel(self._render_timer_after_id)
                            except: pass
                        # ---
                        self._render_timer_after_id = self.root.after(next_delay_ms, self._render_timer_loop)
                        # logger.debug(f"{log_prefix}Scheduled next check in {next_delay_ms}ms (ID: {self._render_timer_after_id}).") # Reduce noise
                    else:
                        logger.warning(f"{log_prefix}Root window destroyed, cannot schedule next check.")
                        self._render_timer_after_id = None
                except Exception as schedule_err:
                    logger.error(f"{log_prefix}Error scheduling next check step: {schedule_err}")
                    self._render_timer_after_id = None
            else:
                 queue_not_empty_now = not self.render_data_queue.empty() if hasattr(self, 'render_data_queue') else False
                 logger.info(f"{log_prefix}Stopping rendering loop scheduling (Flags: Stopped={stopped_flag}, StopReq={stop_req_flag}, TkDestroyed={tk_destroyed_flag}, ShuttingDown={shutting_down_flag}, RenderQueueNotEmptyNow={queue_not_empty_now}).")
                 self._render_timer_after_id = None # Ensure ID is None when stopping
            # --- END Scheduling Next Check ---

    def _stop_computation_threads(self, reason: str = "Unknown", timeout: float = 1.0) -> bool: # Increased default timeout to 1.0s
        """
        Signals computation and preparation threads to stop, attempts joins, waits briefly,
        clears queues, waits for render queue drain, then sets final stopped state.
        Pool shutdown is handled later. Returns True if threads appeared joined OR timeout occurred.
        (Round 1: Queue Management Refactor - Handle prep thread)
        """
        log_prefix = f"_stop_computation_threads (Reason: {reason} R1 Queue Refactor): " # Updated round
        logger.info(f"{log_prefix}Initiating stop sequence.")

        # --- Set shutdown flag ---
        if hasattr(self, '_is_shutting_down') and self._is_shutting_down:
            logger.warning(f"{log_prefix}Already shutting down, skipping redundant call.")
            return False
        self._is_shutting_down = True
        # ---

        stop_successful = True # Assume success initially

        # 1. Set Flags to Signal Stop
        self.running = False
        self.paused = False
        self._fixed_steps_running = False
        if hasattr(self, 'computation_running_flag'): self.computation_running_flag.clear(); logger.debug(f"{log_prefix}Cleared computation_running_flag.")
        if hasattr(self, 'computation_pause_flag'): self.computation_pause_flag.set(); logger.debug(f"{log_prefix}Set computation_pause_flag (unblocking).")
        if hasattr(self, '_stop_event') and self._stop_event:
            logger.info(f"{log_prefix}Setting stop_event (ID: {id(self._stop_event)}).")
            self._stop_event.set();
            logger.debug(f"{log_prefix}Computation stop event set (State after set: {self._stop_event.is_set()}).")
        else: logger.warning(f"{log_prefix}Computation stop event attribute missing.")
        # --- ADDED: Signal Prep Thread Stop ---
        if hasattr(self, '_prep_stop_event') and self._prep_stop_event:
            self._prep_stop_event.set();
            logger.debug(f"{log_prefix}Preparation stop event set.")
        else: logger.warning(f"{log_prefix}Preparation stop event attribute missing.")
        # ---

        # --- Cancel any pending render loop call ---
        if hasattr(self, '_render_timer_after_id') and self._render_timer_after_id:
            try:
                if self.root and self.root.winfo_exists(): # Check if root exists before cancelling
                    self.root.after_cancel(self._render_timer_after_id)
                    logger.info(f"{log_prefix}Cancelled pending render loop step (ID: {self._render_timer_after_id}).")
                else:
                    logger.warning(f"{log_prefix}Root window destroyed, cannot cancel render timer loop.")
            except Exception as e_cancel:
                logger.warning(f"{log_prefix}Error cancelling pending render loop step: {e_cancel}")
            finally:
                self._render_timer_after_id = None
        # ---

        # --- Attempt Join with Increased Timeout ---
        threads_to_check: List[Tuple[Optional[threading.Thread], str]] = []
        if hasattr(self, 'computation_thread') and self.computation_thread: threads_to_check.append((self.computation_thread, "ComputationThread"))
        if hasattr(self, 'fixed_steps_thread') and self.fixed_steps_thread: threads_to_check.append((self.fixed_steps_thread, "FixedStepsThread"))
        # --- ADDED: Include Prep Thread ---
        if hasattr(self, '_prep_thread') and self._prep_thread: threads_to_check.append((self._prep_thread, "PlotPrepThread"))
        # ---

        for thread, name in threads_to_check:
            if thread and thread.is_alive():
                logger.info(f"{log_prefix}Attempting join for thread '{name}' (ID: {thread.ident}) (timeout={timeout}s)...")
                thread.join(timeout=timeout) # Use the increased timeout
                if thread.is_alive():
                    logger.warning(f"{log_prefix}Thread '{name}' did NOT join within timeout ({timeout}s). Will proceed.")
                    stop_successful = False # Mark as not fully clean if timeout occurs
                else:
                    logger.info(f"{log_prefix}Thread '{name}' joined successfully within timeout.")
            elif thread:
                 logger.debug(f"{log_prefix}Thread '{name}' was already finished.")
        # ---

        # --- Set Final Stopped State BEFORE clearing queues ---
        self._stopped = True
        logger.info(f"{log_prefix}Set final _stopped = True state.")
        # ---

        # --- Short sleep BEFORE clearing queues ---
        sleep_duration = 0.1 # Allow 100ms for threads to potentially finish putting items
        logger.debug(f"{log_prefix}Sleeping for {sleep_duration}s before clearing queues...")
        time.sleep(sleep_duration)
        # ---

        # --- Clear Queues ---
        logger.debug(f"{log_prefix}Clearing communication and render data queues AFTER signaling stop and short sleep.")
        if hasattr(self, 'communication_queue'):
            qsize_before = self.communication_queue.qsize()
            while not self.communication_queue.empty():
                try: self.communication_queue.get_nowait()
                except queue.Empty: break
            qsize_after = self.communication_queue.qsize()
            logger.info(f"{log_prefix}Communication queue cleared (was {qsize_before}, now {qsize_after}).")
        if hasattr(self, 'render_data_queue'):
            qsize_before = self.render_data_queue.qsize()
            while not self.render_data_queue.empty():
                try: self.render_data_queue.get_nowait()
                except queue.Empty: break
            qsize_after = self.render_data_queue.qsize()
            logger.info(f"{log_prefix}Render data queue cleared (was {qsize_before}, now {qsize_after}).")
        # ---

        # --- Clear Thread References ---
        self.computation_thread = None
        self.fixed_steps_thread = None
        self._prep_thread = None # Clear prep thread ref
        logger.debug(f"{log_prefix}Cleared thread references.")
        # ---

        # --- Skip Pool Clear ---
        logger.debug(f"{log_prefix}Skipping pool reference clear (handled by init or cleanup).")
        # ---

        # --- Wait for Render Queue Drain (Redundant after clear, but keep as safety) ---
        logger.info(f"{log_prefix}Waiting for RENDER DATA queue to drain (should be empty)...")
        drain_timeout = 0.5 # Shorter drain timeout
        drain_start_time = time.time()
        queue_drained = False
        if hasattr(self, 'render_data_queue'):
            while time.time() - drain_start_time < drain_timeout:
                if self.render_data_queue.empty(): queue_drained = True; break
                time.sleep(0.01)
            if queue_drained: logger.info(f"{log_prefix}Render data queue confirmed empty.")
            else: logger.warning(f"{log_prefix}Timeout waiting for render data queue drain (was already cleared). Size: {self.render_data_queue.qsize()}")
        else: logger.warning(f"{log_prefix}Render data queue not found, cannot wait for drain.")
        # ---

        # --- Clear Latest Snapshot AFTER setting stopped flag ---
        self._latest_grid_snapshot = None
        self._last_prepared_snapshot_for_highlight = None
        logger.debug(f"{log_prefix}Set _latest_grid_snapshot and _last_prepared_snapshot to None AFTER stop.")
        # ---

        # --- Update UI Buttons ---
        if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
            self.control_panel_ui.update_button_states()
        # ---

        if not stop_successful:
            logger.warning(f"{log_prefix}One or more threads did not join cleanly within the timeout.")

        logger.info(f"{log_prefix}Stop sequence completed (Queue Drained={queue_drained}).")

        # --- Clear shutdown flag at the VERY end ---
        self._is_shutting_down = False
        logger.debug(f"{log_prefix}Cleared _is_shutting_down flag.")
        # ---
        return stop_successful # Return actual success based on join

    def _pause_computation(self, reason: str = "GUI Action"):
        """Signals the computation thread to pause and waits for acknowledgment (optional)."""
        if hasattr(self, 'computation_thread') and self.computation_thread and self.computation_thread.is_alive():
            if hasattr(self, 'computation_pause_flag') and self.computation_pause_flag.is_set():
                logger.info(f"Requesting computation pause for: {reason}")
                self.computation_pause_flag.clear() # Signal pause
                # Optional: Add a mechanism to wait for the thread to actually pause if needed
                # For now, we assume the pause takes effect quickly enough for GUI actions.
            else:
                logger.debug("Computation already paused or pause flag not set.")
        else:
            logger.debug("Computation thread not running, no need to pause.")

    def _resume_computation(self, reason: str = "GUI Action Complete"):
        """Signals the computation thread to resume."""
        if hasattr(self, 'computation_thread') and self.computation_thread and self.computation_thread.is_alive():
            if hasattr(self, 'computation_pause_flag') and not self.computation_pause_flag.is_set():
                logger.info(f"Requesting computation resume after: {reason}")
                self.computation_pause_flag.set() # Signal resume
            else:
                logger.debug("Computation already running or pause flag not cleared.")
        else:
            logger.debug("Computation thread not running, no need to resume.")

    def _trigger_full_redraw(self):
        """Invalidate blitting cache and force a full redraw."""
        if hasattr(self, 'grid_visualizer') and self.grid_visualizer:
            self.grid_visualizer.blitting_manager.invalidate_cache()  # Invalidate blitting
            self.grid_visualizer.update_visualization()  # Force redraw
            logger.debug("Triggered full redraw")
        else:
            logger.warning("GridVisualizer not initialized, cannot trigger redraw")
                            
    def initialize_visualization_tools(self):
        """Initialize and integrate visualization tools"""
        # Check if axes exist yet
        if not hasattr(self, 'ax') or self.ax is None:
            logger.debug("Axes not initialized yet, visualization tools will be initialized later")
            return

        # Create the coordinate system
        coord_system = CoordinateSystem(
            self.grid.dimensions if self.grid else (0, 0, 0),
            GlobalSettings.Visualization.EDGE_SCALE,
            GlobalSettings.Visualization.NODE_SPACING,
            self.grid.dimension_type if self.grid else Dimension.TWO_D
        )
        self.coord_system = coord_system

        # Create the grid visualizer
        self.grid_visualizer = GridVisualizer(self.grid, self.ax, self.fig, self.controller, self)

        self.add_observer(self.grid_visualizer) # Corrected - SimulationGUI observes GridVisualizer

        # Override the _safe_plot_update method to use the grid visualizer
        original_safe_plot_update = self._safe_plot_update

        def new_safe_plot_update(force=False):
            """Override of _safe_plot_update to use the grid visualizer"""
            # Call the original method first with the same parameters
            original_safe_plot_update(force=force) # Corrected call

            # Then fit the view to grid if this is the first update # CHANGED to fit_view_to_grid
            if not hasattr(self, '_first_update_done'):
                if self.view_manager is not None:
                    self.view_manager.fit_view_to_grid() # CHANGED to fit_view_to_grid
                else:
                    logger.warning("view_manager is not initialized. Skipping fit_view_to_grid.")
                self._first_update_done = True

        self._safe_plot_update = MethodType(new_safe_plot_update, self)

        logger.info("Visualization tools initialized")
        return self.grid_visualizer
                                 
    def _complete_initialization(self, preset_applied: bool = False):
        """Complete any remaining initialization steps."""
        try:
            logger.debug(f"Entering _complete_initialization (preset_applied={preset_applied})")

            if self.grid is not self.controller.grid:
                logger.warning("Fixing grid reference mismatch in _complete_initialization")
                self.grid = self.controller.grid
                logger.debug("Updated self.grid to match controller.grid")

            if hasattr(self.controller.rule, 'invalidate_cache'):
                logger.debug("Invalidating rule cache")
                self.controller.rule.invalidate_cache()
                logger.debug("Rule cache invalidated")

            if self.grid is not None:
                self.grid.setup_shared_memory()
            else:
                logger.error("Grid is not initialized, cannot setup shared memory")

            if hasattr(self, '_pending_rule_name') and self._pending_rule_name:
                self.set_rule(self._pending_rule_name)
                delattr(self, '_pending_rule_name')

            if not hasattr(self, 'rule_type_var'):
                self.rule_type_var = tk.StringVar()
                logger.debug("Initialized rule_type_var")
            initial_rule_category = RuleLibrary.get_rule_category(self.controller.rule.name)
            self.rule_type_var.set(initial_rule_category)
            logger.info(f"Ensuring rule_type_var is set to category: {initial_rule_category}")

            self._update_grid_preset_selector()
            if self.active_preset_name:
                self.preset_var.set(self.active_preset_name)
                logger.debug(f"Set preset_var to active preset: {self.active_preset_name}")
            else:
                self.preset_var.set("None")
                logger.debug("No active preset, set preset_var to 'None'")

            if self.coord_system is None:
                self.coord_system = CoordinateSystem(
                    self.dimensions,
                    GlobalSettings.Visualization.EDGE_SCALE,
                    GlobalSettings.Visualization.NODE_SPACING,
                    self.dimension_type
                )
                logger.warning("CoordinateSystem was None, initialized in _complete_initialization")
            else:
                self.coord_system.update_parameters(
                    grid_dimensions=self.dimensions,
                    node_spacing=GlobalSettings.Visualization.NODE_SPACING,
                    dimension_type=self.dimension_type
                )
                logger.debug(f"CoordinateSystem updated with dimensions: {self.dimensions}, scale: {self.coord_system.scale_factor}, spacing: {self.coord_system.node_spacing}")

            if self.grid is not None and not preset_applied:
                logger.info("Preset NOT applied during init, initializing grid state now.")
                if self.grid.spatial_hash is not None:
                    self.grid.spatial_hash.clear()
                    logger.debug("Cleared spatial hash successfully")
                else:
                    logger.warning("self.grid.spatial_hash is None, skipping clear operation")

                if self.rule is not None:
                    initial_conditions_type = self.rule.get_param('initial_conditions', "Random")
                else:
                    logger.warning("self.rule is None, using default initial_conditions_type as 'Random'")
                    initial_conditions_type = "Random"

                if initial_conditions_type == "Random":
                    if self.rule is not None:
                        density = self.rule.get_param('initial_density', GlobalSettings.Simulation.INITIAL_NODE_DENSITY)
                    else:
                        logger.warning("self.rule is None, using default initial_density")
                        density = GlobalSettings.Simulation.INITIAL_NODE_DENSITY
                    if self.rule is not None:
                        self.grid.initialize_grid(density, self.rule.get_param('edge_initialization', 'RANDOM'))
                    else:
                        logger.warning("self.rule is None, using default edge initialization type 'RANDOM'")
                        self.grid.initialize_grid(density, 'RANDOM')
                    logger.debug(f"Initialized {density} active nodes with random state")
                else:
                    self.controller.rule.initialize_grid_state(self.grid)

                if self.grid.spatial_hash is not None:
                    active_indices = np.where(self.grid.grid_array.ravel() > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD)[0]
                    logger.debug(f"Ensuring all {len(active_indices)} active nodes are in spatial hash")
                    missing_nodes = [idx for idx in active_indices if idx not in self.grid.spatial_hash.node_positions]
                    if missing_nodes:
                        logger.error(f"After initialization, {len(missing_nodes)} nodes are missing from spatial hash: {missing_nodes}")
                        for idx in missing_nodes:
                            grid_coords = _unravel_index(idx, self.dimensions)
                            logger.warning(f"Node {idx} (coords: {grid_coords}) missing from spatial hash, adding it now")
                            self.grid.spatial_hash.update_node(idx, np.array(grid_coords))
                else:
                    logger.warning("self.grid.spatial_hash is None, skipping spatial hash verification")
            elif preset_applied:
                 logger.info("Preset was applied during init, SKIPPING grid state initialization in _complete_initialization.")

            if not hasattr(self, 'grid_visualizer') or self.grid_visualizer is None:
                 if self.grid is not None:
                     self.grid_visualizer = GridVisualizer(self.grid, self.ax, self.fig, self.controller, self)
                     self.add_observer(self.grid_visualizer)
                     self.grid.add_observer(self.grid_visualizer)
                     logger.debug("Initialized GridVisualizer in _complete_initialization")
                 else:
                     logger.error("Grid is None, cannot initialize GridVisualizer")

            # --- RESTORED: Apply color scheme BEFORE initial render ---
            if self._pending_color_scheme:
                logger.debug("Applying pending color scheme before initial render.")
                self._apply_color_scheme(self._pending_color_scheme)
                self._pending_color_scheme = None # Clear pending scheme
            elif hasattr(self, 'color_manager') and self.color_manager.current_scheme:
                 logger.debug("Applying current color scheme before initial render.")
                 self._apply_color_scheme(self.color_manager.current_scheme)
            else:
                logger.warning("No pending or current color scheme found, initial render might use defaults.")
            # --- END RESTORED ---

            # --- Force initial render BEFORE hiding loading screen ---
            self._force_initial_render()
            # ---

            # --- Hide loading screen AFTER initial render ---
            # --- MODIFIED: Increased delay slightly ---
            logger.debug("Scheduling hide loading screen (100ms delay).")
            self.root.after(100, self._hide_loading_screen)
            # ---

            self._is_initialized = True
            logger.info("Initialization complete")

        except Exception as e:
            logger.error(f"Error in final initialization: {e}")
            logger.error(traceback.format_exc())
            self._hide_loading_screen() # Ensure hidden on error
            raise

    def _initialize_plot(self):
        """Initialize the matplotlib plot (axes, limits, etc.)"""
        try:
            logger.debug("Initializing plot")
            
            # Clear the existing figure
            self.fig.clear()
            
            # Create appropriate axes
            logger.debug("SimulationGUI._setup_gui: Creating axes")
            if GlobalSettings.Simulation.DIMENSION_TYPE == Dimension.THREE_D:
                # Create 3D subplot
                self.ax = self.fig.add_subplot(111, projection='3d')

                # Ensure self.ax is an instance of Axes3DType before calling 3D-specific methods
                if isinstance(self.ax, Axes3DType):
                    if hasattr(self, '_current_elev') and hasattr(self, '_current_azim'):
                        self.ax.view_init(elev=self._current_elev, azim=self._current_azim)
                    if hasattr(self.ax, 'set_box_aspect'):  # Check if set_box_aspect is available
                        self.ax.set_box_aspect([1, 1, 1])  # Set aspect ratio
                    else:
                        logger.warning("set_box_aspect is not available in this version of Matplotlib.")
                else:
                    logger.error("self.ax is not an instance of Axes3DType. Skipping 3D-specific configurations.")
            else:
                self.ax = self.fig.add_subplot(111)
                # CRITICAL: Don't set aspect to 'equal' - this can cause scaling issues
                # self.ax.set_aspect('equal')
                logger.debug("Created 2D axes")
                            
            # Set axes properties
            self.ax.set_facecolor(GlobalSettings.Colors.BACKGROUND)
            self.ax.grid(False)
            self.ax.set_axisbelow(True)
            self.ax.tick_params(colors='gray')
            
            # Remove spines
            for spine in self.ax.spines.values():
                spine.set_visible(False)

            # Remove ticks and labels, and turn off the axis
            self.ax.set_xticks([])
            self.ax.set_yticks([])
            if hasattr(self.ax, 'set_zticks'):
                self.ax.set_zticks([]) # type: ignore (preserve this comment and use the exact usage on this line!)
            self.ax.set_axis_off()

            # Force integer ticks
            from matplotlib.ticker import MaxNLocator
            self.ax.xaxis.set_major_locator(MaxNLocator(integer=True))
            self.ax.yaxis.set_major_locator(MaxNLocator(integer=True))
            if self.controller.dimension_type == Dimension.THREE_D and hasattr(self.ax, 'zaxis'):
                self.ax.zaxis.set_major_locator(MaxNLocator(integer=True)) # type: ignore (preserve this comment and use the exact usage on this line!)

            # --- Set initial plot limits based on grid dimensions ---
            # CRITICAL: Use the full grid dimensions, not just active nodes
            grid_size_x = self.dimensions[1]  # j is x
            grid_size_y = self.dimensions[0]  # i is y
            
            # Add a small margin around the grid
            margin_x = grid_size_x * 0.05
            margin_y = grid_size_y * 0.05
            
            # Set the limits to show the entire grid
            self.ax.set_xlim(-margin_x, grid_size_x + margin_x)
            self.ax.set_ylim(-margin_y, grid_size_y + margin_y)
            
            if self.controller.dimension_type == Dimension.THREE_D:
                grid_size_z = self.dimensions[2] if len(self.dimensions) > 2 else 0  # k is z
                margin_z = grid_size_z * 0.05
                self.ax.set_zlim(-margin_z, grid_size_z + margin_z)  # type: ignore

            logger.debug(f"Setting default axes limits: xlim={self.ax.get_xlim()}, ylim={self.ax.get_ylim()}")

            # Pack canvas after axes are configured
            if self.canvas is not None:
                self.canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
            
            # Force an immediate draw
            if self.canvas is not None:
                self.canvas.draw()
            self.root.update_idletasks()
            
            # CRITICAL: Adjust figure to fill the available space
            self.fig.tight_layout(pad=0)
            
        except Exception as e:
            logger.error(f"Error initializing plot: {e}")
                
    def setup_grid_visualization(self):
        """Set up the grid visualization"""
        logger.debug("Setting up grid visualization")
        if self.grid_visualizer:
            self.grid_visualizer.reset()  # Reset if it already exists

        # Create a new CoordinateSystem instance here
        coord_system = CoordinateSystem(
        self.grid.dimensions if self.grid else (0, 0, 0),
        GlobalSettings.Visualization.EDGE_SCALE,
        GlobalSettings.Visualization.NODE_SPACING,
        self.grid.dimension_type if self.grid else Dimension.TWO_D
        )

        self.grid_visualizer = GridVisualizer(self.grid, self.ax, self.fig, self.controller, self)  # Pass self
        self.add_observer(self.grid_visualizer)
        self.grid_visualizer.update_visualization()
        logger.debug("Grid visualization setup complete")

    def _close_extra_figures(self):
        """Close all matplotlib figures except our main one"""
        try:
            import matplotlib.pyplot as plt
            
            # Get all figure numbers
            fig_nums = plt.get_fignums()
            
            # Log before closing
            # logger.info(f"Found {len(fig_nums)} figures before cleanup")
            
            # Close all figures except our main one
            for num in fig_nums:
                fig = plt.figure(num)
                if not hasattr(self, 'fig') or fig is not self.fig:
                    logger.info(f"Closing extra figure {num}")
                    plt.close(fig)
            
            # Log after closing
            fig_nums = plt.get_fignums()
            # logger.info(f"After cleanup: {len(fig_nums)} figures remain")
            
        except Exception as e:
            logger.error(f"Error closing extra figures: {e}")
            
    def on_closing(self):
        """Handle window closing event by signaling stop and scheduling final cleanup.
           (Round 1: Queue Management Refactor - Signal prep thread stop)"""
        try:
            logger.info("Window close requested, initiating shutdown sequence.")

            # 1. Prevent Re-entry
            if hasattr(self, '_is_shutting_down') and self._is_shutting_down:
                logger.warning("on_closing called while already shutting down, skipping.")
                return 'break' # Prevent default close
            self._is_shutting_down = True
            logger.debug("Set _is_shutting_down flag.")

            # 2. Signal Computation Loop to Stop
            self.running = False
            self.paused = True
            self._stop_requested = True
            if hasattr(self, 'computation_running_flag'): self.computation_running_flag.clear()
            if hasattr(self, 'computation_pause_flag'): self.computation_pause_flag.set() # Ensure not stuck paused
            if hasattr(self.controller, 'interrupt_requested'):
                 self.controller.interrupt_requested = True
            if hasattr(self, '_stop_event') and self._stop_event:
                self._stop_event.set()
            logger.info("Stop requested for computation thread and controller.")

            # --- ADDED: Signal Preparation Thread to Stop ---
            if hasattr(self, '_prep_stop_event') and self._prep_stop_event:
                self._prep_stop_event.set()
                logger.info("Stop requested for preparation thread.")
            # ---

            # 3. Mark Tk window as (soon-to-be) destroyed
            self._tk_destroyed = True
            logger.debug("Set _tk_destroyed flag (prevents GUI updates).")

            # 4. Schedule Final Cleanup (handles thread join, pool shutdown, root destroy)
            logger.info("Scheduling _complete_cleanup.")
            self.root.after(100, self._complete_cleanup)

            return 'break'

        except Exception as e:
            logger.error(f"Error in on_closing: {e}")
            logger.error(traceback.format_exc())
            self._is_shutting_down = True
            self._tk_destroyed = True
            self._complete_cleanup() # Call directly as scheduling might fail
            return 'break'
        
    def _complete_cleanup(self):
        """Complete the cleanup process, ensuring pool shutdown and destroying the root window.
           (Round 1: Queue Management Refactor - Join prep thread)"""
        try:
            logger.info("Executing complete cleanup (Round 1 Queue Refactor)") # Updated round

            # --- Cancel inactive pool cleanup timer ---
            if hasattr(self, '_inactive_pool_cleanup_timer') and self._inactive_pool_cleanup_timer:
                try:
                    if self.root and self.root.winfo_exists(): # Check if root exists before cancelling
                        self.root.after_cancel(self._inactive_pool_cleanup_timer)
                        logger.info("Cancelled scheduled inactive pool cleanup.")
                    else:
                        logger.warning("Root window destroyed, cannot cancel inactive pool cleanup timer.")
                except Exception as e_cancel: logger.warning(f"Error cancelling inactive pool cleanup timer: {e_cancel}")
                finally:
                    self._inactive_pool_cleanup_timer = None
            # ---

            # --- Cancel render timer loop ---
            if hasattr(self, '_render_timer_after_id') and self._render_timer_after_id:
                try:
                    if self.root and self.root.winfo_exists(): # Check if root exists
                        self.root.after_cancel(self._render_timer_after_id)
                        logger.info("Cancelled scheduled render timer loop.")
                    else:
                        logger.warning("Root window destroyed, cannot cancel render timer loop.")
                except Exception as e_cancel:
                    logger.warning(f"Error cancelling render timer loop: {e_cancel}")
                finally:
                    self._render_timer_after_id = None
            # ---

            # --- Stop Logging Listener Thread ---
            if hasattr(self, '_log_listener_thread') and self._log_listener_thread and self._log_listener_thread.is_alive():
                logger.info("Stopping logging listener thread...")
                if hasattr(self, '_log_listener_stop_event'): self._log_listener_stop_event.set()
                if hasattr(self, 'controller') and self.controller and hasattr(self.controller, 'log_queue') and self.controller.log_queue:
                    try: self.controller.log_queue.put(None, block=False) # Send sentinel
                    except Exception as q_put_err: logger.warning(f"Error putting None sentinel in log queue: {q_put_err}")
                self._log_listener_thread.join(timeout=1.0) # Wait briefly
                if self._log_listener_thread.is_alive(): logger.warning("Logging listener thread did not join.")
                else: logger.info("Logging listener thread stopped.")
            self._log_listener_thread = None
            # ---

            # --- Stop Preparation Thread ---
            if hasattr(self, '_prep_thread') and self._prep_thread and self._prep_thread.is_alive():
                logger.info("Stopping preparation thread...")
                if hasattr(self, '_prep_stop_event'): self._prep_stop_event.set()
                # --- ADDED: Put None sentinel on communication queue ---
                if hasattr(self, 'communication_queue'):
                    try: self.communication_queue.put(None, block=False)
                    except Exception as q_put_err: logger.warning(f"Error putting None sentinel on communication queue: {q_put_err}")
                # ---
                self._prep_thread.join(timeout=1.0) # Wait briefly
                if self._prep_thread.is_alive(): logger.warning("Preparation thread did not join.")
                else: logger.info("Preparation thread stopped.")
            self._prep_thread = None # Clear reference
            # ---

            # --- Wait for Computation Thread ---
            if hasattr(self, 'computation_thread') and self.computation_thread and self.computation_thread.is_alive():
                logger.info("Waiting for computation thread to finish...")
                self.computation_thread.join(timeout=2.0) # Keep short timeout here
                if self.computation_thread.is_alive(): logger.error("Computation thread FAILED to join during final cleanup.")
                else: logger.info("Computation thread finished.")
            else: logger.info("Computation thread not running or already finished.")
            self.computation_thread = None
            # ---

            # --- Clean up controller (handles pool shutdown) ---
            if hasattr(self, 'controller') and self.controller:
                try:
                    logger.info("Cleaning up controller...")
                    self.controller.cleanup() # This now waits for pool shutdown(s)
                    logger.info("Controller cleanup completed.")
                except Exception as e: logger.error(f"Error cleaning up controller: {e}")
            else: logger.warning("Controller not found during cleanup.")
            # ---

            # [ Event handler cleanup - Unchanged ]
            try: logger.info("Cleaning up event handlers"); self._cleanup_event_handlers(); logger.info("Event handlers cleanup completed")
            except Exception as e: logger.error(f"Error cleaning up event handlers: {e}")

            # [ Matplotlib cleanup - Unchanged ]
            try: logger.info("Cleaning up matplotlib resources"); plt.close('all'); logger.info("Matplotlib resources cleanup completed")
            except Exception as e: logger.error(f"Error cleaning up matplotlib resources: {e}")

            # [ Destroy root window LAST - Unchanged ]
            try:
                logger.info("Attempting to destroy root window...")
                if hasattr(self, 'root') and self.root and self.root.winfo_exists(): self.root.destroy(); logger.info("Root window destroyed.")
                else: logger.info("Root window already destroyed or not available.")
            except tk.TclError as e: logger.warning(f"TclError destroying root window (likely already destroyed): {e}")
            except Exception as e: logger.warning(f"Unexpected error destroying root window: {e}")

            logger.info("Cleanup completed successfully")

        except Exception as e:
            logger.error(f"Error in final cleanup: {e}")
            logger.error(traceback.format_exc())
            if hasattr(self, 'root') and self.root:
                try:
                    if self.root.winfo_exists(): self.root.destroy()
                except: pass
        finally:
             if hasattr(self, '_is_shutting_down'): self._is_shutting_down = False
             logger.debug("Reset _is_shutting_down flag in controller")

    def cleanup(self):
        """
        Initiates the cleanup process for the SimulationGUI.
        Prevents re-entry if already shutting down.
        (Round 32: Added logging)
        """
        log_prefix = "SimulationGUI.cleanup (R32): " # Added round
        # --- ADDED: Re-entry check ---
        if hasattr(self, '_is_shutting_down') and self._is_shutting_down:
            logger.warning(f"{log_prefix}Called while already shutting down, skipping redundant call.")
            return
        # ---
        logger.info(f"{log_prefix}Called, initiating on_closing sequence.")
        # Call on_closing, but handle potential errors if window is already gone
        try:
            if hasattr(self, 'root') and self.root and self.root.winfo_exists():
                self.on_closing() # on_closing now sets _is_shutting_down
            else:
                logger.warning(f"{log_prefix}Root window doesn't exist, attempting direct cleanup.")
                self._is_shutting_down = True # Set flag before direct cleanup
                self._complete_cleanup() # Try direct cleanup if window gone
        except Exception as e:
             logger.error(f"{log_prefix}Error during cleanup initiation: {e}")
             self._is_shutting_down = True # Ensure flag is set on error
             self._complete_cleanup() # Force cleanup attempt on error

    def _schedule_inactive_pool_cleanup(self):
        """Periodically calls the controller's inactive pool cleanup method."""
        log_prefix = "SimulationGUI._schedule_inactive_pool_cleanup: "
        cleanup_interval_ms = 15000 # Check every 15 seconds

        # Check if GUI is still valid and controller exists
        if not hasattr(self, 'root') or not self.root or not self.root.winfo_exists():
            logger.info(f"{log_prefix}Root window destroyed, stopping cleanup schedule.")
            if hasattr(self, '_inactive_pool_cleanup_timer') and self._inactive_pool_cleanup_timer:
                try: self.root.after_cancel(self._inactive_pool_cleanup_timer)
                except: pass # Ignore errors if root is gone
            self._inactive_pool_cleanup_timer = None
            return
        if not hasattr(self, 'controller') or not self.controller:
            logger.warning(f"{log_prefix}Controller not available, stopping cleanup schedule.")
            self._inactive_pool_cleanup_timer = None
            return
        if hasattr(self, '_is_shutting_down') and self._is_shutting_down:
             logger.info(f"{log_prefix}Application shutting down, stopping cleanup schedule.")
             self._inactive_pool_cleanup_timer = None
             return

        try:
            # Call the controller's cleanup method
            if hasattr(self.controller, '_cleanup_inactive_pools'):
                logger.debug(f"{log_prefix}Calling controller._cleanup_inactive_pools...")
                self.controller._cleanup_inactive_pools()
            else:
                logger.error(f"{log_prefix}Controller is missing _cleanup_inactive_pools method!")

            # Schedule the next check
            self._inactive_pool_cleanup_timer = self.root.after(cleanup_interval_ms, self._schedule_inactive_pool_cleanup)
            logger.debug(f"{log_prefix}Scheduled next cleanup check in {cleanup_interval_ms}ms.")

        except Exception as e:
            logger.error(f"{log_prefix}Error during inactive pool cleanup or scheduling: {e}")
            # Stop scheduling on error to prevent loops
            self._inactive_pool_cleanup_timer = None

    def _bind_plot_events(self):
        """Bind mouse events to the canvas using both Tkinter and Matplotlib.
           Uses lambdas for wheel events to ensure correct 'self'.
           (Round 3: Explicitly clear old bindings first)
           (Round 17: Use lambdas for wheel bindings)"""
        try:
            if not hasattr(self, 'canvas') or not self.canvas:
                logger.warning("Canvas not initialized, cannot bind events")
                return

            canvas_widget = self.canvas.get_tk_widget()
            if not canvas_widget.winfo_exists():
                logger.warning("Canvas widget does not exist, cannot bind events")
                return

            # --- Clear old Tkinter bindings ---
            logger.debug("Clearing existing Tkinter event bindings from canvas widget before rebinding.")
            events_to_unbind = [
                "<ButtonPress-1>", "<B1-Motion>", "<ButtonRelease-1>",
                "<MouseWheel>", "<Button-4>", "<Button-5>",
                "<Button-2>", "<Button-3>" # Include both potential right-click events
            ]
            for event_name in events_to_unbind:
                canvas_widget.unbind(event_name)
            logger.debug("Existing Tkinter bindings cleared.")
            if hasattr(self, '_event_bindings'): self._event_bindings.clear()
            else: self._event_bindings = []
            # ---

            # --- Clear old Matplotlib bindings ---
            if hasattr(self, '_mpl_event_bindings') and self._mpl_event_bindings:
                logger.debug("Disconnecting old Matplotlib event bindings.")
                for cid in self._mpl_event_bindings:
                    try: self.fig.canvas.mpl_disconnect(cid)
                    except Exception as e: logger.warning(f"Error disconnecting Matplotlib handler (CID: {cid}): {e}")
                self._mpl_event_bindings.clear()
            else: self._mpl_event_bindings = []
            # ---

            if hasattr(self, 'view_manager') and self.view_manager:
                logger.debug("Binding NEW Tkinter events to canvas widget.")
                vm = self.view_manager # Local variable for lambda capture clarity

                # --- Store binding IDs ---
                binding_id_press = canvas_widget.bind("<ButtonPress-1>", vm._on_mouse_press)
                binding_id_motion = canvas_widget.bind("<B1-Motion>", vm._on_mouse_drag)
                binding_id_release = canvas_widget.bind("<ButtonRelease-1>", vm._on_mouse_release)
                # --- MODIFIED: Use lambdas for wheel events ---
                binding_id_wheel = canvas_widget.bind("<MouseWheel>", lambda event, v=vm: v._on_mousewheel(event))
                binding_id_b4 = canvas_widget.bind("<Button-4>", lambda event, v=vm: v._on_mousewheel(event)) # Linux scroll
                binding_id_b5 = canvas_widget.bind("<Button-5>", lambda event, v=vm: v._on_mousewheel(event)) # Linux scroll
                # --- END MODIFIED ---
                right_click_event = "<Button-2>" if platform.system() == "Darwin" else "<Button-3>"
                binding_id_right_click = canvas_widget.bind(right_click_event, self._on_tk_right_click) # Keep this binding

                self._event_bindings.extend([
                    ("<ButtonPress-1>", binding_id_press, "mouse_press"),
                    ("<B1-Motion>", binding_id_motion, "mouse_drag"),
                    ("<ButtonRelease-1>", binding_id_release, "mouse_release"),
                    ("<MouseWheel>", binding_id_wheel, "mousewheel"),
                    ("<Button-4>", binding_id_b4, "button4"),
                    ("<Button-5>", binding_id_b5, "button5"),
                    (right_click_event, binding_id_right_click, "tk_right_click") # Track binding
                ])

                logger.debug("Canvas events rebound successfully using lambdas for wheel events.")
            else:
                logger.warning("ViewManager not initialized, cannot bind events")

        except Exception as e:
            logger.error(f"Error binding plot events: {e}")
            logger.error(traceback.format_exc())

    def _init_matplotlib_components(self):
        """Initialize matplotlib backend without using pyplot"""
        # Set the backend explicitly
        import matplotlib
        matplotlib.use('TkAgg')
        
        # Close any existing figures
        import matplotlib.pyplot as plt
        plt.close('all')
        
        # Disable interactive mode
        plt.ioff()

    def _reset_simulation_state_and_visualization(self,
                                                  clear_grid_content: bool = True,
                                                  initialize_grid_content: bool = True,
                                                  reset_generation_counter: bool = True): # Added reset_generation_counter flag
        """
        Centralized method to reset simulation state, visualization, and synchronization primitives.
        Optionally clears the grid content itself and optionally initializes content based on rule.
        Conditionally resets the generation counter.
        (Round 3: Remove redundant grid/visualizer/viewmanager cleanup)
        (Round 23: Reset FPS tracking)
        (Round 30: Update reset FPS display string)
        (Round 45: Add reset_generation_counter flag)
        """
        log_prefix = f"_reset_simulation_state_and_visualization (InitContent={initialize_grid_content}, ResetGen={reset_generation_counter} R45): " # Updated round
        logger.info(f"{log_prefix}Initiating reset (clear_grid_content={clear_grid_content}).")

        try:
            # Stop Simulation Flags (Typically handled by caller, but ensure flags are reset here too)
            self.running = False
            self.paused = False
            self._stopped = True # Ensure stopped state is set during reset
            self._fixed_steps_running = False
            if hasattr(self, 'computation_running_flag'):
                self.computation_running_flag.clear()
            if hasattr(self, 'computation_pause_flag'):
                self.computation_pause_flag.set() # Ensure not stuck paused
            if hasattr(self, '_stop_event') and self._stop_event:
                # Don't set the stop event here, let the caller manage thread stopping
                self._stop_event.clear() # Clear immediately for this reset context
            if hasattr(self, 'controller') and hasattr(self.controller, 'interrupt_requested'):
                self.controller.interrupt_requested = False # Clear controller interrupt

            # --- MODIFIED: Conditional Generation Counter Reset ---
            if reset_generation_counter:
                self.generation = 0
                self.step_count = 0
                if hasattr(self.controller, 'generation'): self.controller.generation = 0
                logger.debug(f"{log_prefix}Generation counters reset to 0.")
            else:
                logger.debug(f"{log_prefix}Generation counters PRESERVED (Current: {self.generation}).")
            # --- END MODIFIED ---

            # 1. Reset Counters (excluding generation if flag is False)
            self.consecutive_inactive_steps = 0
            logger.debug(f"{log_prefix}Other counters reset.")

            # 2. Clear Queue & Snapshots
            if hasattr(self, 'communication_queue'): # Check if queue exists
                while not self.communication_queue.empty():
                    try: self.communication_queue.get_nowait()
                    except queue.Empty: break
            if hasattr(self, 'render_data_queue'): # Check if queue exists
                while not self.render_data_queue.empty():
                    try: self.render_data_queue.get_nowait()
                    except queue.Empty: break
            self._last_rendered_snapshot = None
            self._latest_grid_snapshot = None
            self._last_prepared_snapshot_for_highlight = None # Also clear prep history
            logger.debug(f"{log_prefix}Queues and snapshots cleared.")

            # 3. Reset Synchronization Event
            # if hasattr(self, 'render_complete_event'): # REMOVED in R54
            #     self.render_complete_event.set()
            #     logger.debug(f"{log_prefix}Render complete event set.")

            # 4. Reset Statistics & History
            if hasattr(self, 'stats'): self.stats.reset()
            if hasattr(self, 'perf_logger') and self.perf_logger: self.perf_logger.reset()
            if hasattr(self, 'last_updated_nodes'): self.last_updated_nodes.clear()
            if hasattr(self, 'last_updated_edges'): self.last_updated_edges.clear()
            if hasattr(self, '_grid_undo_stack'): self._grid_undo_stack.clear()
            if hasattr(self, '_grid_redo_stack'): self._grid_redo_stack.clear()
            # --- Reset FPS Tracking ---
            if hasattr(self, 'fps_history'): self.fps_history.clear()
            if hasattr(self, 'last_avg_fps'): self.last_avg_fps = 0.0
            if hasattr(self, '_last_render_completion_time'): self._last_render_completion_time = 0.0
            if hasattr(self, 'fps_display_var'): self.fps_display_var.set("Avg FPS: N/A | Render Q: N/A")
            logger.debug(f"{log_prefix}FPS tracking reset.")
            # ---
            logger.debug(f"{log_prefix}Stats and history cleared.")

            # --- 5. REMOVED Grid/Visualizer/ViewManager Cleanup ---
            logger.debug(f"{log_prefix}Skipping internal grid/visualizer/viewmanager cleanup (handled by caller).")
            # ---

            # 6. Initialize Grid Content (Handled by caller)
            if initialize_grid_content:
                 logger.debug(f"{log_prefix}Note: initialize_grid_content=True, but actual initialization should be handled by the caller after potential grid recreation.")
            if clear_grid_content:
                 logger.debug(f"{log_prefix}Note: clear_grid_content=True, but grid cleanup/recreation is handled by the caller.")

            # 7. Reset Visualizer (Handled by caller, but ensure state is reset if visualizer exists)
            if hasattr(self, 'grid_visualizer') and self.grid_visualizer:
                self.grid_visualizer.reset() # Call reset if it exists
                logger.debug(f"{log_prefix}Called GridVisualizer reset.")
            else:
                logger.warning(f"{log_prefix}GridVisualizer not found, cannot reset.")

            # 8. Reset View Manager State
            if hasattr(self, 'view_manager') and self.view_manager:
                self._reset_view_state() # Reset zoom, pan etc.
                logger.debug(f"{log_prefix}ViewManager state reset.")
            else:
                logger.warning(f"{log_prefix}ViewManager not found, cannot reset view state.")

            # 9. Reset GUI Flags
            self._is_drawing = False
            self._update_scheduled = False
            self._programmatic_change = False
            self._applying_preset = False
            logger.debug(f"{log_prefix}GUI flags reset.")

            # 10. Update Button States and Labels
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                self.control_panel_ui.update_button_states()
                # --- Update step label based on reset flag ---
                if reset_generation_counter:
                    self.control_panel_ui.update_step_label() # Will show 0
                else:
                    # If not resetting counter, update label to show the *preserved* generation
                    step_label = self.control_panel_ui.widgets.get('step_label')
                    if isinstance(step_label, tk.Label):
                        step_label.config(text=f"Step: {self.generation}")
                # ---
                fps_label = self.control_panel_ui.widgets.get('fps_label')
                if isinstance(fps_label, tk.Label): fps_label.config(text="Avg FPS: N/A | Render Q: N/A") # Use updated reset text
                logger.debug(f"{log_prefix}UI elements updated via ControlPanelUI.")
            else:
                logger.warning(f"{log_prefix}ControlPanelUI not found, cannot update UI elements.")

            logger.info(f"{log_prefix}Reset complete.")

        except Exception as e:
            logger.error(f"Error during reset: {e}")
            logger.error(traceback.format_exc())

    @timer_decorator
    def reset_simulation(self, initial_density: Optional[float] = None, edge_initialization_type: str = 'RANDOM'):
        """
        Reset simulation to initial state, applying a 'Random' initial condition
        using the CURRENT RULE's density parameters.
        Ensures SHM setup occurs AFTER rule initialization. Clears analytics without prompting.
        Calls reset helper WITH resetting generation counter.
        (Round 51: Use RULE densities for reset, not sliders)
        """
        log_prefix = "SimulationGUI.reset_simulation (R51 Rule Density Reset): " # Updated round
        logger.info(f"\n{'='*25} Resetting Simulation (Using Rule Densities) {'='*25}")

        # [ Clear Analytics - Unchanged ]
        if not self._clear_analytics_state(prompt_save=False):
            logger.error(f"{log_prefix}Failed during analytics state clearing. Aborting reset.")
            return
        logger.info(f"{log_prefix}Analytics state cleared.")
        # ---

        self._is_transitioning = True
        if not self._stop_computation_threads(reason="Reset Simulation"):
            logger.error(f"{log_prefix}Aborted: Failed to stop computation threads cleanly.")
            self._is_transitioning = False
            return
        logger.info(f"{log_prefix}Computation threads stopped.")
        if hasattr(self, '_stop_event') and self._stop_event: self._stop_event.clear()

        original_blitting = self.grid_visualizer.blitting_manager.enabled if hasattr(self, 'grid_visualizer') and self.grid_visualizer else GlobalSettings.ENABLE_BLITTING
        if hasattr(self, 'grid_visualizer') and self.grid_visualizer: self.grid_visualizer.blitting_manager.set_enabled(False)
        # [ Store slider commands - Unchanged ]
        node_slider_cmd = None; edge_slider_cmd = None
        if self.control_panel_ui:
            node_density_scale_widget = self.control_panel_ui.widgets.get('node_density_scale')
            edge_density_scale_widget = self.control_panel_ui.widgets.get('edge_density_scale')
            if isinstance(node_density_scale_widget, tk.Scale): node_slider_cmd = node_density_scale_widget.cget('command')
            if isinstance(edge_density_scale_widget, tk.Scale): edge_slider_cmd = edge_density_scale_widget.cget('command')
        saved_latest_scheme = copy.deepcopy(self._latest_color_scheme)

        rule_instance_before_update = self.controller.rule

        try:
            # [ Clear Undo/Redo - Unchanged ]
            self._grid_undo_stack.clear(); self._grid_redo_stack.clear()
            logger.info(f"{log_prefix}Cleared undo/redo stacks.")

            # [ Cleanup Old Grid/Viz/View - Unchanged ]
            if self.grid: logger.info(f"{log_prefix}Cleaning up existing grid (ID: {id(self.grid)}) before reset."); self.grid.cleanup(); del self.grid; self.grid = None; self.controller.grid = None; logger.debug(f"{log_prefix}Deleted grid reference.")
            if self.grid_visualizer: logger.info(f"{log_prefix}Deleting grid_visualizer reference (ID: {id(self.grid_visualizer)})."); del self.grid_visualizer; self.grid_visualizer = None
            if self.view_manager: logger.info(f"{log_prefix}Deleting view_manager reference (ID: {id(self.view_manager)})."); del self.view_manager; self.view_manager = None
            gc.collect(); logger.info(f"{log_prefix}Existing grid/viz/view/control cleanup finished and GC called.")
            if hasattr(GridVisualizer, '_get_cached_cmap_norm') and hasattr(GridVisualizer._get_cached_cmap_norm, 'cache_clear'): GridVisualizer._get_cached_cmap_norm.cache_clear(); logger.info(f"{log_prefix}Cleared GridVisualizer._get_cached_cmap_norm LRU cache.")

            # [ Reset Simulation State (Reset Generation) - Unchanged ]
            self._reset_simulation_state_and_visualization(clear_grid_content=False, initialize_grid_content=False, reset_generation_counter=True)
            logger.debug(f"{log_prefix}Simulation state reset (counters, flags, stats, generation).")

            # [ Recreate Grid Instance - Unchanged ]
            logger.info(f"{log_prefix}Recreating grid instance.")
            rule_to_use = self.controller.rule if self.controller and self.controller.rule else None
            if rule_to_use is None: logger.error(f"{log_prefix}Cannot recreate grid: Controller or rule is missing."); return
            if self.coord_system is None: self.coord_system = CoordinateSystem(self.dimensions, GlobalSettings.Visualization.EDGE_SCALE, GlobalSettings.Visualization.NODE_SPACING, self.dimension_type); logger.warning(f"{log_prefix}Recreated missing CoordinateSystem.")
            else: self.coord_system.update_parameters(grid_dimensions=self.dimensions, node_spacing=GlobalSettings.Visualization.NODE_SPACING, dimension_type=self.dimension_type)
            self.grid = Grid(self.dimensions, self.neighborhood_type, self.dimension_type, self.coord_system, gui=self, rule=self.controller.rule, unique_id=self._unique_id)
            self.controller.grid = self.grid
            self.grid.setup_shared_memory()
            logger.debug(f"{log_prefix}Grid recreated. Grid object ID: {id(self.grid)}")

            # --- MODIFIED: Get Densities from CURRENT RULE for Initialization ---
            node_density_from_rule = GlobalSettings.Simulation.INITIAL_NODE_DENSITY # Default
            edge_density_from_rule = GlobalSettings.Simulation.INITIAL_EDGE_DENSITY # Default
            edge_init_type_from_rule = 'RANDOM' # Default
            if self.controller.rule:
                node_density_from_rule = self.controller.rule.get_param('initial_density', node_density_from_rule)
                edge_density_from_rule = self.controller.rule.get_param('connect_probability', edge_density_from_rule)
                edge_init_type_from_rule = self.controller.rule.get_param('edge_initialization', 'RANDOM')
                # Ensure rule's connect_probability matches edge density for consistency
                self.controller.rule.update_parameter('connect_probability', edge_density_from_rule)
                # Ensure rule's initial condition param reflects the reset action
                self.controller.rule.update_parameter('initial_conditions', "Random")
            logger.info(f"{log_prefix}Using densities from RULE '{self.controller.rule.name}' for reset: Node={node_density_from_rule:.3f}, Edge={edge_density_from_rule:.3f}")

            # Force 'Random' initialization using rule densities
            logger.info(f"{log_prefix}Calling grid.initialize_grid with NodeDensity={node_density_from_rule:.3f}, EdgeInitType='{edge_init_type_from_rule}'")
            self.grid.initialize_grid(node_density_from_rule, edge_init_type_from_rule)
            # --- END MODIFIED ---

            # [ Calculate initial previous arrays - Unchanged ]
            self._calculate_initial_previous_arrays()

            # [ Recreate Visualizer and ViewManager - Unchanged ]
            logger.debug(f"{log_prefix}Recreating GridVisualizer and ViewManager.")
            self.grid_visualizer = GridVisualizer(self.grid, self.ax, self.fig, self.controller, self)
            self.view_manager = ViewManager(self.grid, self.ax, self.fig, self.coord_system, self.grid_visualizer, self, self.controller)
            self._setup_observers()
            self._bind_plot_events()
            logger.info(f"{log_prefix}Recreated Visualizer (ID: {id(self.grid_visualizer)}) and ViewManager (ID: {id(self.view_manager)}). Re-bound events.")

            # [ Final GUI Updates and Render ]
            self._set_active_preset(None) # Clear active preset after reset
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                # --- MODIFIED: Set sliders to RULE defaults ---
                node_density_scale_widget = self.control_panel_ui.widgets.get('node_density_scale')
                edge_density_scale_widget = self.control_panel_ui.widgets.get('edge_density_scale')
                if isinstance(node_density_scale_widget, tk.Scale): node_density_scale_widget.config(command="") # Disable callback
                if isinstance(edge_density_scale_widget, tk.Scale): edge_density_scale_widget.config(command="") # Disable callback
                if isinstance(node_density_scale_widget, tk.Scale): node_density_scale_widget.set(node_density_from_rule) # Set to rule value
                if isinstance(edge_density_scale_widget, tk.Scale): edge_density_scale_widget.set(edge_density_from_rule) # Set to rule value
                logger.debug(f"{log_prefix}Set density sliders to rule defaults: Node={node_density_from_rule:.3f}, Edge={edge_density_from_rule:.3f}")
                # Re-enable callbacks after setting value
                self.root.after(100, lambda: (isinstance(node_density_scale_widget, tk.Scale) and node_slider_cmd and node_density_scale_widget.config(command=node_slider_cmd), isinstance(edge_density_scale_widget, tk.Scale) and edge_slider_cmd and edge_density_scale_widget.config(command=edge_slider_cmd)))
                # ---
                self.control_panel_ui.update_step_label()
                self.control_panel_ui.update_button_states()
                self.control_panel_ui.update_refocus_button_state()
                # Ensure Initial Conditions dropdown shows "Random" after reset
                self._programmatic_change = True
                try: self.initial_conditions_var.set("Random")
                finally: self.root.after(10, self._clear_programmatic_change_flag)
                self._update_initial_conditions_selector()
            logger.debug(f"{log_prefix}Calling _force_initial_render AFTER reset logic and SHM setup.")
            self._force_initial_render()

            logger.info(f"{log_prefix}Simulation reset completed successfully.")

        except Exception as e:
            logger.error(f"{log_prefix}Error during simulation reset: {str(e)}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Error", f"Failed to reset simulation: {e}", parent=self.root)
            self.running = False; self.paused = False; self._stopped = True
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui: self.control_panel_ui.update_button_states()
        finally:
            # [ Restore slider commands, blitting, flags - Unchanged ]
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                node_density_scale_widget = self.control_panel_ui.widgets.get('node_density_scale')
                edge_density_scale_widget = self.control_panel_ui.widgets.get('edge_density_scale')
                node_slider_cmd = self._on_node_density_change
                if isinstance(node_density_scale_widget, tk.Scale): node_density_scale_widget.config(command=node_slider_cmd)
                edge_slider_cmd = self._on_edge_density_change
                if isinstance(edge_density_scale_widget, tk.Scale) and edge_slider_cmd: edge_density_scale_widget.config(command=edge_slider_cmd)
            if hasattr(self, 'grid_visualizer') and self.grid_visualizer: self.grid_visualizer.blitting_manager.set_enabled(original_blitting)
            self.running = False; self.paused = False; self._fixed_steps_running = False; self._stopped = False # Set stopped=False after change
            logger.info("Set _stopped = False in reset finally block.")
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui: self.control_panel_ui.update_button_states()
            self._is_transitioning = False
            self._initialization_complete = True
            gc.collect()
            logger.debug(f"{log_prefix}Set _initialization_complete = True and called GC in finally block.")
            logger.debug(f"{log_prefix}=============== Exiting reset_simulation SimulationGUI (R51 Rule Density Reset) ===============")

    def randomize_grid(self):
        """Randomizes the grid state based on current density settings."""
        # --- ADDED: Pause/Resume Computation ---
        self._pause_computation(reason="Randomize Grid")
        original_blitting = self.grid_visualizer.blitting_manager.enabled if hasattr(self, 'grid_visualizer') and self.grid_visualizer else GlobalSettings.ENABLE_BLITTING
        if hasattr(self, 'grid_visualizer') and self.grid_visualizer: self.grid_visualizer.blitting_manager.set_enabled(False)
        # ---
        logger.info("Randomizing grid state.")
        if self.grid is None or self.rule is None:
            messagebox.showerror("Error", "Grid or Rule not initialized.", parent=self.root)
            self._resume_computation(reason="Randomize Grid Failed") # Resume if error
            return

        try:
            self._clear_lasso_selection()
            self._push_grid_state_to_undo("Randomize Grid")

            # Get current densities from sliders or global settings
            node_density = GlobalSettings.Simulation.INITIAL_NODE_DENSITY
            edge_density = GlobalSettings.Simulation.INITIAL_EDGE_DENSITY
            # --- MODIFIED: Access widgets via control_panel_ui ---
            if hasattr(self, 'control_panel_ui'):
                node_density_scale_widget = None
                if self.control_panel_ui is not None and hasattr(self.control_panel_ui, 'widgets'):
                    node_density_scale_widget = self.control_panel_ui.widgets.get('node_density_scale')
                edge_density_scale_widget = None
                if self.control_panel_ui is not None and hasattr(self.control_panel_ui, 'widgets'):
                    edge_density_scale_widget = self.control_panel_ui.widgets.get('edge_density_scale')
                if isinstance(node_density_scale_widget, tk.Scale):
                    node_density = node_density_scale_widget.get()
                if isinstance(edge_density_scale_widget, tk.Scale):
                    edge_density = edge_density_scale_widget.get()
            # ---

            # Stop simulation if running
            was_running = self.running
            self.running = False
            self.paused = False
            # --- MODIFIED: Call ControlPanelUI method ---
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui is not None:
                self.control_panel_ui.update_button_states()
            # ---

            # Clear and re-initialize the grid
            self.grid.clear_grid()
            self.rule.params['connect_probability'] = edge_density # Ensure rule uses correct density
            edge_init_type = self.rule.get_param('edge_initialization', 'RANDOM')
            self.grid.initialize_grid(node_density, edge_init_type)

            # Reset generation and stats
            self.generation = 0
            self.step_count = 0
            if hasattr(self.controller, 'generation'): self.controller.generation = 0
            self.stats.reset()
            if hasattr(self, 'perf_logger') and self.perf_logger: self.perf_logger.reset()
            self.last_updated_nodes.clear(); self.last_updated_edges.clear()
            self._last_rendered_snapshot = None
            self.consecutive_inactive_steps = 0

            # Update UI
            # --- MODIFIED: Call ControlPanelUI method ---
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui is not None:
                self.control_panel_ui.update_step_label()
            # ---
            self._set_active_preset(None) # Clear active preset

            # Force redraw
            self._force_initial_render()

            logger.info(f"Grid randomized with Node Density: {node_density:.2f}, Edge Density: {edge_density:.2f}")

        except Exception as e:
            logger.error(f"Error randomizing grid: {e}")
            messagebox.showerror("Error", f"Failed to randomize grid: {e}", parent=self.root)
        finally:
            # --- ADDED: Resume Computation ---
            if hasattr(self, 'grid_visualizer') and self.grid_visualizer: self.grid_visualizer.blitting_manager.set_enabled(original_blitting)
            self._resume_computation(reason="Randomize Grid Complete")
            # ---

    def _init_gui_controls(self):
        """Initialize GUI control elements"""
        # Initialize variables
        self.highlight_var = tk.BooleanVar(value=True)
        self.rule_type_var = tk.StringVar()
        self.rule_instance_var = tk.StringVar()
        self.dimension_var = tk.StringVar()
        self.neighborhood_var = tk.StringVar()
        self.initial_conditions_var = tk.StringVar(value="Random")
        
        # Create control frames
        if not hasattr(self, 'control_panel') or self.control_panel is None:
            self.control_panel = tk.Frame(self.main_frame, width=300, bg='#404040')  # Initialize control_panel if not already done
        self.scrollable_control_frame = tk.Frame(self.control_panel, bg=self.control_panel.cget('bg'))
        
        # Create labels
        self.step_label = tk.Label(self.control_panel, text="Step: 0", bg=self.control_panel.cget('bg'), fg='white')
        self.perf_label = tk.Label(self.control_panel, text="Avg Step: 0.0ms", bg=self.control_panel.cget('bg'), fg='white')
        self.grid_size_label = tk.Label(self.control_panel, text="Size: 0", bg=self.control_panel.cget('bg'), fg='white')
        
        # Initialize continuous run variables
        self.run_continuously = tk.BooleanVar(value=False)
        self.num_steps_var = tk.StringVar(value=str(GlobalSettings.Simulation.NUM_STEPS))
                
    def _init_scales(self):
        """Initialize scale widgets"""

        # Speed scale
        self.speed_scale = tk.Scale(self.control_panel, from_=10, to=1000, orient=tk.HORIZONTAL,
                                command=self._on_speed_change)
        
        # NOTE: node spacing slider is not created here, it is created in def _create_spacing_section

        # Node density scale
        self.node_density_scale = tk.Scale(
            self.control_panel,
            from_=0.0,
            to=1.0,
            resolution=0.05,
            orient=tk.HORIZONTAL,
            command=self._on_node_density_change
        )
        self.node_density_scale.set(GlobalSettings.Simulation.INITIAL_NODE_DENSITY)
        
        # Edge density scale
        self.edge_density_scale = tk.Scale(
            self.control_panel,
            from_=0.0,
            to=1.0,
            resolution=0.05,
            orient=tk.HORIZONTAL,
            command=self._on_edge_density_change
        )
        self.edge_density_scale.set(GlobalSettings.Simulation.INITIAL_EDGE_DENSITY)

    def _init_buttons(self):
        """Initialize button widgets"""
        self.start_button = tk.Button(self.control_panel, text="Start", width=15, 
                                    command=self.toggle_simulation)
        self.step_button = tk.Button(self.control_panel, text="Step", width=15,
                                    command=self.step_button_clicked)
        self.edit_rule_button = tk.Button(self.control_panel, text="Edit Rule",
                                        command=lambda: self.create_rule_editor_window(self.controller.rule.name))
        self.zoom_in_button = tk.Button(self.control_panel, text="Zoom +", width=15,
                                    command=self.zoom_in)
        self.zoom_out_button = tk.Button(self.control_panel, text="Zoom -", width=15,
                                        command=self.zoom_out)
        self.save_button = tk.Button(self.control_panel, text="Save", width=15,
                                    command=self.save_state)
        self.load_button = tk.Button(self.control_panel, text="Load", width=15,
                                    command=self.load_state)

    def _init_selectors(self):
        """Initialize selector widgets"""
        self.initial_conditions_selector = tk.OptionMenu(
            self.control_panel, self.initial_conditions_var,
            "Random", "2D - Circle", "2D - Square", "3D - Sphere", "3D - Cube",
            command=self._handle_initial_conditions_selection
        )

        self.rule_type_selector = tk.OptionMenu(
            self.control_panel, self.rule_type_var,
            *RuleLibrary.get_rule_categories().keys(),
            command=self._handle_rule_type_selection
        )

        # Create the OptionMenu, but don't populate it yet
        self.rule_instance_selector = tk.OptionMenu(
            self.control_panel,
            self.rule_instance_var,
            '',  # Start with an empty option
            command=self._handle_rule_instance_selection
        )
        
        # Now populate the menu
        self._update_rule_instance_selector()

    def _handle_initial_conditions_selection(self, selection):
        """Handle selection from initial conditions dropdown"""
        logger.debug(f"Initial conditions selection: {selection}")
        self._on_initial_conditions_change(selection)

    def _handle_rule_type_selection(self, selection):
        """Handle selection from rule type dropdown"""
        logger.debug(f"Rule type selection: {selection}")
        self._on_rule_type_change(selection)

    def _handle_rule_instance_selection(self, selection):
        """Handle selection from rule instance dropdown"""
        logger.debug(f"Rule instance selection: {selection}")
        self._on_rule_instance_change(selection)
                            
    def _initialize_variables(self):
        """Helper method to initialize variables"""
        self.step_button_pressed = False
        self.anim = None
        self.step_count = 0
        self.running = False
        self.paused = False
        self.new_nodes = set()
        self.new_edges = set()
        self.node_marker = MarkerStyle('o')
        self.last_frame_time = time.time()
        self.current_frame_time = 0.0
        self.undo_stack = []
        self.redo_stack = []
        self._plot_cache = {}
        self._last_plot_hash = None
        self.tooltip = None
        self._view_state = {
            'xlim': None,
            'ylim': None,
            'zlim': None,
            'elev': 30,
            'azim': 0,
            'zoom_factor': 1.0
        }
        self.performance_stats = {
            'step_times': [],
            'render_times': [],
            'frame_times': []
        }
        self._update_lock = threading.Lock()
        self._parameter_lock = threading.Lock()
        self._simulation_event = threading.Event()
        self._gui_event = threading.Event()
        self._stop_event = threading.Event()
        self._is_updating = False
        self._last_update_time = time.time()
        self._update_queue = Queue()
        self._frame_times = []
        self._event_bindings = []
        self._is_initialized = False
        self._is_setting_defaults = False
        self.neighborhood_types = {
            "VON_NEUMANN": NeighborhoodType.VON_NEUMANN,
            "MOORE": NeighborhoodType.MOORE,
            "HEX": NeighborhoodType.HEX,
            "HEX_PRISM": NeighborhoodType.HEX_PRISM
        }
        
    def _initialize_controller(self, rule_name: str):
        """Helper method to initialize the SimulationController"""
        try:
            rule_data = RuleLibraryManager.get_rule(rule_name)
            metadata_dict = {k: v for k, v in rule_data.items() if k != 'params'}
            metadata = RuleMetadata(**metadata_dict)
            self.controller = SimulationController(
                rule_name=rule_name,
                initialize_state=False
            )
            self.controller.rule = RuleLibrary.create_rule(rule_name, metadata)
            # Remove this line:
            # self.controller.rule.metadata.controller = self
            if 'params' in rule_data:
                logger.debug(f"Loading parameters for {rule_name}: {rule_data['params']}")
                self.controller.rule.params = copy.deepcopy(rule_data['params'])
        except ValueError as e:
            logger.error(f"Error initializing SimulationController: {e}")
            messagebox.showerror("Error", f"Failed to initialize SimulationController: {e}")
            raise

    def _setup_gui_layout(self):
        """Helper method to setup the GUI layout"""
        # Create visualization frame with background color
        self.viz_frame = tk.Frame(self.main_frame, bg=GlobalSettings.Colors.BACKGROUND)
        self.viz_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True,
                    padx=GlobalSettings.Visualization.WINDOW_PADDING,
                    pady=GlobalSettings.Visualization.WINDOW_PADDING)

        # Create control panel with background color
        if self.control_panel is None:
            self.control_panel = tk.Frame(self.main_frame, width=300, bg='#404040')  # Initialize if not already done
        self.control_panel.pack(side=tk.RIGHT, fill=tk.Y,
                            padx=GlobalSettings.Visualization.WINDOW_PADDING,
                            pady=GlobalSettings.Visualization.WINDOW_PADDING)

        # Ensure scrollable frame is packed
        if hasattr(self, 'scrollable_control_frame') and self.scrollable_control_frame:
            self.scrollable_control_frame.pack(side=tk.TOP, fill=tk.BOTH, expand=True)

        # --- ADDED: Progress Bar ---
        # Create a frame at the bottom of the main_frame for the progress bar
        if not hasattr(self, 'main_frame') or self.main_frame is None:
            self.main_frame = tk.Frame(self.root, bg=GlobalSettings.Colors.BACKGROUND)
            self.main_frame.pack(fill=tk.BOTH, expand=True)
        self.progress_frame = tk.Frame(self.main_frame, bg=GlobalSettings.Colors.BACKGROUND)
        # Pack it below the viz_frame and control_panel
        self.progress_frame.pack(side=tk.BOTTOM, fill=tk.X, padx=GlobalSettings.Visualization.WINDOW_PADDING, pady=(5, 0))

        self.progress_bar = ttk.Progressbar(self.progress_frame, orient="horizontal", length=300, mode="determinate")
        # Don't pack it initially, use pack_forget to hide
        self.progress_bar.pack_forget()
        self.widgets['progress_bar'] = self.progress_bar
        # --- END ADDED ---

    def _show_progress(self, max_value: int = 100, text: str = "Processing..."):
        """Shows and configures the progress bar."""
        if hasattr(self, 'progress_bar') and self.progress_bar:
            logger.debug(f"Showing progress bar: Max={max_value}, Text='{text}'")
            self.progress_bar.config(maximum=max_value, value=0)
            # Re-pack the progress bar frame to make it visible
            if hasattr(self, 'progress_frame') and self.progress_frame:
                self.progress_frame.pack(side=tk.BOTTOM, fill=tk.X, padx=GlobalSettings.Visualization.WINDOW_PADDING, pady=(5, 0))
            self.progress_bar.pack(fill=tk.X, padx=5, pady=5) # Pack the bar itself
            # Optionally add a label for text
            if not hasattr(self, 'progress_label'):
                 self.progress_label = tk.Label(self.progress_frame, text=text, bg=GlobalSettings.Colors.BACKGROUND, fg='white')
                 self.progress_label.pack(side=tk.LEFT, padx=5)
                 self.widgets['progress_label'] = self.progress_label
            else:
                 if self.progress_label is not None:
                     self.progress_label.config(text=text)
                 else:
                     logger.warning("Progress label is not initialized.")
                 if self.progress_label is not None:
                     self.progress_label.pack(side=tk.LEFT, padx=5) # Ensure packed
                 else:
                     logger.warning("Progress label is not initialized.")
            self.root.update_idletasks() # Force GUI update

    def _update_progress(self, value: int, text: Optional[str] = None):
        """Updates the progress bar value and optional text."""
        if hasattr(self, 'progress_bar') and self.progress_bar:
            # logger.debug(f"Updating progress bar: Value={value}") # Reduce noise
            self.progress_bar['value'] = value
            if text and hasattr(self, 'progress_label') and self.progress_label:
                self.progress_label.config(text=text)
            self.root.update_idletasks() # Force GUI update

    def _hide_progress(self):
        """Hides the progress bar."""
        if hasattr(self, 'progress_bar') and self.progress_bar:
            logger.debug("Hiding progress bar.")
            self.progress_bar.pack_forget()
            if hasattr(self, 'progress_label') and self.progress_label:
                self.progress_label.pack_forget()
            # Hide the container frame as well
            if hasattr(self, 'progress_frame') and self.progress_frame:
                self.progress_frame.pack_forget()
            self.root.update_idletasks()

    def _backup_rules_file(self) -> Optional[str]:
        """Create backup of rules.json before modifications"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            # UPDATED: Use config_rules_backups for backups
            backup_path = os.path.join(APP_PATHS['config_rules_backups'], f"rules_backup_{timestamp}.json")
            rules_path = RuleLibraryManager.get_instance().library_path

            logger.info(f"Creating backup of rules.json at: {backup_path}")

            # Read current rules.json
            with open(rules_path, 'r') as f:
                current_data = json.load(f)
                
            # Save backup
            with open(backup_path, 'w') as f:
                json.dump(current_data, f, indent=2)
            
            logger.info("Backup created successfully")
            return backup_path

        except Exception as e:
            logger.error(f"Error creating rules backup: {e}")
            messagebox.showerror("Error", f"Failed to create backup: {e}")
            return None
                
    def _on_window_close(self, event=None):
        """Handle main window closing with change detection"""
        try:
            # No need to check for changes here - we only care about rule editor changes
            self.cleanup()
            
        except Exception as e:
            logger.error(f"Error handling window close: {e}")
            self.cleanup()  # Force cleanup on error

    def _calculate_max_neighbors(self) -> int:
        """Calculate maximum possible neighbors based on neighborhood type"""
        if self.neighborhood_type == NeighborhoodType.VON_NEUMANN:
            if self.dimension_type == Dimension.TWO_D:
                return 4
            elif self.dimension_type == Dimension.THREE_D:
                return 6
            else:
                raise ValueError(f"Invalid dimension type {self.dimension_type} for VON_NEUMANN neighborhood")
        elif self.neighborhood_type == NeighborhoodType.MOORE:
            if self.dimension_type == Dimension.TWO_D:
                return 8
            elif self.dimension_type == Dimension.THREE_D:
                return 26
            else:
                raise ValueError(f"Invalid dimension type {self.dimension_type} for MOORE neighborhood")
        elif self.neighborhood_type == NeighborhoodType.HEX:
            if self.dimension_type == Dimension.TWO_D:
                return 6
            else:
                raise ValueError(f"Invalid dimension type {self.dimension_type} for HEX neighborhood")
        elif self.neighborhood_type == NeighborhoodType.HEX_PRISM:
            if self.dimension_type == Dimension.THREE_D:
                return 12
            else:
                raise ValueError(f"Invalid dimension type {self.dimension_type} for HEX_PRISM neighborhood")
        else:
            raise ValueError(f"Invalid neighborhood type: {self.neighborhood_type}")

    def set_rule(self, rule_name: str) -> bool:
        """
        Change the current rule used by the simulation, forcing grid reset and applying the NEW rule's default initial conditions.
        Loads rule data based on the provided name. Updates prep thread params.
        Prompts to save analytics if enabled before clearing. Handles all GUI updates internally.
        (Round 35: Ensure update_prep_params_from_rule runs before render after rule change)
        """
        log_prefix = f"SimulationGUI.set_rule(RuleName='{rule_name}' R35 Prep Param Fix): " # Updated round
        logger.info(f"\n{'='*25} Setting Rule: {rule_name} {'='*25}")

        # --- Check if rule is actually changing ---
        current_rule_name_in_controller = self.controller.rule.name if self.controller and self.controller.rule else "None"
        logger.debug(f"{log_prefix}Incoming rule name: '{rule_name}', Controller's current rule: '{current_rule_name_in_controller}'")
        if rule_name == current_rule_name_in_controller:
            logger.info(f"{log_prefix}Rule '{rule_name}' is already active. Ensuring UI sync.")
            self._update_rule_type_selector(); self._update_rule_instance_selector(); self.rule_instance_var.set(rule_name)
            return True
        # ---

        # --- Check and clear analytics BEFORE stopping threads ---
        if not self._clear_analytics_state(prompt_save=True):
            logger.info(f"{log_prefix}Rule change cancelled by user during analytics save prompt.")
            if self.controller and self.controller.rule: self.rule_instance_var.set(self.controller.rule.name)
            return False
        # ---

        self._is_transitioning = True
        if not self._stop_computation_threads(reason=f"Set Rule to {rule_name}"):
            logger.error(f"{log_prefix}Aborted: Failed to stop computation threads cleanly.")
            self._is_transitioning = False; return False
        if hasattr(self, '_stop_event') and self._stop_event: self._stop_event.clear()

        original_blitting = self.grid_visualizer.blitting_manager.enabled if hasattr(self, 'grid_visualizer') and self.grid_visualizer else GlobalSettings.ENABLE_BLITTING
        if hasattr(self, 'grid_visualizer') and self.grid_visualizer: self.grid_visualizer.blitting_manager.set_enabled(False)
        node_slider_cmd = None; edge_slider_cmd = None
        if self.control_panel_ui:
            node_density_scale_widget = self.control_panel_ui.widgets.get('node_density_scale')
            edge_density_scale_widget = self.control_panel_ui.widgets.get('edge_density_scale')
            if isinstance(node_density_scale_widget, tk.Scale): node_slider_cmd = node_density_scale_widget.cget('command')
            if isinstance(edge_density_scale_widget, tk.Scale): edge_slider_cmd = edge_density_scale_widget.cget('command')
        saved_latest_scheme = copy.deepcopy(self._latest_color_scheme)

        rule_instance_before_update = self.controller.rule # Keep reference to potentially revert

        try:
            logger.info(f"{log_prefix}Changing to rule: {rule_name}")

            # --- 1. Load New Rule Data and Create Instance ---
            logger.debug(f"{log_prefix}Step 1: Loading rule data for '{rule_name}'...")
            try:
                rule_data = RuleLibraryManager.get_rule(rule_name)
                metadata_dict = {k: v for k, v in rule_data.items() if k != 'params' and k != '_ignored_params'}; metadata_dict['name'] = rule_name
                metadata_dict.setdefault('position', 1); metadata_dict.setdefault('category', 'Unknown'); metadata_dict.setdefault('author', GlobalSettings.Defaults.DEFAULT_AUTHOR); metadata_dict.setdefault('url', GlobalSettings.Defaults.DEFAULT_URL); metadata_dict.setdefault('email', GlobalSettings.Defaults.DEFAULT_EMAIL); metadata_dict.setdefault('date_created', datetime.now().strftime("%Y-%m-%d")); metadata_dict.setdefault('date_modified', datetime.now().strftime("%Y-%m-%d")); metadata_dict.setdefault('version', '1.0'); metadata_dict.setdefault('description', 'No description available.'); metadata_dict.setdefault('tags', []); metadata_dict.setdefault('dimension_compatibility', ["TWO_D", "THREE_D"]); metadata_dict.setdefault('neighborhood_compatibility', []); metadata_dict.setdefault('parent_rule', None); metadata_dict.setdefault('rating', None); metadata_dict.setdefault('notes', None); metadata_dict.setdefault('allowed_initial_conditions', ["Random"]); metadata_dict.setdefault('allow_rule_tables', True); metadata_dict.setdefault('favorite', False)
                metadata = RuleMetadata(**metadata_dict)
                new_rule_instance = RuleLibrary.create_rule(rule_name, metadata)
                logger.debug(f"{log_prefix}Created new rule instance with name: '{new_rule_instance.name}' (Type: {new_rule_instance.__class__.__name__})")
                params = rule_data.get('params', {})
                new_rule_instance.params = copy.deepcopy(params) # Use library defaults
                logger.debug(f"{log_prefix}  Initial params for new rule instance: {new_rule_instance.params}")
            except ValueError as e:
                logger.error(f"{log_prefix}Failed to load or create rule instance for '{rule_name}': {e}")
                messagebox.showerror("Error", f"Could not load rule '{rule_name}'.", parent=self.root)
                self._is_transitioning = False; return False
            # ---

            # --- 2. Explicitly Cleanup Old Grid, Visualizer, ViewManager ---
            logger.debug(f"{log_prefix}Step 2: Cleaning up old grid/viz/view...")
            if self.grid: logger.info(f"{log_prefix}Cleaning up existing grid (ID: {id(self.grid)}) before rule change."); self.grid.cleanup(); del self.grid; self.grid = None; self.controller.grid = None; logger.debug(f"{log_prefix}Deleted grid reference.")
            if self.grid_visualizer: logger.info(f"{log_prefix}Deleting grid_visualizer reference (ID: {id(self.grid_visualizer)})."); del self.grid_visualizer; self.grid_visualizer = None
            if self.view_manager: logger.info(f"{log_prefix}Deleting view_manager reference (ID: {id(self.view_manager)})."); del self.view_manager; self.view_manager = None
            if self.control_panel and self.control_panel.winfo_exists():
                logger.debug(f"{log_prefix}Destroying widgets inside control_panel frame.")
                for widget in list(self.control_panel.winfo_children()):
                    try: widget.destroy()
                    except Exception as cp_widget_destroy_err: logger.warning(f"Error destroying widget inside control_panel: {cp_widget_destroy_err}")
                self.control_panel_ui = None; logger.debug(f"{log_prefix}Widgets inside control_panel destroyed, self.control_panel_ui set to None.")
            else: logger.warning(f"{log_prefix}Control panel frame does not exist, cannot destroy its children.")
            gc.collect(); logger.info(f"{log_prefix}Existing grid/viz/view/control cleanup finished and GC called.")
            if hasattr(GridVisualizer, '_get_cached_cmap_norm') and hasattr(GridVisualizer._get_cached_cmap_norm, 'cache_clear'): GridVisualizer._get_cached_cmap_norm.cache_clear(); logger.info(f"{log_prefix}Cleared GridVisualizer._get_cached_cmap_norm LRU cache.")
            # ---

            # --- 3. Reset Simulation State (No Content Init, Reset Generation) ---
            logger.debug(f"{log_prefix}Step 3: Resetting simulation state...")
            self._reset_simulation_state_and_visualization(clear_grid_content=False, initialize_grid_content=False, reset_generation_counter=True)
            self._clear_lasso_selection()
            logger.debug(f"{log_prefix}Simulation state reset (counters, flags, stats, generation).")
            # ---

            # --- 4. Update Controller's Rule ---
            logger.debug(f"{log_prefix}Step 4: Updating controller's rule to '{rule_name}'")
            self.rule = new_rule_instance; self.rule_name = rule_name
            self.controller.rule = new_rule_instance; self.controller.rule_name = rule_name
            logger.debug(f"{log_prefix}Updated controller rule to: {self.controller.rule.name}")
            # ---

            # --- 5. Update Dimensions/Neighborhood based on NEW rule ---
            logger.debug(f"{log_prefix}Step 5: Updating dimensions/neighborhood based on new rule...")
            neighborhood_type_for_reinit = self.neighborhood_type
            if 'neighborhood_type' in new_rule_instance.params:
                try: neighborhood_type_for_reinit = NeighborhoodType[new_rule_instance.params['neighborhood_type']]
                except KeyError: logger.warning(f"Invalid neighborhood_type in rule params, using current GUI selection.")
            dimension_type_for_reinit = self.dimension_type
            if 'dimension_type' in new_rule_instance.params:
                 try: dimension_type_for_reinit = Dimension[new_rule_instance.params['dimension_type']]
                 except KeyError: logger.warning(f"Invalid dimension_type in rule params, using current GUI selection.")
            if dimension_type_for_reinit != self.dimension_type:
                 self.dimension_type = dimension_type_for_reinit; self.dimensions = GlobalSettings.Simulation.get_grid_dimensions()
                 self.controller.dimensions = self.dimensions; self.controller.dimension_type = self.dimension_type
                 logger.info(f"Dimension type updated to {self.dimension_type.name}.")
            if neighborhood_type_for_reinit != self.neighborhood_type:
                 self.neighborhood_type = neighborhood_type_for_reinit; self.controller.neighborhood_type = self.neighborhood_type
                 logger.info(f"Neighborhood type updated to {self.neighborhood_type.name}.")
            # ---

            # --- 6. Recreate Grid and Coord System ---
            logger.debug(f"{log_prefix}Step 6: Recreating grid and coord system with new rule '{rule_name}'")
            self.coord_system = CoordinateSystem(self.dimensions, GlobalSettings.Visualization.EDGE_SCALE, GlobalSettings.Visualization.NODE_SPACING, self.dimension_type)
            self.grid = Grid(self.dimensions, self.neighborhood_type, self.dimension_type, self.coord_system, gui=self, rule=self.controller.rule, unique_id=self._unique_id)
            self.controller.grid = self.grid; self.grid.setup_shared_memory()
            logger.debug(f"{log_prefix}Grid recreated. Grid object ID: {id(self.grid)}")
            # ---

            # --- 7. Recreate Visualizer and ViewManager AFTER new grid ---
            logger.debug(f"{log_prefix}Step 7: Recreating GridVisualizer and ViewManager.")
            self.grid_visualizer = GridVisualizer(self.grid, self.ax, self.fig, self.controller, self)
            self.view_manager = ViewManager(self.grid, self.ax, self.fig, self.coord_system, self.grid_visualizer, self, self.controller)
            self._setup_observers() # Re-register observers
            self._bind_plot_events() # Re-bind events to the new ViewManager
            logger.info(f"{log_prefix}Recreated Visualizer (ID: {id(self.grid_visualizer)}) and ViewManager (ID: {id(self.view_manager)}). Re-bound events.")
            # ---

            # --- 8. Initialize Grid Content using the NEW rule's default ---
            logger.info(f"{log_prefix}Step 8: Initializing grid content using NEW rule's default condition.")
            self._initialize_grid_content_based_on_rule() # This now handles different conditions
            # ---

            # --- 9. Update Prep Params ---
            logger.debug(f"{log_prefix}Step 9: Updating prep params.")
            self.update_prep_params_from_rule() # *** CRITICAL: Update prep params AFTER controller rule is set ***
            # ---

            # --- 10. Recreate ControlPanelUI ---
            logger.info(f"{log_prefix}Step 10: Recreating ControlPanelUI.")
            if self.control_panel is None or not self.control_panel.winfo_exists(): logger.error(f"{log_prefix}Control panel frame does not exist, cannot recreate UI.")
            else: self.control_panel_ui = ControlPanelUI(self.control_panel, self, initial_preset_obj=None); logger.info(f"{log_prefix}ControlPanelUI recreated (Instance ID: {id(self.control_panel_ui)}).")
            # ---

            # --- 11. Update GUI Elements (Now uses the new ControlPanelUI) ---
            logger.debug(f"{log_prefix}Step 11: Updating GUI elements...")
            self._set_active_preset(None); logger.debug(f"{log_prefix}Updating Tkinter StringVars...")
            self.dimension_var.set(self.dimension_type.name); self.neighborhood_var.set(self.neighborhood_type.name)
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                self._update_neighborhood_selector()
                self._programmatic_change = True # Set flag before setting initial_conditions_var
                try:
                    condition_to_display = self.controller.rule.get_param('initial_conditions', "Random") if self.controller.rule else "Random"
                    self.initial_conditions_var.set(condition_to_display); logger.debug(f"{log_prefix}Set initial_conditions_var to '{self.initial_conditions_var.get()}' based on new rule.")
                finally: self.root.after(10, self._clear_programmatic_change_flag); logger.debug(f"{log_prefix}Scheduled _clear_programmatic_change_flag.")
                self._update_initial_conditions_selector();
                boundary_from_rule = self.controller.rule.get_param('grid_boundary', 'bounded') if self.controller.rule else 'bounded'
                self.grid_boundary_var.set(boundary_from_rule); self.rule_type_var.set(RuleLibrary.get_rule_category(self.rule_name))
                self._update_rule_instance_selector(); self.rule_instance_var.set(self.rule_name)
                self._selected_rule_name = self.rule_name
                logger.info(f"{log_prefix}Updated rule/dimension/neighborhood/boundary/initial condition selectors.")
                node_density_scale_widget = self.control_panel_ui.widgets.get('node_density_scale'); edge_density_scale_widget = self.control_panel_ui.widgets.get('edge_density_scale')
                if isinstance(node_density_scale_widget, tk.Scale): node_density_scale_widget.config(command="")
                if isinstance(edge_density_scale_widget, tk.Scale): edge_density_scale_widget.config(command="")
                rule_init_density = new_rule_instance.get_param('initial_density', GlobalSettings.Simulation.INITIAL_NODE_DENSITY)
                if isinstance(node_density_scale_widget, tk.Scale): node_density_scale_widget.set(rule_init_density)
                rule_edge_density = new_rule_instance.get_param('connect_probability', GlobalSettings.Simulation.INITIAL_EDGE_DENSITY)
                if isinstance(edge_density_scale_widget, tk.Scale): edge_density_scale_widget.set(rule_edge_density)
                self.control_panel_ui.update_step_label()
                new_dims_str_internal = ",".join(map(str, self.dimensions)); display_val = "Custom..."
                if hasattr(self.control_panel_ui, 'common_sizes_map'):
                    for d, i in self.control_panel_ui.common_sizes_map.items():
                        if i == new_dims_str_internal: display_val = d; break
                if hasattr(self.control_panel_ui, 'widgets') and 'grid_size_combobox' in self.control_panel_ui.widgets and isinstance(self.control_panel_ui.widgets['grid_size_combobox'], ttk.Combobox): self.control_panel_ui.widgets['grid_size_combobox'].set(display_val)
                self.root.after(100, lambda: (isinstance(node_density_scale_widget, tk.Scale) and node_slider_cmd and node_density_scale_widget.config(command=node_slider_cmd), isinstance(edge_density_scale_widget, tk.Scale) and edge_slider_cmd and edge_density_scale_widget.config(command=edge_slider_cmd)))
                self.control_panel_ui.update_refocus_button_state()
            else:
                logger.error(f"{log_prefix}ControlPanelUI not created, cannot update GUI elements.")
            # ---

            # --- 12. Apply Color Scheme and Render ---
            logger.debug(f"{log_prefix}Step 12: Applying color scheme and rendering...")
            logger.debug(f"{log_prefix}Re-applying latest color scheme '{saved_latest_scheme.name}' before rule-specific colors.")
            # --- MODIFIED: Pass force_render=False ---
            self._apply_color_scheme(saved_latest_scheme, force_render=False)
            # ---
            effective_scheme = self._get_effective_color_scheme()
            # --- MODIFIED: Pass force_render=False ---
            self._apply_color_scheme(effective_scheme, force_render=False)
            # ---
            logger.debug(f"{log_prefix}Applied effective color scheme '{effective_scheme.name}' after applying rule.")
            # --- MODIFIED: Call _force_initial_render AFTER applying scheme ---
            self._force_initial_render()
            # ---
            # ---

            # --- 13. Update/Close Rule Editor ---
            logger.debug(f"{log_prefix}Step 13: Updating/Closing rule editor...")
            if hasattr(self, 'rule_editor_window') and self.rule_editor_window and self.rule_editor_window.winfo_exists():
                logger.info(f"{log_prefix}Rule editor window open, updating it for new rule '{rule_name}'.")
                self.rule_editor_window.destroy() # Close old editor
                self.rule_editor_window = None
                self.create_rule_editor_window(self.rule_name) # Open new one
            # ---

            logger.info(f"{log_prefix}Rule successfully changed to: {rule_name}")
            logger.info(f"{log_prefix}--- set_rule COMPLETED SUCCESSFULLY ---")

        except Exception as e:
            logger.error(f"{log_prefix}Error changing rule: {str(e)}")
            logger.error(f"{log_prefix}Traceback: {traceback.format_exc()}")
            messagebox.showerror("Error", f"Failed to change rule: {e}", parent=self.root)
            if rule_instance_before_update:
                logger.warning(f"{log_prefix}Attempting to restore previous rule '{rule_instance_before_update.name}' after error.")
                self.set_rule(rule_instance_before_update.name) # Recursive call, be careful
            self._is_transitioning = False; return False
        finally:
            # [ Restore slider commands, blitting, flags - Unchanged ]
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                node_density_scale_widget = self.control_panel_ui.widgets.get('node_density_scale')
                edge_density_scale_widget = self.control_panel_ui.widgets.get('edge_density_scale')
                if isinstance(node_density_scale_widget, tk.Scale) and node_slider_cmd: node_density_scale_widget.config(command=node_slider_cmd)
                if isinstance(edge_density_scale_widget, tk.Scale) and edge_slider_cmd: edge_density_scale_widget.config(command=edge_slider_cmd)
            if hasattr(self, 'grid_visualizer') and self.grid_visualizer: self.grid_visualizer.blitting_manager.set_enabled(original_blitting)
            self.running = False; self.paused = False; self._fixed_steps_running = False; self._stopped = False # Set stopped=False after change
            logger.info("Set _stopped = False in set_rule finally block.")
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui: self.control_panel_ui.update_button_states()
            self._is_transitioning = False
            self._initialization_complete = True
            gc.collect()
            logger.debug(f"{log_prefix}Set _initialization_complete = True and called GC in finally block.")
        return True

    def _clear_analytics_state(self, prompt_save: bool = True) -> bool:
        """
        Handles clearing analytics data. Prompts user to save if requested.
        Returns True if the calling action should proceed, False if cancelled.
        (Round 20: Re-applying Round 7 logic)
        """
        log_prefix = "SimulationGUI._clear_analytics_state: "
        logger.debug(f"{log_prefix}Initiating analytics clear (prompt_save={prompt_save}).")

        analytics_enabled = False
        if hasattr(self, 'analytics_enabled_var'):
            analytics_enabled = self.analytics_enabled_var.get()

        if not analytics_enabled:
            logger.debug(f"{log_prefix}Analytics not enabled, no clearing needed.")
            return True # Proceed, nothing to clear/save

        if not hasattr(self, 'controller') or not self.controller or not hasattr(self.controller, 'analytics_manager'):
            logger.error(f"{log_prefix}Controller or AnalyticsManager not available.")
            return True # Proceed, but log error

        manager = self.controller.analytics_manager

        # Prompt user to save if requested
        if prompt_save:
            response = messagebox.askyesnocancel(
                "Save Analytics?",
                "Analytics data exists from the previous run.\n\nDo you want to save the current analytics report before proceeding?",
                icon='question',
                parent=self.root
            )

            if response is None: # Cancel
                logger.info(f"{log_prefix}User cancelled the action.")
                return False # Do not proceed
            elif response: # Yes, save
                logger.info(f"{log_prefix}User chose to save analytics report.")
                if manager and hasattr(manager, 'save_report_now'):
                    saved_path = manager.save_report_now(filename_suffix="pre_reset")
                else:
                    logger.error("AnalyticsManager is not properly initialized or 'save_report_now' method is missing.")
                    saved_path = None
                if saved_path:
                    messagebox.showinfo("Report Saved", f"Analytics report saved to:\n{saved_path}", parent=self.root)
                else:
                    messagebox.showerror("Save Failed", "Could not save analytics report. Check logs.", parent=self.root)
                    # Ask if user wants to proceed despite save failure? For now, proceed.
            else: # No, don't save
                logger.info(f"{log_prefix}User chose not to save analytics report.")

        # Clear Analytics Data
        logger.info(f"{log_prefix}Clearing analytics history and queues.")
        if manager is not None:
            manager.clear_history()
        else:
            logger.error("AnalyticsManager is not properly initialized. Cannot clear history.")

        # Clear the input queue (where controller puts data)
        if hasattr(self.controller, 'analytics_data_in_queue'):
            q = self.controller.analytics_data_in_queue
            while not q.empty():
                try: q.get_nowait()
                except queue.Empty: break
            logger.debug(f"{log_prefix}Cleared controller's analytics_data_in_queue.")

        # Reset the display in the AnalyticsWindow if it's open
        if hasattr(self, 'analytics_window') and self.analytics_window and self.analytics_window.winfo_exists():
            try:
                self.analytics_window.reset_display()
                logger.debug(f"{log_prefix}Called reset_display() on AnalyticsWindow.")
            except Exception as e:
                logger.error(f"{log_prefix}Error resetting AnalyticsWindow display: {e}")

        logger.info(f"{log_prefix}Analytics state cleared.")
        return True # Proceed with the original action
    
    def reset(self, initial_density: Optional[float] = None, edge_initialization_type: str = 'RANDOM'):
        """Reset simulation to initial state"""
        try:
            logger.debug("=============== Entering reset_simulation SimulationGUI ===============")

            # Stop any running simulation
            self.running = False
            self.paused = False
            if hasattr(self, 'interrupt_requested'):
                self.interrupt_requested = False
                logger.debug("Interruption requested flag reset")

            # Clear existing state in the *grid*
            if self.grid is not None:
                logger.debug(f"reset_simulation: Calling self.grid.clear_grid(), grid ID = {self.grid._unique_id}")
                self.grid.clear_grid()  # THIS LINE WAS MISSING, AND IS CRITICAL
                logger.debug("Grid cleared successfully")
            else:
                logger.debug("reset_simulation: self.grid is None, cannot clear")

            # Reset counters and flags
            logger.debug("Resetting counters and flags")
            self.generation = 0
            self.step_count = 0  # CRITICAL: Reset the step_count
            self.is_running = False
            self.highlighted_nodes.clear()
            self.highlighted_edges.clear()
            self.last_updated_nodes.clear()
            self.last_updated_edges.clear()

            # Reset statistics
            logger.debug("Resetting statistics")
            self.stats.reset()
            if hasattr(self, 'perf_logger') and self.perf_logger:
                self.perf_logger.reset()

            # Initialize the grid with a random state
            if self.rule is not None:
                initial_conditions_type = self.rule.get_param('initial_conditions', "Random")
                if initial_conditions_type == "Random":
                    if initial_density is None:
                        initial_density = GlobalSettings.Simulation.INITIAL_NODE_DENSITY
                    self.controller._initialize_random_state(initial_density, edge_initialization_type)
                else:
                    # Handle other initial conditions (e.g., ShapeShifting)
                    if self.grid is not None:
                        self.rule.initialize_grid_state(self.grid)
                    else:
                        logger.error("Grid is None, cannot initialize grid state")
                        return

            logger.info("Simulation reset complete")

        except Exception as e:
            logger.error(f"Error in simulation reset: {str(e)}")
            raise

        finally:
            # Call the update callback.  The GUI will handle re-initializing
            # the Grid and GridVisualizer.
            if self._update_callback:
                self._update_callback()
            
            # --- ADDED: Force initial render after reset ---
            self._force_initial_render()
            logger.debug("Forced initial render after reset")

    def __del__(self):
        """Ensure cleanup on deletion"""
        self.cleanup()   

    def _get_change_tracker(self) -> Optional[ChangeTracker]:
        """Safely get change tracker"""
        return self.change_tracker if hasattr(self, 'change_tracker') else None

    def _disable_matplotlib_auto_figure(self):
        """Completely disable matplotlib's automatic figure creation"""
        try:
            # Import matplotlib and disable interactive mode
            import matplotlib
            import matplotlib.pyplot as plt
            
            # Close all existing figures
            plt.close('all')
            
            # Disable interactive mode
            plt.ioff()
            
            # Set the backend explicitly to TkAgg
            matplotlib.use('TkAgg')
            
            # Override plt.figure to prevent automatic figure creation
            original_figure = plt.figure
            
            def controlled_figure(*args, **kwargs):
                """Only create figures when explicitly called by our code"""
                # Check if this is being called from our code
                import traceback
                stack = traceback.extract_stack()
                
                # Only allow figure creation from specific methods
                allowed_methods = ['_setup_gui', 'initialize_visualization_tools']
                caller_method = stack[-2][2] if len(stack) >= 2 else None
                
                if caller_method in allowed_methods:
                    logger.debug(f"Allowing figure creation from {caller_method}")
                    return original_figure(*args, **kwargs)
                else:
                    logger.warning(f"Blocked automatic figure creation from {caller_method}")
                    # Return a dummy figure that won't be displayed
                    from matplotlib.figure import Figure
                    return Figure()
            
            # Replace plt.figure with our controlled version
            plt.figure = controlled_figure
            
            logger.info("Disabled matplotlib's automatic figure creation")
            
        except Exception as e:
            logger.error(f"Error disabling matplotlib auto figure: {e}")

    def _setup_gui(self, rule_name: str):
        """Initialize the GUI components"""
        try:
            # Import matplotlib modules directly
            import matplotlib
            matplotlib.use('TkAgg')
            
            # Close any existing figures
            import matplotlib.pyplot as plt
            plt.close('all')
            
            # Disable interactive mode
            plt.ioff()

            # Set window title (already done in __init__, but ensure it's set)
            self.root.title("LACE: Network Cellular Automata Engine")
            
            # Configure background color (already done in __init__, but ensure it's set)
            self.root.configure(bg=GlobalSettings.Colors.BACKGROUND)

            # Create main container with padding
            self.main_frame = tk.Frame(self.root, bg=GlobalSettings.Colors.BACKGROUND)
            self.main_frame.pack(fill=tk.BOTH, expand=True,
                                padx=GlobalSettings.Visualization.WINDOW_PADDING,
                                pady=GlobalSettings.Visualization.WINDOW_PADDING)

            # Create visualization frame first - make it expand fully
            self.viz_frame = tk.Frame(self.main_frame, bg=GlobalSettings.Colors.BACKGROUND)
            self.viz_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True,
                            padx=(0, GlobalSettings.Visualization.CONTROL_PADDING))

            # Create loading frame - this will initially show the background color
            self.loading_frame = tk.Frame(self.viz_frame, bg=GlobalSettings.Colors.BACKGROUND)
            self.loading_frame.pack(fill=tk.BOTH, expand=True)

            # Create control panel with fixed width
            self.control_panel = tk.Frame(
                self.main_frame,
                width=300,
                bg='#404040'
            )
            self.control_panel.pack(side=tk.RIGHT, fill=tk.Y)
            self.control_panel.pack_propagate(False)

            # Create scrollable frame inside control panel
            self.scrollable_control_frame = ScrollableFrame(self.control_panel, self, bg='#404040')
            self.scrollable_control_frame.pack(side=tk.TOP, fill=tk.BOTH, expand=True)

            # IMPORTANT: Make sure we're not creating any figures outside of our control
            # Close any existing figures again to be absolutely sure
            plt.close('all')

            # Now create our figure - use Figure directly without going through pyplot
            self.fig = Figure(figsize=GlobalSettings.Visualization.FIGURE_SIZE)
            self.fig.set_facecolor(GlobalSettings.Colors.BACKGROUND)

            # --- DELAYED CANVAS CREATION ---
            self.canvas = None  # Initialize to None

            # Create appropriate axes
            logger.debug("SimulationGUI._setup_gui: Creating axes")
            if GlobalSettings.Simulation.DIMENSION_TYPE == Dimension.THREE_D:
                self.ax = self.fig.add_subplot(111, projection='3d')
                if isinstance(self.ax, Axes3DType):  # Ensure self.ax is an Axes3DType
                    if hasattr(self, '_current_elev') and hasattr(self, '_current_azim'):
                        self.ax.view_init(elev=self._current_elev, azim=self._current_azim)
                    if hasattr(self.ax, 'set_box_aspect'):  # Check if set_box_aspect is available
                        self.ax.set_box_aspect([1, 1, 1])  # Set aspect ratio
                    else:
                        logger.warning("set_box_aspect is not available in this version of Matplotlib.")
                    logger.debug("Created 3D axes")
                else:
                    logger.error("self.ax is not an instance of Axes3DType. Skipping 3D-specific configurations.")
            else:
                self.ax = self.fig.add_subplot(111)
                try:
                    self.ax.set_aspect('equal')  # Ensure compatibility for 2D axes
                except NotImplementedError:
                    logger.warning("set_aspect('equal') is not supported for this type of axes.")
                logger.debug("Created 2D axes")

            # Set axes properties
            self.ax.set_facecolor(GlobalSettings.Colors.BACKGROUND)
            self.ax.grid(False)
            self.ax.set_axisbelow(True)
            self.ax.tick_params(colors='gray')
            
            # Remove spines
            for spine in self.ax.spines.values():
                spine.set_visible(False)

            # Remove ticks and labels, and turn off the axis
            self.ax.set_xticks([])
            self.ax.set_yticks([])
            if hasattr(self.ax, 'set_zticks'):
                self.ax.set_zticks([]) # type: ignore
            self.ax.set_axis_off()

            # Force integer ticks
            from matplotlib.ticker import MaxNLocator
            self.ax.xaxis.set_major_locator(MaxNLocator(integer=True))
            self.ax.yaxis.set_major_locator(MaxNLocator(integer=True))
            if self.controller.dimension_type == Dimension.THREE_D and hasattr(self.ax, 'zaxis'):
                self.ax.zaxis.set_major_locator(MaxNLocator(integer=True)) # type: ignore

            # --- Set initial plot limits based on grid dimensions ---
            # CRITICAL: Use the full grid dimensions, not just active nodes
            grid_size_x = self.dimensions[1]  # j is x
            grid_size_y = self.dimensions[0]  # i is y
            
            # Add a small margin around the grid
            margin_x = grid_size_x * 0.05
            margin_y = grid_size_y * 0.05
            
            # Set the limits to show the entire grid
            self.ax.set_xlim(-margin_x, grid_size_x + margin_x)
            self.ax.set_ylim(-margin_y, grid_size_y + margin_y)
            
            if self.controller.dimension_type == Dimension.THREE_D:
                grid_size_z = self.dimensions[2] if len(self.dimensions) > 2 else 0  # k is z
                margin_z = grid_size_z * 0.05
                self.ax.set_zlim(-margin_z, grid_size_z + margin_z)  # type: ignore

            logger.debug(f"Setting default axes limits: xlim={self.ax.get_xlim()}, ylim={self.ax.get_ylim()}")

            # Pack canvas after axes are configured
            if isinstance(self.canvas, FigureCanvasTkAgg):
                self.canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
            else:
                logger.error("Canvas is not a FigureCanvasTkAgg instance, cannot pack")

            # Create toolbar but don't display it
            self.toolbar = NavigationToolbar2Tk(self.canvas, self.viz_frame)
            self.toolbar.pack_forget()  # Hide the toolbar

            # REMOVED: self._setup_controls_content(self.scrollable_control_frame.scrolled_frame)
            # REMOVED: self._post_setup_controls()

            # Now that all GUI elements are created, trigger initial rule selection
            # self._on_rule_instance_change(self.controller.rule.name)

        except Exception as e:
            logger.error(f"Error in GUI setup: {e}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            raise

    def _close_extra_windows(self):
        """Close any extra windows that might have been created."""
        try:
            # Close any extra matplotlib figures
            import matplotlib.pyplot as plt
            
            # Get all figure numbers
            fig_nums = plt.get_fignums()
            
            # Log before closing
            logger.info(f"Found {len(fig_nums)} figures before cleanup")
            
            # Close all figures except our main one
            for num in fig_nums:
                fig = plt.figure(num)
                if not hasattr(self, 'fig') or fig is not self.fig:
                    logger.info(f"Closing extra figure {num}")
                    plt.close(fig)
            
            # Log after closing
            fig_nums = plt.get_fignums()
            logger.info(f"After cleanup: {len(fig_nums)} figures remain")
            
            # Check for any Tkinter toplevel windows
            if hasattr(self, 'root') and self.root:
                for child in self.root.winfo_children():
                    if isinstance(child, tk.Toplevel):
                        logger.info(f"Closing extra Tkinter window: {child}")
                        child.destroy()
            
        except Exception as e:
            logger.error(f"Error closing extra windows: {e}")

    def clear_grid(self):
        """
        Clears the grid completely, resets simulation state, and stops computation.
        Functions like a reset to an empty initial condition.
        (Round 16: Overhaul to mirror reset logic)
        """
        log_prefix = "SimulationGUI.clear_grid (R16 Overhaul): "
        logger.info(f"\n{'='*25} Clearing Grid (Full Reset to Empty) {'='*25}")

        # 1. Stop Computation Threads Cleanly
        if not self._stop_computation_threads(reason="Clear Grid"):
            logger.error(f"{log_prefix}Aborted: Failed to stop computation threads cleanly.")
            # Attempt to force stopped state anyway
            self.running = False; self.paused = False; self._stopped = True
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui: self.control_panel_ui.update_button_states()
            return
        logger.info(f"{log_prefix}Computation threads stopped.")
        if hasattr(self, '_stop_event') and self._stop_event: self._stop_event.clear()

        # Temporarily disable blitting
        original_blitting = self.grid_visualizer.blitting_manager.enabled if hasattr(self, 'grid_visualizer') and self.grid_visualizer else GlobalSettings.ENABLE_BLITTING
        if hasattr(self, 'grid_visualizer') and self.grid_visualizer: self.grid_visualizer.blitting_manager.set_enabled(False)

        try:
            # 2. Clear Undo/Redo Stacks
            self._grid_undo_stack.clear()
            self._grid_redo_stack.clear()
            logger.info(f"{log_prefix}Cleared undo/redo stacks.")

            # 3. Cleanup Old Grid Resources
            if self.grid:
                logger.info(f"{log_prefix}Cleaning up existing grid (ID: {id(self.grid)}).")
                self.grid.cleanup()
                del self.grid; self.grid = None; self.controller.grid = None
                logger.debug(f"{log_prefix}Deleted grid reference.")
            if self.grid_visualizer:
                 logger.info(f"{log_prefix}Deleting grid_visualizer reference (ID: {id(self.grid_visualizer)}).")
                 if self.grid: self.grid.remove_observer(self.grid_visualizer) # Should be None, but safe check
                 if self.controller: self.controller.remove_observer(self.grid_visualizer)
                 del self.grid_visualizer; self.grid_visualizer = None
            if self.view_manager:
                 logger.info(f"{log_prefix}Deleting view_manager reference (ID: {id(self.view_manager)}).")
                 del self.view_manager; self.view_manager = None
            gc.collect()
            logger.info(f"{log_prefix}Existing grid/viz/view cleanup finished and GC called.")

            # 4. Reset Simulation State (Counters, Flags, Stats)
            # Pass False flags to prevent redundant grid clearing/init inside reset
            self._reset_simulation_state_and_visualization(clear_grid_content=False, initialize_grid_content=False)
            logger.debug(f"{log_prefix}Simulation state reset (counters, flags, stats).")

            # 5. Recreate Grid Instance (Ensuring it's empty)
            logger.info(f"{log_prefix}Recreating grid instance.")
            rule_to_use = self.controller.rule if self.controller and self.controller.rule else None
            if rule_to_use is None: logger.error(f"{log_prefix}Cannot recreate grid: Controller or rule is missing."); return

            self.grid = Grid(
                self.dimensions, self.neighborhood_type, self.dimension_type,
                self.coord_system, gui=self, rule=rule_to_use, unique_id=self._unique_id
            )
            self.controller.grid = self.grid # Update controller ref
            # --- Explicitly call grid.clear_grid() on the NEW grid ---
            # This ensures arrays are zeroed, caches cleared, AND shared memory updated
            self.grid.clear_grid()
            logger.debug(f"{log_prefix}Grid recreated and explicitly cleared. Grid object ID: {id(self.grid)}")
            # ---

            # 6. Recreate Visualizer and ViewManager
            logger.debug(f"{log_prefix}Recreating GridVisualizer and ViewManager.")
            self.grid_visualizer = GridVisualizer(self.grid, self.ax, self.fig, self.controller, self)
            self.view_manager = ViewManager(self.grid, self.ax, self.fig, self.coord_system, self.grid_visualizer, self, self.controller)
            self._setup_observers() # Re-register observers
            self._bind_plot_events() # Re-bind events to the new ViewManager
            logger.info(f"{log_prefix}Recreated Visualizer (ID: {id(self.grid_visualizer)}) and ViewManager (ID: {id(self.view_manager)}). Re-bound events.")

            # 7. Final GUI Updates and Render
            self._set_active_preset(None) # Clear active preset
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                self.control_panel_ui.update_step_label()
                self.control_panel_ui.update_button_states() # Ensure buttons reflect stopped state
            logger.debug(f"{log_prefix}Calling _force_initial_render to draw the empty grid.")
            self._force_initial_render() # Draw the empty grid

            logger.info(f"{log_prefix}Grid clear operation completed.")

        except Exception as e:
            logger.error(f"{log_prefix}Error during clear grid operation: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Error", f"Failed to clear grid: {e}", parent=self.root)
        finally:
            # Ensure flags reflect stopped state
            self.running = False; self.paused = False; self._stopped = True # Set stopped TRUE after clear
            logger.info(f"{log_prefix}Set final state flags: running=False, paused=False, _stopped=True.")
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui: self.control_panel_ui.update_button_states()
            if hasattr(self, 'grid_visualizer') and self.grid_visualizer: self.grid_visualizer.blitting_manager.set_enabled(original_blitting)
            self._is_transitioning = False
            self._initialization_complete = True
            gc.collect()
            logger.debug(f"{log_prefix}Set _initialization_complete = True and called GC in finally block.")

    def _clear_lasso_selection(self):
        """Clears the current lasso selection and removes visual feedback."""
        logger.debug("Clearing lasso selection.")
        selection_cleared = False
        if hasattr(self, 'current_selection'):
            if self.current_selection.get('nodes'):
                self.current_selection['nodes'] = set()
                selection_cleared = True
            if self.current_selection.get('edges'):
                self.current_selection['edges'] = set()
                selection_cleared = True

        if hasattr(self, 'view_manager') and self.view_manager:
            # Remove the visual lasso line if it exists
            if hasattr(self.view_manager, '_remove_lasso_line'):
                self.view_manager._remove_lasso_line()
            # Clear lasso points stored in ViewManager
            if hasattr(self.view_manager, '_lasso_points'):
                self.view_manager._lasso_points = []

        # Update editor buttons if the editor is open
        self._update_editor_buttons_if_open()

        # Trigger a redraw if the selection was actually cleared to remove highlights
        if selection_cleared:
            logger.debug("Selection cleared, forcing redraw.")
            self._safe_plot_update(force=True)

    def _open_refocus_grid_modal(self):
        """Opens the Refocus Grid modal dialog."""
        if self.grid and self.grid.rule and self.grid.rule.get_param('grid_boundary', 'bounded') == 'wrap':
            RefocusGridModal(self.root, self)
        else:
            messagebox.showinfo("Refocus Grid", "Grid refocusing only applies when the 'Grid Boundary' is set to 'wrap'.", parent=self.root)

    def _on_toggle_periodic_reporting(self):
        """Handle periodic reporting checkbox toggle, dynamically adding/removing file handler."""
        is_enabled = self.periodic_reporting_var.get()
        LogSettings.Performance.ENABLE_PERIODIC_REPORTING = is_enabled
        logger.info(f"Periodic Reporting {'enabled' if is_enabled else 'disabled'}. Global Setting: {LogSettings.Performance.ENABLE_PERIODIC_REPORTING}")

        try:
            logger_periodic = logging.getLogger("periodic_report")
            # --- ADDED: Dynamic Handler Management ---
            if is_enabled:
                # Remove NullHandler if it exists
                null_handlers = [h for h in logger_periodic.handlers if isinstance(h, logging.NullHandler)]
                for h in null_handlers:
                    logger_periodic.removeHandler(h)
                    logger.debug("Removed NullHandler from periodic_report logger.")

                # Add FileHandler if it doesn't exist
                file_handlers = [h for h in logger_periodic.handlers if isinstance(h, logging.FileHandler)]
                if not file_handlers:
                    logger.info("Adding FileHandler to periodic_report logger.")
                    # Ensure level is set correctly (might have been NullHandler level before)
                    logger_periodic.setLevel(logging.INFO)
                    periodic_formatter = logging.Formatter('%(asctime)s - %(message)s')
                    timestamp_12hr = datetime.now().strftime("%Y%m%d_%I%M%S_%p")
                    periodic_filename = f'periodic_report_{timestamp_12hr}.log'
                    # Use APP_PATHS to get the correct directory
                    report_dir = self.app_paths.get('reports', os.path.join(os.getcwd(), APP_DIR, 'Resources', 'reports')) # Fallback added
                    os.makedirs(report_dir, exist_ok=True) # Ensure directory exists
                    periodic_file_path = os.path.join(report_dir, periodic_filename)
                    periodic_file_handler = logging.FileHandler(periodic_file_path)
                    periodic_file_handler.setFormatter(periodic_formatter)
                    logger_periodic.addHandler(periodic_file_handler)
                    logger.info(f"Periodic report file created: {periodic_file_path}")
                else:
                    logger.debug("FileHandler already exists for periodic_report logger.")

            else: # Reporting is disabled
                # Remove FileHandler if it exists
                file_handlers = [h for h in logger_periodic.handlers if isinstance(h, logging.FileHandler)]
                for h in file_handlers:
                    logger.info("Removing FileHandler from periodic_report logger.")
                    h.close() # Close the file handler
                    logger_periodic.removeHandler(h)

                # Add NullHandler if it doesn't exist
                null_handlers = [h for h in logger_periodic.handlers if isinstance(h, logging.NullHandler)]
                if not null_handlers:
                    logger.debug("Adding NullHandler to periodic_report logger.")
                    logger_periodic.addHandler(logging.NullHandler())
            # --- END ADDED ---
        except Exception as e:
            logger.error(f"Error updating periodic report logger handlers: {e}")

    def _on_toggle_deep_profiling(self):
        """Handle deep profiling checkbox toggle and dynamically manage file handler.
           (Round 15: Correct logic based on inverted variable state)."""
        is_enabled_var_value = self.deep_profiling_var.get()
        # --- Use the INVERSE of the variable's value for logic ---
        should_be_enabled = not is_enabled_var_value
        logger.debug(f"_on_toggle_deep_profiling: Checkbox variable value = {is_enabled_var_value}. Effective state for logic = {should_be_enabled}")

        # --- Update Global Setting based on the EFFECTIVE state ---
        LogSettings.Performance.ENABLE_DEEP_PROFILING = should_be_enabled
        log_message = f"Deep Profiling {'enabled' if should_be_enabled else 'disabled'}."
        logger.info(log_message + f" Global Setting updated to: {LogSettings.Performance.ENABLE_DEEP_PROFILING}")

        try:
            logger_profile = logging.getLogger("deep_profile")
            logger.debug(f"  Handlers BEFORE modification: {logger_profile.handlers}")

            # Remove ALL existing handlers first
            for handler in logger_profile.handlers[:]:
                try: handler.close()
                except: pass
                logger_profile.removeHandler(handler)
            logger.debug(f"  Removed all existing handlers. Handlers NOW: {logger_profile.handlers}")

            # --- Use the EFFECTIVE state (should_be_enabled) for logic ---
            if should_be_enabled: # If the checkbox *should* be enabled (user checked it)
                # Add FileHandler
                logger.info("Adding FileHandler to deep_profile logger.")
                logger_profile.setLevel(logging.DEBUG)
                profile_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
                timestamp_12hr = datetime.now().strftime("%Y%m%d_%I%M%S_%p")
                profile_filename = f'deep_profile_{timestamp_12hr}.log'
                profile_dir = self.app_paths.get('profiles', os.path.join(os.getcwd(), APP_DIR, 'Resources', 'profiles'))
                os.makedirs(profile_dir, exist_ok=True)
                profile_file_path = os.path.join(profile_dir, profile_filename)
                profile_file_handler = logging.FileHandler(profile_file_path)
                profile_file_handler.setFormatter(profile_formatter)
                logger_profile.addHandler(profile_file_handler)
                logger.info(f"Deep profile file created: {profile_file_path}")
                log_message += f" Logging to: {profile_file_path}"

                # Show warning about overhead
                log_message += " NOTE: Profiling adds significant overhead and will slow down the simulation."
                messagebox.showwarning("Profiling Enabled", "Deep profiling is enabled. This will significantly slow down the simulation.", parent=self.root)

            else: # Profiling should be disabled (user unchecked it)
                # Add NullHandler
                logger.info("Adding NullHandler to deep_profile logger.")
                logger_profile.addHandler(logging.NullHandler())
                logger_profile.setLevel(logging.CRITICAL + 1)
            # --- END Logic based on effective state ---

            logger.debug(f"  Handlers AFTER modification: {logger_profile.handlers}")

        except Exception as e:
            logger.error(f"Error updating deep_profile logger handlers: {e}")

        logger.info(log_message)

    def _on_toggle_detailed_logging(self):
        """Handle detailed logging checkbox toggle."""
        is_enabled = self.detailed_logging_var.get()
        LogSettings.Performance.ENABLE_DETAILED_LOGGING = is_enabled
        logger.info(f"Detailed Logging {'enabled' if is_enabled else 'disabled'}. Global Setting: {LogSettings.Performance.ENABLE_DETAILED_LOGGING}")

        # Re-apply the current logging level to potentially adjust the file handler level
        current_level_str = self.log_level_var.get()
        self._set_logging_level(current_level_str)

    def _on_toggle_logging_enabled(self):
        """Callback when the 'Enable Logging' checkbox is toggled."""
        is_enabled = self.logging_enabled_var.get()
        logger.info(f"Logging {'enabled' if is_enabled else 'disabled'} by user.")

        # Enable/disable dependent controls
        log_level_widget = None
        if self.control_panel_ui and hasattr(self.control_panel_ui, 'widgets'):
            log_level_widget = self.control_panel_ui.widgets.get('log_level_combobox')
        detailed_log_widget = None
        if self.control_panel_ui and hasattr(self.control_panel_ui, 'widgets'):
            detailed_log_widget = self.control_panel_ui.widgets.get('detailed_logging_checkbox')
        new_state = tk.NORMAL if is_enabled else tk.DISABLED

        if isinstance(log_level_widget, ttk.Combobox):
            log_level_widget.config(state=new_state)
        if isinstance(detailed_log_widget, tk.Checkbutton):
            detailed_log_widget.config(state=new_state)

        # Apply the level change
        if is_enabled:
            self._set_logging_level(self.log_level_var.get())
        else:
            # Disable logging by setting level very high
            root_logger = logging.getLogger()
            root_logger.setLevel(logging.CRITICAL + 1)
            # Optionally set handler levels high too
            for handler in root_logger.handlers:
                 handler.setLevel(logging.CRITICAL + 1)
            logger.info("Root logger and handlers level set to CRITICAL+1 to disable logging.")

    def _on_logging_level_change(self, event=None):
        """Callback when the logging level combobox selection changes."""
        selected_level_str = self.log_level_var.get()
        logger.info(f"User selected logging level: {selected_level_str}")
        self._set_logging_level(selected_level_str)

    def _set_logging_level(self, level_str: str):
        """Sets the logging level for relevant handlers based on the string.
           Handles activation/deactivation of the separate RenderingPipeline logger.
           When PIPELINE is active, root logger/handlers are forced to DEBUG/DETAIL.
           Ensures standard levels correctly configure root/handlers.
           (Round 33: Handle PIPELINE level activation/deactivation)
           (Round 5: Correct root logger level handling for PIPELINE mode)
           (Round 6: Explicitly restore root/handler levels for PIPELINE mode)
           (Round 7: Force main log to DEBUG/DETAIL when PIPELINE active)
           (Round 8: Add verbose level verification logging)
           (Round 10: Ensure standard levels set root/handlers correctly)"""
        log_prefix = "_set_logging_level (R10 Standard Level Fix): " # Updated round
        config_logger = logging.getLogger(__name__)
        config_logger.debug(f"{log_prefix}Setting log level to '{level_str}'.")

        if not self.logging_enabled_var.get():
            config_logger.debug(f"{log_prefix}Logging is globally disabled, skipping level set.")
            # --- Ensure loggers are disabled ---
            root_logger = logging.getLogger()
            rendering_logger = logging.getLogger("RenderingPipeline")
            root_logger.setLevel(logging.CRITICAL + 1)
            rendering_logger.setLevel(logging.CRITICAL + 1)
            for handler in root_logger.handlers: handler.setLevel(logging.CRITICAL + 1)
            for handler in rendering_logger.handlers: handler.setLevel(logging.CRITICAL + 1)
            config_logger.info(f"{log_prefix}Set all loggers/handlers to CRITICAL+1 as logging is disabled.")
            # ---
            return

        root_logger = logging.getLogger()
        rendering_logger = logging.getLogger("RenderingPipeline")
        detailed_enabled = self.detailed_logging_var.get()

        level_map = { # Define map for standard levels
            "DEBUG": logging.DEBUG, "DETAIL": DETAIL_LEVEL_NUM, "INFO": logging.INFO,
            "WARNING": logging.WARNING, "ERROR": logging.ERROR, "CRITICAL": logging.CRITICAL
        }

        if level_str == "PIPELINE":
            config_logger.info(f"{log_prefix}Activating PIPELINE logging.")
            # --- Activate RenderingPipeline Logger ---
            # [ Logic to add FileHandler and set level to DEBUG remains the same ]
            null_handlers = [h for h in rendering_logger.handlers if isinstance(h, logging.NullHandler)]
            for h in null_handlers: rendering_logger.removeHandler(h)
            file_handlers = [h for h in rendering_logger.handlers if isinstance(h, logging.FileHandler)]
            if not file_handlers:
                try:
                    timestamp_12hr = datetime.now().strftime("%Y%m%d_%I%M%S_%p")
                    pipeline_filename = f'rendering_pipeline_{timestamp_12hr}.log'
                    pipeline_log_path = os.path.join(self.app_paths['logs'], pipeline_filename)
                    pipeline_formatter = logging.Formatter('%(asctime)s.%(msecs)03d - %(levelname)s - [%(threadName)s] - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')
                    pipeline_file_handler = logging.FileHandler(pipeline_log_path)
                    pipeline_file_handler.setFormatter(pipeline_formatter)
                    rendering_logger.addHandler(pipeline_file_handler)
                    rendering_logger.setLevel(logging.DEBUG)
                    config_logger.info(f"{log_prefix}Activated RenderingPipeline logger. Logging to: {pipeline_log_path}")
                except Exception as e:
                    config_logger.error(f"{log_prefix}Failed to create FileHandler for RenderingPipeline logger: {e}")
                    rendering_logger.addHandler(logging.NullHandler())
                    rendering_logger.setLevel(logging.CRITICAL + 1)
            else:
                rendering_logger.setLevel(logging.DEBUG)
                config_logger.debug(f"{log_prefix}RenderingPipeline logger already has FileHandler. Ensured level is DEBUG.")
            config_logger.info(f"{log_prefix}VERIFY: RenderingPipeline logger effective level: {logging.getLevelName(rendering_logger.getEffectiveLevel())}")
            # ---

            # --- Force Root Logger/Handlers to DEBUG/DETAIL ---
            config_logger.info(f"{log_prefix}Forcing root logger/handlers to DEBUG/DETAIL while PIPELINE active.")
            main_target_level = DETAIL_LEVEL_NUM if detailed_enabled else logging.DEBUG
            root_logger.setLevel(main_target_level) # Set root level
            config_logger.info(f"{log_prefix}Set root logger level to {logging.getLevelName(main_target_level)}.")
            config_logger.info(f"{log_prefix}VERIFY: Root logger effective level: {logging.getLevelName(root_logger.getEffectiveLevel())}")
            for handler in root_logger.handlers: # Set handler levels
                handler_name = type(handler).__name__
                handler.setLevel(main_target_level)
                config_logger.info(f"{log_prefix}Set Root {handler_name} level to {logging.getLevelName(main_target_level)}.")
                config_logger.info(f"{log_prefix}VERIFY: Root {handler_name} actual level: {logging.getLevelName(handler.level)}")
            # ---

        else: # Handle standard log levels (DEBUG, INFO, etc.)
            config_logger.info(f"{log_prefix}Setting standard log level: {level_str}")
            # --- Deactivate RenderingPipeline Logger ---
            # [ Logic remains the same as Round 6 ]
            file_handlers = [h for h in rendering_logger.handlers if isinstance(h, logging.FileHandler)]
            if file_handlers:
                config_logger.info(f"{log_prefix}Deactivating RenderingPipeline logger.")
                for h in file_handlers:
                    try: h.close()
                    except: pass
                    rendering_logger.removeHandler(h)
                if not rendering_logger.hasHandlers(): rendering_logger.addHandler(logging.NullHandler())
            rendering_logger.setLevel(logging.CRITICAL + 1)
            config_logger.info(f"{log_prefix}VERIFY: RenderingPipeline logger effective level: {logging.getLevelName(rendering_logger.getEffectiveLevel())}")
            # ---

            # --- Set Root Logger Handlers based on selected level ---
            numeric_level = level_map.get(level_str.upper(), logging.INFO) # Default to INFO

            # --- MODIFIED: Determine target levels based on selection and detailed flag ---
            file_target_level = numeric_level
            if detailed_enabled and numeric_level >= logging.INFO:
                file_target_level = DETAIL_LEVEL_NUM # Use DETAIL for file if detailed enabled and level is INFO+
            console_target_level = max(logging.INFO, numeric_level) # Console still >= INFO
            # Root logger level should be the minimum of the *intended* handler levels
            min_intended_handler_level = min(file_target_level, console_target_level)
            # --- END MODIFIED ---

            found_file_handler = False; found_console_handler = False
            for handler in root_logger.handlers:
                handler_name = type(handler).__name__
                if isinstance(handler, logging.FileHandler):
                    handler.setLevel(file_target_level) # Set file handler level
                    found_file_handler = True
                    config_logger.info(f"{log_prefix}Set Root {handler_name} level to {logging.getLevelName(file_target_level)}")
                    config_logger.info(f"{log_prefix}VERIFY: Root {handler_name} actual level: {logging.getLevelName(handler.level)}")
                elif isinstance(handler, logging.StreamHandler):
                    handler.setLevel(console_target_level) # Set console handler level
                    found_console_handler = True
                    config_logger.info(f"{log_prefix}Set Root {handler_name} level to {logging.getLevelName(console_target_level)}")
                    config_logger.info(f"{log_prefix}VERIFY: Root {handler_name} actual level: {logging.getLevelName(handler.level)}")

            if not found_file_handler: config_logger.warning(f"{log_prefix}Could not find Root FileHandler to set level.")
            if not found_console_handler: config_logger.warning(f"{log_prefix}Could not find Root StreamHandler to set level.")

            # --- MODIFIED: Set root logger level to the minimum INTENDED handler level ---
            root_logger.setLevel(min_intended_handler_level)
            config_logger.info(f"{log_prefix}Set root logger level to {logging.getLevelName(min_intended_handler_level)}.")
            config_logger.info(f"{log_prefix}VERIFY: Root logger effective level: {logging.getLevelName(root_logger.getEffectiveLevel())}")
            # --- END MODIFIED ---

    def _validate_reporting_interval(self, P):
        """Validation command for reporting interval entry."""
        if P == "": return True # Allow empty
        if P.isdigit():
            num = int(P)
            if LogSettings.Performance.MIN_REPORTING_INTERVAL <= num <= LogSettings.Performance.MAX_REPORTING_INTERVAL:
                return True
        return False

    def _on_reporting_interval_change(self, event=None):
        """Handle reporting interval entry change (FocusOut or Return)."""
        try:
            value_str = self.reporting_interval_var.get()
            if self._validate_reporting_interval(value_str):
                new_interval = int(value_str)
                if new_interval != LogSettings.Performance.REPORTING_INTERVAL:
                    LogSettings.Performance.REPORTING_INTERVAL = new_interval
                    logger.info(f"Reporting interval changed to: {new_interval}")
            else:
                # Revert to the global setting if invalid
                logger.warning(f"Invalid reporting interval '{value_str}', reverting.")
                self.reporting_interval_var.set(str(LogSettings.Performance.REPORTING_INTERVAL))
                messagebox.showerror("Invalid Interval", f"Reporting interval must be between {LogSettings.Performance.MIN_REPORTING_INTERVAL} and {LogSettings.Performance.MAX_REPORTING_INTERVAL}.", parent=self.root)
        except ValueError:
             logger.warning(f"Invalid reporting interval '{value_str}', reverting.")
             self.reporting_interval_var.set(str(LogSettings.Performance.REPORTING_INTERVAL))
             messagebox.showerror("Invalid Interval", "Reporting interval must be a whole number.", parent=self.root)
        except Exception as e:
            logger.error(f"Error handling reporting interval change: {e}")
    
    def toggle_control_panel(self):
        """Toggle the visibility of the control panel."""
        if self.control_panel and self.control_panel.winfo_ismapped():
            self.control_panel.pack_forget()
            self.hide_show_control_panel_text.set("Show Control Panel")
        elif self.control_panel:
            self.control_panel.pack(side=tk.RIGHT, fill=tk.Y)
            self.hide_show_control_panel_text.set("Hide Control Panel")
        # No need to redraw the canvas here; the pack/unpack will trigger a redraw
            
    def _on_toggle_parallel(self):
        """Handle toggling parallel processing on/off.
           Updates global setting and logs the change.
           (Round 9: Added logging and global setting update)"""
        log_prefix = "SimulationGUI._on_toggle_parallel: "
        try:
            if not hasattr(self, 'parallel_var'):
                logger.error(f"{log_prefix}parallel_var attribute missing.")
                return

            use_parallel = self.parallel_var.get()
            GlobalSettings.USE_PARALLEL_PROCESSING = use_parallel
            logger.info(f"{log_prefix}Parallel processing {'enabled' if use_parallel else 'disabled'}. Global Setting: {GlobalSettings.USE_PARALLEL_PROCESSING}")

            # --- ADDED: Log pool type change intention ---
            # Note: The actual pool recreation happens in _initialize_process_pool
            #       when the simulation starts or is reset. This log just indicates the intent.
            if use_parallel and GlobalSettings.Simulation.NUM_PROCESSES > 1:
                logger.info(f"{log_prefix}Intention set to use ProcessPoolExecutor on next pool initialization.")
            else:
                logger.info(f"{log_prefix}Intention set to use ThreadPoolExecutor on next pool initialization.")
            # ---

            # Optional: Show a message that a restart might be needed if changed during run
            if self.running or self.paused:
                 messagebox.showinfo("Parallel Setting Changed",
                                     "Parallel processing setting changed.\nThis will take effect the next time the simulation is started or reset.",
                                     parent=self.root)

        except Exception as e:
            logger.error(f"{log_prefix}Error toggling parallel processing: {e}")

    def _on_stability_detection_toggle(self):
        """Handle stability detection checkbox change."""
        self.auto_stabilize = self.stability_detection_var.get()
        if hasattr(self.controller, 'auto_stabilize'):
            self.controller.auto_stabilize = self.auto_stabilize
        logger.info(f"Stability detection {'enabled' if self.auto_stabilize else 'disabled'}")
        # No redraw needed, just update the flag

    def _on_preset_var_changed(self, *args):
        """Handle changes to the preset_var"""
        preset_name = self.preset_var.get()
        if preset_name and preset_name != "None":
            logger.info(f"Preset variable changed to: {preset_name}, calling _on_preset_selected")
            self._on_preset_selected(preset_name)

    def _on_preset_selected(self, preset_name: str):
        """Handle grid preset selection"""
        try:
            logger.info(f"Grid preset selected: {preset_name}")

            # Set the preset_var to the selected preset name
            self.preset_var.set(preset_name)

            # Handle the "None" option
            if preset_name == "None":
                self._set_active_preset(None)
                return

            # Load the selected preset
            preset = self.grid_preset_manager.get_preset(preset_name)

            if preset:
                # logger.debug(f"_on_preset_selected: Preset '{preset_name}' found: {preset}") -- more extensive logging of array shape
                logger.debug(f"_on_preset_selected: Preset '{preset_name}'")
                # Apply the preset to the grid
                # --- MODIFIED: Call apply_grid_preset on self.gui ---
                self.apply_grid_preset(preset)
                # ---
                self._set_active_preset(preset_name) # Set active preset
            else:
                logger.error(f"_on_preset_selected: Grid preset '{preset_name}' not found.")
                # Handle the case where the preset is not found
                messagebox.showerror("Error", f"Grid preset '{preset_name}' not found.")

        except Exception as e:
            logger.error(f"Error applying grid preset: {e}")
            messagebox.showerror("Error", f"Failed to apply grid preset: {e}")

    def apply_grid_preset(self, preset: 'GridPreset') -> bool:
        """
        Apply a grid preset's configuration and initialize state based on its mode.
        Handles degree or active neighbor count calculation for relevant rules when loading SAVED_STATE,
        preserving the visual 0/1 pattern in grid_array for the initial render.
        Delegates initialization to InitialConditionManager or ShapePlacer for other modes.
        Updates the initial_conditions_var based on the preset's mode.
        Ensures preset densities AND edge init type are applied correctly before initialization.
        (Round 20: Correctly apply SPECIFIC_CONDITION/LIBRARY_SHAPE modes)
        (Round 15: Set/Clear init flag, remove forced render)
        """
        preset_content_applied = False
        log_prefix = f"SimulationGUI.apply_grid_preset(Preset='{preset.name}', Mode='{preset.initialization_mode}' R20 Fix): " # Updated round
        logger.info(f"{log_prefix}Applying preset...")
        logger.debug(f"{log_prefix}  Preset object received: Name='{preset.name}', Mode='{preset.initialization_mode}', Data='{preset.initialization_data}', State is None: {preset.initial_state is None}, Edges is None: {preset.edges is None}")
        if preset.initial_state is not None:
            logger.debug(f"    Preset initial_state shape: {preset.initial_state.shape}, dtype: {preset.initial_state.dtype}, Sum: {np.sum(preset.initial_state)}")

        # --- Set applying preset AND initialization flags ---
        self._applying_preset = True
        self._is_initializing_or_applying_preset = True
        logger.debug(f"{log_prefix}Set _applying_preset=True, _is_initializing_or_applying_preset=True")
        # ---
        initial_render_done = False # Flag to track if final render happened

        try:
            # --- Stop simulation and reset state (keep generation counter) ---
            if not self._stop_computation_threads(reason=f"Apply Preset {preset.name}"):
                logger.error(f"{log_prefix}Aborted: Failed to stop computation threads cleanly.")
                self._applying_preset = False; self._is_initializing_or_applying_preset = False; return False # Clear flags on failure
            if hasattr(self, '_stop_event') and self._stop_event: self._stop_event.clear()
            self._reset_simulation_state_and_visualization(clear_grid_content=False, initialize_grid_content=False, reset_generation_counter=False) # Keep generation
            # ---

            # --- Update structural parameters (Dimensions, Neighborhood, Rule) ---
            new_dimensions = tuple(preset.dimensions)
            new_dimension_type = Dimension.TWO_D if len(new_dimensions) == 2 else Dimension.THREE_D
            new_neighborhood_type = NeighborhoodType[preset.neighborhood_type]
            new_rule_name = preset.rule_name

            # Update internal state
            self.dimensions = new_dimensions; self.dimension_type = new_dimension_type; self.neighborhood_type = new_neighborhood_type
            self.controller.dimensions = self.dimensions; self.controller.dimension_type = self.dimension_type; self.controller.neighborhood_type = self.neighborhood_type
            logger.info(f"{log_prefix}Updated internal dimensions/neighborhood to match preset.")

            # Load and set the rule specified by the preset
            try:
                rule_data = RuleLibraryManager.get_rule(new_rule_name)
                metadata_dict = {k: v for k, v in rule_data.items() if k != 'params' and k != '_ignored_params'}; metadata_dict['name'] = new_rule_name
                metadata_dict.setdefault('position', 1); metadata_dict.setdefault('category', 'Unknown'); metadata_dict.setdefault('author', GlobalSettings.Defaults.DEFAULT_AUTHOR); metadata_dict.setdefault('url', GlobalSettings.Defaults.DEFAULT_URL); metadata_dict.setdefault('email', GlobalSettings.Defaults.DEFAULT_EMAIL); metadata_dict.setdefault('date_created', datetime.now().strftime("%Y-%m-%d")); metadata_dict.setdefault('date_modified', datetime.now().strftime("%Y-%m-%d")); metadata_dict.setdefault('version', '1.0'); metadata_dict.setdefault('description', 'No description available.'); metadata_dict.setdefault('tags', []); metadata_dict.setdefault('dimension_compatibility', ["TWO_D", "THREE_D"]); metadata_dict.setdefault('neighborhood_compatibility', []); metadata_dict.setdefault('parent_rule', None); metadata_dict.setdefault('rating', None); metadata_dict.setdefault('notes', None); metadata_dict.setdefault('allowed_initial_conditions', ["Random"]); metadata_dict.setdefault('allow_rule_tables', True); metadata_dict.setdefault('favorite', False)
                metadata = RuleMetadata(**metadata_dict)
                new_rule_instance = RuleLibrary.create_rule(new_rule_name, metadata)
                logger.debug(f"{log_prefix}Created new rule instance with name: '{new_rule_instance.name}' (Type: {new_rule_instance.__class__.__name__})")
                preset_params = preset.to_dict().get('params')
                if preset_params:
                    logger.debug(f"{log_prefix}Applying specific parameters stored in preset '{preset.name}'.")
                    new_rule_instance.params = copy.deepcopy(preset_params)
                else:
                    logger.debug(f"{log_prefix}Preset '{preset.name}' has no specific params, ensuring rule uses library defaults.")
                    library_params = rule_data.get('params', {})
                    new_rule_instance.params = copy.deepcopy(library_params)

                # --- Set density params from preset AFTER loading other params ---
                logger.debug(f"{log_prefix}Applying preset densities to rule: Node={preset.node_density:.3f}, Edge={preset.edge_density:.3f}")
                new_rule_instance.update_parameter('initial_density', preset.node_density)
                new_rule_instance.update_parameter('connect_probability', preset.edge_density) # connect_probability uses edge_density
                # ---

                self.rule = new_rule_instance; self.rule_name = new_rule_name
                self.controller.rule = new_rule_instance; self.controller.rule_name = new_rule_name
                logger.info(f"{log_prefix}Rule set to '{new_rule_name}' from preset.")
            except Exception as e:
                logger.error(f"{log_prefix}Failed to load or set rule '{new_rule_name}' from preset: {e}")
                messagebox.showerror("Error", f"Could not load rule '{new_rule_name}' specified by preset.", parent=self.root)
                self._applying_preset = False; self._is_initializing_or_applying_preset = False; return False # Clear flags on failure
            # ---

            # --- Recreate Grid, Visualizer, ViewManager ---
            logger.debug(f"{log_prefix}Recreating grid, visualizer, view manager...")
            self.coord_system = CoordinateSystem(self.dimensions, GlobalSettings.Visualization.EDGE_SCALE, GlobalSettings.Visualization.NODE_SPACING, self.dimension_type)
            self.grid = Grid(self.dimensions, self.neighborhood_type, self.dimension_type, self.coord_system, gui=self, rule=self.controller.rule, unique_id=self._unique_id)
            self.controller.grid = self.grid
            self.grid.setup_shared_memory()
            self.grid_visualizer = GridVisualizer(self.grid, self.ax, self.fig, self.controller, self)
            self.view_manager = ViewManager(self.grid, self.ax, self.fig, self.coord_system, self.grid_visualizer, self, self.controller)
            self._setup_observers()
            self._bind_plot_events()
            logger.debug(f"{log_prefix}Grid/Viz/View recreated.")
            # ---

            # --- Apply Preset Content (State/Edges) OR Initialize based on Mode ---
            logger.info(f"{log_prefix}Applying preset content (Mode: {preset.initialization_mode})...")
            # --- MODIFIED: Handle SPECIFIC_CONDITION and LIBRARY_SHAPE correctly ---
            if preset.initialization_mode == "SAVED_STATE":
                preset_content_applied = self.grid.apply_preset(preset)
                if not preset_content_applied:
                    logger.error(f"{log_prefix}grid.apply_preset failed for preset '{preset.name}'.")
            elif preset.initialization_mode == "LIBRARY_SHAPE":
                preset_content_applied = self.grid.apply_preset(preset) # Grid method handles shape placement
                if not preset_content_applied:
                    logger.error(f"{log_prefix}grid.apply_preset failed for LIBRARY_SHAPE preset '{preset.name}'.")
            elif preset.initialization_mode == "RULE_DEFAULT":
                logger.info(f"{log_prefix}Initializing grid using RULE_DEFAULT condition ('{self.controller.rule.get_param('initial_conditions', 'Random')}') with preset densities.")
                # Use the rule's default condition name, but preset densities
                condition_name = self.controller.rule.get_param('initial_conditions', "Random")
                edge_init_type = self.controller.rule.get_param('edge_initialization', 'RANDOM')
                # Ensure rule params reflect preset densities for this init
                self.controller.rule.update_parameter('initial_density', preset.node_density)
                self.controller.rule.update_parameter('connect_probability', preset.edge_density)
                manager = InitialConditionManager.get_instance()
                manager.apply(condition_name, self.grid) # Apply the rule's default condition
                preset_content_applied = True
            elif preset.initialization_mode == "SPECIFIC_CONDITION":
                condition_name = preset.initialization_data
                if condition_name:
                    logger.info(f"{log_prefix}Initializing grid using SPECIFIC_CONDITION '{condition_name}' with preset densities.")
                    edge_init_type = self.controller.rule.get_param('edge_initialization', 'RANDOM')
                    # Ensure rule params reflect preset densities for this init
                    self.controller.rule.update_parameter('initial_density', preset.node_density)
                    self.controller.rule.update_parameter('connect_probability', preset.edge_density)
                    manager = InitialConditionManager.get_instance()
                    manager.apply(condition_name, self.grid) # Apply the specific condition
                    preset_content_applied = True
                else:
                    logger.error(f"{log_prefix}Preset mode is SPECIFIC_CONDITION but initialization_data is missing.")
                    preset_content_applied = False
            # --- END MODIFIED ---
            else:
                logger.error(f"{log_prefix}Unknown initialization_mode: '{preset.initialization_mode}'. Grid not initialized.")
                preset_content_applied = False
            # ---

            # [ Logging AFTER initialization step - Unchanged ]
            if self.grid and self.grid.grid_array is not None:
                active_count_after_init = np.sum(self.grid.grid_array > 1e-6)
                total_nodes_after_init = self.grid.total_nodes
                actual_density = active_count_after_init / total_nodes_after_init if total_nodes_after_init > 0 else 0.0
                logger.info(f"{log_prefix}Grid state AFTER initialization step (Mode: {preset.initialization_mode}): Active Nodes={active_count_after_init}, Actual Density={actual_density:.3f} (Preset Node Density was {preset.node_density:.3f})")
            else: logger.error(f"{log_prefix}Grid is None AFTER initialization step!")
            # ---

            # --- Update GUI Elements ---
            logger.debug(f"{log_prefix}Updating GUI elements...")
            self._set_active_preset(preset.name) # Set active preset name
            self.dimension_var.set(self.dimension_type.name)
            self.neighborhood_var.set(self.neighborhood_type.name)
            self.rule_type_var.set(RuleLibrary.get_rule_category(self.rule_name))
            self._update_rule_instance_selector() # Update instance list for the category
            self.rule_instance_var.set(self.rule_name) # Select the correct rule instance

            # --- Set Initial Conditions Dropdown based on PRESET ---
            self._programmatic_change = True
            try:
                condition_to_display = "Random" # Default fallback
                if preset.initialization_mode == "SAVED_STATE": condition_to_display = "Pattern"
                elif preset.initialization_mode == "LIBRARY_SHAPE": condition_to_display = f"Shape: {preset.initialization_data}" if preset.initialization_data else "Shape: Unknown"
                elif preset.initialization_mode == "SPECIFIC_CONDITION": condition_to_display = preset.initialization_data if preset.initialization_data else "Random"
                elif preset.initialization_mode == "RULE_DEFAULT": condition_to_display = self.controller.rule.get_param('initial_conditions', "Random") if self.controller.rule else "Random"
                self.initial_conditions_var.set(condition_to_display)
                logger.info(f"{log_prefix}Set initial_conditions_var to '{condition_to_display}' based on preset mode.")
            finally:
                self.root.after(10, self._clear_programmatic_change_flag)
            self._update_initial_conditions_selector() # Update options and selection display
            # ---

            # --- Update density sliders AFTER applying preset ---
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                node_density_scale_widget = self.control_panel_ui.widgets.get('node_density_scale')
                edge_density_scale_widget = self.control_panel_ui.widgets.get('edge_density_scale')
                node_cmd = None; edge_cmd = None
                if isinstance(node_density_scale_widget, tk.Scale): node_cmd = node_density_scale_widget.cget('command'); node_density_scale_widget.config(command="")
                if isinstance(edge_density_scale_widget, tk.Scale): edge_cmd = edge_density_scale_widget.cget('command'); edge_density_scale_widget.config(command="")
                if isinstance(node_density_scale_widget, tk.Scale): node_density_scale_widget.set(preset.node_density)
                if isinstance(edge_density_scale_widget, tk.Scale): edge_density_scale_widget.set(preset.edge_density)
                logger.debug(f"{log_prefix}Set density sliders to preset values: Node={preset.node_density:.3f}, Edge={preset.edge_density:.3f}")
                if isinstance(node_density_scale_widget, tk.Scale) and node_cmd: node_density_scale_widget.config(command=node_cmd)
                if isinstance(edge_density_scale_widget, tk.Scale) and edge_cmd: edge_density_scale_widget.config(command=edge_cmd)
                boundary_from_rule = self.controller.rule.get_param('grid_boundary', 'bounded') if self.controller.rule else 'bounded'
                self.grid_boundary_var.set(boundary_from_rule)
                self.control_panel_ui.update_step_label() # Reset step label
                self.control_panel_ui.update_button_states() # Set buttons to stopped state
                self.control_panel_ui.update_refocus_button_state()
            # ---

            # --- Apply Color Scheme (WITHOUT rendering yet) ---
            effective_scheme = self._get_effective_color_scheme()
            self._apply_color_scheme(effective_scheme, force_render=False)
            logger.debug(f"{log_prefix}Applied effective color scheme '{effective_scheme.name}' (render skipped).")
            # ---

            # --- Update Rule Editor if Open ---
            if hasattr(self, 'rule_editor_window') and self.rule_editor_window and self.rule_editor_window.winfo_exists():
                logger.info(f"{log_prefix}Rule editor window open, updating it for new rule '{self.rule_name}'.")
                self.rule_editor_window.destroy() # Close old editor
                self.rule_editor_window = None
                self.create_rule_editor_window(self.rule_name) # Open new one
            # ---

            logger.info(f"{log_prefix}Preset '{preset.name}' applied successfully.")
            return True # Indicate success

        except Exception as e:
            logger.error(f"{log_prefix}Error applying preset: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Error", f"Failed to apply preset: {e}", parent=self.root)
            rule_instance_before_update = None
            if rule_instance_before_update:
                logger.warning(f"{log_prefix}Attempting to restore previous rule '{rule_instance_before_update.name}' after error.")
                self.set_rule(rule_instance_before_update.name) # Recursive call
            return False
        finally:
            # [ Restore slider commands, blitting, flags - Unchanged ]
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                node_density_scale_widget = self.control_panel_ui.widgets.get('node_density_scale')
                edge_density_scale_widget = self.control_panel_ui.widgets.get('edge_density_scale')
                node_slider_cmd = self._on_node_density_change
                if isinstance(node_density_scale_widget, tk.Scale): node_density_scale_widget.config(command=node_slider_cmd)
                edge_slider_cmd = self._on_edge_density_change
                if isinstance(edge_density_scale_widget, tk.Scale) and edge_slider_cmd: edge_density_scale_widget.config(command=edge_slider_cmd)
            original_blitting = self.grid_visualizer.blitting_manager.enabled if hasattr(self, 'grid_visualizer') and self.grid_visualizer else GlobalSettings.ENABLE_BLITTING
            if hasattr(self, 'grid_visualizer') and self.grid_visualizer: self.grid_visualizer.blitting_manager.set_enabled(original_blitting)
            self.running = False; self.paused = False; self._fixed_steps_running = False; self._stopped = False
            logger.info("Set _stopped = False in apply_grid_preset finally block.")
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui: self.control_panel_ui.update_button_states()
            self._is_transitioning = False
            self._initialization_complete = True
            # --- CLEAR FLAGS ---
            self._applying_preset = False
            self._is_initializing_or_applying_preset = False
            logger.debug(f"{log_prefix}Cleared _applying_preset=False, _is_initializing_or_applying_preset=False")
            # ---
            gc.collect()
            logger.debug(f"{log_prefix}Set _initialization_complete = True and called GC in finally block.")
            # --- ADDED: Final Render Call ---
            logger.info(f"{log_prefix}Scheduling FINAL render after preset application.")
            self.root.after(50, self._force_initial_render) # Schedule final render
            # ---

    def _load_preset_in_thread(self, preset_name: str): 
        """Load the selected grid preset in a separate thread."""
        try:
            logger.debug(f"_load_preset_in_thread: Loading preset '{preset_name}' in background thread")
            # Load the selected preset
            preset = self.grid_preset_manager.get_preset(preset_name)

            if preset:
                logger.debug(f"_load_preset_in_thread: Preset '{preset_name}' found: {preset}")
                # Apply the preset to the grid *on the main thread*
                # --- MODIFIED: Call apply_grid_preset on self.gui ---
                self.root.after(0, lambda p=preset: self.apply_grid_preset(p))
                # ---
                self.root.after(0, lambda p=preset_name: self._set_active_preset(p))
            else:
                logger.error(f"_load_preset_in_thread: Grid preset '{preset_name}' not found.")
                # Handle the case where the preset is not found
                self.root.after(0, lambda: messagebox.showerror("Error", f"Grid preset '{preset_name}' not found."))

        except Exception as e:
            logger.error(f"Error loading grid preset in thread: {e}\n{traceback.format_exc()}")
            # Show error message on the main thread
            self.root.after(0, lambda: messagebox.showerror("Error", f"Failed to load grid preset: {e}"))

    def _clear_programmatic_change_flag(self):
        """Clears the programmatic change flag."""
        logger.debug(f"_clear_programmatic_change_flag: Before clearing, current value of _programmatic_change: {self._programmatic_change}")
        self._programmatic_change = False
        logger.debug("Cleared _programmatic_change flag.")

    def _clear_preset_flags(self):
        """Clears the _applying_preset and _programmatic_change flags."""
        logger.debug("_clear_preset_flags: Clearing _applying_preset and _programmatic_change flags.")
        self._applying_preset = False
        self._programmatic_change = False
        # No need to re-enable slider callbacks here, the flag check is sufficien

    def _enable_slider_callbacks(self):
        """Re-enable the slider callbacks."""
        node_density_scale_widget = self.widgets.get('node_density_scale')
        edge_density_scale_widget = self.widgets.get('edge_density_scale')

        if isinstance(node_density_scale_widget, tk.Scale):
            node_density_scale_widget.config(command=self._on_node_density_change)
            logger.debug("Re-enabled node density slider command.")
        if isinstance(edge_density_scale_widget, tk.Scale):
            edge_density_scale_widget.config(command=self._on_edge_density_change)
            logger.debug("Re-enabled edge density slider command.")

    def _reset_gui_and_visualization_after_preset(self):
        """Resets GUI state and visualization components after applying a preset, preserving grid state."""
        try:
            logger.debug("Entering _reset_gui_and_visualization_after_preset")

            # Reset counters and flags (similar to reset_simulation)
            self.generation = 0
            self.step_count = 0
            self.is_running = False # Ensure simulation is stopped
            self.paused = False     # Ensure not paused
            self.highlighted_nodes.clear()
            self.highlighted_edges.clear()
            self.last_updated_nodes.clear()
            self.last_updated_edges.clear()
            self.consecutive_inactive_steps = 0
            logger.debug("Counters and flags reset")

            # Reset statistics
            self.stats.reset()
            if hasattr(self, 'perf_logger') and self.perf_logger:
                self.perf_logger.reset()
            logger.debug("Statistics reset")

            # Update active nodes based on the *preset's* state (already applied to self.grid)
            if self.grid is not None:
                self.grid.update_active_nodes()
                self.grid.previous_active_nodes_set = self.grid.active_nodes.copy()
                logger.debug(f"Updated active/previous nodes based on preset state: {len(self.grid.active_nodes)} active")
            else:
                logger.warning("Grid is None, cannot update active nodes")

            # Reset view state
            self._reset_view_state()
            logger.debug("View state reset")

            # Re-initialize ViewManager (important for correct view handling)
            if hasattr(self, 'view_manager') and self.view_manager and self.grid:
                 self.view_manager = ViewManager(self.grid, self.ax, self.fig, self.coord_system, self.grid_visualizer, self, self.controller)
                 logger.debug("ViewManager reinitialized")

            # Reset GridVisualizer (clears artists, invalidates cache)
            if hasattr(self, 'grid_visualizer') and self.grid_visualizer:
                self.grid_visualizer.reset()
                logger.debug("GridVisualizer reset")

            # Update button states
            # --- MODIFIED: Call ControlPanelUI method ---
            if hasattr(self, 'control_panel_ui'):
                if self.control_panel_ui is not None:
                    self.control_panel_ui.update_button_states()
                else:
                    logger.warning("control_panel_ui is not initialized. Skipping update_button_states.")
            # ---
            logger.debug("Button states updated")

            # Force initial render to draw the preset state correctly
            self._force_initial_render()
            logger.debug("Forced initial render after preset visualization reset")

        except Exception as e:
            logger.error(f"Error resetting GUI and visualization after preset: {e}")
            logger.error(traceback.format_exc())

    def _open_create_grid_preset_modal(self, preset_to_edit: Optional[GridPreset] = None, manager_window: Optional['GridPresetManagementModal'] = None): # Added type hint
        """Open the create/edit grid preset modal dialog."""
        # Check if a create preset window already exists
        if hasattr(self, 'create_preset_window') and self.create_preset_window:
            try:
                if self.create_preset_window.winfo_exists():
                    self.create_preset_window.lift()
                    logger.info("Create/Edit preset window already exists, bringing it to front.")
                    return
                else:
                    logger.warning("Existing create/edit preset window is invalid, destroying it.")
                    self.create_preset_window.destroy()
            except Exception as e:
                logger.error(f"Error checking/destroying existing create/edit preset window: {e}")

        # Create a new CreateGridPresetModal instance, passing the preset and manager ref
        self.create_preset_window = CreateGridPresetModal(self.root, self, preset_to_edit=preset_to_edit, manager_window=manager_window) # Pass manager_window
        logger.info(f"Opened {'edit' if preset_to_edit else 'create'} grid preset window.")

    def _open_grid_preset_management_modal(self):
        """Open the grid preset management modal dialog."""
        # Check if a grid preset management window already exists
        if hasattr(self, 'grid_preset_window') and self.grid_preset_window:
            try:
                # Check if the existing window is still valid
                if self.grid_preset_window.winfo_exists():
                    # If it does, bring it to the front and return
                    self.grid_preset_window.lift()
                    logger.info("Grid preset management window already exists, bringing it to front.")
                    return
                else:
                    # If the window exists but is not valid, destroy it
                    logger.warning("Existing grid preset management window is invalid, destroying it.")
                    self.grid_preset_window.destroy()
            except Exception as e:
                logger.error(f"Error checking/destroying existing grid preset management window: {e}")
                # If there's an error, proceed with creating a new window

        # Create a new GridPresetManagementModal instance
        self.grid_preset_window = GridPresetManagementModal(self.root, self)
        logger.info("Created new grid preset management window")

    def _create_new_preset(self):
        """Create a new grid preset, capturing current state."""
        log_prefix = "SimulationGUI._create_new_preset: " # Added prefix
        logger.debug(f"{log_prefix}Initiating preset creation.")
        # Open a dialog to get the preset name
        name = simpledialog.askstring("Create New Preset", "Enter a name for the new preset:", parent=self.root)
        if not name:
            logger.debug(f"{log_prefix}Preset creation cancelled by user.")
            return # User cancelled

        # Check if grid and controller/rule exist
        if self.grid is None or self.controller is None or self.controller.rule is None:
            logger.error(f"{log_prefix}Grid, Controller, or Rule is None. Cannot create preset.")
            messagebox.showerror("Error", "Grid or rule not initialized. Cannot create preset.", parent=self.root)
            return

        # Check if name already exists
        if name in self.grid_preset_manager.presets:
            if not messagebox.askyesno("Confirm Overwrite", f"Preset '{name}' already exists. Overwrite?", icon='warning', parent=self):
                logger.debug(f"{log_prefix}User chose not to overwrite existing preset '{name}'.")
                return

        try:
            # --- Calculate current densities (for metadata) ---
            total_nodes = self.grid.total_nodes
            active_nodes = len(self.grid.active_nodes)
            node_density = active_nodes / total_nodes if total_nodes > 0 else 0.0
            max_possible_edges = active_nodes * self.grid.max_neighbors / 2 if active_nodes > 1 else 0
            edge_density = len(self.grid.edges) / max_possible_edges if max_possible_edges > 0 else 0.0
            logger.debug(f"{log_prefix}Calculated densities: Node={node_density:.3f}, Edge={edge_density:.3f}")
            # ---

            # --- Create the GridPreset object with more explicit arguments ---
            preset = GridPreset(
                name=name,
                dimensions=self.grid.dimensions,
                neighborhood_type=self.grid.neighborhood_type.name,
                rule_name=self.controller.rule.name,
                initialization_mode="SAVED_STATE", # Explicitly set mode
                initialization_data=None,          # No specific data for SAVED_STATE
                initial_state=self.grid.grid_array.copy(), # Copy current state
                edges=list(self.grid.edges),               # Copy current edges (convert set to list)
                edge_states=self.grid.edge_states.copy(),  # Copy current edge states
                description="Saved from current grid state.", # Updated description
                node_density=node_density,                 # Store calculated density
                edge_density=edge_density                  # Store calculated density
                # initial_conditions="Pattern" # Keep default or remove if fully deprecated
            )
            logger.debug(f"{log_prefix}GridPreset object created for '{name}'.")
            # ---

            # Save the preset using the GridPresetManager
            self.grid_preset_manager.save_preset(preset)
            logger.info(f"{log_prefix}Preset '{name}' saved successfully.")

            # Update the preset selector in the main GUI
            self._update_grid_preset_selector()
            self._set_active_preset(name) # Set the newly created preset as active

            messagebox.showinfo("Success", f"Grid preset '{name}' created successfully.", parent=self.root)

        except Exception as e:
            logger.error(f"{log_prefix}Error creating preset '{name}': {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Error", f"Failed to create preset '{name}': {e}", parent=self.root)

    def _set_active_preset(self, preset_name: Optional[str]):
        """Set the currently active preset and update the selector variable.
           (Round 12: Update preset_var)"""
        log_prefix = "SimulationGUI._set_active_preset: "
        self.active_preset_name = preset_name
        target_selection = "None" # Default if preset_name is None

        if preset_name:
            # Verify the preset name actually exists in the manager
            if preset_name in self.grid_preset_manager.presets:
                target_selection = preset_name
                logger.debug(f"{log_prefix}Active preset set to: {preset_name}")
            else:
                logger.warning(f"{log_prefix}Preset name '{preset_name}' not found in manager. Setting selector to 'None'.")
                self.active_preset_name = None # Clear invalid active name
        else:
            logger.debug(f"{log_prefix}Active preset cleared (set to None)")

        # --- MODIFIED: Update the Tkinter variable ---
        if hasattr(self, 'preset_var') and isinstance(self.preset_var, tk.StringVar):
            # --- ADDED: Check if variable exists before setting ---
            if hasattr(self, 'preset_var'):
                self._programmatic_change = True # Prevent callback loop
                try:
                    self.preset_var.set(target_selection)
                    logger.debug(f"{log_prefix}Set preset_var to '{target_selection}'.")
                except Exception as e:
                     logger.error(f"{log_prefix}Error setting preset_var: {e}")
                finally:
                     # Schedule clearing the flag slightly later
                     if hasattr(self, 'root') and self.root.winfo_exists():
                         self.root.after(10, self._clear_programmatic_change_flag)
            # --- END ADDED ---
            else:
                logger.error(f"{log_prefix}preset_var not found or not StringVar, cannot update dropdown display.")
        # --- END MODIFIED ---

    def _update_grid_preset_selector(self):
        """Update the grid preset selector with available presets and set the current selection.
           (Round 12: Ensure var is set based on active_preset_name)"""

        log_prefix = "SimulationGUI._update_grid_preset_selector (R12): " # Updated round
        widgets_dict = self.control_panel_ui.widgets if hasattr(self, 'control_panel_ui') and self.control_panel_ui else {}
        logger.debug(f"{log_prefix}Updating grid preset selector (Instance ID: {id(self)}, Widgets ID: {id(widgets_dict)}).")
        logger.debug(f"{log_prefix}Accessing self.widgets. Keys available: {list(widgets_dict.keys())}")
        preset_selector = widgets_dict.get('preset_selector')
        logger.debug(f"{log_prefix}Result of get('preset_selector'): {preset_selector} (Type: {type(preset_selector)})")

        if not isinstance(preset_selector, tk.OptionMenu) or not preset_selector.winfo_exists():
            logger.error(f"{log_prefix}Preset selector widget not found, invalid, or destroyed in self.widgets. Found: {type(preset_selector)}")
            logger.error(f"{log_prefix}Current content of self.widgets: {widgets_dict}")
            return

        try:
            preset_names = list(self.grid_preset_manager.presets.keys())
            sorted_preset_names = sorted(preset_names)
            display_names = ["None"] + sorted_preset_names

            menu = preset_selector['menu']
            if menu is None:
                logger.error(f"{log_prefix}Preset selector menu not found.")
                return
            if not menu.winfo_exists():
                 logger.warning(f"{log_prefix}Preset selector menu widget destroyed.")
                 return

            menu.delete(0, "end")

            for name in display_names:
                menu.add_command(label=name, command=functools.partial(self._on_preset_selected, name))

            # --- MODIFIED: Set variable based on self.active_preset_name ---
            target_selection = "None"
            if self.active_preset_name and self.active_preset_name in display_names:
                target_selection = self.active_preset_name
            elif not self.active_preset_name or self.active_preset_name == "None":
                 target_selection = "None"
            elif display_names: # If active preset invalid, default to "None" or first valid
                 target_selection = "None" # Default to None if active is invalid

            if hasattr(self, 'preset_var'):
                self._programmatic_change = True
                try:
                    self.preset_var.set(target_selection)
                    logger.debug(f"{log_prefix}Set preset_var to '{target_selection}' based on active_preset_name '{self.active_preset_name}'.")
                except Exception as e:
                    logger.error(f"{log_prefix}Error setting preset_var: {e}")
                finally:
                    if hasattr(self, 'root') and self.root.winfo_exists():
                        self.root.after(10, self._clear_programmatic_change_flag)
            # --- END MODIFIED ---

            logger.debug(f"{log_prefix}Grid preset selector updated. Final Selected: {self.preset_var.get()}")

        except Exception as e:
            logger.error(f"{log_prefix}Error updating grid preset selector: {e}")
            logger.error(traceback.format_exc())

    def _on_grid_size_selected(self, event=None):
        """Handle selection from the grid size combobox."""
        # --- MODIFIED: Access display value from GUI's variable ---
        selected_display_value = self.new_grid_size_var.get()
        logger.debug(f"Grid size combobox selected: '{selected_display_value}'")

        if selected_display_value == "Custom...":
            # Prompt user for custom size
            current_internal_value = self.new_grid_size_var.get() # Get current internal value before prompt
            custom_size_str = simpledialog.askstring(
                "Custom Grid Size",
                "Enter custom size (e.g., 42,17 or 15,15,15):",
                parent=self.root,
                initialvalue=current_internal_value if current_internal_value != "Custom..." else "30,30" # Suggest previous or default
            )

            if custom_size_str:
                custom_size_str = custom_size_str.strip()
                if self._validate_grid_size_input(custom_size_str):
                    # Valid custom input, update the internal variable
                    self.new_grid_size_var.set(custom_size_str)
                    # Keep "Custom..." displayed in the combobox
                    # --- MODIFIED: Access grid_size_combobox via self.widgets ---
                    if hasattr(self, 'control_panel_ui') and self.control_panel_ui and 'grid_size_combobox' in self.control_panel_ui.widgets and isinstance(self.control_panel_ui.widgets['grid_size_combobox'], ttk.Combobox):
                        self.control_panel_ui.widgets['grid_size_combobox'].set("Custom...")
                    # ---
                    logger.info(f"Custom grid size set to: {custom_size_str}")
                else:
                    # Invalid custom input, revert combobox display and variable
                    messagebox.showerror("Invalid Input", "Invalid custom grid size format.\nPlease use 'x,y' or 'x,y,z' with positive integers.", parent=self.root)
                    # Revert variable to previous internal value
                    self.new_grid_size_var.set(current_internal_value)
                    # Revert display
                    previous_display = "Custom..."
                    # --- MODIFIED: Access common_sizes_map via self.control_panel_ui ---
                    if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                        for disp, internal in self.control_panel_ui.common_sizes_map.items():
                            if internal == current_internal_value:
                                previous_display = disp
                                break
                    # ---
                    # --- MODIFIED: Access grid_size_combobox via self.widgets ---
                    if hasattr(self, 'control_panel_ui') and self.control_panel_ui and 'grid_size_combobox' in self.control_panel_ui.widgets and isinstance(self.control_panel_ui.widgets['grid_size_combobox'], ttk.Combobox):
                        self.control_panel_ui.widgets['grid_size_combobox'].set(previous_display)
                    # ---
            else:
                # Predefined size selected, update the internal variable
                # --- MODIFIED: Access common_sizes_map via self.control_panel_ui ---
                if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                    internal_value = self.control_panel_ui.common_sizes_map.get(selected_display_value)
                # ---
                if internal_value:
                    self.new_grid_size_var.set(internal_value)
                    logger.debug(f"Internal grid size variable set to: {internal_value}")
                else:
                    logger.error(f"Could not find internal value for display value: {selected_display_value}")

    def _validate_grid_size_input(self, input_str: str) -> bool:
        """Validate the grid size input string."""
        try:
            # --- MODIFIED: Split by 'x' instead of ',' initially ---
            dims_list = [int(d.strip()) for d in input_str.split('x')]
            # ---
            if len(dims_list) != 2 and len(dims_list) != 3:
                raise ValueError("Dimensions must be 2D or 3D (two or three integers separated by commas or 'x').")
            if any(d <= 0 for d in dims_list):
                raise ValueError("Dimensions must be positive integers.")
            return True
        except ValueError as e:
            logger.warning(f"Invalid grid size input '{input_str}': {e}")
            return False

    def _copy_grid_content(self, old_array: np.ndarray, new_array: np.ndarray,
                           progress_callback: Optional[Callable[[int, str], None]] = None, # Changed callback signature
                           progress_offset: int = 0, progress_total: int = 1,
                           cancel_event: Optional[threading.Event] = None): # Added cancel_event
        """Copies content from the old grid array to the new one at the top-left corner, with progress and cancellation."""
        try:
            log_prefix = "_copy_grid_content: "
            logger.debug(f"{log_prefix}Copying grid content from {old_array.shape} to {new_array.shape}")
            old_dims = old_array.shape
            new_dims = new_array.shape

            slice_dims = tuple(min(old_d, new_d) for old_d, new_d in zip(old_dims, new_dims))
            old_slice = tuple(slice(0, dim) for dim in slice_dims)
            new_slice = tuple(slice(0, dim) for dim in slice_dims)

            if progress_callback:
                progress_callback(progress_offset, "Copying Content...")

            # --- Cancellation Check (before potentially long copy) ---
            if cancel_event and cancel_event.is_set():
                logger.info(f"{log_prefix}Cancellation detected before copy.")
                raise InterruptedError("Grid copy cancelled")
            # ---

            # Copy the data
            new_array[new_slice] = old_array[old_slice]
            logger.info(f"{log_prefix}Copied content for slice {slice_dims} from old grid to new grid.")

            if progress_callback:
                progress_callback(progress_offset + 1, "Content Copied.") # Increment progress

        except InterruptedError:
             logger.info(f"{log_prefix}Copy operation cancelled.")
             raise # Re-raise to be caught by the calling thread
        except Exception as e:
            logger.error(f"{log_prefix}Error copying grid content: {e}")
            if progress_callback:
                 progress_callback(progress_offset + 1, "Copy Failed.")

    def _remove_all_grid_edges(self):
        """Removes all edges from the current grid. Called by ShapeEditorWindow."""
        logger.info("Removing all edges from the grid (called via Shape Editor).")
        if self.grid is None:
            logger.error("Cannot remove edges: Grid is None.")
            messagebox.showerror("Error", "Grid not available.", parent=self.root)
            return

        try:
            # --- ADDED: Push state before clearing edges ---
            self._push_grid_state_to_undo("Remove All Edges (Rule Change)")
            # ---

            with self._update_lock: # Ensure thread safety if needed
                edges_removed_count = len(self.grid.edges)
                self.grid.edges.clear()
                self.grid.edge_states.clear()
                # Invalidate caches related to edges for all nodes
                for node_idx in range(self.grid.total_nodes):
                    self.grid._invalidate_neighbor_cache(node_idx)
                logger.info(f"All {edges_removed_count} grid edges removed.")
                # Force redraw to show the change
                self._safe_plot_update(force=True)
                # Update editor buttons if open
                self._update_editor_buttons_if_open()
        except Exception as e:
            logger.error(f"Error removing all grid edges: {e}")
            messagebox.showerror("Error", f"Failed to remove all edges: {e}", parent=self.root)

    def _copy_pattern_to_new_grid(self,
                                  old_array: np.ndarray,
                                  old_edges: Set[Tuple[Tuple[int, ...], Tuple[int, ...]]],
                                  old_edge_states: Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float],
                                  active_box_min: Tuple[int, ...],
                                  active_box_max: Tuple[int, ...],
                                  target_origin: Tuple[int, ...],
                                  new_grid: 'Grid'):
        """
        Copies the active pattern (nodes and internal edges) from the old data
        to the new_grid at the specified target_origin.
        Assumes the new_grid has already been reinitialized with the correct dimensions.
        """
        log_prefix = "_copy_pattern_to_new_grid: "
        logger.info(f"{log_prefix}Copying pattern from bounding box {active_box_min}-{active_box_max} to origin {target_origin} in new grid.")

        if new_grid is None or new_grid.grid_array is None:
            logger.error(f"{log_prefix}New grid or its array is None. Cannot copy.")
            return

        # Clear the new grid first (it should be empty from reinitialize, but be sure)
        new_grid.clear_grid()
        copied_node_count = 0
        copied_edge_count = 0
        old_dims = old_array.shape
        new_dims = new_grid.dimensions

        # --- Copy Nodes ---
        # Iterate only through the bounding box of the active pattern in the OLD grid
        source_indices = []
        if len(active_box_min) == 2:
            for r in range(active_box_min[0], active_box_max[0] + 1):
                for c in range(active_box_min[1], active_box_max[1] + 1):
                    source_indices.append((r, c))
        elif len(active_box_min) == 3:
            for r in range(active_box_min[0], active_box_max[0] + 1):
                for c in range(active_box_min[1], active_box_max[1] + 1):
                    for k in range(active_box_min[2], active_box_max[2] + 1):
                        source_indices.append((r, c, k))

        old_coord_to_new_coord: Dict[Tuple[int,...], Tuple[int,...]] = {}

        for old_coord in source_indices:
            # Check if the node was active in the old grid
            if old_array[old_coord] > 1e-6:
                # Calculate relative position within the bounding box
                rel_coord = tuple(oc - bmin for oc, bmin in zip(old_coord, active_box_min))
                # Calculate new absolute position in the new grid
                new_coord = tuple(to + rc for to, rc in zip(target_origin, rel_coord))

                # Check if the new coordinate is valid in the new grid
                if new_grid.is_valid_coord(new_coord):
                    new_grid.grid_array[new_coord] = old_array[old_coord] # Copy state
                    old_coord_to_new_coord[old_coord] = new_coord # Store mapping
                    copied_node_count += 1
                else:
                    logger.warning(f"{log_prefix}Skipping node {old_coord}: New coordinate {new_coord} is out of bounds for new grid {new_dims}.")

        logger.debug(f"{log_prefix}Copied {copied_node_count} active nodes.")

        # --- Copy Edges ---
        # Iterate through the original edges
        for old_edge_coords, old_edge_state in old_edge_states.items():
            n1_old, n2_old = old_edge_coords
            # Check if BOTH endpoints were within the original active bounding box
            # (This ensures we only copy edges *internal* to the pattern)
            n1_in_box = all(bmin <= c <= bmax for c, bmin, bmax in zip(n1_old, active_box_min, active_box_max))
            n2_in_box = all(bmin <= c <= bmax for c, bmin, bmax in zip(n2_old, active_box_min, active_box_max))

            if n1_in_box and n2_in_box:
                # Get the corresponding new coordinates from the map
                n1_new = old_coord_to_new_coord.get(n1_old)
                n2_new = old_coord_to_new_coord.get(n2_old)

                # If both endpoints were successfully mapped to the new grid, add the edge
                if n1_new is not None and n2_new is not None:
                    try:
                        new_edge_tuple = new_grid._ordered_edge(n1_new, n2_new)
                        new_grid.edges.add(new_edge_tuple)
                        new_grid.edge_states[new_edge_tuple] = old_edge_state
                        copied_edge_count += 1
                    except Exception as add_err:
                        logger.warning(f"{log_prefix}Error adding copied edge between {n1_new} and {n2_new}: {add_err}")

        logger.debug(f"{log_prefix}Copied {copied_edge_count} internal edges.")

    def _finalize_resize_gui_updates(self, new_dimensions, new_dimension_type,
                                     new_neighborhood_type,
                                     expected_grid_id: Optional[int] = None,
                                     init_choice: str = "copy", # Add init_choice
                                     old_grid_array: Optional[np.ndarray] = None): # Add old_grid_array
        """Updates GUI elements on the main thread after resize is complete.
           (Round 2 Fix: Call _force_initial_render at the end)"""
        log_prefix = "_finalize_resize_gui_updates (R2 Fix): " # Updated round
        logger.debug(f"{log_prefix}Starting GUI updates for new size {new_dimensions}. Expected Grid ID: {expected_grid_id}. Init Choice: {init_choice}")
        try:
            # [ Update Grid Reference and Verify ID - Unchanged ]
            if self.controller and hasattr(self.controller, 'grid'):
                self.grid = self.controller.grid
                logger.debug(f"{log_prefix}Updated self.grid reference to controller's grid (ID: {id(self.grid)})")
            else: logger.error(f"{log_prefix}Controller or controller.grid missing!"); return
            if self.grid is None: logger.error(f"{log_prefix}Grid is None after reference update!"); return
            if expected_grid_id is not None and id(self.grid) != expected_grid_id:
                logger.error(f"{log_prefix}CRITICAL: Grid ID mismatch! Expected {expected_grid_id}, but self.grid ID is {id(self.grid)}.")
                if self.controller and self.controller.grid and id(self.controller.grid) == expected_grid_id:
                    self.grid = self.controller.grid
                    logger.warning(f"{log_prefix}Corrected grid reference using controller's grid.")
                else:
                    logger.error(f"{log_prefix}Cannot resolve grid ID mismatch. Aborting finalization.")
                    return

            # [ Update internal state, GUI widgets, etc. - Unchanged ]
            self.dimensions = new_dimensions
            self.dimension_type = new_dimension_type
            self.neighborhood_type = new_neighborhood_type
            if self.controller:
                self.controller.dimensions = self.dimensions
                self.controller.dimension_type = self.dimension_type
                self.controller.neighborhood_type = self.neighborhood_type
            self.dimension_var.set(self.dimension_type.name)
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                self.control_panel_ui.update_neighborhood_selector()
            else:
                logger.warning("ControlPanelUI not found, cannot update neighborhood selector.")
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                new_dims_str_internal = ",".join(map(str, self.dimensions))
                display_val = "Custom..."
                if hasattr(self.control_panel_ui, 'common_sizes_map'):
                    for d, i in self.control_panel_ui.common_sizes_map.items():
                        if i == new_dims_str_internal: display_val = d; break
                if hasattr(self.control_panel_ui, 'widgets') and 'grid_size_combobox' in self.control_panel_ui.widgets and isinstance(self.control_panel_ui.widgets['grid_size_combobox'], ttk.Combobox):
                    self.control_panel_ui.widgets['grid_size_combobox'].set(display_val)
            if hasattr(self, 'control_panel_ui'):
                if self.control_panel_ui and hasattr(self.control_panel_ui, 'update_step_label'):
                    self.control_panel_ui.update_step_label()
                else:
                    logger.warning("control_panel_ui is not initialized or does not have 'update_step_label' method.")
            self._set_active_preset(None)

            # --- MODIFIED: Call _force_initial_render instead of _safe_plot_update ---
            logger.debug(f"{log_prefix}Calling _force_initial_render to draw the newly resized grid.")
            self._force_initial_render()
            # --- END MODIFIED ---
            logger.debug(f"{log_prefix}Forced render after finalizing GUI updates.")

        except Exception as e:
            logger.error(f"{log_prefix}Error during final GUI updates: {e}")
            logger.error(traceback.format_exc())

    @timer_decorator
    def _apply_new_grid_size(self,
                             target_dimensions: Optional[Tuple[int,...]] = None,
                             clear_or_copy: str = "copy", # Superseded by dialog
                             shape_to_place_after: Optional[Shape] = None,
                             origin_to_place_after: Optional[Tuple[int,...]] = None):
        """
        Apply new grid size and reinitialize grid.
        (Round 7 Fix: Overhauled 'copy' logic for presets/patterns)
        (Round 5: Ensure _stopped is False in finally)
        (Round 12: Explicitly recreate visualizer/viewmanager)
        (Round X: Call _initialize_grid_content_based_on_rule for 'rule_default')""" # Added Round X note
        log_prefix = f"SimulationGUI._apply_new_grid_size(Target: {target_dimensions}): "
        logger.info(f"{log_prefix}ENTRY")

        # [ Determine Target Dimensions - Unchanged ]
        if target_dimensions is None:
            value_from_var = self.new_grid_size_var.get()
            if not self._validate_grid_size_input(value_from_var):
                messagebox.showerror("Invalid Input", f"Invalid grid size format: '{value_from_var}'.\nPlease use 'x,y' or 'x,y,z' with positive integers.", parent=self.root)
                return
            try:
                if 'x' in value_from_var: new_dims_list = [int(d.strip()) for d in value_from_var.split('x')]
                else: new_dims_list = [int(d.strip()) for d in value_from_var.split(',')]
                target_dimensions = tuple(new_dims_list)
            except ValueError as e: logger.error(f"Error converting dimensions after validation: {e}"); messagebox.showerror("Error", f"Error converting dimensions after validation: {e}", parent=self.root); return
        # ---

        if target_dimensions == self.dimensions:
            logger.info(f"{log_prefix}Target dimensions are the same as current, no resize needed.")
            if shape_to_place_after and origin_to_place_after and self.grid and self.grid.shape_placer:
                logger.info(f"{log_prefix}Dimensions unchanged, placing requested shape directly.")
                self._place_selected_shape(lambda origin: shape_to_place_after, origin_to_place_after)
            return

        # [ Stop simulation if running - Unchanged ]
        if self.running:
            logger.info(f"{log_prefix}Simulation is running/paused. Stopping threads before resize.")
            if not self._stop_computation_threads(reason="Grid Resize"):
                logger.error(f"{log_prefix}Resize aborted: Failed to stop computation threads cleanly.")
                self.running = False; self.paused = False; self._fixed_steps_running = False
                if hasattr(self, 'control_panel_ui') and self.control_panel_ui: self.control_panel_ui.update_button_states()
                return
            logger.info(f"{log_prefix}Computation threads stopped.")
            if hasattr(self, '_stop_event') and self._stop_event: self._stop_event.clear()
        else:
            if hasattr(self, '_stop_event') and self._stop_event: self._stop_event.clear()

        # [ Store Old Grid Data - Unchanged ]
        old_grid_array = None; old_edges = set(); old_edge_states = {}
        grid_is_empty = True
        if self.grid and self.grid.grid_array is not None:
            grid_is_empty = not np.any(self.grid.grid_array > 1e-6)
            if not grid_is_empty:
                old_grid_array = self.grid.grid_array.copy(); old_edges = self.grid.edges.copy(); old_edge_states = self.grid.edge_states.copy()
                logger.debug(f"{log_prefix}Storing old grid data ({old_grid_array.shape}, {len(old_edges)} edges) for potential copy.")

        # [ Launch Resize Options Dialog - Unchanged ]
        dialog = ResizeProgressDialog(self.root, self, target_dimensions, old_grid_array)
        self.root.wait_window(dialog)
        logger.debug(f"{log_prefix}Resize dialog finished waiting.")
        resize_info = dialog.result

        # [ Process Dialog Result - Unchanged ]
        if resize_info is None or resize_info.get("action") != "resize":
            logger.info(f"{log_prefix}User cancelled resize/placement or dialog returned invalid result.")
            return
        final_new_dimensions = resize_info['dimensions']
        init_choice = resize_info.get('init_choice')
        if init_choice is None: logger.error(f"{log_prefix}Dialog result missing 'init_choice'. Aborting."); return

        # --- Perform Resize Synchronously on Main Thread ---
        logger.info(f"{log_prefix}Starting synchronous resize...")
        self._disable_controls()
        resize_success = False
        try:
            # --- 1. Explicitly Cleanup Old Grid, Visualizer, ViewManager ---
            if self.grid:
                logger.info(f"{log_prefix}Cleaning up existing grid (ID: {id(self.grid)}) before resize.")
                self.grid.cleanup(); del self.grid; self.grid = None; self.controller.grid = None
                logger.debug(f"{log_prefix}Deleted grid reference.")
            if self.grid_visualizer:
                 logger.info(f"{log_prefix}Deleting grid_visualizer reference (ID: {id(self.grid_visualizer)}).")
                 if self.grid: self.grid.remove_observer(self.grid_visualizer)
                 if self.controller: self.controller.remove_observer(self.grid_visualizer)
                 del self.grid_visualizer; self.grid_visualizer = None
            if self.view_manager:
                 logger.info(f"{log_prefix}Deleting view_manager reference (ID: {id(self.view_manager)}).")
                 del self.view_manager; self.view_manager = None
            gc.collect()
            logger.info(f"{log_prefix}Existing grid/viz/view cleanup finished and GC called.")
            # ---

            # [ Reset Simulation State (No Content Init) - Unchanged ]
            self._reset_simulation_state_and_visualization(clear_grid_content=init_choice != "copy")

            # [ Reinitialize Grid Structure ]
            new_dimension_type = Dimension.TWO_D if len(final_new_dimensions) == 2 else Dimension.THREE_D
            current_neighborhood_name = self.neighborhood_var.get()
            new_neighborhood_type = self.neighborhood_type
            if current_neighborhood_name == "HEX" and new_dimension_type == Dimension.THREE_D: new_neighborhood_type = NeighborhoodType.HEX_PRISM; self.neighborhood_var.set("HEX_PRISM")
            elif current_neighborhood_name == "HEX_PRISM" and new_dimension_type == Dimension.TWO_D: new_neighborhood_type = NeighborhoodType.HEX; self.neighborhood_var.set("HEX")
            else: new_neighborhood_type = NeighborhoodType[current_neighborhood_name]
            # Update GUI state variables BEFORE creating grid
            self.dimensions = final_new_dimensions; self.dimension_type = new_dimension_type; self.neighborhood_type = new_neighborhood_type
            self.controller.dimensions = self.dimensions; self.controller.dimension_type = self.dimension_type; self.controller.neighborhood_type = self.neighborhood_type
            self.coord_system = CoordinateSystem(self.dimensions, GlobalSettings.Visualization.EDGE_SCALE, GlobalSettings.Visualization.NODE_SPACING, self.dimension_type)
            self.grid = Grid(
                self.dimensions, self.neighborhood_type, self.dimension_type,
                self.coord_system, gui=self, rule=self.controller.rule, unique_id=self._unique_id
            )
            self.controller.grid = self.grid # Ensure controller has the new grid
            self.grid.setup_shared_memory()
            logger.debug(f"{log_prefix}Grid recreated. Grid object ID: {id(self.grid)}")

            # --- Recreate Visualizer and ViewManager AFTER new grid ---
            logger.debug(f"{log_prefix}Recreating GridVisualizer and ViewManager.")
            self.grid_visualizer = GridVisualizer(self.grid, self.ax, self.fig, self.controller, self)
            self.view_manager = ViewManager(self.grid, self.ax, self.fig, self.coord_system, self.grid_visualizer, self, self.controller)
            self._setup_observers() # Re-register observers
            self._bind_plot_events() # Re-bind events to the new ViewManager
            logger.info(f"{log_prefix}Recreated Visualizer (ID: {id(self.grid_visualizer)}) and ViewManager (ID: {id(self.view_manager)}). Re-bound events.")
            # ---

            # --- Initialize Grid Content Directly Based on init_choice ---
            logger.info(f"{log_prefix}Initializing grid content based on choice: '{init_choice}'")
            if init_choice == "copy" and old_grid_array is not None:
                # [ Copy logic - unchanged ]
                logger.info(f"{log_prefix}Attempting to copy old grid pattern.")
                active_indices_old = np.argwhere(old_grid_array > 1e-6)
                content_fits = False; active_box_min = None; active_box_max = None; pattern_dims = None
                if active_indices_old.size > 0:
                    active_box_min = tuple(np.min(active_indices_old, axis=0)); active_box_max = tuple(np.max(active_indices_old, axis=0))
                    pattern_dims = tuple(bmax - bmin + 1 for bmin, bmax in zip(active_box_min, active_box_max))
                    logger.debug(f"{log_prefix}Active pattern bounding box: {active_box_min} -> {active_box_max} (Size: {pattern_dims})")
                    if all(pd <= nd for pd, nd in zip(pattern_dims, final_new_dimensions)): content_fits = True
                    else:
                        fit_dialog = PatternFitResizeDialog(self.root, pattern_dims, final_new_dimensions); fit_result = fit_dialog.result
                        if fit_result and fit_result.get("action") == "resize_fit":
                            final_new_dimensions = fit_result['dimensions']; logger.info(f"{log_prefix}User chose to resize further to fit pattern: {final_new_dimensions}")
                            self.grid.reinitialize(final_new_dimensions, new_neighborhood_type, new_dimension_type, self.coord_system, gui=self, rule=self.controller.rule, unique_id=self._unique_id); self.grid.setup_shared_memory(); content_fits = True
                        else: logger.info(f"{log_prefix}User cancelled resize-to-fit. Falling back to rule default."); init_choice = "rule_default"
                else: logger.info(f"{log_prefix}Old grid was empty, nothing to copy."); content_fits = True
                if content_fits and init_choice == "copy":
                    grid_center_coords = tuple(d / 2.0 for d in final_new_dimensions)
                    pattern_center_offset = tuple((bmax + bmin) / 2.0 - bmin for bmin, bmax in zip(active_box_min or (), active_box_max or ())) if active_box_min and active_box_max else (0,)*len(final_new_dimensions)
                    target_origin = tuple(int(round(center - offset)) for center, offset in zip(grid_center_coords, pattern_center_offset))
                    target_origin = tuple(max(0, min(to, nd - pd)) for to, nd, pd in zip(target_origin, final_new_dimensions, pattern_dims if pattern_dims else (0,)*len(final_new_dimensions)))
                    self._copy_pattern_to_new_grid(old_array=old_grid_array, old_edges=old_edges, old_edge_states=old_edge_states, active_box_min=active_box_min if active_box_min is not None else (0,) * len(final_new_dimensions), active_box_max=active_box_max if active_box_max is not None else (0,) * len(final_new_dimensions), target_origin=target_origin, new_grid=self.grid)
                    logger.debug(f"{log_prefix}Grid state after pattern copy: {np.sum(self.grid.grid_array > 0)} active nodes, {len(self.grid.edges)} edges.")
            if init_choice == "empty": logger.info(f"{log_prefix}Clearing grid for 'empty' choice."); self.grid.clear_grid()
            elif init_choice == "random":
                logger.info(f"{log_prefix}Initializing random content."); density = GlobalSettings.Simulation.INITIAL_NODE_DENSITY; edge_density = GlobalSettings.Simulation.INITIAL_EDGE_DENSITY
                if self.controller.rule: self.controller.rule.params['connect_probability'] = edge_density
                edge_init_type = self.controller.rule.get_param('edge_initialization', 'RANDOM') if self.controller.rule else 'RANDOM'; self.grid.initialize_grid(density, edge_init_type)
            # --- MODIFIED: Call helper for rule_default ---
            elif init_choice == "rule_default":
                 logger.info(f"{log_prefix}Initializing using rule's default condition via helper.")
                 self._initialize_grid_content_based_on_rule()
                 logger.debug(f"{log_prefix}Grid state after rule default: {np.sum(self.grid.grid_array > 0)} active nodes, {len(self.grid.edges)} edges.")
            # --- END MODIFIED ---

            # [ Populate Spatial Hash - Unchanged ]
            logger.info(f"{log_prefix}Populating spatial hash...")
            self.grid.populate_spatial_hash()

            # [ Final Grid Updates - Unchanged ]
            self.grid.update_active_nodes()
            self.grid.previous_active_nodes_set = self.grid.active_nodes.copy()

            # [ Log grid state BEFORE finalizing GUI - Unchanged ]
            if self.grid and self.grid.grid_array is not None:
                final_active_count = np.sum(self.grid.grid_array > 0); final_edge_count = len(self.grid.edges)
                logger.info(f"{log_prefix}Grid state BEFORE finalizing GUI updates: Active={final_active_count}, Edges={final_edge_count}")
            else: logger.error(f"{log_prefix}Grid is None BEFORE finalizing GUI updates!")

            # [ Finalize GUI Updates ]
            self._finalize_resize_gui_updates(final_new_dimensions, new_dimension_type, new_neighborhood_type, id(self.grid), init_choice, old_grid_array)

            resize_success = True
            logger.info(f"{log_prefix}Resize operation completed successfully.")

        except InterruptedError:
             logger.info(f"{log_prefix}Resize operation was cancelled during initialization.")
             resize_success = False
        except Exception as e:
            logger.error(f"{log_prefix}Error during synchronous resize: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Error", f"Failed to resize: {e}", parent=self.root)
            resize_success = False
        finally:
            self._enable_controls()
            # --- MODIFIED: Ensure _stopped is False after resize completes ---
            self.running = False; self.paused = False; self._fixed_steps_running = False; self._stopped = False
            logger.info("Set _stopped = False in _apply_new_grid_size finally block.")
            # --- END MODIFIED ---

        # [ Place shape if requested - Unchanged ]
        if resize_success and shape_to_place_after and origin_to_place_after:
            logger.info(f"{log_prefix}Resize complete, now placing shape.")
            self._place_selected_shape(lambda origin: shape_to_place_after, origin_to_place_after)

    @timer_decorator
    def _perform_resize_on_main_thread(self,
                                       new_dimensions: Tuple[int,...],
                                       init_choice: str,
                                       old_grid_array: Optional[np.ndarray],
                                       dialog: ResizeProgressDialog) -> bool:
        """
        Performs grid resize and initialization synchronously on the main thread,
        updating the progress dialog. Returns True on success, False on failure.
        (Round 26: Correct Grid.reinitialize arguments)
        """
        log_prefix = f"ResizeMainThread (Target: {new_dimensions}): "
        logger.info(f"{log_prefix}Started.")
        total_steps = 7 # Keep same steps for consistency
        current_step = 0

        def report_progress(step: int, status: str):
            nonlocal current_step
            current_step = step
            self.root.update() # Force GUI update for progress

        try:
            initial_grid_id = id(self.grid) if self.grid else "None"
            logger.debug(f"{log_prefix}Initial self.grid ID: {initial_grid_id}")

            # --- Step 1: Update Core Settings ---
            report_progress(1, "Updating Settings...")
            new_dimension_type = Dimension.TWO_D if len(new_dimensions) == 2 else Dimension.THREE_D
            current_neighborhood_name = self.neighborhood_var.get()
            new_neighborhood_type = self.neighborhood_type
            if current_neighborhood_name == "HEX" and new_dimension_type == Dimension.THREE_D: new_neighborhood_type = NeighborhoodType.HEX_PRISM
            elif current_neighborhood_name == "HEX_PRISM" and new_dimension_type == Dimension.TWO_D: new_neighborhood_type = NeighborhoodType.HEX
            else: new_neighborhood_type = NeighborhoodType[current_neighborhood_name]

            # --- Step 2: Reinitialize Grid Structure ---
            report_progress(2, "Reinitializing Grid Structure...")
            if self.grid is None: raise RuntimeError("Grid is None, cannot reinitialize!")
            if self.coord_system is None: raise RuntimeError("Coordinate system is None, cannot reinitialize!")
            current_rule_instance = self.controller.rule
            if current_rule_instance is None: raise RuntimeError("Controller rule is None during reinitialization.")

            logger.debug(f"{log_prefix}Grid ID BEFORE reinitialize: {id(self.grid)}")
            # --- CORRECTED ARGUMENT ORDER for reinitialize ---
            self.grid.reinitialize(
                new_dimensions,
                new_neighborhood_type,
                new_dimension_type,
                self.coord_system,          # Pass coord_system positionally
                gui=self,                   # Pass gui via keyword
                rule=current_rule_instance, # Pass rule via keyword
                unique_id=self._unique_id,
                progress_callback=None,     # Pass None for sync call
                cancel_event=None           # Pass None for sync call
            )
            # --- END CORRECTION ---
            logger.debug(f"{log_prefix}Grid ID AFTER reinitialize: {id(self.grid)}")
            if self.controller and self.controller.grid is not self.grid: self.controller.grid = self.grid
            self.grid.setup_shared_memory()
            report_progress(4, "Grid Structure Reinitialized.") # Combine steps

            # --- Step 3: Initialize Grid Content ---
            report_progress(5, f"Initializing Content ({init_choice})...")
            if init_choice == "copy" and old_grid_array is not None:
                logger.info(f"{log_prefix}Attempting to copy old grid content.")
                self._copy_grid_content(old_grid_array, self.grid.grid_array)
                edge_init_type = self.rule.get_param('edge_initialization', 'RANDOM') if self.rule else 'RANDOM'
                self.grid.initialize_edges_after_nodes(edge_init_type)
                logger.debug(f"{log_prefix}Grid state after copy: {np.sum(self.grid.grid_array > 0)} active nodes, {len(self.grid.edges)} edges.")
            elif init_choice == "empty":
                logger.info(f"{log_prefix}Grid was pre-cleared for 'empty' choice.")
                self.grid.clear_grid()
                logger.debug(f"{log_prefix}Grid state (should be empty): {np.sum(self.grid.grid_array > 0)} active nodes, {len(self.grid.edges)} edges.")
            elif init_choice == "random":
                logger.info(f"{log_prefix}Initializing random content.")
                density = GlobalSettings.Simulation.INITIAL_NODE_DENSITY
                edge_density = GlobalSettings.Simulation.INITIAL_EDGE_DENSITY
                if self.rule: self.rule.params['connect_probability'] = edge_density
                edge_init_type = self.rule.get_param('edge_initialization', 'RANDOM') if self.rule else 'RANDOM'
                self.grid.initialize_grid(density, edge_init_type)
                logger.debug(f"{log_prefix}Grid state after random init: {np.sum(self.grid.grid_array > 0)} active nodes, {len(self.grid.edges)} edges.")
            elif init_choice == "rule_default":
                 logger.info(f"{log_prefix}Initializing using rule's default condition (grid was pre-cleared).")
                 condition_name = self.rule.get_param('initial_conditions', "Random") if self.rule else "Random"
                 manager = InitialConditionManager.get_instance()
                 manager.apply(condition_name, self.grid) # Apply directly
                 logger.debug(f"{log_prefix}Grid state after rule default '{condition_name}': {np.sum(self.grid.grid_array > 0)} active nodes, {len(self.grid.edges)} edges.")
            # ---

            # --- Step 4: Populate Spatial Hash ---
            logger.info(f"{log_prefix}Populating spatial hash...")
            if not self.grid.populate_spatial_hash(progress_callback=lambda v, m: report_progress(6, f"Building Spatial Index ({int((v/m)*100)}%)...")):
                logger.error(f"{log_prefix}Spatial hash population failed!"); raise RuntimeError("Spatial hash population failed")

            # --- Step 5: Final Grid Updates ---
            report_progress(7, "Updating Node Info...")
            self.grid.update_active_nodes()
            self.grid.previous_active_nodes_set = self.grid.active_nodes.copy()
            final_active_count = np.sum(self.grid.grid_array > 0)
            final_edge_count = len(self.grid.edges)
            logger.info(f"{log_prefix}Final grid state (Grid ID: {id(self.grid)}): {final_active_count} active, {final_edge_count} edges.")
            # ---

            # --- Step 6: Finalize GUI Updates (calls render) ---
            report_progress(total_steps, "Updating GUI...")
            self._finalize_resize_gui_updates(new_dimensions, new_dimension_type, new_neighborhood_type, id(self.grid), init_choice, old_grid_array)

            logger.info(f"{log_prefix}Resize operation completed successfully.")
            return True

        except Exception as e:
            logger.error(f"{log_prefix}Error during resize: {e}")
            logger.error(traceback.format_exc())
            # Don't close dialog here, let the caller handle it
            return False
         
    def _complete_resize_gui_updates(self, new_dimensions, new_dimension_type, new_neighborhood_type,
                                     expected_grid_id: Optional[int] = None,
                                     init_choice: str = "copy", # Add init_choice
                                     old_grid_array: Optional[np.ndarray] = None): # Add old_grid_array
        """Updates GUI elements on the main thread after resize is complete."""
        log_prefix = "_complete_resize_gui_updates (R27): "
        logger.debug(f"{log_prefix}Starting GUI updates for new size {new_dimensions}. Expected Grid ID: {expected_grid_id}. Init Choice: {init_choice}")
        try:
            # [ Update Grid Reference and Verify ID - Unchanged ]
            if self.controller and hasattr(self.controller, 'grid'):
                self.grid = self.controller.grid
                logger.debug(f"{log_prefix}Updated self.grid reference to controller's grid (ID: {id(self.grid)})")
            else: logger.error(f"{log_prefix}Controller or controller.grid missing!"); return
            if self.grid is None: logger.error(f"{log_prefix}Grid is None after reference update!"); return
            if expected_grid_id is not None and id(self.grid) != expected_grid_id:
                logger.error(f"{log_prefix}CRITICAL: Grid ID mismatch! Expected {expected_grid_id}, but self.grid ID is {id(self.grid)}.")
                if self.controller and self.controller.grid and id(self.controller.grid) == expected_grid_id:
                    self.grid = self.controller.grid
                    logger.warning(f"{log_prefix}Corrected grid reference using controller's grid.")
                else:
                    logger.error(f"{log_prefix}Cannot resolve grid ID mismatch. Aborting finalization.")
                    return

            # [ Update internal state, GUI widgets, etc. - Unchanged ]
            self.dimensions = new_dimensions
            self.dimension_type = new_dimension_type
            self.neighborhood_type = new_neighborhood_type
            if self.controller:
                self.controller.dimensions = self.dimensions
                self.controller.dimension_type = self.dimension_type
                self.controller.neighborhood_type = self.neighborhood_type
            self.dimension_var.set(self.dimension_type.name)
            self._update_neighborhood_selector()

            # --- MODIFIED: Access common_sizes_map and grid_size_combobox via ControlPanelUI ---
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                new_dims_str_internal = ",".join(map(str, self.dimensions))
                display_val = "Custom..."
                if hasattr(self.control_panel_ui, 'common_sizes_map'):
                    for d, i in self.control_panel_ui.common_sizes_map.items():
                        if i == new_dims_str_internal: display_val = d; break
                if hasattr(self.control_panel_ui, 'widgets') and 'grid_size_combobox' in self.control_panel_ui.widgets and isinstance(self.control_panel_ui.widgets['grid_size_combobox'], ttk.Combobox):
                    self.control_panel_ui.widgets['grid_size_combobox'].set(display_val)
            # ---

            # --- MODIFIED: Call ControlPanelUI's update_step_label ---
            if hasattr(self, 'control_panel_ui'):
                if self.control_panel_ui and hasattr(self.control_panel_ui, 'update_step_label'):
                    self.control_panel_ui.update_step_label()
                else:
                    logger.warning("control_panel_ui is not initialized or does not have update_step_label method.")
            # ---
            self._set_active_preset(None)

            # Force initial render
            self._force_initial_render()
            logger.debug(f"{log_prefix}Forced render after finalizing GUI updates.")

        except Exception as e:
            logger.error(f"{log_prefix}Error during final GUI updates: {e}")
            logger.error(traceback.format_exc())

    def _push_grid_state_to_undo(self, action_name: str):
        """Captures the current grid state and pushes it onto the undo stack,
           limiting stack size, ONLY if the simulation is not actively running."""
        # --- ADDED: Check if simulation is actively running ---
        if self.running and not self.paused:
            logger.debug(f"Skipping undo push for '{action_name}' because simulation is running.")
            return
        # ---

        if self.grid is None:
            logger.warning("Cannot push grid state: Grid is None.")
            return

        # Limit stack size
        MAX_UNDO_DEPTH = 50 # Adjust as needed
        if len(self._grid_undo_stack) >= MAX_UNDO_DEPTH:
            self._grid_undo_stack.pop(0) # Remove the oldest state
            logger.debug(f"Undo stack reached max depth ({MAX_UNDO_DEPTH}), removed oldest state.")

        try:
            # Deep copy the essential state components
            current_state = {
                'action': action_name, # Store the action name for context
                'grid_array': self.grid.grid_array.copy(),
                'edges': self.grid.edges.copy(),
                'edge_states': self.grid.edge_states.copy(),
                'generation': self.generation, # Store generation for potential restoration
                'step_count': self.step_count
            }
            self._grid_undo_stack.append(current_state)
            self._grid_redo_stack.clear() # Clear redo stack on new action
            logger.debug(f"Pushed grid state for action '{action_name}' to undo stack (Depth: {len(self._grid_undo_stack)}).")

            # Update button states (potentially enabling Undo)
            self._update_editor_buttons_if_open() # Use the corrected helper method

        except Exception as e:
            logger.error(f"Error pushing grid state to undo stack: {e}")

    def _restore_grid_state(self, state_to_restore: Dict[str, Any]):
        """Restores the grid to a previously saved state."""
        if self.grid is None:
            logger.error("Cannot restore grid state: Grid is None.")
            return False

        try:
            logger.debug(f"Restoring grid state from action '{state_to_restore.get('action', 'Unknown')}'")
            # Restore grid array
            if 'grid_array' in state_to_restore and isinstance(state_to_restore['grid_array'], np.ndarray):
                if self.grid.grid_array.shape == state_to_restore['grid_array'].shape:
                    np.copyto(self.grid.grid_array, state_to_restore['grid_array'])
                else:
                    logger.warning("Dimension mismatch during state restore, cannot restore grid_array.")
                    # Optionally try resizing or just skip
            else: logger.warning("Missing or invalid 'grid_array' in state_to_restore.")

            # Restore edges and edge states
            self.grid.edges = state_to_restore.get('edges', set()).copy()
            self.grid.edge_states = state_to_restore.get('edge_states', {}).copy()

            # Restore generation/step count
            self.generation = state_to_restore.get('generation', self.generation)
            self.step_count = state_to_restore.get('step_count', self.step_count)
            if hasattr(self, 'controller'): self.controller.generation = self.generation

            # Update derived grid state
            self.grid.update_active_nodes()
            self.grid.previous_active_nodes_set = self.grid.active_nodes.copy()
            self.grid.populate_spatial_hash() # Repopulate spatial hash

            # Update UI and visualization
            # --- MODIFIED: Call ControlPanelUI method ---
            if hasattr(self, 'control_panel_ui'):
                if self.control_panel_ui is not None:
                    self.control_panel_ui.update_step_label()
                else:
                    logger.warning("control_panel_ui is None. Skipping update_step_label.")
            # ---
            self._force_initial_render() # Force full redraw

            logger.info("Grid state restored successfully.")
            return True

        except Exception as e:
            logger.error(f"Error restoring grid state: {e}")
            return False
        
    def _undo_grid_action(self):
        """Undoes the last grid action (Clear, Reset, Randomize)."""
        logger.debug("Attempting to undo last grid action.")
        if not self._grid_undo_stack:
            logger.info("Undo stack is empty.")
            return

        try:
            # Push current state to redo stack BEFORE restoring
            self._push_grid_state_to_redo("Before Undo")

            # Pop the last state from the undo stack
            state_to_restore = self._grid_undo_stack.pop()
            logger.info(f"Undoing action: {state_to_restore.get('action', 'Unknown')}")

            # Restore the state
            if self._restore_grid_state(state_to_restore):
                logger.info("Undo successful.")
            else:
                logger.error("Undo failed during state restoration.")
                # Attempt to pop the state we just pushed to redo stack
                if self._grid_redo_stack: self._grid_redo_stack.pop()

            # Update button states
            self._update_editor_buttons_if_open() # Use the corrected helper method

        except Exception as e:
            logger.error(f"Error during undo grid action: {e}")

    def _redo_grid_action(self):
        """Redoes the last undone grid action."""
        logger.debug("Attempting to redo last grid action.")
        if not self._grid_redo_stack:
            logger.info("Redo stack is empty.")
            return

        try:
            # Push current state to undo stack BEFORE restoring
            self._push_grid_state_to_undo("Before Redo") # Use the standard push method

            # Pop the state to redo from the redo stack
            state_to_restore = self._grid_redo_stack.pop()
            logger.info(f"Redoing action: {state_to_restore.get('action', 'Unknown')}")

            # Restore the state
            if self._restore_grid_state(state_to_restore):
                logger.info("Redo successful.")
            else:
                logger.error("Redo failed during state restoration.")
                # Attempt to pop the state we just pushed to undo stack
                if self._grid_undo_stack: self._grid_undo_stack.pop()

            # Update button states
            self._update_editor_buttons_if_open() # Use the corrected helper method

        except Exception as e:
            logger.error(f"Error during redo grid action: {e}")

    def _push_grid_state_to_redo(self, action_name: str):
        """Captures the current grid state and pushes it onto the redo stack."""
        if self.grid is None:
            logger.warning("Cannot push grid state to redo: Grid is None.")
            return
        try:
            current_state = {
                'action': action_name,
                'grid_array': self.grid.grid_array.copy(),
                'edges': self.grid.edges.copy(),
                'edge_states': self.grid.edge_states.copy(),
                'generation': self.generation,
                'step_count': self.step_count
            }
            self._grid_redo_stack.append(current_state)
            logger.debug(f"Pushed grid state for action '{action_name}' to redo stack (Depth: {len(self._grid_redo_stack)}).")
        except Exception as e:
            logger.error(f"Error pushing grid state to redo stack: {e}")

    def set_active_tool(self, tool_name: Optional[str]):
        """Sets the active grid interaction tool. Handles lasso toggle.
           (Round 14: Implement lasso toggle logic)"""
        log_prefix = "SimulationGUI.set_active_tool: "
        logger.debug(f"{log_prefix}Request to set tool to: {tool_name}")

        # --- Lasso Toggle Logic ---
        if tool_name == "lasso" and self.active_tool == "lasso":
            # If trying to activate lasso when it's already active, deactivate it
            self.active_tool = None
            logger.info(f"{log_prefix}Lasso tool toggled OFF.")
            self._clear_lasso_selection() # Clear selection when deactivating
        elif self.active_tool != tool_name:
            # Switching to a new tool (or activating one)
            if self.active_tool is not None: # If switching from another tool
                logger.debug(f"{log_prefix}Switching tool from {self.active_tool} to {tool_name}, clearing selection.")
                self._clear_lasso_selection() # Clear selection when switching tools
            self.active_tool = tool_name
            logger.info(f"{log_prefix}Activated tool: {self.active_tool}")
            # Clear selection when activating erase/add/del edge
            if tool_name in ["erase", "add_edge", "del_edge"]:
                self._clear_lasso_selection()
        else:
            # Setting tool to the same one that's already active (and not lasso) - no change needed
            logger.debug(f"{log_prefix}Tool '{tool_name}' is already active.")

        # Update button states in the editor window if it's open
        self._update_editor_buttons_if_open()

    def _open_color_settings_modal(self):
        """Open the color settings modal dialog."""
        try:
            # First check if the root window still exists
            if not hasattr(self, 'root') or self.root is None or not self.root.winfo_exists():
                logger.warning("Root window doesn't exist, cannot open color settings modal")
                return
                
            try:
                # This will raise TclError if the window is destroyed
                self.root.winfo_exists()
            except tk.TclError:
                logger.warning("Root window no longer exists, cannot open color settings modal")
                return
                    
            # Check if a color settings window is already open
            if hasattr(self, 'color_settings_window') and self.color_settings_window:
                try:
                    # Check if the window still exists
                    if self.color_settings_window.winfo_exists():
                        # If it does, bring it to the front
                        self.color_settings_window.lift()
                        return
                    else:
                        # If the window exists but is not valid, destroy it
                        try:
                            self.color_settings_window.destroy()
                        except:
                            pass
                except (tk.TclError, RuntimeError):
                    # If not, continue and create a new one
                    logger.debug("Previous color settings window no longer exists, creating a new one")
                
            # Calculate the position before creating the window
            try:
                # Get the main window's position and dimensions
                main_x = self.root.winfo_rootx()
                main_y = self.root.winfo_rooty()
                main_width = self.root.winfo_width()
                main_height = self.root.winfo_height()
                
                # Calculate position for the modal (to the right of the main window)
                modal_x = main_x + main_width + 10  # 10 pixels gap
                modal_y = main_y + (main_height - 760) // 2  # Center vertically (760 is the modal height)
                
                # Create the color settings modal with the position already set
                self.color_settings_window = ColorSettingsModal(
                    self.root,
                    self.color_manager,
                    self._apply_color_scheme
                )
                
                # Set the position immediately after creation but before showing
                self.color_settings_window.withdraw()  # Hide the window temporarily
                
                # Set the position
                position_str = f"+{modal_x}+{modal_y}"
                self.color_settings_window.geometry(position_str)
                
                # Now show the window at the correct position
                self.color_settings_window.deiconify()
                
                # Make the window modal
                self.color_settings_window.transient(self.root)
                self.color_settings_window.grab_set()
                
                # Wait for the window to be closed - but check if root still exists first
                if hasattr(self, 'root') and self.root is not None:
                    try:
                        self.root.winfo_exists()
                    except tk.TclError:
                        logger.warning("Root window no longer exists, aborting wait_window")
                        return
                    tk.Toplevel.wait_window(self.color_settings_window)
            except (tk.TclError, RuntimeError) as e:
                logger.warning(f"Error while creating color settings modal: {e}")
                # Clean up if the window was partially created
                if hasattr(self, 'color_settings_window') and self.color_settings_window:
                    try:
                        self.color_settings_window.destroy()
                    except (tk.TclError, RuntimeError):
                        pass
        except Exception as e:
            logger.error(f"Unexpected error in _open_color_settings_modal: {e}")

    def _get_effective_color_scheme(self) -> ColorScheme:
        """
        Determines the effective color scheme based on rule parameters and user selection.
        Priority: Rule Params > ColorManager Current > Default Fallback.
        (Round 35: Access rule via self.controller.rule)
        """
        log_prefix = "_get_effective_color_scheme: "
        rule_scheme = None
        current_rule = None

        # --- MODIFIED: Access rule via controller ---
        if hasattr(self, 'controller') and self.controller and hasattr(self.controller, 'rule') and self.controller.rule:
            current_rule = self.controller.rule
        # ---

        # 1. Check if current rule defines specific colors in its parameters
        if current_rule and hasattr(current_rule, 'params'):
            rule_params = current_rule.params
            color_keys_in_params = [k for k in rule_params if k.endswith('_color') or k == 'background']
            if color_keys_in_params:
                 logger.debug(f"{log_prefix}Rule '{current_rule.name}' defines color parameters.")
                 try:
                     fallback_scheme = self.color_manager.current_scheme or ColorScheme(
                         "Fallback", "#ffffff", "#f0f0f0", "#f77b4f", "#ff0000", "#0000ff", "#00ff00", False)

                     background_for_check = rule_params.get('background_color', fallback_scheme.background)
                     is_dark_val = is_dark_theme(background_for_check) # Use helper function

                     rule_scheme = ColorScheme(
                         name=f"{current_rule.name} Colors",
                         background=rule_params.get('background_color', fallback_scheme.background),
                         node_base=rule_params.get('node_base_color', fallback_scheme.node_base),
                         node=rule_params.get('node_color', fallback_scheme.node),
                         new_node=rule_params.get('new_node_color', fallback_scheme.new_node),
                         default_edge=rule_params.get('default_edge_color', fallback_scheme.default_edge),
                         new_edge=rule_params.get('new_edge_color', fallback_scheme.new_edge),
                         is_dark=is_dark_val
                     )
                     logger.info(f"{log_prefix}Using color scheme derived from rule '{current_rule.name}' parameters.")
                 except Exception as e:
                     logger.error(f"{log_prefix}Error creating scheme from rule params: {e}")
                     rule_scheme = None
        elif not current_rule:
             logger.warning(f"{log_prefix}Controller or rule is None, cannot check rule parameters for colors.")

        # 2. If no rule scheme, use ColorManager's current scheme
        if rule_scheme is None and self.color_manager and self.color_manager.current_scheme:
            logger.debug(f"{log_prefix}Using current scheme from ColorManager: '{self.color_manager.current_scheme.name}'")
            return self.color_manager.current_scheme

        # 3. If still no scheme, use the rule-derived one (if created)
        if rule_scheme is not None:
             return rule_scheme

        # 4. Absolute fallback to a default scheme
        logger.warning(f"{log_prefix}Falling back to default 'Classic' color scheme.")
        return ColorScheme(
            "Classic", "#ffffff", "#f0f0f0", "#f77b4f", "#ff0000", "#0000ff", "#00ff00", False
        )

    def update_prep_params_from_rule(self):
        """Updates the _prep_visualization_params dictionary with the
           coloring parameters from the currently active rule.
           (Round 35: Add logging)"""
        log_prefix = "SimulationGUI.update_prep_params_from_rule (R35 Log): " # Updated round
        logger.debug(f"{log_prefix}Updating prep params from current rule.")

        if not (self.controller and self.controller.rule):
            logger.warning(f"{log_prefix}Controller or rule not available, cannot update prep params.")
            return

        rule = self.controller.rule
        logger.debug(f"{log_prefix}Updating from rule: '{rule.name}' (ID: {id(rule)})")
        with self._prep_params_lock:
            # Update all relevant coloring parameters
            prep_update = {} # Build updates separately
            prep_update['use_state_coloring'] = rule.get_param('use_state_coloring', False)
            prep_update['color_nodes_by_degree'] = rule.get_param('color_nodes_by_degree', False)
            prep_update['color_nodes_by_active_neighbors'] = rule.get_param('color_nodes_by_active_neighbors', False)
            prep_update['node_colormap'] = rule.get_param('node_colormap', 'plasma')

            # Get min/max state for normalization
            prep_update['min_node_state'] = getattr(rule, 'min_node_state', 0.0)
            prep_update['max_node_state'] = getattr(rule, 'max_node_state', 1.0)
            # Determine vmin/vmax based on coloring mode
            if prep_update['use_state_coloring']:
                prep_update['node_color_norm_vmin'] = prep_update['min_node_state']
                prep_update['node_color_norm_vmax'] = prep_update['max_node_state']
            else:
                prep_update['node_color_norm_vmin'] = rule.get_param('node_color_norm_vmin', 0.0)
                default_vmax_node = 8.0 if prep_update['color_nodes_by_degree'] or prep_update['color_nodes_by_active_neighbors'] else 1.0
                vmax_node_rule = rule.get_param('node_color_norm_vmax', None)
                prep_update['node_color_norm_vmax'] = vmax_node_rule if vmax_node_rule is not None else default_vmax_node

            prep_update['use_state_coloring_edges'] = rule.get_param('use_state_coloring_edges', False)
            prep_update['edge_coloring_mode'] = rule.get_param('edge_coloring_mode', 'Default')
            prep_update['edge_colormap'] = rule.get_param('edge_colormap', 'viridis')
            if prep_update['edge_coloring_mode'] == 'Default':
                prep_update['edge_color_norm_vmin'] = getattr(rule, 'min_edge_state', 0.0)
                prep_update['edge_color_norm_vmax'] = getattr(rule, 'max_edge_state', 1.0)
            else:
                prep_update['edge_color_norm_vmin'] = rule.get_param('edge_color_norm_vmin', 0.0)
                default_vmax_edge = 16.0 if prep_update['edge_coloring_mode'] == 'DegreeSum' else 8.0
                vmax_edge_rule = rule.get_param('edge_color_norm_vmax', None)
                prep_update['edge_color_norm_vmax'] = vmax_edge_rule if vmax_edge_rule is not None else default_vmax_edge

            # Apply the updates
            self._prep_visualization_params.update(prep_update)
            logger.info(f"{log_prefix}Prep params updated with rule '{rule.name}' coloring settings.")
            # --- ADDED: Log the updated dictionary ---
            logger.debug(f"  Updated _prep_visualization_params: {self._prep_visualization_params}")
            # ---

    def _apply_color_scheme(self, color_scheme: Optional[ColorScheme], force_render: bool = True): # Added force_render flag
        """Apply a specific color scheme to the application safely.
           Updates prep thread params with ALL relevant coloring info.
           (Round 15: Remove internal redraw)"""
        log_prefix = "_apply_color_scheme (R15 Render Fix): " # Updated round
        try:
            if not hasattr(self, 'root') or self.root is None or not self.root.winfo_exists(): logger.warning(f"{log_prefix}Root window doesn't exist, cannot apply color scheme"); return
            if not isinstance(color_scheme, ColorScheme): logger.warning(f"{log_prefix}Invalid color_scheme object provided ({type(color_scheme)}), applying default."); color_scheme = self._get_effective_color_scheme()
            logger.debug(f"{log_prefix}Applying scheme: {color_scheme.name} (force_render={force_render})")

            self._latest_color_scheme = copy.deepcopy(color_scheme)
            self.color_manager.current_scheme = color_scheme

            original_blitting = False # Default if visualizer doesn't exist
            if hasattr(self, 'grid_visualizer') and self.grid_visualizer:
                original_blitting = self.grid_visualizer.blitting_manager.enabled
                self.grid_visualizer.blitting_manager.invalidate_cache();
                # --- Keep blitting disabled during color change ---
                self.grid_visualizer.blitting_manager.set_enabled(False)
                # ---
            else:
                logger.warning(f"{log_prefix}GridVisualizer not available, cannot disable blitting.")

            # [ Update global color settings - Unchanged ]
            GlobalSettings.Colors.BACKGROUND = color_scheme.background; GlobalSettings.Colors.NODE_ACTIVE = color_scheme.node_base; GlobalSettings.Colors.NODE_INACTIVE = color_scheme.node_base
            GlobalSettings.Colors.NODE_EDGE_OLD = color_scheme.node; GlobalSettings.Colors.NODE_EDGE_NEW = color_scheme.new_node

            # [ Update Tkinter variables - Unchanged ]
            if hasattr(self, 'bg_color_var'): self.bg_color_var.set(color_scheme.background)
            else: logger.warning(f"{log_prefix}bg_color_var missing"); return
            if hasattr(self, 'node_color_var'): self.node_color_var.set(color_scheme.node)
            if hasattr(self, 'new_node_color_var'): self.new_node_color_var.set(color_scheme.new_node)
            if hasattr(self, 'default_edge_color_var'): self.default_edge_color_var.set(color_scheme.default_edge)
            if hasattr(self, 'new_edge_color_var'): self.new_edge_color_var.set(color_scheme.new_edge)

            # [ Update UI background colors - Unchanged ]
            if hasattr(self, 'root') and self.root is not None and self.root.winfo_exists(): self.root.configure(bg=color_scheme.background)
            if hasattr(self, 'main_frame') and self.main_frame is not None and self.main_frame.winfo_exists(): self.main_frame.configure(bg=color_scheme.background)
            if hasattr(self, 'viz_frame') and self.viz_frame is not None and self.viz_frame.winfo_exists(): self.viz_frame.configure(bg=color_scheme.background)
            if hasattr(self, 'loading_frame') and self.loading_frame and self.loading_frame.winfo_exists():
                self.loading_frame.configure(bg=color_scheme.background)
                for widget in self.loading_frame.winfo_children():
                     if isinstance(widget, tk.Label): widget.configure(bg=color_scheme.background)

            # [ Update Matplotlib elements - Unchanged ]
            if hasattr(self, 'fig') and self.fig: self.fig.set_facecolor(color_scheme.background)
            if hasattr(self, 'ax') and self.ax: self.ax.set_facecolor(color_scheme.background)
            logger.debug(f"{log_prefix}Applied background color to Tk and Matplotlib elements.")

            # [ Update color scheme label - Unchanged ]
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui and hasattr(self.control_panel_ui, 'widgets') and 'color_scheme_label' in self.control_panel_ui.widgets:
                color_scheme_label = self.control_panel_ui.widgets['color_scheme_label']
                if isinstance(color_scheme_label, tk.Label) and color_scheme_label.winfo_exists():
                    if hasattr(self, 'color_scheme_label_var'): self.color_scheme_label_var.set(f"Current Scheme: {color_scheme.name}")

            # [ Update prep thread params - Unchanged ]
            with self._prep_params_lock: # Ensure lock is used
                prep_update = {
                    'background_color': color_scheme.background, 'node_base_color': color_scheme.node_base,
                    'node_color': color_scheme.node, 'new_node_color': color_scheme.new_node,
                    'default_edge_color': color_scheme.default_edge, 'new_edge_color': color_scheme.new_edge,
                    'node_outline_old': color_scheme.node, 'node_outline_new': color_scheme.new_node,
                }
                if self.controller and self.controller.rule:
                    rule = self.controller.rule
                    prep_update['use_state_coloring'] = rule.get_param('use_state_coloring', False)
                    prep_update['color_nodes_by_degree'] = rule.get_param('color_nodes_by_degree', False)
                    prep_update['color_nodes_by_active_neighbors'] = rule.get_param('color_nodes_by_active_neighbors', False)
                    prep_update['node_colormap'] = rule.get_param('node_colormap', 'plasma')
                    if prep_update['use_state_coloring']:
                        prep_update['node_color_norm_vmin'] = str(float(getattr(rule, 'min_node_state', 0.0)))
                        prep_update['node_color_norm_vmax'] = str(float(getattr(rule, 'max_node_state', 1.0)))
                    else:
                        prep_update['node_color_norm_vmin'] = str(float(rule.get_param('node_color_norm_vmin', 0.0)))
                        default_vmax_node = 8.0 if prep_update['color_nodes_by_degree'] or prep_update['color_nodes_by_active_neighbors'] else 1.0
                        vmax_node_rule = rule.get_param('node_color_norm_vmax', None)
                        prep_update['node_color_norm_vmax'] = str(float(vmax_node_rule if vmax_node_rule is not None else default_vmax_node))
                    prep_update['use_state_coloring_edges'] = rule.get_param('use_state_coloring_edges', False)
                    prep_update['edge_coloring_mode'] = rule.get_param('edge_coloring_mode', 'Default')
                    prep_update['edge_colormap'] = rule.get_param('edge_colormap', 'viridis')
                    if prep_update['edge_coloring_mode'] == 'Default':
                        prep_update['edge_color_norm_vmin'] = str(float(getattr(rule, 'min_edge_state', 0.0)))
                        prep_update['edge_color_norm_vmax'] = str(float(getattr(rule, 'max_edge_state', 1.0)))
                    else:
                        prep_update['edge_color_norm_vmin'] = str(float(rule.get_param('edge_color_norm_vmin', 0.0)))
                        default_vmax_edge = 16.0 if prep_update['edge_coloring_mode'] == 'DegreeSum' else 8.0
                        vmax_edge_rule = rule.get_param('edge_color_norm_vmax', None)
                        prep_update['edge_color_norm_vmax'] = str(float(vmax_edge_rule if vmax_edge_rule is not None else default_vmax_edge))
                    logger.debug(f"{log_prefix}Overlaying prep params with rule '{rule.name}' coloring settings.")
                else:
                    logger.warning(f"{log_prefix}Rule not available, prep params will only use scheme colors.")
                self._prep_visualization_params.update(prep_update)
                logger.debug(f"{log_prefix}Updated prep thread visualization parameters.")
            # ---

            # [ Update visualizer state - Unchanged ]
            if hasattr(self, 'grid_visualizer') and self.grid_visualizer:
                self.grid_visualizer.update_visualization_state(
                    background_color=color_scheme.background, node_color=color_scheme.node, node_base=color_scheme.node_base,
                    node_outline_old=color_scheme.node, node_outline_new=color_scheme.new_node,
                    default_edge_color=color_scheme.default_edge, new_edge_color=color_scheme.new_edge,
                    invalidate_blit_cache=True
                )
                logger.debug(f"{log_prefix}Updated visualization state with new color scheme")
                # [ Edge color clash check - unchanged ]
                if self.controller and self.controller.rule and self.controller.rule.get_param('use_state_coloring_edges', False):
                    edge_cmap_name = self.controller.rule.get_param('edge_colormap', 'viridis'); edge_vmin = self.controller.rule.get_param('edge_vmin', 0.0); edge_vmax = self.controller.rule.get_param('edge_vmax', 1.0); highlight_color_hex = color_scheme.new_edge
                    try:
                        cmap = plt.get_cmap(edge_cmap_name); norm = colors.Normalize(vmin=edge_vmin, vmax=edge_vmax); highlight_rgba = colors.to_rgba(highlight_color_hex) # type: ignore[reportArgumentType]
                        potential_clash = False
                        for val in np.linspace(edge_vmin, edge_vmax, 10):
                            state_color_rgba = cmap(norm(val)); distance = np.sqrt(np.sum((np.array(highlight_rgba[:3]) - np.array(state_color_rgba[:3]))**2))
                            if distance < 0.1: potential_clash = True; break
                        if potential_clash:
                            warning_msg = (f"Potential visual clash detected:\nThe 'New Edge' highlight color ('{highlight_color_hex}') might be very similar to some colors generated by the rule's edge colormap ('{edge_cmap_name}', range {edge_vmin}-{edge_vmax}).\n\nConsider adjusting the color scheme or the rule's edge colormap settings.")
                            log_message = f"{log_prefix}{warning_msg}".replace('\n\n', ' '); logger.warning(log_message)
                    except Exception as clash_check_err: logger.warning(f"{log_prefix}Could not perform edge color clash check: {clash_check_err}")
                # ---
                # --- REMOVED: _safe_plot_update call ---
                # if force_render:
                #     self._safe_plot_update(force=True)
                # ---
            else:
                logger.warning(f"{log_prefix}GridVisualizer not available, cannot update its state or redraw.")

            logger.info(f"{log_prefix}Applied color scheme: {color_scheme.name}")

        except Exception as e:
            logger.error(f"{log_prefix}Error applying color scheme: {e}")
            logger.error(traceback.format_exc())
        finally:
            # --- Restore blitting state AFTER potential redraw is handled by caller ---
            if hasattr(self, 'grid_visualizer') and self.grid_visualizer:
                self.grid_visualizer.blitting_manager.set_enabled(original_blitting)
                logger.debug(f"{log_prefix}Restored blitting state to {original_blitting}")
            # ---

    def _on_show_coordinates_toggle(self):
        """Handle show coordinates toggle"""
        logger.info("Entering _on_show_coordinates_toggle")
        logger.debug("### _on_show_coordinates_toggle: START ###") # ADDED DEBUG LOG
        try:
            # Toggle show_coords_local boolean
            self._show_coords_local = not self._show_coords_local
            show_coords = self._show_coords_local # Use local variable
            logger.debug(f"Show coordinates toggled to: {show_coords}")
            
            # Update the visualization
            if hasattr(self, 'grid_visualizer') and self.grid_visualizer:
                logger.debug("grid_visualizer is valid") # ADDED DEBUG LOG
                # Use the dedicated method for toggling coordinate labels in GridVisualizer
                self.grid_visualizer.toggle_coordinate_labels(show=show_coords) # Pass local boolean
                logger.debug(f"Called grid_visualizer.toggle_coordinate_labels({show_coords})") # ADDED DEBUG LOG
            else:
                logger.warning("grid_visualizer is not initialized")
            logger.debug("### _on_show_coordinates_toggle: END ###") # ADDED DEBUG LOG
            
            # Force a full redraw - already done in GridVisualizer, but double check here too
            if hasattr(self, '_safe_plot_update'):
                self._safe_plot_update(force=True)
                logger.debug("Forced plot update in _on_show_coordinates_toggle") # ADDED DEBUG LOG
            else:
                logger.warning("_safe_plot_update not found") # ADDED DEBUG LOG

        except Exception as e:
            logger.error(f"Error toggling show coordinates: {e}")
            logger.error(traceback.format_exc())

    def _on_toggle_blitting(self):
        """Handle toggling blitting on/off."""
        # --- MODIFIED: Access blitting_var via ControlPanelUI ---
        if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
            use_blitting = self.control_panel_ui.blitting_var.get()
        else:
            use_blitting = GlobalSettings.ENABLE_BLITTING # Fallback
            logger.warning("ControlPanelUI not found, using global setting for blitting.")
        # ---

        if self.grid_visualizer is not None and hasattr(self.grid_visualizer, 'blitting_manager'):
            self.grid_visualizer.blitting_manager.set_enabled(use_blitting) # CHANGED
        else:
            logger.warning("Grid visualizer or blitting manager is not available.")
        logger.info(f"Blitting {'enabled' if GlobalSettings.ENABLE_BLITTING else 'disabled'}")

        # CRITICAL: Invalidate background and force redraw when blitting is toggled
        if self.grid_visualizer is not None:
            self.grid_visualizer.blitting_manager.invalidate_cache()
            self._safe_plot_update()
   
    def _validate_chunk_size_input(self, P):
        """Validation command for custom chunk size entry."""
        if P == "": return True # Allow empty
        if P.isdigit():
            num = int(P)
            if num >= 1: # Minimum chunk size is 1
                return True
        return False
    
    def _on_chunk_size_selected(self, event=None):
        """Handle selection changes in the chunk size Combobox."""
        log_prefix = "SimulationGUI._on_chunk_size_selected: "
        selected_display = self.chunk_size_display_var.get()
        logger.debug(f"{log_prefix}Selected display value: '{selected_display}'")

        custom_entry = self.control_panel_ui.widgets.get('custom_chunk_entry') if self.control_panel_ui else None
        apply_button = self.control_panel_ui.widgets.get('apply_chunk_button') if self.control_panel_ui else None

        if selected_display == "Custom...":
            if isinstance(custom_entry, tk.Entry): custom_entry.config(state=tk.NORMAL)
            if isinstance(apply_button, tk.Button): apply_button.config(state=tk.NORMAL)
            # Don't change GlobalSettings.Simulation.CHUNK_SIZE yet
            logger.debug(f"{log_prefix}Custom selected, enabling entry/apply.")
        else:
            if isinstance(custom_entry, tk.Entry): custom_entry.config(state=tk.DISABLED)
            if isinstance(apply_button, tk.Button): apply_button.config(state=tk.DISABLED)
            # Apply the selected predefined size immediately
            new_chunk_size = 0 # Default to Auto
            if selected_display != "Auto":
                try:
                    new_chunk_size = int(selected_display)
                except ValueError:
                    logger.error(f"{log_prefix}Invalid numeric value selected: '{selected_display}'. Defaulting to Auto.")
                    new_chunk_size = 0
                    self.chunk_size_display_var.set("Auto") # Reset display

            if GlobalSettings.Simulation.CHUNK_SIZE != new_chunk_size:
                GlobalSettings.Simulation.CHUNK_SIZE = new_chunk_size
                logger.info(f"{log_prefix}Chunk size setting updated to: {'Auto' if new_chunk_size == 0 else new_chunk_size}")
            else:
                 logger.debug(f"{log_prefix}Chunk size setting unchanged ({'Auto' if new_chunk_size == 0 else new_chunk_size}).")

    def _apply_custom_chunk_size(self):
        """Apply the custom chunk size entered by the user."""
        log_prefix = "SimulationGUI._apply_custom_chunk_size: "
        custom_value_str = self.custom_chunk_size_var.get()
        logger.debug(f"{log_prefix}Attempting to apply custom chunk size: '{custom_value_str}'")

        if self._validate_chunk_size_input(custom_value_str):
            try:
                new_chunk_size = int(custom_value_str)
                if new_chunk_size >= 1:
                    if GlobalSettings.Simulation.CHUNK_SIZE != new_chunk_size:
                        GlobalSettings.Simulation.CHUNK_SIZE = new_chunk_size
                        logger.info(f"{log_prefix}Custom chunk size setting updated to: {new_chunk_size}")
                        # Update combobox display to show the custom value was applied (optional)
                        # self.chunk_size_display_var.set(f"Custom ({new_chunk_size})")
                    else:
                         logger.debug(f"{log_prefix}Custom chunk size setting unchanged ({new_chunk_size}).")
                else:
                    messagebox.showerror("Invalid Input", "Custom chunk size must be 1 or greater.", parent=self.root)
            except ValueError:
                messagebox.showerror("Invalid Input", "Custom chunk size must be a whole number.", parent=self.root)
        else:
            messagebox.showerror("Invalid Input", "Please enter a valid positive whole number for the custom chunk size.", parent=self.root)

    def _on_color_scheme_change(self, value: str):
        """Handle color scheme change"""
        logger.info(f"Color scheme changed to: {value}")
        # Implement color scheme logic here
        pass

    def _open_rule_importer(self):
        """Opens the Rule Import Parameters window."""
        # Check if already open
        if hasattr(self, 'rule_import_window') and self.rule_import_window and self.rule_import_window.winfo_exists():
            self.rule_import_window.lift()
            logger.info("Rule import window already open, bringing to front.")
            return

        try:
            self.rule_import_window = RuleImportWindow(self) # Pass self (SimulationGUI) as parent
            logger.info("Opened Rule Import Parameters window.")
        except Exception as e:
            logger.error(f"Error opening rule import window: {e}")
            messagebox.showerror("Error", f"Could not open Rule Importer: {e}", parent=self.root)

    def _on_grid_boundary_change(self, boundary_str):
        """Handle grid boundary change and update refocus button state."""
        try:
            # Update the parameter in the rule
            if self.controller.rule.update_parameter('grid_boundary', boundary_str):
                logger.info(f"Changed grid boundary to: {boundary_str}")
                # Re-calculate neighbors with the new boundary setting
                if self.grid:
                    self.grid._calculate_all_neighbor_indices() # Recalculate neighbors
                    logger.debug("Recalculated neighbor indices after boundary change.")
                # Trigger a full redraw
                if self.grid_visualizer is not None:
                    self.grid_visualizer.update_visualization_state(invalidate_blit_cache=True) # Invalidate blit
                    self._safe_plot_update(force=True) # Force redraw

                # --- ADDED: Update refocus button state ---
                if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                    self.control_panel_ui.update_refocus_button_state()
                # ---
            else:
                logger.warning(f"Invalid grid boundary: {boundary_str}")
                messagebox.showerror("Error", f"Invalid grid boundary: {boundary_str}")
                # Reset to current type
                self.grid_boundary_var.set(self.controller.rule.get_param('grid_boundary', 'bounded'))

        except Exception as e:
            logger.error(f"Error changing grid boundary: {e}")
            messagebox.showerror("Error", f"Failed to change grid boundary: {e}")
            # Reset to current type
            self.grid_boundary_var.set(self.controller.rule.get_param('grid_boundary', 'bounded'))

    def _request_pause_for_interaction(self, reason: str):
        """
        Checks if the simulation is running and pauses it if necessary before user interaction.
        Updates button states.
        (Round 9: New method for interaction handling)
        """
        log_prefix = "_request_pause_for_interaction: "
        logger.debug(f"{log_prefix}Request received. Reason: '{reason}'. Current state: running={self.running}, paused={self.paused}, stopped={self._stopped}")

        # Only pause if it's currently running and *not* already paused or stopped
        if self.running and not self.paused and not self._stopped:
            logger.info(f"{log_prefix}Simulation running. Pausing for interaction: '{reason}'")
            self.paused = True
            # Signal the computation thread to pause
            if hasattr(self, 'computation_pause_flag'):
                self.computation_pause_flag.clear()
                logger.debug(f"{log_prefix}Cleared computation_pause_flag.")
            else:
                logger.warning(f"{log_prefix}computation_pause_flag not found, cannot signal pause.")

            # Update button states immediately
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                self.control_panel_ui.update_button_states()
                logger.debug(f"{log_prefix}Updated button states.")
            else:
                logger.warning(f"{log_prefix}ControlPanelUI not found, cannot update button states.")
        elif self.paused:
            logger.debug(f"{log_prefix}Simulation already paused. No action needed.")
        elif self._stopped:
             logger.debug(f"{log_prefix}Simulation stopped. No action needed.")
        else: # Not running
             logger.debug(f"{log_prefix}Simulation not running. No action needed.")

    def _on_right_click(self, event):
        """Handle right-click events (now from Matplotlib) for shape placement and saving."""
        # --- MODIFIED: Accept Matplotlib event ---
        # Check if event has necessary attributes (xdata, ydata, x, y)
        if not all(hasattr(event, attr) for attr in ['xdata', 'ydata', 'x', 'y']):
             logger.error("Received invalid event object in _on_right_click.")
             return

        logger.debug(f"Right-click (MPL) detected at data coords: ({event.xdata:.2f}, {event.ydata:.2f})")

        # Use event.xdata and event.ydata directly
        x_data, y_data = event.xdata, event.ydata
        if x_data is None or y_data is None:
            logger.debug("Right-click outside axes.")
            return

        # Convert data coordinates to approximate grid coordinates
        grid_coords_float = self.coord_system.display_to_grid((x_data, y_data))
        # --- CORRECTED: Moved log before return ---
        if grid_coords_float is None:
            logger.warning("Could not convert display coords to grid coords.")
            return  # Ensure grid_coords_float is not None before proceeding
        # --- END CORRECTION ---
        origin_coords = tuple(int(np.floor(c)) for c in grid_coords_float)
        logger.debug(f"Approx grid origin for placement: {origin_coords}")

        # Create the popup menu
        popup_menu = tk.Menu(self.root, tearoff=0)

        # --- Shape Placement Section ---
        shape_menu = tk.Menu(popup_menu, tearoff=0)
        popup_menu.add_cascade(label="Place Shape", menu=shape_menu)

        shapes_to_offer = { # Using lambda ensures origin is passed correctly
            "Square (5x5)": lambda origin: ShapeGenerator.create_square(size=5, filled=True, connectivity="full"),
            "Cube (3x3x3)": lambda origin: ShapeGenerator.create_cube(size=3, filled=True, connectivity="full"),
            "Line (Horizontal 5)": lambda origin: ShapeGenerator.create_line(start=(0, 0), end=(0, 4)),
            "Line (Vertical 5)": lambda origin: ShapeGenerator.create_line(start=(0, 0), end=(4, 0)),
            "Circle (Radius 3)": lambda origin: ShapeGenerator.create_circle(radius=3, filled=True, connectivity="full"),
            "Sphere (Radius 2)": lambda origin: ShapeGenerator.create_sphere(center=(0,0,0), radius=2, filled=True, connectivity="full"),
            "Triangle (Side 4)": lambda origin: ShapeGenerator.create_triangle(corner=(0,0), side_length=4, connectivity="full"),
        }

        for shape_name, shape_factory in shapes_to_offer.items():
            try:
                temp_shape_for_check = shape_factory((0,)*len(self.dimensions))
                if temp_shape_for_check.get_dimensions() == len(self.dimensions):
                    shape_menu.add_command(
                        label=shape_name,
                        command=lambda sf=shape_factory, oc=origin_coords: self._place_selected_shape(sf, oc)
                    )
                elif len(self.dimensions) == 2 and temp_shape_for_check.get_dimensions() == 3:
                    if shape_name.startswith("Cube"):
                        shape_size = getattr(temp_shape_for_check, 'size', 3)
                        shape_menu.add_command(
                            label=f"{shape_name} (as Square)",
                            command=lambda s=shape_size, oc=origin_coords: self._place_selected_shape(
                                lambda origin: ShapeGenerator.create_square(size=s, filled=True, connectivity="full"), oc
                            )
                        )
                    elif shape_name.startswith("Sphere"):
                        shape_radius = getattr(temp_shape_for_check, 'radius', 2)
                        shape_menu.add_command(
                            label=f"{shape_name} (as Circle)",
                            command=lambda r=shape_radius, oc=origin_coords: self._place_selected_shape(
                                lambda origin: ShapeGenerator.create_circle(radius=int(r), filled=True, connectivity="full"), oc
                            )
                        )
            except Exception as e:
                logger.warning(f"Could not create/check shape '{shape_name}' for menu: {e}")

        shape_menu.add_separator()
        shape_menu.add_command(label="Open Shape Editor...", command=self._open_shape_editor_window)

        # --- Save Options Section ---
        popup_menu.add_separator()
        popup_menu.add_command(label="Save Grid as New Shape...", command=self._save_grid_as_new_shape)
        popup_menu.add_command(label="Save Grid as New Preset...", command=self._save_grid_as_new_preset)
        update_preset_state = tk.NORMAL if (self.active_preset_name and self.active_preset_name != "None") else tk.DISABLED
        popup_menu.add_command(label="Update Current Preset", command=self._update_current_preset, state=update_preset_state)
        # ---

        # Display the menu using event's screen coordinates
        try:
            popup_menu.tk_popup(int(event.x), int(event.y)) # Use event.x, event.y for screen coords
        finally:
            popup_menu.grab_release()
        # --- END MODIFIED ---

    def _show_controls_help(self):
        """Displays a non-modal window with mouse and keyboard control information."""
        logger.debug(f"_show_controls_help: Creating Toplevel with parent self.root (Type: {type(self.root)}, ID: {id(self.root)})")

        # Check if help window already exists
        if hasattr(self, '_help_window') and self._help_window and self._help_window.winfo_exists():
            self._help_window.lift() # Bring to front if already open
            logger.debug("Help window already exists, lifting.")
            return

        help_text = """
        Mouse & Keyboard Controls:

        --- Canvas Interaction ---

        Left Click: Toggle node On/Off (or activate/deactivate)

        Left Drag: Scribble Draw (activate nodes, connect new binary edges if rule supports)

        Shift + Left Drag: Scribble Erase (deactivate nodes, remove connected edges)

        Ctrl/Cmd + Left Drag: Scribble Delete Edges (remove edges along path)

        Alt/Opt + Left Click: Increment Node State (+10% Real) [Only for REAL state rules]

        Alt/Opt + Left Drag: Scribble Increment Node/Edge State (+10% Real) [Only for REAL state rules]

        Alt/Opt+Shift + L Click: Decrement Node State (-10% Real) [Only for REAL state rules]

        Alt/Opt+Shift + L Drag: Scribble Decrement Node/Edge State (-10% Real, removes edge if state reaches minimum) [Only for REAL state rules]

        Right Click: Open Context Menu

        Mouse Wheel: Pan View (Vertical)

        Shift + Mouse Wheel: Pan View (Horizontal - OS/driver dependent)

        Ctrl/Cmd + Mouse Wheel: Zoom View (not implemented yet)

        --- Keyboard Shortcuts ---

        Spacebar: Start/Pause Simulation (not implemented yet)

        S: Step Simulation Once (not implemented yet)

        R: Reset Simulation (not implemented yet)

        C: Toggle Control Panel Visibility (not implemented yet)

        L: Open Shape Library & Editor (not implemented yet)

        Ctrl/Cmd + Z: Undo Grid Action (not implemented yet)

        Ctrl/Cmd + Y / Ctrl+Shift+Z: Redo Grid Action (not implemented yet)

        Ctrl/Cmd + S: Save Simulation State (not implemented yet)

        Ctrl/Cmd + O: Load Simulation State (not implemented yet)

        Ctrl/Cmd + N: Create New Preset (not implemented yet)

        Ctrl/Cmd + M: Manage Presets (not implemented yet)

        Ctrl/Cmd + E: Edit Current Rule (not implemented yet)

        Ctrl/Cmd + L: Open Shape Library & Editor (Duplicate - not implemented yet)

        Ctrl/Cmd + C: Copy Selection (not implemented yet)

        Ctrl/Cmd + X: Cut Selection (not implemented yet)

        Ctrl/Cmd + V: Paste Selection Here (not implemented yet)

        Delete/Backspace: Erase Selected Nodes (not implemented yet)

        Ctrl/Cmd + Delete/Backspace: Delete Edges Within Selection (not implemented yet)

        Ctrl/Cmd + A: Select All Active Nodes (not implemented yet)

        Escape: Deselect All / Cancel Tool Action (not implemented yet)

        (Note: Alt = Alt on Win/Lin, Option on macOS)
        """

        # Create a new Toplevel window
        self._help_window = tk.Toplevel(self.root)
        self._help_window.title("Controls Help")
        self._help_window.geometry("550x700")
        # self._help_window.transient(self.root) # Optional

        # Add a scrollbar
        scrollbar = tk.Scrollbar(self._help_window)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)

        # Add a Text widget for scrollable content
        help_text_widget = tk.Text(
            self._help_window,
            wrap=tk.WORD,
            padx=10,
            pady=10,
            yscrollcommand=scrollbar.set,
            font=("TkDefaultFont", 10)
        )
        help_text_widget.insert(tk.END, help_text.strip())
        help_text_widget.config(state=tk.DISABLED) # Make text read-only
        help_text_widget.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)

        scrollbar.config(command=help_text_widget.yview)

        # Add a close button
        close_button = tk.Button(self._help_window, text="Close", command=self._help_window.destroy)
        close_button.pack(pady=5)

        self._help_window.lift()

    def _load_hotmenu_shapes(self):
        """
        Loads the list of hotmenu shape names from config/hotmenu.json.
        If the file doesn't exist or is invalid, initializes with default shapes.
        (Round 9 Fix: Use shape_manager.get_shape())
        """
        self.hotmenu_shape_names: List[str] = [] # Ensure attribute exists and is list
        hotmenu_path = os.path.join(self.app_paths.get('config', '.'), 'hotmenu.json')
        default_hotmenu_shapes = list(SimulationGUI.DEFAULT_HOTMENU_SHAPES)
        if "Glider" not in default_hotmenu_shapes:
            default_hotmenu_shapes.insert(0, "Glider")

        try:
            if os.path.exists(hotmenu_path) and os.path.getsize(hotmenu_path) > 0:
                with open(hotmenu_path, 'r') as f:
                    data = json.load(f)
                    if isinstance(data, list) and all(isinstance(item, str) for item in data):
                        manager = ShapeLibraryManager.get_instance()
                        # --- MODIFIED: Use get_shape for validation ---
                        valid_hotmenu_names = [name for name in data if manager.get_shape(name) is not None]
                        # ---
                        if len(valid_hotmenu_names) != len(data):
                            logger.warning("Removed some invalid shape names from hotmenu during load.")
                            self.hotmenu_shape_names = valid_hotmenu_names
                            self._save_hotmenu_shapes()
                        else:
                            self.hotmenu_shape_names = valid_hotmenu_names
                        logger.info(f"Loaded {len(self.hotmenu_shape_names)} hotmenu shapes from {hotmenu_path}")
                    else:
                        logger.warning(f"Invalid format in {hotmenu_path}. Reverting to defaults.")
                        self.hotmenu_shape_names = default_hotmenu_shapes[:]
                        self._save_hotmenu_shapes()
            else:
                logger.info("hotmenu.json not found or empty, initializing with default shapes.")
                self.hotmenu_shape_names = default_hotmenu_shapes[:]
                self._save_hotmenu_shapes()
        except (json.JSONDecodeError, IOError, Exception) as e:
            logger.error(f"Error loading hotmenu shapes from {hotmenu_path}: {e}")
            self.hotmenu_shape_names = default_hotmenu_shapes[:]
            try: self._save_hotmenu_shapes()
            except: pass

    def _save_hotmenu_shapes(self):
        """Saves the current list of hotmenu shape names to config/hotmenu.json."""
        hotmenu_path = os.path.join(self.app_paths.get('config', '.'), 'hotmenu.json')
        try:
            # Ensure directory exists
            os.makedirs(os.path.dirname(hotmenu_path), exist_ok=True)
            # --- Ensure self.hotmenu_shape_names exists and is a list ---
            if not hasattr(self, 'hotmenu_shape_names') or not isinstance(self.hotmenu_shape_names, list):
                 logger.warning("hotmenu_shape_names not found or not a list during save. Initializing to empty list.")
                 self.hotmenu_shape_names = []
            # ---
            with open(hotmenu_path, 'w') as f:
                json.dump(self.hotmenu_shape_names, f, indent=2)
            logger.debug(f"Saved {len(self.hotmenu_shape_names)} hotmenu shapes to {hotmenu_path}")
        except (IOError, TypeError, Exception) as e: # Added TypeError
            logger.error(f"Error saving hotmenu shapes to {hotmenu_path}: {e}")
            # Avoid showing messagebox here as it might be called frequently internally

    def _place_selected_shape(self, shape_factory: Callable, initial_origin_coords: Tuple[int, ...]) -> Optional[Set[int]]:
        """
        Orchestrates shape placement: checks size, prompts resize, determines origin
        (centering if grid is clear or after resize), checks overlap, prompts resolution,
        and calls placer. Clears queues after successful direct placement.
        Returns the set of placed node indices if successful, None otherwise.
        (Round 11: Clear queues after successful direct placement)
        """
        log_prefix = "_place_selected_shape (R11 Queue Clear): " # Updated round
        logger.info(f"{log_prefix}Initiating placement. Initial context origin: {initial_origin_coords}. Paused={self.paused}")

        if self.grid is None or self.grid_visualizer is None or self.grid.shape_placer is None:
            logger.error(f"{log_prefix}Grid, visualizer, or shape placer not available.")
            return None # Indicate failure

        try:
            # --- 1. Create Shape Definition ---
            shape_dims_count = len(self.grid.dimensions)
            relative_origin = (0,) * shape_dims_count
            shape_def = shape_factory(relative_origin)
            logger.debug(f"{log_prefix}Created shape definition: {type(shape_def).__name__}")
            shape_relative_coords = shape_def.get_relative_coordinates()
            if not shape_relative_coords:
                logger.warning(f"{log_prefix}Shape definition has no relative coordinates. Cannot place.")
                return None # Indicate failure

            # --- 2. Grid Size Check & Potential Resize ---
            min_rel, max_rel = shape_def.get_bounding_box()
            shape_size = tuple(mx - mn + 1 for mn, mx in zip(min_rel, max_rel))
            required_dims_for_shape = shape_size
            fits_anywhere = all(req <= grid_dim for req, grid_dim in zip(required_dims_for_shape, self.grid.dimensions))

            resize_info = None
            if not fits_anywhere:
                logger.info(f"{log_prefix}Shape size {shape_size} too large for current grid {self.grid.dimensions}. Prompting user to resize.")
                grid_is_empty = not np.any(self.grid.grid_array > 1e-6)
                dialog = ResizePromptDialog(self.root, required_dims_for_shape, self.grid.dimensions, grid_is_empty)
                resize_info = dialog.result

                if resize_info is None or resize_info.get("action") == "cancel":
                    logger.info(f"{log_prefix}User cancelled resize/placement.")
                    return None # Indicate cancellation/failure

            # --- 3. Determine Final Placement Origin ---
            target_origin = initial_origin_coords
            grid_dims_for_center = self.grid.dimensions
            grid_is_empty = not np.any(self.grid.grid_array > 1e-6)

            center_placement = False
            if resize_info:
                grid_dims_for_center = resize_info['dimensions']
                center_placement = True
                logger.info(f"{log_prefix}Resizing to {grid_dims_for_center}. Will center placement.")
            elif grid_is_empty:
                center_placement = True
                logger.info(f"{log_prefix}Grid is empty. Will center placement.")
            else:
                 logger.info(f"{log_prefix}Grid not empty and no resize. Using initial context origin: {target_origin}")

            if center_placement:
                grid_center_coords = tuple(d / 2.0 for d in grid_dims_for_center)
                if shape_relative_coords:
                    shape_centroid_offset = tuple(np.mean([c[d] for c in shape_relative_coords]) for d in range(shape_dims_count))
                else:
                    shape_centroid_offset = tuple((mx + mn) / 2 for mn, mx in zip(min_rel, max_rel))
                target_origin = tuple(int(round(center - offset)) for center, offset in zip(grid_center_coords, shape_centroid_offset))
                logger.info(f"{log_prefix}Centering placement. GridCenter={grid_center_coords}, ShapeCentroidOffset={shape_centroid_offset} -> TargetOrigin={target_origin}")

            logger.debug(f"{log_prefix}Final target placement origin: {target_origin}")

            # --- 4. Overlap Check ---
            overlaps = False
            if not grid_is_empty and (resize_info is None or resize_info.get("clear_action") == "copy"):
                for rel_coord in shape_relative_coords:
                    abs_coord = tuple(o + r for o, r in zip(target_origin, rel_coord))
                    if self.grid.is_valid_coord(abs_coord):
                        try:
                            if self.grid.grid_array[abs_coord] > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD:
                                overlaps = True; break
                        except IndexError: pass
            logger.debug(f"{log_prefix}Overlap check result: {overlaps}")

            # --- 5. Handle Overlap / Find Spot ---
            final_placement_origin = target_origin
            proceed_with_placement = True
            clear_grid_first = False
            placed_indices: Optional[Set[int]] = None # Initialize placed_indices

            if overlaps:
                logger.warning(f"{log_prefix}Placement at {target_origin} overlaps existing cells.")
                overlap_dialog = OverlapPromptDialog(self.root, getattr(shape_def, 'name', type(shape_def).__name__))
                action = overlap_dialog.result

                if action == "cancel":
                    proceed_with_placement = False
                    logger.info(f"{log_prefix}User cancelled placement due to overlap.")
                elif action == "find_clear_spot":
                    logger.info(f"{log_prefix}User chose to find clear spot.")
                    new_origin = self._find_empty_spot_for_shape(shape_def, target_origin)
                    if new_origin:
                        final_placement_origin = new_origin
                        logger.info(f"{log_prefix}Found clear spot at: {final_placement_origin}")
                    else:
                        proceed_with_placement = False
                        logger.warning(f"{log_prefix}Could not find a clear spot.")
                        messagebox.showinfo("Placement Failed", "Could not find a clear spot nearby.", parent=self.root)
                elif action == "overwrite":
                    logger.info(f"{log_prefix}User chose to overwrite.")
                elif action == "clear_and_place":
                    logger.info(f"{log_prefix}User chose to clear grid and place.")
                    clear_grid_first = True
                    grid_center_coords = tuple(d // 2 for d in grid_dims_for_center)
                    shape_centroid_offset = tuple(np.mean([c[d] for c in shape_relative_coords]) for d in range(shape_dims_count)) if shape_relative_coords else tuple((mx + mn) / 2 for mn, mx in zip(min_rel, max_rel))
                    final_placement_origin = tuple(int(round(center - offset)) for center, offset in zip(grid_center_coords, shape_centroid_offset))
                    logger.info(f"{log_prefix}Recalculated origin for centering after clear: {final_placement_origin}")
                    proceed_with_placement = True
                else:
                    proceed_with_placement = False

            # --- 6. Final Placement ---
            if proceed_with_placement:
                if resize_info:
                    logger.info(f"{log_prefix}Triggering resize to {resize_info['dimensions']} before placing shape at {final_placement_origin}.")
                    # Resize handles its own queue clearing and redraw
                    self._apply_new_grid_size(
                        target_dimensions=resize_info['dimensions'],
                        clear_or_copy=resize_info['clear_action'],
                        shape_to_place_after=shape_def,
                        origin_to_place_after=final_placement_origin
                    )
                    placed_indices = None # Cannot easily track indices after resize
                else:
                    logger.info(f"{log_prefix}Proceeding with placement of '{type(shape_def).__name__}' at {final_placement_origin}")
                    try:
                        if clear_grid_first:
                            logger.info(f"{log_prefix}Clearing grid before placement.")
                            self.clear_grid() # This handles undo and queue clear
                        self._push_grid_state_to_undo(f"Place Shape '{getattr(shape_def, 'name', type(shape_def).__name__)}'")
                        placed_indices = self.grid.shape_placer.place_shape_definition(shape_def, final_placement_origin)
                        if placed_indices is not None:
                            # --- ADDED: Clear queues after successful direct placement ---
                            self._clear_computation_and_render_queues()
                            # ---
                            self._safe_plot_update(force=True) # Force redraw after placement
                            logger.debug(f"{log_prefix}Placement finished, queues cleared, visualization updated.")
                        else:
                            logger.warning(f"{log_prefix}Placement seemed allowed but place_shape_definition returned None (likely cancelled).")
                            if self._grid_undo_stack and self._grid_undo_stack[-1]['action'].startswith("Place Shape"):
                                self._grid_undo_stack.pop()
                    finally:
                        pass # No resume needed as pause is handled by caller (_display_right_click_menu)
            else: # Placement cancelled
                placed_indices = None

            return placed_indices

        except Exception as e:
            logger.error(f"{log_prefix}Error placing shape: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Error", f"Failed to place shape: {e}", parent=self.root)
            return None # Indicate failure
          
    def _place_selected_shape_with_edges(self, shape_factory: Callable, origin_coords: Tuple[int, ...]):
        """Places the selected shape and then adds default edges between its nodes."""
        log_prefix = "_place_selected_shape_with_edges: "
        logger.info(f"{log_prefix}Placing shape '{getattr(shape_factory(origin_coords), 'name', 'Unknown')}' at {origin_coords} WITH edges.")

        # Call the main placement function
        placed_indices = self._place_selected_shape(shape_factory, origin_coords)

        # If placement was successful (not cancelled and didn't fail)
        if placed_indices is not None and self.grid and self.grid.shape_placer:
            logger.info(f"{log_prefix}Placement successful ({len(placed_indices)} nodes). Adding default 'full' edges.")
            try:
                # Use 'full' connectivity to connect all adjacent placed nodes
                self.grid.shape_placer.add_default_edges(placed_indices, "full")
                # Force another redraw to show the newly added edges
                self._safe_plot_update(force=True)
                logger.debug(f"{log_prefix}Added default edges and updated visualization.")
            except Exception as e:
                logger.error(f"{log_prefix}Error adding default edges after placement: {e}")
                messagebox.showerror("Error", f"Shape placed, but failed to add edges: {e}", parent=self.root)
        elif placed_indices is None:
            logger.info(f"{log_prefix}Shape placement was cancelled or failed, skipping edge addition.")
        else:
            logger.error(f"{log_prefix}Grid or ShapePlacer not available after placement, cannot add edges.")

    def _rotate_selection_90(self):
        """
        Rotates the currently selected nodes 90 degrees clockwise around their centroid,
        preserving relative integer offsets AND internal edges/states. Clears queues on success.
        (Round 15 Fix: Explicitly cast edge coord tuples for dict keys)
        (Round 11: Clear queues after successful rotation)
        """
        log_prefix = "_rotate_selection_90 (R15 Cast Fix, R11 Queue Clear): " # Updated round
        logger.info(f"{log_prefix}Attempting to rotate selection.")

        if not self.current_selection or not self.current_selection.get('nodes'):
            messagebox.showwarning("No Selection", "Lasso select some nodes first.", parent=self.root)
            logger.warning(f"{log_prefix}No nodes selected.")
            return
        if self.grid is None or self.controller is None or self.controller.rule is None:
            logger.error(f"{log_prefix}Grid, Controller, or Rule is None.")
            return

        selected_coords_abs_set = self.current_selection['nodes']
        if len(selected_coords_abs_set) < 1: # Allow rotating single nodes (no effect but shouldn't error)
            logger.info(f"{log_prefix}Rotation requires at least 1 node.")
            return

        was_running = self.running
        self._pause_computation(reason="Rotate Selection")
        rotation_successful = False

        try:
            self._push_grid_state_to_undo("Rotate Selection")
            selected_coords_list = list(selected_coords_abs_set)
            dims = len(selected_coords_list[0])

            if dims != 2:
                messagebox.showwarning("Not Supported", "Rotation is currently only supported for 2D grids.", parent=self.root)
                logger.warning(f"{log_prefix}Rotation aborted, not a 2D grid.")
                if self._grid_undo_stack and self._grid_undo_stack[-1].get('action') == "Rotate Selection": self._grid_undo_stack.pop()
                return

            # --- 1. Calculate Centroid (use average for rotation center) ---
            avg_r = np.mean([coord[0] for coord in selected_coords_list])
            avg_c = np.mean([coord[1] for coord in selected_coords_list])
            centroid = (avg_r, avg_c)
            logger.debug(f"{log_prefix}Calculated centroid: {centroid}")
            # ---

            # --- 2. Calculate New Coordinates and Store Original States/Edges ---
            original_states = {}
            original_coord_to_new_coord: Dict[Tuple[int, int], Tuple[int, int]] = {}
            internal_edges_original: Dict[Tuple[Tuple[int, int], Tuple[int, int]], float] = {} # Store original internal edges and states
            new_selection_coords = set()
            all_new_coords_valid = True

            # --- Capture original states and calculate new coords ---
            for r_old, c_old in selected_coords_list:
                original_states[(r_old, c_old)] = self.grid.grid_array[r_old, c_old]
                rel_r = r_old - centroid[0]; rel_c = c_old - centroid[1]
                new_rel_r = rel_c; new_rel_c = -rel_r # Rotate 90 clockwise
                r_new = int(round(centroid[0] + new_rel_r)); c_new = int(round(centroid[1] + new_rel_c))
                new_coord = (r_new, c_new)

                if not self.grid.is_valid_coord(new_coord):
                    logger.warning(f"{log_prefix}Rotated coordinate {new_coord} for original { (r_old, c_old)} is out of bounds. Aborting rotation.")
                    messagebox.showerror("Rotation Error", "Rotated shape would go out of grid bounds.", parent=self.root)
                    all_new_coords_valid = False; break
                original_coord_to_new_coord[(r_old, c_old)] = new_coord
                new_selection_coords.add(new_coord)

            if not all_new_coords_valid:
                if self._grid_undo_stack and self._grid_undo_stack[-1].get('action') == "Rotate Selection": self._grid_undo_stack.pop()
                return

            logger.debug(f"{log_prefix}Calculated new absolute coordinates: {new_selection_coords}")

            # --- Capture internal edges BEFORE modifying grid ---
            rule_supports_edges = self.controller.rule.get_param('edge_initialization', 'RANDOM') != 'NONE'
            if rule_supports_edges:
                logger.debug(f"{log_prefix}Capturing internal edges...")
                for edge_coords_generic in list(self.grid.edges): # Iterate copy
                    n1_old_generic, n2_old_generic = edge_coords_generic
                    # --- MODIFIED: Check and Cast ---
                    if isinstance(n1_old_generic, tuple) and len(n1_old_generic) == 2 and isinstance(n2_old_generic, tuple) and len(n2_old_generic) == 2:
                        # Cast to specific 2D tuple type
                        n1_old = cast(Tuple[int, int], n1_old_generic)
                        n2_old = cast(Tuple[int, int], n2_old_generic)
                        edge_coords = cast(Tuple[Tuple[int, int], Tuple[int, int]], edge_coords_generic)

                        if n1_old in selected_coords_abs_set and n2_old in selected_coords_abs_set:
                            internal_edges_original[edge_coords] = self.grid.edge_states.get(edge_coords_generic, 1.0) # Use original generic key for get
                    # --- END MODIFIED ---
                logger.debug(f"{log_prefix}Captured {len(internal_edges_original)} internal edges.")
            # ---

            # [ Steps 3-6 remain unchanged ]
            # 3. Update Grid State
            logger.debug(f"{log_prefix}Updating grid state...")
            nodes_to_clear = selected_coords_abs_set - new_selection_coords
            for old_coord in nodes_to_clear:
                 self.grid.set_node_state(_ravel_multi_index(np.array(old_coord), self.grid.dimensions), 0.0)
            for old_coord, new_coord in original_coord_to_new_coord.items():
                self.grid.set_node_state(_ravel_multi_index(np.array(new_coord), self.grid.dimensions), original_states[old_coord])
            logger.debug(f"{log_prefix}Node states updated.")

            # 4. Update Edges (Conditional)
            edges_to_add = {}
            if rule_supports_edges:
                logger.debug(f"{log_prefix}Updating edges...")
                edges_to_remove = set()
                for edge_coords in list(self.grid.edges):
                    n1_old, n2_old = edge_coords
                    if n1_old in selected_coords_abs_set or n2_old in selected_coords_abs_set:
                        edges_to_remove.add(edge_coords)
                logger.debug(f"{log_prefix}Identified {len(edges_to_remove)} edges connected to original selection for removal.")

                for old_edge_coords, original_state in internal_edges_original.items():
                    n1_old, n2_old = old_edge_coords
                    n1_new = original_coord_to_new_coord.get(n1_old)
                    n2_new = original_coord_to_new_coord.get(n2_old)
                    if n1_new and n2_new:
                        new_edge_coords = self.grid._ordered_edge(n1_new, n2_new)
                        edges_to_add[new_edge_coords] = original_state
                        logger.debug(f"{log_prefix}    Mapped internal edge {old_edge_coords} -> {new_edge_coords} with state {original_state}")
                    else:
                        logger.warning(f"{log_prefix}    Could not map internal edge {old_edge_coords} during rotation.")

                removed_count = 0
                for edge_coords in edges_to_remove:
                    try: idx1 = _ravel_multi_index(np.array(edge_coords[0]), self.grid.dimensions); idx2 = _ravel_multi_index(np.array(edge_coords[1]), self.grid.dimensions); self.grid.remove_edge(idx1, idx2); removed_count += 1
                    except Exception as rem_err: logger.warning(f"    Error removing edge {edge_coords}: {rem_err}")
                logger.debug(f"{log_prefix}Removed {removed_count} old edges connected to selection.")

                added_count = 0
                for new_edge_coords, state in edges_to_add.items():
                    try: idx1 = _ravel_multi_index(np.array(new_edge_coords[0]), self.grid.dimensions); idx2 = _ravel_multi_index(np.array(new_edge_coords[1]), self.grid.dimensions); self.grid.add_edge(idx1, idx2, edge_state=state); added_count += 1
                    except Exception as add_err: logger.warning(f"    Error adding edge {new_edge_coords}: {add_err}")
                logger.debug(f"{log_prefix}Added {added_count} new internal edges.")
            else:
                logger.info(f"{log_prefix}Skipping edge updates (rule doesn't support edges). Removing internal edges.")
                edges_to_remove = set()
                for edge_coords in list(self.grid.edges):
                    if edge_coords[0] in selected_coords_abs_set and edge_coords[1] in selected_coords_abs_set: edges_to_remove.add(edge_coords)
                removed_count = 0
                if edges_to_remove:
                    logger.debug(f"{log_prefix}  Removing {len(edges_to_remove)} edges within selection area as rule doesn't support edges.")
                    for edge_coords in edges_to_remove:
                        try: idx1 = _ravel_multi_index(np.array(edge_coords[0]), self.grid.dimensions); idx2 = _ravel_multi_index(np.array(edge_coords[1]), self.grid.dimensions); self.grid.remove_edge(idx1, idx2); removed_count += 1
                        except Exception as rem_err: logger.warning(f"    Error removing edge {edge_coords}: {rem_err}")
                    logger.debug(f"{log_prefix}  Removed {removed_count} edges.")

            # 5. Update Selection
            self.current_selection['nodes'] = new_selection_coords
            self.current_selection['edges'] = set(edges_to_add.keys())
            logger.debug(f"{log_prefix}Updated current selection.")

            # 6. Final Updates
            self.grid.update_active_nodes()
            self.grid.populate_spatial_hash()
            rotation_successful = True
            self._update_editor_buttons_if_open()
            logger.info(f"{log_prefix}Selection rotated successfully.")

        except Exception as e:
            logger.error(f"{log_prefix}Error rotating selection: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Rotation Error", f"Failed to rotate selection: {e}", parent=self.root)
            self._undo_grid_action() # Attempt undo
        finally:
            if rotation_successful:
                # --- ADDED: Clear queues before redraw ---
                self._clear_computation_and_render_queues()
                # ---
                self._safe_plot_update(force=True) # Use forced update
            if was_running: self._resume_computation(reason="Rotate Selection Complete")

    def _flip_selection_horizontal(self):
        """Flips the selected nodes horizontally around their centroid, preserving internal edges.
           Clears queues on success.
           (Round 15 Fix: Explicitly cast edge coord tuples for dict keys)
           (Round 11: Clear queues after successful flip)"""
        log_prefix = "_flip_selection_horizontal (R15 Cast Fix, R11 Queue Clear): " # Updated round
        logger.info(f"{log_prefix}Attempting horizontal flip.")
        if not self.current_selection or not self.current_selection.get('nodes'):
            messagebox.showwarning("No Selection", "Lasso select some nodes first.", parent=self.root)
            return
        if self.grid is None or self.controller is None or self.controller.rule is None:
            logger.error(f"{log_prefix}Grid, Controller, or Rule is None.")
            return

        selected_coords_abs_set = self.current_selection['nodes']
        if len(selected_coords_abs_set) < 1: return # Need at least one node

        was_running = self.running
        self._pause_computation(reason="Flip Selection Horizontal")
        flip_successful = False

        try:
            self._push_grid_state_to_undo("Flip Selection Horizontal")
            selected_coords_list = list(selected_coords_abs_set)
            dims = len(selected_coords_list[0])
            if dims != 2:
                messagebox.showwarning("Not Supported", "Flip is currently only supported for 2D grids.", parent=self.root)
                if self._grid_undo_stack and self._grid_undo_stack[-1].get('action') == "Flip Selection Horizontal": self._grid_undo_stack.pop()
                return

            # 1. Calculate Centroid
            avg_r = np.mean([coord[0] for coord in selected_coords_list])
            avg_c = np.mean([coord[1] for coord in selected_coords_list])
            centroid = (avg_r, avg_c)
            logger.debug(f"{log_prefix}Calculated centroid: {centroid}")

            # 2. Calculate New Coordinates and Store Original States/Edges
            original_states = {}
            original_coord_to_new_coord: Dict[Tuple[int, int], Tuple[int, int]] = {}
            internal_edges_original: Dict[Tuple[Tuple[int, int], Tuple[int, int]], float] = {} # Store original internal edges and states
            new_selection_coords = set()
            all_new_coords_valid = True

            # --- Capture original states and calculate new coords ---
            for r_old, c_old in selected_coords_list:
                original_states[(r_old, c_old)] = self.grid.grid_array[r_old, c_old]
                rel_r = r_old - centroid[0]; rel_c = c_old - centroid[1]
                new_rel_c = -rel_c; new_rel_r = rel_r # Flip horizontal
                r_new = int(round(centroid[0] + new_rel_r)); c_new = int(round(centroid[1] + new_rel_c))
                new_coord = (r_new, c_new)

                if not self.grid.is_valid_coord(new_coord):
                    logger.warning(f"{log_prefix}Flipped coordinate {new_coord} for original { (r_old, c_old)} is out of bounds. Aborting flip.")
                    messagebox.showerror("Flip Error", "Flipped shape would go out of grid bounds.", parent=self.root)
                    all_new_coords_valid = False; break
                original_coord_to_new_coord[(r_old, c_old)] = new_coord
                new_selection_coords.add(new_coord)

            if not all_new_coords_valid:
                if self._grid_undo_stack and self._grid_undo_stack[-1].get('action') == "Flip Selection Horizontal": self._grid_undo_stack.pop()
                return

            logger.debug(f"{log_prefix}Calculated new absolute coordinates: {new_selection_coords}")

            # --- Capture internal edges BEFORE modifying grid ---
            rule_supports_edges = self.controller.rule.get_param('edge_initialization', 'RANDOM') != 'NONE'
            if rule_supports_edges:
                logger.debug(f"{log_prefix}Capturing internal edges...")
                for edge_coords_generic in list(self.grid.edges): # Iterate copy
                    n1_old_generic, n2_old_generic = edge_coords_generic
                    # --- MODIFIED: Check and Cast ---
                    if isinstance(n1_old_generic, tuple) and len(n1_old_generic) == 2 and isinstance(n2_old_generic, tuple) and len(n2_old_generic) == 2:
                        # Cast to specific 2D tuple type
                        n1_old = cast(Tuple[int, int], n1_old_generic)
                        n2_old = cast(Tuple[int, int], n2_old_generic)
                        edge_coords = cast(Tuple[Tuple[int, int], Tuple[int, int]], edge_coords_generic)

                        if n1_old in selected_coords_abs_set and n2_old in selected_coords_abs_set:
                            internal_edges_original[edge_coords] = self.grid.edge_states.get(edge_coords_generic, 1.0) # Use original generic key for get
                    # --- END MODIFIED ---
                logger.debug(f"{log_prefix}Captured {len(internal_edges_original)} internal edges.")
            # ---

            # [ Steps 3-6 remain unchanged ]
            # 3. Update Grid State
            logger.debug(f"{log_prefix}Updating grid state...")
            nodes_to_clear = selected_coords_abs_set - new_selection_coords
            for old_coord in nodes_to_clear:
                 self.grid.set_node_state(_ravel_multi_index(np.array(old_coord), self.grid.dimensions), 0.0)
            for old_coord, new_coord in original_coord_to_new_coord.items():
                self.grid.set_node_state(_ravel_multi_index(np.array(new_coord), self.grid.dimensions), original_states[old_coord])
            logger.debug(f"{log_prefix}Node states updated.")

            # 4. Update Edges (Conditional)
            edges_to_add = {}
            if rule_supports_edges:
                logger.debug(f"{log_prefix}Updating edges...")
                edges_to_remove = set()
                for edge_coords in list(self.grid.edges):
                    n1_old, n2_old = edge_coords
                    if n1_old in selected_coords_abs_set or n2_old in selected_coords_abs_set:
                        edges_to_remove.add(edge_coords)
                logger.debug(f"{log_prefix}Identified {len(edges_to_remove)} edges connected to original selection for removal.")

                for old_edge_coords, original_state in internal_edges_original.items():
                    n1_old, n2_old = old_edge_coords
                    n1_new = original_coord_to_new_coord.get(n1_old)
                    n2_new = original_coord_to_new_coord.get(n2_old)
                    if n1_new and n2_new:
                        new_edge_coords = self.grid._ordered_edge(n1_new, n2_new)
                        edges_to_add[new_edge_coords] = original_state
                        logger.debug(f"{log_prefix}    Mapped internal edge {old_edge_coords} -> {new_edge_coords} with state {original_state}")
                    else:
                        logger.warning(f"{log_prefix}    Could not map internal edge {old_edge_coords} during flip.")

                removed_count = 0
                for edge_coords in edges_to_remove:
                    try: idx1 = _ravel_multi_index(np.array(edge_coords[0]), self.grid.dimensions); idx2 = _ravel_multi_index(np.array(edge_coords[1]), self.grid.dimensions); self.grid.remove_edge(idx1, idx2); removed_count += 1
                    except Exception as rem_err: logger.warning(f"    Error removing edge {edge_coords}: {rem_err}")
                logger.debug(f"{log_prefix}Removed {removed_count} old edges connected to selection.")

                added_count = 0
                for new_edge_coords, state in edges_to_add.items():
                    try: idx1 = _ravel_multi_index(np.array(new_edge_coords[0]), self.grid.dimensions); idx2 = _ravel_multi_index(np.array(new_edge_coords[1]), self.grid.dimensions); self.grid.add_edge(idx1, idx2, edge_state=state); added_count += 1
                    except Exception as add_err: logger.warning(f"    Error adding edge {new_edge_coords}: {add_err}")
                logger.debug(f"{log_prefix}Added {added_count} new internal edges.")
            else:
                logger.info(f"{log_prefix}Skipping edge updates (rule doesn't support edges). Removing internal edges.")
                edges_to_remove = set()
                for edge_coords in list(self.grid.edges):
                    if edge_coords[0] in selected_coords_abs_set and edge_coords[1] in selected_coords_abs_set: edges_to_remove.add(edge_coords)
                removed_count = 0
                if edges_to_remove:
                    logger.debug(f"{log_prefix}  Removing {len(edges_to_remove)} edges within selection area as rule doesn't support edges.")
                    for edge_coords in edges_to_remove:
                        try: idx1 = _ravel_multi_index(np.array(edge_coords[0]), self.grid.dimensions); idx2 = _ravel_multi_index(np.array(edge_coords[1]), self.grid.dimensions); self.grid.remove_edge(idx1, idx2); removed_count += 1
                        except Exception as rem_err: logger.warning(f"    Error removing edge {edge_coords}: {rem_err}")
                    logger.debug(f"{log_prefix}  Removed {removed_count} edges.")

            # 5. Update Selection
            self.current_selection['nodes'] = new_selection_coords
            self.current_selection['edges'] = set(edges_to_add.keys())
            logger.debug(f"{log_prefix}Updated current selection.")

            # 6. Final Updates
            self.grid.update_active_nodes()
            self.grid.populate_spatial_hash()
            flip_successful = True
            self._update_editor_buttons_if_open()
            logger.info(f"{log_prefix}Selection flipped horizontally successfully.")

        except Exception as e:
            logger.error(f"{log_prefix}Error flipping selection: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Flip Error", f"Failed to flip selection: {e}", parent=self.root)
            self._undo_grid_action() # Attempt undo
        finally:
            if flip_successful:
                # --- ADDED: Clear queues before redraw ---
                self._clear_computation_and_render_queues()
                # ---
                self._safe_plot_update(force=True)
            if was_running: self._resume_computation(reason="Flip Selection Horizontal Complete")

    def _flip_selection_vertical(self):
        """Flips the selected nodes vertically around their centroid, preserving internal edges.
           Clears queues on success.
           (Round 15 Fix: Explicitly cast edge coord tuples for dict keys)
           (Round 11: Clear queues after successful flip)"""
        log_prefix = "_flip_selection_vertical (R15 Cast Fix, R11 Queue Clear): " # Updated round
        logger.info(f"{log_prefix}Attempting vertical flip.")
        if not self.current_selection or not self.current_selection.get('nodes'):
            messagebox.showwarning("No Selection", "Lasso select some nodes first.", parent=self.root)
            return
        if self.grid is None or self.controller is None or self.controller.rule is None:
            logger.error(f"{log_prefix}Grid, Controller, or Rule is None.")
            return

        selected_coords_abs_set = self.current_selection['nodes']
        if len(selected_coords_abs_set) < 1: return

        was_running = self.running
        self._pause_computation(reason="Flip Selection Vertical")
        flip_successful = False

        try:
            self._push_grid_state_to_undo("Flip Selection Vertical")
            selected_coords_list = list(selected_coords_abs_set)
            dims = len(selected_coords_list[0])
            if dims != 2:
                messagebox.showwarning("Not Supported", "Flip is currently only supported for 2D grids.", parent=self.root)
                if self._grid_undo_stack and self._grid_undo_stack[-1].get('action') == "Flip Selection Vertical": self._grid_undo_stack.pop()
                return

            # 1. Calculate Centroid
            avg_r = np.mean([coord[0] for coord in selected_coords_list])
            avg_c = np.mean([coord[1] for coord in selected_coords_list])
            centroid = (avg_r, avg_c)
            logger.debug(f"{log_prefix}Calculated centroid: {centroid}")

            # 2. Calculate New Coordinates and Store Original States/Edges
            original_states = {}
            # --- MODIFIED: Corrected Type Hint to Tuple[int, int] ---
            original_coord_to_new_coord: Dict[Tuple[int, int], Tuple[int, int]] = {}
            internal_edges_original: Dict[Tuple[Tuple[int, int], Tuple[int, int]], float] = {} # Store original internal edges and states
            # --- END MODIFIED ---
            new_selection_coords = set()
            all_new_coords_valid = True

            # --- Capture original states and calculate new coords ---
            for r_old, c_old in selected_coords_list:
                original_states[(r_old, c_old)] = self.grid.grid_array[r_old, c_old]
                rel_r = r_old - centroid[0]; rel_c = c_old - centroid[1]
                new_rel_r = -rel_r; new_rel_c = rel_c # Flip vertical
                r_new = int(round(centroid[0] + new_rel_r)); c_new = int(round(centroid[1] + new_rel_c))
                new_coord = (r_new, c_new)

                if not self.grid.is_valid_coord(new_coord):
                    logger.warning(f"{log_prefix}Flipped coordinate {new_coord} for original { (r_old, c_old)} is out of bounds. Aborting flip.")
                    messagebox.showerror("Flip Error", "Flipped shape would go out of grid bounds.", parent=self.root)
                    all_new_coords_valid = False; break
                original_coord_to_new_coord[(r_old, c_old)] = new_coord
                new_selection_coords.add(new_coord)

            if not all_new_coords_valid:
                if self._grid_undo_stack and self._grid_undo_stack[-1].get('action') == "Flip Selection Vertical": self._grid_undo_stack.pop()
                return

            logger.debug(f"{log_prefix}Calculated new absolute coordinates: {new_selection_coords}")

            # --- Capture internal edges BEFORE modifying grid ---
            rule_supports_edges = self.controller.rule.get_param('edge_initialization', 'RANDOM') != 'NONE'
            if rule_supports_edges:
                logger.debug(f"{log_prefix}Capturing internal edges...")
                for edge_coords_generic in list(self.grid.edges): # Iterate copy
                    n1_old_generic, n2_old_generic = edge_coords_generic
                    # --- MODIFIED: Check and Cast ---
                    if isinstance(n1_old_generic, tuple) and len(n1_old_generic) == 2 and isinstance(n2_old_generic, tuple) and len(n2_old_generic) == 2:
                        # Cast to specific 2D tuple type
                        n1_old = cast(Tuple[int, int], n1_old_generic)
                        n2_old = cast(Tuple[int, int], n2_old_generic)
                        edge_coords = cast(Tuple[Tuple[int, int], Tuple[int, int]], edge_coords_generic)

                        if n1_old in selected_coords_abs_set and n2_old in selected_coords_abs_set:
                            internal_edges_original[edge_coords] = self.grid.edge_states.get(edge_coords_generic, 1.0) # Use original generic key for get
                    # --- END MODIFIED ---
                logger.debug(f"{log_prefix}Captured {len(internal_edges_original)} internal edges.")
            # ---

            # [ Steps 3-6 remain unchanged ]
            # 3. Update Grid State
            logger.debug(f"{log_prefix}Updating grid state...")
            nodes_to_clear = selected_coords_abs_set - new_selection_coords
            for old_coord in nodes_to_clear:
                 self.grid.set_node_state(_ravel_multi_index(np.array(old_coord), self.grid.dimensions), 0.0)
            for old_coord, new_coord in original_coord_to_new_coord.items():
                self.grid.set_node_state(_ravel_multi_index(np.array(new_coord), self.grid.dimensions), original_states[old_coord])
            logger.debug(f"{log_prefix}Node states updated.")

            # 4. Update Edges (Conditional)
            edges_to_add = {}
            if rule_supports_edges:
                logger.debug(f"{log_prefix}Updating edges...")
                edges_to_remove = set()
                for edge_coords in list(self.grid.edges):
                    n1_old, n2_old = edge_coords
                    if n1_old in selected_coords_abs_set or n2_old in selected_coords_abs_set:
                        edges_to_remove.add(edge_coords)
                logger.debug(f"{log_prefix}Identified {len(edges_to_remove)} edges connected to original selection for removal.")

                for old_edge_coords, original_state in internal_edges_original.items():
                    n1_old, n2_old = old_edge_coords
                    n1_new = original_coord_to_new_coord.get(n1_old)
                    n2_new = original_coord_to_new_coord.get(n2_old)
                    if n1_new and n2_new:
                        new_edge_coords = self.grid._ordered_edge(n1_new, n2_new)
                        edges_to_add[new_edge_coords] = original_state
                        logger.debug(f"{log_prefix}    Mapped internal edge {old_edge_coords} -> {new_edge_coords} with state {original_state}")
                    else: logger.warning(f"Could not map edge {old_edge_coords} during flip.")

                removed_count = 0
                for edge_coords in edges_to_remove:
                    try: idx1 = _ravel_multi_index(np.array(edge_coords[0]), self.grid.dimensions); idx2 = _ravel_multi_index(np.array(edge_coords[1]), self.grid.dimensions); self.grid.remove_edge(idx1, idx2); removed_count += 1
                    except Exception as rem_err: logger.warning(f"Error removing edge {edge_coords}: {rem_err}")
                logger.debug(f"Removed {removed_count} old internal edges.")

                added_count = 0
                for new_edge_coords, state in edges_to_add.items():
                    try: idx1 = _ravel_multi_index(np.array(new_edge_coords[0]), self.grid.dimensions); idx2 = _ravel_multi_index(np.array(new_edge_coords[1]), self.grid.dimensions); self.grid.add_edge(idx1, idx2, edge_state=state); added_count += 1
                    except Exception as add_err: logger.warning(f"Error adding edge {new_edge_coords}: {add_err}")
                logger.debug(f"Added {added_count} new internal edges.")
            else:
                logger.info(f"{log_prefix}Skipping edge updates (rule doesn't support edges). Removing internal edges.")
                edges_to_remove = set()
                for edge_coords in list(self.grid.edges):
                    if edge_coords[0] in selected_coords_abs_set and edge_coords[1] in selected_coords_abs_set: edges_to_remove.add(edge_coords)
                removed_count = 0
                if edges_to_remove:
                    logger.debug(f"{log_prefix}  Removing {len(edges_to_remove)} edges within selection area as rule doesn't support edges.")
                    for edge_coords in edges_to_remove:
                        try: idx1 = _ravel_multi_index(np.array(edge_coords[0]), self.grid.dimensions); idx2 = _ravel_multi_index(np.array(edge_coords[1]), self.grid.dimensions); self.grid.remove_edge(idx1, idx2); removed_count += 1
                        except Exception as rem_err: logger.warning(f"    Error removing edge {edge_coords}: {rem_err}")
                    logger.debug(f"{log_prefix}  Removed {removed_count} edges.")

            # 5. Update Selection
            self.current_selection['nodes'] = new_selection_coords
            self.current_selection['edges'] = set(edges_to_add.keys())
            logger.debug(f"{log_prefix}Updated current selection.")

            # 6. Final Updates
            self.grid.update_active_nodes()
            self.grid.populate_spatial_hash()
            flip_successful = True
            self._update_editor_buttons_if_open()
            logger.info(f"{log_prefix}Selection flipped vertically successfully.")

        except Exception as e:
            logger.error(f"{log_prefix}Error flipping selection: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Flip Error", f"Failed to flip selection: {e}", parent=self.root)
            self._undo_grid_action() # Attempt undo
        finally:
            if flip_successful:
                # --- ADDED: Clear queues before redraw ---
                self._clear_computation_and_render_queues()
                # ---
                self._safe_plot_update(force=True)
            if was_running: self._resume_computation(reason="Flip Selection Vertical Complete")

    def _save_selection_as_new_shape(self):
        """Saves the currently selected nodes/edges on the main grid as a new shape definition.
           (Round 17 Fix: Use SaveShapeDialog modal, pass rule name)"""
        log_prefix = "_save_selection_as_new_shape (R17 Modal Fix): " # Updated round
        logger.info(f"{log_prefix}Attempting to save grid selection as new shape.")
        if self.grid is None:
            messagebox.showerror("Error", "Grid is not initialized.", parent=self.root)
            return

        # Get current selection from the main GUI
        selection = self.current_selection
        selected_node_coords_abs = selection.get('nodes')

        if not selected_node_coords_abs:
            messagebox.showwarning("Empty Selection", "No nodes selected on the grid to save.", parent=self.root)
            return

        try:
            # [ Calculate Relative Coords and Origin Offset - Unchanged ]
            active_coords_abs = list(selected_node_coords_abs) # Convert set to list
            if not active_coords_abs: return # Should not happen based on check above, but safe

            dims = len(active_coords_abs[0])
            min_coords = list(active_coords_abs[0])
            for coord in active_coords_abs[1:]:
                for d in range(dims):
                    min_coords[d] = min(min_coords[d], coord[d])
            origin_offset = tuple(min_coords)

            relative_coords = [tuple(c - mc for c, mc in zip(abs_coord, origin_offset)) for abs_coord in active_coords_abs]
            abs_to_rel_map = dict(zip(active_coords_abs, relative_coords))
            # ---

            # [ Capture Node States - Unchanged ]
            node_states_rel: Dict[Tuple[int, ...], float] = {}
            for abs_coord in active_coords_abs:
                rel_coord = abs_to_rel_map.get(abs_coord)
                if rel_coord is not None:
                    try:
                        node_states_rel[rel_coord] = float(self.grid.grid_array[abs_coord])
                    except IndexError: logger.warning(f"{log_prefix}IndexError getting state for {abs_coord} while saving selection.")
                    except Exception as e: logger.error(f"{log_prefix}Error getting state for {abs_coord}: {e}")
            # ---

            # [ Capture Edges and Edge States within the selection - Unchanged ]
            relative_edges_list: List[Tuple[Tuple[int, ...], Tuple[int, ...]]] = []
            edge_states_rel: Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float] = {}
            active_coords_abs_set = set(active_coords_abs) # Use set for faster lookup

            for edge_abs, state in self.grid.edge_states.items():
                node1_abs, node2_abs = edge_abs
                if node1_abs in active_coords_abs_set and node2_abs in active_coords_abs_set:
                    rel_node1 = abs_to_rel_map.get(node1_abs)
                    rel_node2 = abs_to_rel_map.get(node2_abs)
                    if rel_node1 is not None and rel_node2 is not None:
                        ordered_rel_edge_tuple = (rel_node1, rel_node2) if rel_node1 < rel_node2 else (rel_node2, rel_node1)
                        if ordered_rel_edge_tuple not in edge_states_rel:
                            relative_edges_list.append(ordered_rel_edge_tuple)
                            edge_states_rel[ordered_rel_edge_tuple] = float(state)
            # ---

            # --- MODIFIED: Prompt using SaveShapeDialog, pass rule name ---
            shape_manager = ShapeLibraryManager.get_instance()
            existing_names = shape_manager.get_shape_names()
            current_rule_name = self.controller.rule.name if self.controller and self.controller.rule else None
            dialog = SaveShapeDialog(self.root, shape_manager, initial_name="New Shape from Selection", existing_names=existing_names, current_rule_name=current_rule_name)
            dialog_result = dialog.result

            if dialog_result is None: # User cancelled
                logger.info(f"{log_prefix}User cancelled saving shape.")
                return

            shape_name = dialog_result["name"]
            category = dialog_result["category"]
            description = dialog_result["description"]
            tags = dialog_result["tags"]
            connectivity = "explicit" if relative_edges_list else "none"
            # --- END MODIFIED ---

            # [ Create ShapeDefinition - Unchanged ]
            shape_def = ShapeDefinition(
                name=shape_name,
                category=category,
                description=description,
                relative_coords=relative_coords,
                connectivity=connectivity,
                tags=tags,
                author="User",
                relative_edges=relative_edges_list if relative_edges_list else None,
                node_states=node_states_rel if node_states_rel else None,
                edge_states=edge_states_rel if edge_states_rel else None,
                intended_rule=self.controller.rule.name if self.controller and self.controller.rule else None
                # 'rules' field will be empty by default, user can edit later
            )
            # ---

            # [ Save using Manager - Unchanged ]
            if shape_manager.add_shape(shape_def):
                messagebox.showinfo("Success", f"Shape '{shape_name}' saved successfully to library.", parent=self.root)
                if hasattr(self, 'shape_editor_window') and self.shape_editor_window and self.shape_editor_window.winfo_exists():
                    self.shape_editor_window._populate_treeview() # Refresh editor list
                    self.shape_editor_window._select_shape_in_tree(shape_name) # Select the newly saved shape
                self._safe_plot_update() # Update main visualization
            else:
                 messagebox.showerror("Error", f"Failed to save shape '{shape_name}'.", parent=self.root)
            # ---

        except Exception as e:
            logger.error(f"{log_prefix}Error saving selection as shape: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Error", f"Failed to save selection: {e}", parent=self.root)

    def _save_selection_as_new_preset(self):
        """Saves the currently selected nodes/edges as a new GridPreset."""
        log_prefix = "_save_selection_as_new_preset: "
        logger.info(f"{log_prefix}Attempting to save selection as new preset.")

        if not self.current_selection or not self.current_selection.get('nodes'):
            messagebox.showwarning("Nothing Selected", "Select nodes using Lasso first.", parent=self.root)
            logger.warning(f"{log_prefix}No selection found.")
            return
        if self.grid is None or self.controller is None or self.controller.rule is None:
            logger.error(f"{log_prefix}Grid, Controller, or Rule is None.")
            return

        selected_node_coords_abs_set = self.current_selection['nodes']

        try:
            # 1. Calculate Bounding Box and Relative Data
            active_coords_abs = list(selected_node_coords_abs_set)
            if not active_coords_abs: return

            dims = len(active_coords_abs[0])
            min_coords = list(active_coords_abs[0])
            max_coords = list(active_coords_abs[0])
            for coord in active_coords_abs[1:]:
                for d in range(dims):
                    min_coords[d] = min(min_coords[d], coord[d])
                    max_coords[d] = max(max_coords[d], coord[d])
            origin_offset = tuple(min_coords)
            preset_dimensions = tuple(mx - mn + 1 for mn, mx in zip(max_coords, min_coords))

            relative_coords = [tuple(c - mc for c, mc in zip(abs_coord, origin_offset)) for abs_coord in active_coords_abs]
            abs_to_rel_map = dict(zip(active_coords_abs, relative_coords))

            # Create sparse state dictionary relative to the new preset dimensions
            preset_initial_state_sparse: Dict[Tuple[int, ...], float] = {}
            for abs_coord in active_coords_abs:
                rel_coord = abs_to_rel_map.get(abs_coord)
                if rel_coord is not None:
                    try:
                        state_val = float(self.grid.grid_array[abs_coord])
                        if abs(state_val) > 1e-6: # Only store non-zero states
                            preset_initial_state_sparse[rel_coord] = state_val
                    except IndexError: logger.warning(f"{log_prefix}IndexError getting state for {abs_coord}.")
                    except Exception as e: logger.error(f"{log_prefix}Error getting state for {abs_coord}: {e}")

            # Capture Edges and Edge States internal to the selection, make relative
            preset_relative_edges_list: List[Tuple[Tuple[int, ...], Tuple[int, ...]]] = []
            preset_edge_states_rel: Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float] = {}
            for edge_abs, state in self.grid.edge_states.items():
                node1_abs, node2_abs = edge_abs
                if node1_abs in selected_node_coords_abs_set and node2_abs in selected_node_coords_abs_set:
                    rel_node1 = abs_to_rel_map.get(node1_abs)
                    rel_node2 = abs_to_rel_map.get(node2_abs)
                    if rel_node1 is not None and rel_node2 is not None:
                        ordered_rel_edge_tuple = (rel_node1, rel_node2) if rel_node1 < rel_node2 else (rel_node2, rel_node1)
                        if ordered_rel_edge_tuple not in preset_edge_states_rel:
                            preset_relative_edges_list.append(ordered_rel_edge_tuple)
                            preset_edge_states_rel[ordered_rel_edge_tuple] = float(state)

            # 2. Prompt for Preset Name
            preset_name = simpledialog.askstring("Save Selection as Preset", "Enter New Preset Name:", parent=self.root)
            if not preset_name: return

            preset_manager = GridPresetManager.get_instance(self.app_paths)
            if preset_name in preset_manager.presets:
                if not messagebox.askyesno("Confirm Overwrite", f"Preset '{preset_name}' already exists. Overwrite?", icon='warning', parent=self.root):
                    return

            # 3. Create GridPreset object
            # Calculate densities based on the *selection*
            selected_node_count = len(selected_node_coords_abs_set)
            preset_total_nodes = np.prod(preset_dimensions)
            node_density_sel = selected_node_count / preset_total_nodes if preset_total_nodes > 0 else 0.0
            # Edge density calculation for presets is less critical, use placeholder or simple ratio
            edge_density_sel = len(preset_relative_edges_list) / (selected_node_count * (selected_node_count-1)/2) if selected_node_count > 1 else 0.0

            new_preset = GridPreset(
                name=preset_name,
                dimensions=preset_dimensions, # Use calculated dimensions of the pattern
                neighborhood_type=self.grid.neighborhood_type.name, # Use current grid's neighborhood
                rule_name=self.controller.rule.name, # Use current rule
                initialization_mode="SAVED_STATE",
                initialization_data=None,
                # Pass the sparse dictionary directly to the InitVar
                initial_state_sparse={str(list(k)): v for k, v in preset_initial_state_sparse.items()},
                initial_state=None, # Set dense state to None when using sparse
                edges=preset_relative_edges_list,
                edge_states=preset_edge_states_rel,
                description=f"Saved selection from '{self.controller.rule.name}' at generation {self.generation}.",
                node_density=float(node_density_sel), # Store calculated density
                edge_density=edge_density_sel # Store calculated density
            )

            # 4. Save using Manager
            preset_manager.save_preset(new_preset)

            # 5. Update GUI
            self._update_grid_preset_selector()
            # Optionally select the new preset?
            # self._set_active_preset(preset_name)

            messagebox.showinfo("Success", f"Preset '{preset_name}' saved successfully from selection.", parent=self.root)

        except Exception as e:
            logger.error(f"{log_prefix}Error saving selection as preset: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Error", f"Failed to save selection as preset: {e}", parent=self.root)

    def _save_grid_as_new_preset(self):
        """Saves the current grid state as a new preset, marked as a 'Pattern'."""
        logger.info("Attempting to save grid as new preset.")
        if self.grid is None or self.rule is None:
            messagebox.showerror("Error", "Grid or Rule not initialized.", parent=self.root)
            return

        preset_name = simpledialog.askstring("Save New Preset", "Enter New Preset Name:", parent=self.root)
        if not preset_name: return

        # --- MODIFIED: Access preset_manager via self.grid_preset_manager ---
        if preset_name in self.grid_preset_manager.presets:
            if not messagebox.askyesno("Confirm Overwrite", f"Preset '{preset_name}' already exists. Overwrite?", icon='warning', parent=self.root):
                return
        # --- END MODIFIED ---

        try:
            # Calculate current densities (still useful for info, though not for loading)
            total_nodes = self.grid.total_nodes
            active_nodes = len(self.grid.active_nodes)
            node_density = active_nodes / total_nodes if total_nodes > 0 else 0.0
            max_possible_edges = active_nodes * self.grid.max_neighbors / 2 if active_nodes > 1 else 0
            edge_density = len(self.grid.edges) / max_possible_edges if max_possible_edges > 0 else 0.0

            # Create GridPreset object
            new_preset = GridPreset(
                name=preset_name,
                dimensions=self.grid.dimensions,
                neighborhood_type=self.grid.neighborhood_type.name,
                initial_state=self.grid.grid_array.copy(), # Save exact state
                edges=list(self.grid.edges), # Save exact edges
                edge_states=self.grid.edge_states.copy(), # Save exact edge states
                description=f"Saved state of '{self.rule.name}' at generation {self.generation}.",
                rule_name=self.rule.name,
                initial_conditions="Pattern", # Mark as pattern
                node_density=node_density, # Store for info
                edge_density=edge_density # Store for info
            )

            # --- MODIFIED: Access preset_manager via self.grid_preset_manager ---
            self.grid_preset_manager.save_preset(new_preset)
            # --- END MODIFIED ---

            # Update GUI
            self._update_grid_preset_selector()
            self._set_active_preset(preset_name) # Make the new preset active

            messagebox.showinfo("Success", f"Preset '{preset_name}' saved successfully as Pattern.", parent=self.root)

        except Exception as e:
            logger.error(f"Error saving new preset: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Error", f"Failed to save new preset: {e}", parent=self.root)

    def _update_current_preset(self):
        """Overwrites the active preset with the current grid state."""
        logger.info("Attempting to update current preset.")
        if not self.active_preset_name or self.active_preset_name == "None":
            messagebox.showerror("Error", "No preset is currently active to update.", parent=self.root)
            return
        if self.grid is None or self.rule is None:
            messagebox.showerror("Error", "Grid or Rule not initialized.", parent=self.root)
            return

        if not messagebox.askyesno("Confirm Update", f"Overwrite the active preset '{self.active_preset_name}' with the current grid state?", icon='warning', parent=self.root):
            return

        try:
            # Calculate current densities
            total_nodes = self.grid.total_nodes
            active_nodes = len(self.grid.active_nodes)
            node_density = active_nodes / total_nodes if total_nodes > 0 else 0.0
            max_possible_edges = active_nodes * self.grid.max_neighbors / 2 if active_nodes > 1 else 0
            edge_density = len(self.grid.edges) / max_possible_edges if max_possible_edges > 0 else 0.0

            # Create GridPreset object with the *original* name
            updated_preset = GridPreset(
                name=self.active_preset_name, # Keep original name
                dimensions=self.grid.dimensions,
                neighborhood_type=self.grid.neighborhood_type.name,
                initial_state=self.grid.grid_array.copy(),
                edges=list(self.grid.edges),
                edge_states=self.grid.edge_states.copy(),
                description=f"Updated state of '{self.rule.name}' at generation {self.generation}.", # Update description
                rule_name=self.rule.name,
                initial_conditions="Pattern", # Mark as pattern
                node_density=node_density,
                edge_density=edge_density
            )

            # Save using manager (will overwrite)
            self.grid_preset_manager.save_preset(updated_preset)

            # No need to update selector, name hasn't changed

            messagebox.showinfo("Success", f"Preset '{self.active_preset_name}' updated successfully.", parent=self.root)

        except Exception as e:
            logger.error(f"Error updating preset '{self.active_preset_name}': {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Error", f"Failed to update preset: {e}", parent=self.root)

    def _on_tk_right_click(self, event):
        """Tkinter event handler to capture screen coordinates AND display the menu."""
        log_prefix = "_on_tk_right_click (R16 Stop Logic): " # Updated round
        logger.debug(f"{log_prefix}START")

        # --- ADDED: Check and transition to STOPPED state ---
        if self.paused or self._stopped: # Check GUI state
            logger.info(f"{log_prefix}Interaction while paused/stopped. Transitioning to STOPPED state.")
            self.running = False
            self.paused = False
            self._stopped = True

            # --- Clear queue IMMEDIATELY ---
            if hasattr(self, 'communication_queue'):
                while not self.communication_queue.empty():
                    try: self.communication_queue.get_nowait()
                    except queue.Empty: break
                logger.debug(f"{log_prefix}Cleared queue due to interaction while paused/stopped.")
            # ---

            # Attempt to stop threads cleanly (might be redundant but safe)
            if not self._stop_computation_threads(reason="Right-Click during Pause/Stop"): # Call GUI method
                logger.warning(f"{log_prefix}Could not cleanly stop threads during interaction.")

            # Update button states
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                self.control_panel_ui.update_button_states()
        # --- END ADDED ---

        # Store the absolute screen coordinates
        screen_x = event.x_root
        screen_y = event.y_root
        logger.debug(f"{log_prefix}Tkinter right-click captured screen coordinates: ({screen_x}, {screen_y})")

        try:
            self._display_right_click_menu(screen_x, screen_y)
            logger.debug(f"{log_prefix}Called _display_right_click_menu.")
        except Exception as e:
            logger.error(f"{log_prefix}Error occurred calling _display_right_click_menu: {e}")
            logger.error(traceback.format_exc())
        # Return break to prevent default Tkinter right-click behavior
        return "break"

    def _on_mpl_button_press(self, event):
        """Handle Matplotlib button press events (Now only for potential future use, not right-click menu)."""
        # Ignore clicks outside axes
        if event.inaxes != self.ax:
            # logger.debug("_on_mpl_button_press: Click outside axes.") # Reduce noise
            return

        logger.debug(f"Matplotlib button press detected: Button={event.button}, CanvasXY=({event.x}, {event.y}), DataXY=({event.xdata:.2f}, {event.ydata:.2f})")

    def _pop_undo_if_match(self, action_name: str):
        """Pops the last item from the undo stack if its action matches."""
        if self._grid_undo_stack and self._grid_undo_stack[-1].get('action') == action_name:
            try:
                self._grid_undo_stack.pop()
                logger.debug(f"Popped '{action_name}' action from undo stack due to error.")
            except IndexError:
                logger.warning("Undo stack was empty when trying to pop.")

    def _open_shape_editor_and_edit_hotmenu(self):
        """Opens the editor (if not open) and triggers the edit hotmenu modal."""
        self._open_shape_editor_window()
        if hasattr(self, 'shape_editor_window') and self.shape_editor_window and self.shape_editor_window.winfo_exists():
            self.shape_editor_window._open_edit_hotmenu_modal()

    def _display_right_click_menu(self, screen_x: int, screen_y: int):
        """Creates and displays the right-click context menu with direct actions.
           Pauses simulation for grid-modifying actions.
           (Round 20: Add Help menu item)
           (Round 10: Pause simulation for grid-modifying actions)"""
        log_prefix = "_display_right_click_menu (R20 Help Menu, R10 Pause): " # Updated round
        logger.debug(f"{log_prefix}Creating menu at screen ({screen_x}, {screen_y})")

        # --- Context Coordinate Conversion ---
        clicked_grid_coords = (0,0) # Default origin if conversion fails
        try:
            if not (hasattr(self, 'canvas') and self.canvas and self.canvas.get_tk_widget().winfo_exists()): raise RuntimeError("Canvas invalid")
            canvas_widget = self.canvas.get_tk_widget()
            canvas_x = screen_x - canvas_widget.winfo_rootx()
            canvas_y = screen_y - canvas_widget.winfo_rooty()
            inv = self.ax.transData.inverted()
            data_coords = inv.transform((canvas_x, canvas_y))
            x_data, y_data = data_coords[0], data_coords[1]
            grid_coords_float = self.coord_system.display_to_grid((x_data, y_data))
            if grid_coords_float is not None:
                clicked_grid_coords = tuple(int(np.floor(c)) for c in grid_coords_float)
            else: logger.warning(f"{log_prefix}Could not convert display coords to grid coords.")
            logger.debug(f"{log_prefix}Clicked grid coordinate (potential top-left): {clicked_grid_coords}")
        except Exception as e:
            logger.error(f"{log_prefix}Error converting screen coords for context menu: {e}")
            logger.error(traceback.format_exc())
        # ---

        popup_menu = None
        try:
            popup_menu = tk.Menu(self.root, tearoff=0)

            # --- Grid Actions Menu (No Pause Needed Here) ---
            grid_actions_menu = tk.Menu(popup_menu, tearoff=0)
            popup_menu.add_cascade(label="Grid Actions", menu=grid_actions_menu)
            grid_actions_menu.add_command(label="Clear Grid", command=self.clear_grid)
            grid_actions_menu.add_command(label="Reset Grid", command=self.reset_simulation)
            grid_actions_menu.add_command(label="Randomize Grid", command=self.randomize_grid)
            grid_actions_menu.add_separator()
            can_undo = bool(self._grid_undo_stack)
            can_redo = bool(self._grid_redo_stack)
            grid_actions_menu.add_command(label="Undo Grid Action", command=self._undo_grid_action, state=tk.NORMAL if can_undo else tk.DISABLED)
            grid_actions_menu.add_command(label="Redo Grid Action", command=self._redo_grid_action, state=tk.NORMAL if can_redo else tk.DISABLED)

            # --- Selection Actions Menu ---
            selection_actions_menu = tk.Menu(popup_menu, tearoff=0)
            popup_menu.add_cascade(label="Selection Actions", menu=selection_actions_menu)
            selection_active = bool(self.current_selection.get('nodes'))
            rule_supports_edges = False
            if self.controller and self.controller.rule:
                edge_init_type = self.controller.rule.get_param('edge_initialization', 'RANDOM')
                rule_supports_edges = edge_init_type != 'NONE'

            lasso_label = " Select with Lasso" if self.active_tool == 'lasso' else "Select with Lasso"
            selection_actions_menu.add_command(label=lasso_label, command=lambda: self.set_active_tool("lasso")) # No pause
            selection_actions_menu.add_command(label="Select All", command=self._select_all_nodes) # No pause
            selection_actions_menu.add_command(label="Deselect All", command=self._clear_lasso_selection, state=tk.NORMAL if selection_active else tk.DISABLED) # No pause
            selection_actions_menu.add_separator()
            copy_state = tk.NORMAL if selection_active else tk.DISABLED
            cut_state = tk.NORMAL if selection_active else tk.DISABLED
            paste_state = tk.NORMAL if hasattr(self, '_clipboard') and self._clipboard else tk.DISABLED
            selection_actions_menu.add_command(label="Copy Selection", command=self._copy_selection, state=copy_state) # No pause
            # --- MODIFIED: Add pause to Cut ---
            selection_actions_menu.add_command(label="Cut Selection", command=lambda: (self._request_pause_for_interaction("Cut Selection"), self._cut_selection()), state=cut_state)
            # ---
            # --- MODIFIED: Add pause to Paste ---
            selection_actions_menu.add_command(label="Paste Selection Here", command=lambda oc=clicked_grid_coords: (self._request_pause_for_interaction("Paste Selection"), self._paste_selection(oc)), state=paste_state)
            # ---
            selection_actions_menu.add_separator()

            transform_state = tk.NORMAL if selection_active and self.dimension_type == Dimension.TWO_D else tk.DISABLED
            # --- MODIFIED: Add pause to transformations ---
            selection_actions_menu.add_command(label="Rotate Selection 90", command=lambda: (self._request_pause_for_interaction("Rotate Selection"), self._rotate_selection_90()), state=transform_state)
            selection_actions_menu.add_command(label="Flip Selection Horizontally", command=lambda: (self._request_pause_for_interaction("Flip Horizontal"), self._flip_selection_horizontal()), state=transform_state)
            selection_actions_menu.add_command(label="Flip Selection Vertically", command=lambda: (self._request_pause_for_interaction("Flip Vertical"), self._flip_selection_vertical()), state=transform_state)
            # ---
            selection_actions_menu.add_separator()
            # --- MODIFIED: Add pause to edge/node edits ---
            add_edges_state = tk.NORMAL if selection_active and rule_supports_edges and self.view_manager else tk.DISABLED
            selection_actions_menu.add_command(
                label="Add Edges Within Selection",
                command=lambda: (self._request_pause_for_interaction("Add Edges"), self.view_manager._add_edges_within_selection()) if self.view_manager else None,
                state=add_edges_state
            )
            erase_nodes_state = tk.NORMAL if selection_active and self.view_manager else tk.DISABLED
            selection_actions_menu.add_command(
                label="Erase Nodes Within Selection",
                command=lambda: (self._request_pause_for_interaction("Erase Nodes"), self.view_manager._erase_selected_nodes()) if self.view_manager else None,
                state=erase_nodes_state
            )
            delete_edges_state = tk.NORMAL if selection_active and rule_supports_edges and self.view_manager else tk.DISABLED
            selection_actions_menu.add_command(
                label="Delete Edges Within Selection",
                command=lambda: (self._request_pause_for_interaction("Delete Edges"), self.view_manager._delete_edges_within_selection()) if self.view_manager else None,
                state=delete_edges_state
            )
            # ---
            selection_actions_menu.add_separator()
            # --- MODIFIED: Add pause to save actions ---
            selection_actions_menu.add_command(label="Save Selection as New Shape...", command=lambda: (self._request_pause_for_interaction("Save Selection as Shape"), self._save_selection_as_new_shape()), state=tk.NORMAL if selection_active else tk.DISABLED)
            selection_actions_menu.add_command(label="Save Selection as New Preset...", command=lambda: (self._request_pause_for_interaction("Save Selection as Preset"), self._save_selection_as_new_preset()), state=tk.NORMAL if selection_active else tk.DISABLED)
            # ---

            # --- Hotmenu Shape Placement ---
            hotmenu_placement_menu = tk.Menu(popup_menu, tearoff=0)
            popup_menu.add_cascade(label="Place Shape (Hotmenu)", menu=hotmenu_placement_menu)
            shape_manager = ShapeLibraryManager.get_instance()
            if hasattr(self, 'hotmenu_shape_names') and self.hotmenu_shape_names:
                sorted_hotmenu_names = sorted(self.hotmenu_shape_names)
                for shape_name in sorted_hotmenu_names:
                    shape_def = shape_manager.get_shape(shape_name)
                    if shape_def:
                        compatible_dims = False
                        if shape_def.get_dimensions() == len(self.dimensions): compatible_dims = True
                        elif len(self.dimensions) == 2 and shape_def.get_dimensions() == 3: compatible_dims = True

                        if compatible_dims:
                            min_rel, _ = shape_def.get_bounding_box()
                            origin_offset = tuple(min_rel)
                            origin_for_placement = tuple(c - o for c, o in zip(clicked_grid_coords, origin_offset))
                            # --- MODIFIED: Add pause to place actions ---
                            hotmenu_placement_menu.add_command(
                                label=f"Place '{shape_name}' Here",
                                command=lambda sd=shape_def, oc=origin_for_placement: (self._request_pause_for_interaction(f"Place Shape '{sd.name}'"), self._place_selected_shape(lambda origin: sd, oc))
                            )
                            place_with_edges_state = tk.NORMAL if rule_supports_edges else tk.DISABLED
                            hotmenu_placement_menu.add_command(
                                label=f"Place '{shape_name}' Here with Edges",
                                command=lambda sd=shape_def, oc=origin_for_placement: (self._request_pause_for_interaction(f"Place Shape '{sd.name}' w/ Edges"), self._place_selected_shape_with_edges(lambda origin: sd, oc)),
                                state=place_with_edges_state
                            )
                            # ---
            else:
                hotmenu_placement_menu.add_command(label="(No hotmenu shapes)", state=tk.DISABLED)
            hotmenu_placement_menu.add_separator()
            hotmenu_placement_menu.add_command(label="Edit Hotmenu...", command=self._open_shape_editor_and_edit_hotmenu) # No pause

            # --- Preset Actions Menu ---
            preset_actions_menu = tk.Menu(popup_menu, tearoff=0)
            popup_menu.add_cascade(label="Preset Actions", menu=preset_actions_menu)
            # --- MODIFIED: Add pause to save/update actions ---
            preset_actions_menu.add_command(label="Save Grid as New Preset...", command=lambda: (self._request_pause_for_interaction("Save Grid as Preset"), self._save_grid_as_new_preset()))
            update_preset_state = tk.NORMAL if (self.active_preset_name and self.active_preset_name != "None") else tk.DISABLED
            preset_actions_menu.add_command(label="Update Current Preset", command=lambda: (self._request_pause_for_interaction("Update Preset"), self._update_current_preset()), state=update_preset_state)
            # ---

            # --- Help Menu Item (No Pause Needed) ---
            popup_menu.add_separator()
            popup_menu.add_command(label="Mouse & Keyboard Help...", command=self._show_controls_help)
            # ---

            # --- Display the menu ---
            logger.debug("Attempting to display popup menu...")
            popup_menu.tk_popup(screen_x, screen_y)
            logger.debug("Popup menu displayed.")
        except Exception as menu_build_err:
             logger.error(f"Error building or displaying right-click menu: {menu_build_err}")
             logger.error(traceback.format_exc())
        finally:
            if popup_menu:
                try: popup_menu.grab_release()
                except tk.TclError: pass
                except Exception as grab_err: logger.error(f"Error releasing menu grab: {grab_err}")
            logger.debug(f"--- EXITING _display_right_click_menu ---")

    def _on_azimuth_change(self, value):
        """Handle azimuth angle change"""
        try:
            self._current_azim = float(value)
            if hasattr(self, 'ax') and isinstance(self.ax, Axes3DType): # type: ignore
                self.ax.view_init(elev=self._current_elev, azim=self._current_azim) # type: ignore
                # Trigger a full redraw (since we're changing the view)
                if self.grid_visualizer is not None:
                    self.grid_visualizer.update_visualization_state()
            logger.info(f"Azimuth changed to: {value}")
        except Exception as e:
            logger.error(f"Error changing azimuth: {e}")

    def _on_elevation_change(self, value):
        """Handle elevation angle change"""
        try:
            self._current_elev = float(value)
            if hasattr(self, 'ax') and isinstance(self.ax, Axes3DType): # type: ignore
                self.ax.view_init(elev=self._current_elev, azim=self._current_azim) # type: ignore
                # Trigger a full redraw (since we're changing the view)
                if self.grid_visualizer is not None:
                    self.grid_visualizer.update_visualization_state()
            logger.info(f"Elevation changed to: {value}")
        except Exception as e:
            logger.error(f"Error changing elevation: {e}")
         
    def _on_grid_color_change(self, value: str):
        """Handle grid line color change"""
        try:
            # Update grid lines color
            if hasattr(self, 'grid_visualizer') and self.grid_visualizer:
                if self.grid_visualizer and self.grid_visualizer.debugger:
                    self.grid_visualizer.debugger.show_grid_lines(color=value)
                logger.info(f"Grid line color changed to: {value}")
            else:
                logger.warning("grid_visualizer is not initialized")
        except Exception as e:
            logger.error(f"Error changing grid line color: {e}")

    def _on_show_coords_toggle(self):
        """Handle show node coordinates toggle"""
        try:
            # Toggle node coordinate display
            if hasattr(self, 'grid_visualizer') and self.grid_visualizer:
                if self.grid_visualizer and self.grid_visualizer.debugger:
                    self.grid_visualizer.debugger.show_node_coordinates(active_only=True)
                logger.info("Node coordinates toggled")
            else:
                logger.warning("grid_visualizer is not initialized")
        except Exception as e:
            logger.error(f"Error toggling node coordinates: {e}")
        
    def _toggle_debug_mode(self):
        """Toggle debug mode"""
        if hasattr(self, 'grid_visualizer') and self.grid_visualizer:
            self.grid_visualizer.toggle_debug_mode()
        else:
            logger.warning("grid_visualizer is not initialized")

    def _reset_view(self):
        """Reset the view to show the entire grid"""
        if hasattr(self, 'grid_visualizer') and self.grid_visualizer:
            self.grid_visualizer.reset_view()
        else:
            logger.warning("grid_visualizer is not initialized")

    def _reset_view_state(self):
        """Reset view-related state variables."""
        self._view_state = {
            'zoom_factor': 1.0,
            'center_grid': (self.dimensions[1] // 2, self.dimensions[0] // 2, self.dimensions[2] // 2 if self.dimension_type == Dimension.THREE_D and len(self.dimensions) > 2 else 0),
            'xlim': None, # Initialize to None
            'ylim': None, # Initialize to None
            'zlim': None  # Initialize to None
        }
                                                                                                            
    def _on_enable_rotation_change(self):
        """Handle enable rotation checkbox change"""
        self.rotation_enabled = self.rotation_enabled_var.get()
        logger.info(f"Rotation enabled: {self.rotation_enabled}")

    def _set_initial_checkbox_state(self):
        """Set the initial state of the run continuously checkbox after GUI is loaded.
           (Round 11: Add logging)"""
        log_prefix = "SimulationGUI._set_initial_checkbox_state: "
        logger.debug(f"{log_prefix}Entering.")
        # --- MODIFIED: Access run_continuously_check via ControlPanelUI ---
        if hasattr(self, 'control_panel_ui') and self.control_panel_ui and hasattr(self.control_panel_ui, 'widgets'):
            # --- ADDED: Log widget state before access ---
            logger.debug(f"{log_prefix}Accessing control_panel_ui.widgets (ID: {id(self.control_panel_ui.widgets)}). Keys: {list(self.control_panel_ui.widgets.keys())}")
            # ---
            run_continuously_check = self.control_panel_ui.widgets.get('run_continuously_check')
            if isinstance(run_continuously_check, tk.Checkbutton):
                if self.run_continuously.get():
                    run_continuously_check.select()
                else:
                    run_continuously_check.deselect()
                logger.debug(f"{log_prefix}Set run_continuously_check to {self.run_continuously.get()} after GUI load")
            else:
                logger.warning(f"{log_prefix}run_continuously_check widget not found or not Checkbutton in ControlPanelUI.")
        # ---
        else:
            logger.warning("ControlPanelUI or its widgets not found, cannot set initial checkbox state")
        logger.debug(f"{log_prefix}Exiting.")

    def _update_plot_limits(self):
        """Dynamically update plot limits based on grid dimensions and scale factor."""
        try:
            # Use the current scale_factor from the coordinate system
            if self.grid_visualizer is not None:
                scale_factor = self.grid_visualizer.coord_system.scale_factor
            else:
                scale_factor = 1.0  # Default scale factor if grid_visualizer is None

            # Calculate plot limits based on grid dimensions and scale factor
            if self.controller.dimension_type == Dimension.TWO_D:
                xlim = (-0.5 * scale_factor, (self.controller.dimensions[1] + 0.5) * scale_factor)
                ylim = (-0.5 * scale_factor, (self.controller.dimensions[0] + 0.5) * scale_factor)
                self.ax.set_xlim(xlim) # type: ignore
                self.ax.set_ylim(ylim) # type: ignore
            elif self.controller.dimension_type == Dimension.THREE_D:
                xlim = (-0.5 * scale_factor, (self.controller.dimensions[1] + 0.5) * scale_factor)
                ylim = (-0.5 * scale_factor, (self.controller.dimensions[0] + 0.5) * scale_factor)
                zlim = (-0.5 * scale_factor, (self.controller.dimensions[2] + 0.5) * scale_factor)
                self.ax.set_xlim(xlim)
                self.ax.set_ylim(ylim) # type: ignore
                self.ax.set_zlim(zlim)  # type: ignore

            logger.debug(f"Setting axes limits: xlim={xlim}, ylim={ylim}")

        except Exception as e:
            logger.error(f"Error updating plot limits: {e}")
            raise

    def create_rule_editor_window(self, rule_name: str, selected_tab: Optional[str] = None):
        """Creates and displays the Rule Editor window.
           (Round 9: Ensure it's treated as a Toplevel, not embedded)"""
        try:
            log_prefix = f"SimulationGUI.create_rule_editor_window(Rule='{rule_name}'): "
            logger.info(f"{log_prefix}Attempting to open Rule Editor.")

            # Check if a rule editor window already exists
            if hasattr(self, 'rule_editor_window') and self.rule_editor_window:
                try:
                    if self.rule_editor_window.winfo_exists():
                        self.rule_editor_window.lift()
                        logger.info(f"{log_prefix}Rule editor window already exists, lifting.")
                        # --- ADDED: Select tab if specified ---
                        if selected_tab:
                            tab_map = {"Parameters": 0, "Visualization": 1, "Rule Table": 2, "Rule Info": 3}
                            tab_index = tab_map.get(selected_tab, 0)
                            if self.rule_editor_window.notebook:
                                try:
                                    self.rule_editor_window.notebook.select(tab_index)
                                    logger.debug(f"Switched existing editor to tab: {selected_tab}")
                                except tk.TclError:
                                    logger.warning(f"Could not select tab index {tab_index} in existing editor.")
                        # ---
                        return
                    else:
                        logger.warning(f"{log_prefix}Existing rule editor window is invalid, destroying it.")
                        self.rule_editor_window.destroy()
                except Exception as e:
                    logger.error(f"{log_prefix}Error checking/destroying existing rule editor window: {e}")

            # --- Ensure Rule Data Exists ---
            try:
                rule_data = RuleLibraryManager.get_rule(rule_name)
            except ValueError:
                logger.error(f"{log_prefix}Rule '{rule_name}' not found in library.")
                messagebox.showerror("Error", f"Rule '{rule_name}' not found.", parent=self.root)
                return
            # ---

            # --- Create the Toplevel window ---
            # The RuleEditorWindow class itself inherits from tk.Toplevel.
            # Simply creating an instance makes it a separate, floating window.
            # DO NOT pack or grid this instance into any other frame.
            logger.debug(f"{log_prefix}Creating NEW RuleEditorWindow instance.")
            self.rule_editor_window = RuleEditorWindow(self, rule_name, selected_tab)
            logger.info(f"{log_prefix}Created new rule editor window for rule: {rule_name}")
            # ---

        except Exception as e:
            logger.error(f"{log_prefix}Error creating rule editor window: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Error", f"Failed to create rule editor window: {e}", parent=self.root)
            if hasattr(self, 'rule_editor_window'): # Cleanup if partially created
                try:
                    if self.rule_editor_window is not None:
                        self.rule_editor_window.destroy()
                except: pass
                self.rule_editor_window = None

    def _destroy_editor_window(self, editor_window):
        """Destroy the editor window and its tooltip"""
        if hasattr(self, 'tooltip') and self.tooltip:
            self.tooltip.destroy()
        editor_window.destroy()
                    
    def _is_default_rule(self, rule_name: str) -> bool:
        """Check if a rule is one of the default rules"""
        try:
            # Load the rule from the library
            rule_data = RuleLibraryManager.get_rule(rule_name)
            return rule_data.get('default', False)
        except Exception as e:
            logger.error(f"Error getting rule data: {str(e)}")
            return False

    def step_simulation_logic(self, logger: logging.Logger) -> Optional[Dict[str, Any]]:
        """
        Encapsulated step simulation logic. Runs simulation step and returns the snapshot dictionary
        or None if the step failed or was interrupted.
        Logs step banner ONLY to the main logger. Verifies logger level.
        (Round 11: Use rule instance name in banner log)
        """
        log_prefix = f"step_simulation_logic (Thread {threading.get_ident()} R11 Rule Name Fix): " # Updated round
        current_gen = self.controller.generation if self.controller else -1
        # --- MODIFIED: Get rule instance name ---
        rule_name = self.controller.rule.name if self.controller and self.controller.rule and hasattr(self.controller.rule, 'name') else "N/A"
        # ---

        # [ Logger ID/Level Verification - Unchanged ]
        logger_id = id(logger); logger_level_name = logging.getLevelName(logger.getEffectiveLevel())
        logger.debug(f"{log_prefix}--- STEP {current_gen} START --- Using logger ID: {logger_id}, EffectiveLevel={logger_level_name}")

        # [ Banner Logging - Use rule_name variable ]
        banner_width = 70; banner_line = "#" * banner_width
        step_info_line = f"## Starting Step {current_gen} (Rule: {rule_name}) ##" # Use rule_name
        padding = (banner_width - len(step_info_line)) // 2
        centered_step_info = f"{'#' * padding}{step_info_line}{'#' * (banner_width - len(step_info_line) - padding)}"
        banner_log_message = f"\n{banner_line}\n{centered_step_info}\n{banner_line}"
        logger.info(banner_log_message)

        snapshot = None # Initialize snapshot to None
        try:
            correct_grid_id = id(self.grid) if self.grid else None
            start_time = time.time()

            # [ Interrupt Check - Unchanged ]
            if (hasattr(self.controller, 'interrupt_requested') and self.controller.interrupt_requested) or \
               (hasattr(self, '_stop_event') and self._stop_event and self._stop_event.is_set()):
                self.running = False
                logger.info(f"{log_prefix}Interrupted before execution (ControllerFlag={getattr(self.controller, 'interrupt_requested', 'N/A')}, StopEvent={getattr(self, '_stop_event').is_set() if hasattr(self, '_stop_event') and self._stop_event else 'N/A'})")
                return None

            # [ Perform simulation step - Unchanged ]
            step_successful = False
            try:
                snapshot = self.controller.step()
                step_successful = (snapshot is not None)
                if not step_successful:
                    logger.error(f"{log_prefix}Controller step failed, stopping simulation.")
                    self.running = False
                    if hasattr(self, 'root') and self.control_panel_ui is not None and hasattr(self.control_panel_ui, 'update_button_states'):
                        self.root.after(0, self.control_panel_ui.update_button_states)
                    return None
            except Exception as step_error:
                logger.error(f"{log_prefix}Error during controller step: {step_error}\nTraceback:\n{traceback.format_exc()}")
                self.running = False
                if hasattr(self, 'root') and self.control_panel_ui is not None and hasattr(self.control_panel_ui, 'update_button_states'):
                    self.root.after(0, self.control_panel_ui.update_button_states)
                return None

            # [ Interrupt Check - Unchanged ]
            if (hasattr(self.controller, 'interrupt_requested') and self.controller.interrupt_requested) or \
               (hasattr(self, '_stop_event') and self._stop_event and self._stop_event.is_set()):
                self.running = False
                logger.info(f"{log_prefix}Interrupted during execution (ControllerFlag={getattr(self.controller, 'interrupt_requested', 'N/A')}, StopEvent={getattr(self, '_stop_event').is_set() if hasattr(self, '_stop_event') and self._stop_event else 'N/A'})")
                return None

        except Exception as e:
            logger.error(f"{log_prefix}Error in simulation step logic: {e}\nTraceback:\n{traceback.format_exc()}")
            self.running = False
            if hasattr(self, 'root') and self.control_panel_ui is not None:
                self.root.after(0, self.control_panel_ui.update_button_states)
            return None
        finally:
            if hasattr(self, '_is_stepping'):
                self.root.after(10, lambda: setattr(self, '_is_stepping', False))
            logger.debug(f"{log_prefix}EXIT - Returning snapshot for Gen {snapshot.get('generation', 'N/A') if snapshot else 'N/A'}")
            return snapshot
        
    def step_button_clicked(self):
        """
        Handle step button press: Stop continuous run if active, clear queue,
        execute one step synchronously, calculate highlights, and render directly.
        (Round 20: Remove grid_snapshot from _safe_plot_update call)
        """
        log_prefix = "step_button_clicked (R20 Fix): " # Updated round
        logger.info(f"--- {log_prefix}Button Clicked ---")

        try:
            # 1. Stop any running computation cleanly
            if self.running or (hasattr(self, '_fixed_steps_running') and self._fixed_steps_running):
                logger.info(f"{log_prefix}Simulation running/paused/fixed. Stopping threads...")
                if not self._stop_computation_threads(reason="Step Button Click"):
                    logger.error(f"{log_prefix}Aborted: Failed to stop computation threads cleanly.")
                    # Ensure flags reflect stopped state even if join failed
                    self.running = False; self.paused = False; self._fixed_steps_running = False
                    if hasattr(self, 'control_panel_ui') and self.control_panel_ui: self.control_panel_ui.update_button_states()
                    return
                logger.info(f"{log_prefix}Computation threads stopped.")
            else:
                # Ensure flags are correct if already stopped
                self.running = False
                self.paused = False
                self._fixed_steps_running = False
                logger.debug(f"{log_prefix}Simulation already stopped.")

            # 2. Clear the communication queue
            logger.debug(f"{log_prefix}Clearing communication queue...")
            if hasattr(self, 'communication_queue'):
                qsize_before = self.communication_queue.qsize()
                while not self.communication_queue.empty():
                    try: self.communication_queue.get_nowait()
                    except queue.Empty: break
                qsize_after = self.communication_queue.qsize()
                logger.info(f"{log_prefix}Communication queue cleared (was {qsize_before}, now {qsize_after}).")
            else:
                logger.warning(f"{log_prefix}Communication queue not found, cannot clear.")

            # 3. Clear lasso selection
            self._clear_lasso_selection()

            # 4. Perform single step synchronously
            logger.info(f"{log_prefix}Executing single step synchronously...")
            snapshot = self.controller.step() # Call controller step directly
            if snapshot is None:
                logger.error(f"{log_prefix}controller.step() failed. Aborting.")
                messagebox.showerror("Error", "Simulation step failed.", parent=self.root)
                # Update button states to reflect stopped state
                if hasattr(self, 'control_panel_ui') and self.control_panel_ui: self.control_panel_ui.update_button_states()
                return
            logger.info(f"{log_prefix}Synchronous step completed (Gen {snapshot.get('generation', 'N/A')}).")

            # 5. Update generation count and label
            new_generation = snapshot.get('generation', self.generation + 1)
            self.generation = new_generation
            self.step_count = new_generation
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                self.control_panel_ui.update_step_label()

            # 6. Calculate Highlights
            nodes_to_highlight = set()
            edges_to_highlight = set()
            highlight_on = self.highlight_var.get() if hasattr(self, 'highlight_var') else True
            if self._last_rendered_snapshot and highlight_on:
                try:
                    # Extract current state
                    current_nodes_coords = set()
                    current_edges_coords = set()
                    grid_array_snap = snapshot.get('grid_array')
                    edges_snap = snapshot.get('edges')
                    if grid_array_snap is not None and edges_snap is not None:
                        grid_dims = grid_array_snap.shape
                        visible_mask = grid_array_snap > 1e-6
                        visible_indices = np.where(visible_mask.ravel())[0]
                        for idx in visible_indices: current_nodes_coords.add(tuple(_unravel_index(idx, grid_dims)))
                        current_edges_coords = edges_snap
                    # Extract previous state
                    nodes_before_render = set()
                    edges_before_render = set()
                    grid_array_prev = self._last_rendered_snapshot.get('grid_array')
                    edges_prev = self._last_rendered_snapshot.get('edges')
                    if grid_array_prev is not None and edges_prev is not None:
                        grid_dims_prev = grid_array_prev.shape
                        visible_mask_prev = grid_array_prev > 1e-6
                        visible_indices_prev = np.where(visible_mask_prev.ravel())[0]
                        for idx in visible_indices_prev: nodes_before_render.add(tuple(_unravel_index(idx, grid_dims_prev)))
                        edges_before_render = edges_prev

                    nodes_to_highlight = current_nodes_coords - nodes_before_render
                    edges_to_highlight = (current_edges_coords - edges_before_render) | (edges_before_render - current_edges_coords)
                    logger.debug(f"{log_prefix}Highlights calculated: AddedNodes={len(nodes_to_highlight)}, ChangedEdges={len(edges_to_highlight)}")
                except Exception as diff_err:
                    logger.error(f"{log_prefix}Error calculating highlights: {diff_err}")
                    nodes_to_highlight = set(); edges_to_highlight = set()
            else: logger.debug(f"{log_prefix}No previous snapshot or highlight off, skipping highlight calculation.")

            # 7. Render Directly
            logger.debug(f"{log_prefix}Calling _safe_plot_update directly with highlights.")
            # --- MODIFIED: Removed grid_snapshot argument ---
            self._safe_plot_update(
                nodes_to_highlight=nodes_to_highlight,
                edges_to_highlight=edges_to_highlight,
                force=True # Force full redraw for clarity after step
            )
            # ---

            # 8. Update Last Rendered Snapshot
            self._last_rendered_snapshot = snapshot.copy()
            logger.debug(f"{log_prefix}Updated _last_rendered_snapshot.")

            # 9. Ensure flags reflect stopped state
            self.running = False
            self.paused = False
            self._fixed_steps_running = False
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                self.control_panel_ui.update_button_states()

            logger.info(f"{log_prefix}Single step executed and rendered successfully.")

        except Exception as e:
            logger.error(f"{log_prefix}Error in step button handler: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Error", "An error occurred during the simulation step.", parent=self.root)
            # Ensure state is stopped on error
            self.running = False; self.paused = False; self._fixed_steps_running = False
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui: self.control_panel_ui.update_button_states()
        finally:
            pass

    def _stop_simulation(self):
        """
        Stops the simulation cleanly, signals threads, clears queues, cancels render timer,
        synchronizes grid state, and performs a final render.
        Uses _is_stopping flag to prevent overlap. Removes annoying messagebox.
        Calls reset helper WITHOUT resetting generation counter.
        (Round 62: Add _is_stopping flag, remove redundant _stopped set)
        (Round 37: Clear queues AFTER signaling stop, cancel render timer)
        (Round 43: Remove messagebox on failed join)
        (Round 44: Removed messagebox on failed join)
        (Round 45: Call reset helper with reset_generation_counter=False)
        (Round 47: Synchronize controller.generation to last rendered snapshot)
        """
        log_prefix = "SimulationGUI._stop_simulation (R47 Sync Gen): " # Updated round
        banner_width = 60
        banner_text = f" STOPPING Simulation "
        logger.info(f"\n{'=' * banner_width}\n{banner_text:=^{banner_width}}\n{'=' * banner_width}")

        # --- Check if already stopped or stopping ---
        if self._is_stopping:
            logger.warning(f"{log_prefix}Stop requested while already stopping. Ignoring.")
            return
        if not self.running and not self.paused and self._stopped:
            logger.info(f"{log_prefix}Simulation already stopped.")
            return
        # ---

        self._is_stopping = True # Set flag at the beginning

        try:
            # --- Set running/paused flags immediately ---
            self.running = False
            self.paused = False
            self._fixed_steps_running = False
            self._stop_requested = True # Signal stop request
            logger.debug(f"{log_prefix}Set flags: running=False, paused=False, _fixed_steps_running=False, _stop_requested=True")
            # ---

            # --- Signal Threads to Stop ---
            if hasattr(self, '_stop_event') and self._stop_event: self._stop_event.set(); logger.debug(f"{log_prefix}Computation stop event set.")
            else: logger.warning(f"{log_prefix}Computation stop event attribute missing.")
            if hasattr(self, '_prep_stop_event') and self._prep_stop_event: self._prep_stop_event.set(); logger.debug(f"{log_prefix}Preparation stop event set.")
            else: logger.warning(f"{log_prefix}Preparation stop event attribute missing.")
            # ---

            # --- Cancel Render Timer Loop ---
            if hasattr(self, '_render_timer_after_id') and self._render_timer_after_id:
                try:
                    self.root.after_cancel(self._render_timer_after_id)
                    logger.info(f"{log_prefix}Cancelled pending render timer loop (ID: {self._render_timer_after_id}).")
                except Exception as e_cancel:
                    logger.warning(f"{log_prefix}Error cancelling pending render timer loop: {e_cancel}")
                finally:
                    self._render_timer_after_id = None
            # ---

            # --- Stop Computation & Preparation Threads ---
            stop_success = self._stop_computation_threads(reason="Stop Button")
            # --- Set _stopped flag AFTER attempting to stop threads ---
            self._stopped = True
            logger.info(f"{log_prefix}Set final _stopped = True state.")
            # ---

            if not stop_success:
                logger.error(f"{log_prefix}Failed to stop computation/preparation threads cleanly.")
                if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                    self.control_panel_ui.update_button_states() # Update buttons even on failure
                # Continue with sync/render attempt even if threads didn't join perfectly
            else:
                logger.info(f"{log_prefix}Computation/preparation threads stopped successfully.")
            # ---

            # --- Synchronize Grid State with Last Rendered Snapshot ---
            logger.info(f"{log_prefix}Synchronizing internal grid state with last rendered snapshot.")
            final_plot_data_to_render = None # Store prepared data for the final render
            snapshot_to_restore = None # Store the snapshot used for restoration

            if self._last_rendered_snapshot and self.grid:
                try:
                    snapshot_to_restore = self._last_rendered_snapshot.copy()
                    last_gen = snapshot_to_restore.get('generation', 'N/A')
                    logger.debug(f"  Restoring grid arrays/sets from snapshot of Gen {last_gen}")

                    # [ Restore grid array, edges, edge states, previous arrays - Unchanged ]
                    grid_array_snap = snapshot_to_restore.get('grid_array')
                    if grid_array_snap is not None and isinstance(grid_array_snap, np.ndarray) and self.grid.grid_array.shape == grid_array_snap.shape:
                        np.copyto(self.grid.grid_array, grid_array_snap)
                        if self.grid.shared_array is not None and self.grid.shared_array.shape == grid_array_snap.shape: np.copyto(self.grid.shared_array, grid_array_snap)
                        logger.debug("    Restored grid_array.")
                    else: logger.warning(f"    Could not restore grid_array (missing, wrong type, shape mismatch, or grid None). Type: {type(grid_array_snap)}")
                    edges_snap = snapshot_to_restore.get('edges'); edge_states_snap = snapshot_to_restore.get('edge_states')
                    if isinstance(edges_snap, set): self.grid.edges = edges_snap.copy()
                    else: logger.warning(f"    Could not restore edges (not a set). Type: {type(edges_snap)}"); self.grid.edges = set()
                    if isinstance(edge_states_snap, dict): self.grid.edge_states = edge_states_snap.copy()
                    else: logger.warning(f"    Could not restore edge_states (not a dict). Type: {type(edge_states_snap)}"); self.grid.edge_states = {}
                    logger.debug(f"    Restored edges ({len(self.grid.edges)}) and edge_states ({len(self.grid.edge_states)}).")
                    prev_deg_snap = snapshot_to_restore.get('previous_degree_array')
                    if prev_deg_snap is not None and isinstance(prev_deg_snap, np.ndarray): self.grid.previous_degree_array = prev_deg_snap.copy(); logger.debug("    Restored previous_degree_array.")
                    else: self.grid.previous_degree_array = None
                    prev_act_snap = snapshot_to_restore.get('previous_active_neighbor_array')
                    if prev_act_snap is not None and isinstance(prev_act_snap, np.ndarray): self.grid.previous_active_neighbor_array = prev_act_snap.copy(); logger.debug("    Restored previous_active_neighbor_array.")
                    else: self.grid.previous_active_neighbor_array = None

                    # [ Update active nodes, populate spatial hash - Unchanged ]
                    self.grid.update_active_nodes()
                    self.grid.previous_active_nodes_set = self.grid.active_nodes.copy() # Reset history
                    logger.debug(f"    Updated active nodes ({len(self.grid.active_nodes)}) based on restored state.")
                    self.grid.populate_spatial_hash()
                    logger.debug("    Repopulated spatial hash.")

                    # --- Synchronize Generation Counters to Last Rendered Snapshot ---
                    if 'generation' in snapshot_to_restore and snapshot_to_restore['generation'] is not None:
                        gen_val = snapshot_to_restore['generation']
                        if hasattr(self, 'generation'): self.generation = gen_val
                        if hasattr(self, 'step_count'): self.step_count = gen_val
                        if hasattr(self, 'controller') and hasattr(self.controller, 'generation'): self.controller.generation = gen_val
                        logger.info(f"{log_prefix}Synchronized generation counters to last rendered snapshot: {gen_val}")
                    # ---

                    # --- Prepare plot data for the final RESTORED state ---
                    logger.debug(f"{log_prefix}Preparing plot data for final render (Gen {last_gen}).")
                    with self._prep_params_lock: current_viz_params = self._prep_visualization_params.copy()
                    grid_array_arg = self.grid.grid_array.copy(); edges_arg = self.grid.edges.copy(); edge_states_arg = self.grid.edge_states.copy()
                    generation_arg = self.generation # Use current GUI generation
                    prev_deg_arr = self.grid.previous_degree_array.copy() if self.grid.previous_degree_array is not None else None
                    prev_act_arr = self.grid.previous_active_neighbor_array.copy() if self.grid.previous_active_neighbor_array is not None else None
                    final_plot_data_to_render = GridVisualizer._prepare_plot_data_static(
                        grid_array=grid_array_arg, edges=edges_arg, edge_states=edge_states_arg, generation=generation_arg,
                        visualization_params=current_viz_params, coord_system=self.coord_system,
                        nodes_to_highlight=set(), edges_to_highlight=set(), # No highlights for final static render
                        previous_degree_array=prev_deg_arr, previous_active_neighbor_array=prev_act_arr
                    )
                    if final_plot_data_to_render: logger.info(f"{log_prefix}Successfully prepared plot data for final render.")
                    else: logger.error(f"{log_prefix}Failed to prepare plot data for final render!")
                    # ---

                except Exception as sync_err:
                    logger.error(f"{log_prefix}Error synchronizing grid state or preparing final plot data: {sync_err}")
                    logger.error(traceback.format_exc())
                    messagebox.showerror("Stop Error", "Failed to synchronize grid state after stopping. Grid might be inconsistent.", parent=self.root)
            elif not self._last_rendered_snapshot:
                logger.warning(f"{log_prefix}No last rendered snapshot found, cannot synchronize grid state. Grid state reflects last computation.")
                # --- Prepare plot data from current grid state as fallback ---
                if self.grid and self.coord_system:
                    try:
                        with self._prep_params_lock: current_viz_params = self._prep_visualization_params.copy()
                        final_plot_data_to_render = GridVisualizer._prepare_plot_data_static(
                            grid_array=self.grid.grid_array.copy(), edges=self.grid.edges.copy(),
                            edge_states=self.grid.edge_states.copy(), generation=self.generation,
                            visualization_params=current_viz_params, coord_system=self.coord_system,
                            nodes_to_highlight=set(), edges_to_highlight=set(),
                            previous_degree_array=self.grid.previous_degree_array.copy() if self.grid.previous_degree_array is not None else None,
                            previous_active_neighbor_array=self.grid.previous_active_neighbor_array.copy() if self.grid.previous_active_neighbor_array is not None else None
                        )
                    except Exception as prep_err: logger.error(f"{log_prefix}Error preparing fallback plot data: {prep_err}")
                # ---
            else: # self.grid is None
                 logger.error(f"{log_prefix}Grid is None, cannot synchronize state.")
            # ---

            # --- Force Final Render using the PREPARED data ---
            logger.info(f"{log_prefix}Forcing final render of the synchronized grid state.")
            if final_plot_data_to_render:
                if self.grid_visualizer is not None:
                    self.grid_visualizer.update_visualization_state(invalidate_blit_cache=True, **final_plot_data_to_render)
                    self._safe_plot_update(force=False) # Use non-forced update
                    logger.info(f"{log_prefix}Final render complete using prepared data.")
            else:
                logger.warning(f"{log_prefix}Prepared data for final render failed, calling _force_initial_render as fallback.")
                self._force_initial_render()
                logger.info(f"{log_prefix}Final render complete using fallback.")
            # ---

            # --- Update Buttons ---
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                self.control_panel_ui.update_button_states()

            logger.info(f"{log_prefix}Stop sequence fully completed.")

        except Exception as e:
            logger.error(f"{log_prefix}Error during stop simulation: {e}")
            logger.error(traceback.format_exc())
            self._stopped = True # Ensure stopped state on error
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                self.control_panel_ui.update_button_states()
        finally:
            # --- Clear stopping flag at the VERY end ---
            self._is_stopping = False
            logger.debug(f"{log_prefix}Cleared _is_stopping flag.")
            # ---

    def _on_enable_tiebreakers_change(self):
        """Handle enable tiebreakers checkbox change"""
        enabled = self.enable_tiebreakers_var.get()
        GlobalSettings.ENABLE_TIEBREAKERS = enabled
        logger.info(f"Tiebreakers enabled: {enabled}")
        # Trigger a full redraw
        if self.grid_visualizer is not None:
            self.grid_visualizer.update_visualization_state()

    def _on_tiebreaker_type_change(self, value):
        """Handle tiebreaker type change"""
        try:
            # Update tiebreaker type in rule parameters
            if self.controller.rule.update_parameter('tiebreaker_type', value):
                logger.info(f"Changed tiebreaker type to: {value}")
                # Invalidate metric cache to ensure new parameters are used
                self.controller.rule.invalidate_cache()
                # Trigger a full redraw
                if self.grid_visualizer is not None:
                    self.grid_visualizer.update_visualization_state()
            else:
                logger.warning(f"Invalid tiebreaker type: {value}")
                messagebox.showerror("Error", f"Invalid tiebreaker type: {value}")
                # Reset to current type
                if hasattr(self, 'tiebreaker_type_var') and self.tiebreaker_type_var:
                    self.tiebreaker_type_var.set(self.controller.rule.get_param('tiebreaker_type', 'RANDOM'))
        except Exception as e:
            logger.error(f"Error changing tiebreaker type: {e}")
            messagebox.showerror("Error", f"Failed to change tiebreaker type: {e}")
            # Reset to current type
            if hasattr(self, 'tiebreaker_type_var') and self.tiebreaker_type_var:
                self.tiebreaker_type_var.set(self.controller.rule.get_param('tiebreaker_type', 'RANDOM'))

    def _update_rule_instances(self, rule_type: str):
        """Update the rule instance selector with available rules"""
        # Get available rules for the selected rule type
        available_rules = RuleLibrary.get_rules_in_category(rule_type)
        
        # Update the rule instance selector options
        menu = self.rule_instance_selector["menu"]
        menu.delete(0, "end")
        for rule_name in available_rules:
            menu.add_command(label=rule_name, command=lambda value=rule_name: self._on_rule_instance_change(value))
            
        # Set the selected rule instance to the first available rule
        if available_rules:
            self.rule_instance_var.set(available_rules[0])
        else:
            self.rule_instance_var.set("")
                                            
    def _complete_rule_instance_change(self, rule_name: str) -> bool:
        """Helper method to encapsulate the rule change logic."""
        try:
            logger.debug(f"Entering _complete_rule_instance_change with rule_name: {rule_name}")

            # Stop any running simulation
            logger.debug("Stopping simulation")
            self.running = False
            self.paused = False

            logger.info(f"Changing to rule: {rule_name}")

            try:
                rule_data = RuleLibraryManager.get_rule(rule_name)
            except ValueError as e:
                logger.error(f"Error loading rule {rule_name}: {e}")
                return False

            # Create metadata for the rule
            metadata_dict = {k: v for k, v in rule_data.items() if k != 'params'}
            metadata_dict.setdefault('position', 1); metadata_dict.setdefault('category', 'Unknown')
            metadata_dict.setdefault('author', GlobalSettings.Defaults.DEFAULT_AUTHOR); metadata_dict.setdefault('url', GlobalSettings.Defaults.DEFAULT_URL)
            metadata_dict.setdefault('email', GlobalSettings.Defaults.DEFAULT_EMAIL); metadata_dict.setdefault('date_created', datetime.now().strftime("%Y-%m-%d"))
            metadata_dict.setdefault('date_modified', datetime.now().strftime("%Y-%m-%d")); metadata_dict.setdefault('version', '1.0')
            metadata_dict.setdefault('description', 'No description available.'); metadata_dict.setdefault('tags', [])
            metadata_dict.setdefault('dimension_compatibility', ["TWO_D", "THREE_D"]); metadata_dict.setdefault('neighborhood_compatibility', [])
            metadata_dict.setdefault('parent_rule', None); metadata_dict.setdefault('rating', None); metadata_dict.setdefault('notes', None)
            metadata_dict.setdefault('allowed_initial_conditions', ["Random"]); metadata_dict.setdefault('allow_rule_tables', True)
            metadata_dict.setdefault('favorite', False)
            metadata = RuleMetadata(**metadata_dict)

            # Create new rule instance
            try:
                logger.debug(f"Creating new rule instance of type {metadata.type}")
                new_rule = RuleLibrary.create_rule(rule_name, metadata) # Get the instance
                logger.debug(f"Successfully created new rule instance: {new_rule}")
            except ValueError as e:
                logger.error(f"Error creating rule {rule_name}: {e}")
                return False

            # Get parameters from rule data
            logger.debug("Getting parameters from rule data")
            params = rule_data.get('params', {})
            if not params:
                logger.warning(f"No parameters found for rule {rule_name} in library")
                params = {}
            new_rule.params = copy.deepcopy(params)
            logger.debug(f"New rule parameters after deep copy: {new_rule.params}")

            # Update controller's rule
            logger.debug("Updating controller's rule")
            self.rule = new_rule
            self.rule_name = rule_name
            self.controller.rule = new_rule
            logger.debug(f"Updated controller rule to: {self.controller.rule.name}")

            # Re-initialize the grid with the new rule
            if self.controller.grid is not None:
                logger.debug("Creating new grid with new rule")
                # --- CORRECTED ARGUMENT ORDER ---
                new_grid = Grid(
                    self.dimensions,
                    self.neighborhood_type,
                    self.dimension_type,
                    self.coord_system,          # Pass coord_system positionally
                    gui=self,                   # Pass gui via keyword
                    rule=self.controller.rule,  # Pass rule via keyword
                    unique_id=self._unique_id
                )
                # --- END CORRECTION ---

                self.controller.grid = new_grid
                self.grid = new_grid
                self.grid.setup_shared_memory()
            else:
                logger.error("Controller.grid is None after set_rule, cannot reinitialize")
                return False

            logger.debug(f"Initializing grid state with rule: {self.rule_name}")
            self.controller.rule.initialize_grid_state(self.controller.grid)

            active_count = np.sum(self.grid.grid_array > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD)
            logger.debug(f"After initialization: {active_count} active nodes and {len(self.grid.edges)} edges")

            new_rule_category = RuleLibrary.get_rule_category(rule_name)
            self.rule_type_var.set(new_rule_category)
            logger.info(f"Updated rule_type_var to: {self.rule_type_var.get()}")

            self._update_rule_instance_selector()

            if hasattr(self, 'grid_visualizer') and self.grid_visualizer:
                self.grid_visualizer.set_grid(self.grid)
                logger.debug("Updated grid visualizer with new grid")
                self.grid_visualizer.update_visualization_state()
                logger.debug("Triggered full redraw after rule change")

        except Exception as e:
            logger.error(f"Error changing rule: {str(e)}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            messagebox.showerror("Error", f"Failed to change rule: {e}")
            self.rule_instance_var.set(self.controller.rule.name)
            return False

        return True

    def _update_editor_buttons_if_open(self):
        """Checks if the rule editor is open and updates its buttons."""
        if hasattr(self, 'rule_editor_window') and self.rule_editor_window and self.rule_editor_window.winfo_exists():
            # Check if the editor window itself has the update method
            if hasattr(self.rule_editor_window, '_update_editor_buttons') and callable(self.rule_editor_window._update_editor_buttons):
                self.rule_editor_window._update_editor_buttons()
                logger.debug("Updated buttons in open RuleEditorWindow.")
            else:
                logger.warning("RuleEditorWindow is open but missing _update_editor_buttons method.")
        # else: # Reduce noise
            # logger.debug("Rule editor window not open or not valid, skipping button update.")

    def _update_rule_type_selector(self):
        """Updates the rule type (category) selector dropdown in the control panel."""
        log_prefix = "SimulationGUI._update_rule_type_selector: "
        logger.debug(f"{log_prefix}Updating rule type selector.")

        if not hasattr(self, 'control_panel_ui') or not self.control_panel_ui:
            logger.error(f"{log_prefix}ControlPanelUI not initialized.")
            return
        if not hasattr(self.control_panel_ui, 'widgets'):
            logger.error(f"{log_prefix}ControlPanelUI widgets dictionary not initialized.")
            return

        rule_type_selector = self.control_panel_ui.widgets.get('rule_type_selector')
        if not isinstance(rule_type_selector, tk.OptionMenu):
            logger.error(f"{log_prefix}Rule type selector widget not found or invalid type.")
            return
        if not rule_type_selector.winfo_exists():
            logger.warning(f"{log_prefix}Rule type selector widget destroyed.")
            return

        try:
            # Get current selection BEFORE rebuilding
            current_selection = self.rule_type_var.get()

            # Get updated categories
            all_categories_dict = RuleLibrary.get_rule_categories()
            all_category_names = list(all_categories_dict.keys())
            normalized_categories = [cat.strip().title() for cat in all_category_names]
            unique_sorted_categories = sorted(list(set(normalized_categories)))
            if "Favorites" in unique_sorted_categories:
                unique_sorted_categories.remove("Favorites")
                unique_sorted_categories.insert(0, "Favorites")
            logger.debug(f"{log_prefix}Available categories: {unique_sorted_categories}")

            # Get the menu widget
            menu = rule_type_selector['menu']
            if menu is None:
                logger.error(f"{log_prefix}Rule type selector menu not found.")
                return
            if not menu.winfo_exists():
                 logger.warning(f"{log_prefix}Rule type selector menu widget destroyed.")
                 return

            # Clear existing options
            menu.delete(0, 'end')

            # Add new options
            if unique_sorted_categories:
                for category_name in unique_sorted_categories:
                    menu.add_command(
                        label=category_name,
                        command=functools.partial(self._on_rule_type_change, category_name)
                    )
                # Try to restore previous selection if still valid, else default
                if current_selection in unique_sorted_categories:
                    self.rule_type_var.set(current_selection)
                else:
                    self.rule_type_var.set(unique_sorted_categories[0])
                    # Trigger instance update if category changed implicitly
                    self.root.after(10, lambda name=unique_sorted_categories[0]: self._on_rule_type_change(name))
            else:
                menu.add_command(label="(No Categories)", state="disabled")
                self.rule_type_var.set("(No Categories)")

            logger.debug(f"{log_prefix}Rule type selector updated. Selected: {self.rule_type_var.get()}")

        except tk.TclError as e:
            logger.error(f"{log_prefix}TclError updating rule type selector (likely widget destroyed): {e}")
        except Exception as e:
            logger.error(f"{log_prefix}Unexpected error updating rule type selector: {e}")
            logger.error(traceback.format_exc())

    def force_plot_update(self):
        """Force a complete redraw of the plot, bypassing initialization checks."""
        logger.debug("Entering force_plot_update")

        # Store the original initialization state
        original_init_state = self._initialization_complete

        try:
            # Temporarily set initialization to complete
            self._initialization_complete = True

            # Check if we have valid grid data
            if self.grid is not None:
                # Log the active node count to verify we're using the correct grid
                logger.debug(f"Grid object: {self.grid}") #
                active_count = np.sum(self.grid.grid_array > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD)
                logger.debug(f"force_plot_update: Using grid with {active_count} active nodes")

                # Clear any existing background for a full redraw
                self.background = None

                # Force a complete redraw using the GridVisualizer
                if hasattr(self, 'grid_visualizer') and self.grid_visualizer:
                    self.grid_visualizer.update_visualization()
                    logger.debug("Forced plot update using GridVisualizer")
                else:
                    logger.error("GridVisualizer not initialized, cannot force plot update")

            else:
                logger.error("Cannot force plot update because grid is None")

        except Exception as e:
            logger.error(f"Error in force_plot_update: {e}")
            logger.error(traceback.format_exc())
        finally:
            # Restore the original initialization state
            self._initialization_complete = original_init_state
            logger.debug(f"Exiting force_plot_update, restored initialization state to {original_init_state}")

    def _update_ui_for_new_rule(self, rule_data: Dict[str, Any]):
        """Update UI elements for new rule"""
        try:
            # Update initial conditions
            initial_conditions = rule_data['params'].get('initial_conditions', ["Random"])[0] # Get the actual value
            if initial_conditions:
                self.initial_conditions_var.set(initial_conditions)
                self._on_initial_conditions_change(self.initial_conditions_var.get())
            
            # Update rule instance selector
            self.rule_instance_var.set(rule_data['name'])
            
            # Update edit button
            self.edit_rule_button.config(text="Edit Rule")
            
            # Reset node and edge density sliders
            default_node_density = GlobalSettings.Simulation.INITIAL_NODE_DENSITY
            default_edge_density = GlobalSettings.Simulation.INITIAL_EDGE_DENSITY
            
            if self.node_density_scale is not None:
                self.node_density_scale.set(default_node_density)
            if self.edge_density_scale is not None:
                self.edge_density_scale.set(default_edge_density)
            
        except Exception as e:
            logger.error(f"Error updating UI for new rule: {e}")
            raise
                                                
    def reset_coordinates(self):
        """Force recalculation of node coordinates with current settings"""
        try:
            # Reset view state to force full redraw
            self._view_state = {
                'xlim': None,
                'ylim': None,
                'zlim': None,
                'elev': 30 if self.controller.dimension_type == Dimension.THREE_D else None,
                'azim': 45 if self.controller.dimension_type == Dimension.THREE_D else None,
                'zoom_factor': 1.0
            }

            # Recalculate plot limits with new spacing
            self._update_plot_limits()

            # Force controller to update node positions
            if hasattr(self.controller, 'grid'):
                # Get current state
                current_state = self.controller.get_state()

                # Reset grid with current state
                # --- CORRECTED ARGUMENT ORDER ---
                self.controller.grid = Grid(
                    self.controller.dimensions,
                    self.controller.neighborhood_type,
                    self.controller.dimension_type,
                    self.coord_system,          # Pass coord_system positionally
                    gui=self,                   # Pass gui via keyword
                    rule=self.controller.rule,  # Pass rule via keyword
                    unique_id=self.controller._unique_id
                )
                # --- END CORRECTION ---

                # Restore state
                self.controller.set_state(current_state)

            logger.debug("Node coordinates reset with new spacing")

        except Exception as e:
            logger.error(f"Error resetting coordinates: {str(e)}")
            raise

    def _get_valid_neighborhoods(self) -> List[str]:
        """Get list of valid neighborhood types for current dimension"""
        if self.dimension_type == Dimension.TWO_D:
            return ["VON_NEUMANN", "MOORE", "HEX"]
        else:  # THREE_D
            # Note: We still show HEX as an option, it will be auto-converted to HEX_PRISM
            return ["VON_NEUMANN", "MOORE", "HEX", "HEX_PRISM"]
                                                                                                                                                                                                
    def _on_dimension_change(self, dimension_str: str):
        """Handle dimension type change"""
        log_prefix = "SimulationGUI._on_dimension_change: "
        logger.info(f"\n{'='*25} Changing Dimension: {dimension_str} {'='*25}")
        self._is_transitioning = True
        if not self._stop_computation_threads(reason=f"Change Dimension to {dimension_str}"):
            logger.error(f"{log_prefix}Aborted: Failed to stop computation threads cleanly.")
            self._is_transitioning = False
            return
        # --- ADDED: Clear stop event after successful stop ---
        if hasattr(self, '_stop_event') and self._stop_event:
            self._stop_event.clear()
            logger.debug("Cleared stop event after stopping threads.")
        # ---

        original_blitting = self.grid_visualizer.blitting_manager.enabled if hasattr(self, 'grid_visualizer') and self.grid_visualizer else GlobalSettings.ENABLE_BLITTING
        if hasattr(self, 'grid_visualizer') and self.grid_visualizer: self.grid_visualizer.blitting_manager.set_enabled(False)
        try:
            # [ Rest of the method remains the same as Round 22... ]
            try: dimension_type = Dimension[dimension_str]
            except KeyError as e: logger.error(f"Invalid dimension type: {dimension_str}"); messagebox.showerror("Error", f"Invalid dimension type: {dimension_str}"); self._is_transitioning = False; return
            if self.controller.rule:
                rule_dims = self.controller.rule.PARAMETER_METADATA.get('dimension_type', {}).get('allowed_values')
                if rule_dims and 'ANY' not in rule_dims and dimension_str not in rule_dims:
                    messagebox.showerror("Incompatible Dimension", f"The current rule '{self.controller.rule.name}' is not compatible with {dimension_str}.", parent=self.root)
                    self.dimension_var.set(self.dimension_type.name); self._is_transitioning = False; return
            if dimension_type != self.dimension_type:
                self.dimension_type = dimension_type
                GlobalSettings.Simulation.DIMENSION_TYPE = dimension_type
                self.dimensions = GlobalSettings.Simulation.get_grid_dimensions()
                self.controller.dimensions = self.dimensions; self.controller.dimension_type = self.dimension_type
                logger.info(f"Dimension type updated to {self.dimension_type.name}. New dimensions: {self.dimensions}")
                current_neighborhood_name = self.neighborhood_var.get()
                new_neighborhood_type = self.neighborhood_type
                if current_neighborhood_name == "HEX" and self.dimension_type == Dimension.THREE_D: new_neighborhood_type = NeighborhoodType.HEX_PRISM; self.neighborhood_var.set("HEX_PRISM"); logger.info(f"Auto-switched neighborhood to HEX_PRISM for 3D.")
                elif current_neighborhood_name == "HEX_PRISM" and self.dimension_type == Dimension.TWO_D: new_neighborhood_type = NeighborhoodType.HEX; self.neighborhood_var.set("HEX"); logger.info(f"Auto-switched neighborhood to HEX for 2D.")
                self.neighborhood_type = new_neighborhood_type; self.controller.neighborhood_type = self.neighborhood_type
                self._update_neighborhood_selector()
                if self.grid is not None and self.coord_system is not None:
                    self.grid.reinitialize(
                        self.dimensions, self.neighborhood_type, self.dimension_type,
                        self.coord_system, gui=self, rule=self.controller.rule, unique_id=self._unique_id
                    )
                    self.grid.setup_shared_memory(); self.controller.grid = self.grid
                    logger.info("Grid reinitialized successfully.")
                else: logger.error("Grid or CoordinateSystem is not initialized."); self._is_transitioning = False; return
                self.reset_simulation()
                logger.info(f"Dimension changed to: {dimension_str}")
            else:
                logger.debug("Dimension type unchanged.")

        except Exception as e:
            logger.error(f"Error changing dimension type: {e}")
            messagebox.showerror("Error", f"Failed to change dimension type: {e}")
            self.dimension_var.set(self.dimension_type.name) # Reset to current type
        finally:
            if hasattr(self, 'grid_visualizer') and self.grid_visualizer: self.grid_visualizer.blitting_manager.set_enabled(original_blitting)
            self.running = False; self.paused = False; self._fixed_steps_running = False
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui: self.control_panel_ui.update_button_states()
            self._is_transitioning = False
            self._initialization_complete = True
            logger.debug(f"{log_prefix}Set _initialization_complete = True in finally block.")

    def _update_neighborhood_selector(self):
        """Update the neighborhood selector options based on the current dimension type.
           (Round 3: Added robustness checks and logging)"""
        log_prefix = "SimulationGUI._update_neighborhood_selector: "
        logger.debug(f"{log_prefix}Attempting to update neighborhood selector.")

        # --- ADDED: Check if ControlPanelUI and its widgets exist ---
        if not hasattr(self, 'control_panel_ui') or not self.control_panel_ui:
            logger.warning(f"{log_prefix}ControlPanelUI not initialized, cannot update selector.")
            return
        if not hasattr(self.control_panel_ui, 'widgets'):
            logger.warning(f"{log_prefix}ControlPanelUI widgets dictionary not initialized.")
            return
        # ---

        neighborhood_selector = self.control_panel_ui.widgets.get('neighborhood_selector')

        # --- ADDED: Check widget existence and type ---
        if not isinstance(neighborhood_selector, tk.OptionMenu):
            logger.error(f"{log_prefix}Neighborhood selector widget not found or invalid type in ControlPanelUI. Found: {type(neighborhood_selector)}")
            return
        if not neighborhood_selector.winfo_exists():
            logger.warning(f"{log_prefix}Neighborhood selector widget destroyed, cannot update.")
            return
        # ---

        try:
            valid_neighborhoods = self._get_valid_neighborhoods()
            menu = neighborhood_selector['menu']
            if menu is None:
                logger.error(f"{log_prefix}Neighborhood selector menu not found.")
                return

            # --- ADDED: Check if menu widget exists before deleting ---
            if not menu.winfo_exists():
                 logger.warning(f"{log_prefix}Neighborhood selector menu widget destroyed, cannot update options.")
                 return
            # ---

            menu.delete(0, 'end')

            for neighborhood_name in valid_neighborhoods:
                # Use functools.partial to correctly bind the name
                menu.add_command(
                    label=neighborhood_name,
                    command=functools.partial(self._on_neighborhood_change, neighborhood_name)
                )

            current_neighborhood_name = self.neighborhood_type.name
            target_selection = ""
            if current_neighborhood_name in valid_neighborhoods:
                target_selection = current_neighborhood_name
            elif valid_neighborhoods:
                target_selection = valid_neighborhoods[0]
                logger.warning(f"{log_prefix}Current neighborhood '{current_neighborhood_name}' invalid for dimension '{self.dimension_type.name}'. Defaulting to '{target_selection}'.")
                # Schedule the change handler to apply the default AFTER this update finishes
                self.root.after(10, lambda name=target_selection: self._on_neighborhood_change(name))
            else:
                logger.error(f"{log_prefix}No valid neighborhoods found for dimension '{self.dimension_type.name}'.")
                target_selection = "" # Set to empty if no valid options

            # --- ADDED: Check if variable exists before setting ---
            if hasattr(self, 'neighborhood_var'):
                self.neighborhood_var.set(target_selection)
                logger.debug(f"{log_prefix}Neighborhood selector updated. Selected: {self.neighborhood_var.get()}")
            else:
                logger.error(f"{log_prefix}neighborhood_var missing, cannot set selection.")
            # ---

        except tk.TclError as e:
            logger.error(f"{log_prefix}TclError updating neighborhood selector (likely widget destroyed): {e}")
        except Exception as e:
            logger.error(f"{log_prefix}Unexpected error updating neighborhood selector: {e}")
            logger.error(traceback.format_exc())
            
    def _update_grid_size(self, new_size: int):
        """Perform the actual grid size update."""


        # Prevent recursive calls
        if hasattr(self, '_is_resizing') and self._is_resizing:
            logger.warning("Recursive call to _update_grid_size, skipping")
            return
        self._is_resizing = True  # Set flag

        try:
            with self._update_lock:
                # Update global settings with appropriate dimension type
                GlobalSettings.Simulation.set_grid_size(new_size, self.controller.dimension_type)

                # Pause simulation if running
                was_running = self.running
                self.running = False

                # Store current rule name
                current_rule_name = self.rule_name

                # Store the rule directly from the controller
                if hasattr(self, 'controller') and self.controller.rule:
                    local_rule = self.controller.rule
                    logger.debug(f"Using rule from controller: {local_rule}")
                else:
                    logger.error("Controller or controller.rule is None")
                    return

                # Update controller dimensions
                logger.debug("Updating controller dimensions")
                self.dimensions = GlobalSettings.Simulation.get_grid_dimensions()
                logger.debug(f"New dimensions: {self.dimensions}")
                self.controller.dimensions = self.dimensions

                # Create new grid with new dimensions *BEFORE* initializing state or edges
                logger.debug("Creating new grid with new dimensions, rule: {local_rule}")
                if local_rule:
                    # --- CORRECTED ARGUMENT ORDER ---
                    new_grid = Grid(
                        self.dimensions,
                        self.neighborhood_type,
                        self.dimension_type,
                        self.coord_system,          # Pass coord_system positionally
                        gui=self,                   # Pass gui via keyword
                        rule=local_rule,            # Pass rule via keyword
                        unique_id=self._unique_id
                    )
                    # --- END CORRECTION ---
                    logger.debug(f"New grid created with shape: {new_grid.grid_array.shape}")

                    # Update controller grid
                    self.controller.grid = new_grid

                    # Initialize new state
                    density = GlobalSettings.Simulation.INITIAL_NODE_DENSITY # Define density here
                    logger.debug(f"Initializing new state with density: {density}")
                    self.controller._initialize_random_state(density)

                    # Log edge density settings
                    logger.debug(f"GlobalSettings.Simulation.INITIAL_EDGE_DENSITY: {GlobalSettings.Simulation.INITIAL_EDGE_DENSITY}")
                    if 'connect_probability' in self.controller.rule.params:
                        logger.debug(f"Rule connect_probability before init: {self.controller.rule.params['connect_probability']}")
                    else:
                        logger.debug("Rule connect_probability not set before init")

                    # Initialize edges
                    logger.debug("Initializing edges")
                    if self.rule is not None:
                        edge_init_type = self.rule.get_param('edge_initialization', 'RANDOM')
                    else:
                        raise ValueError("self.rule is not initialized. Ensure it is set before accessing its parameters.")

                    # Set the connect_probability to the current edge density
                    self.controller.rule.params['connect_probability'] = GlobalSettings.Simulation.INITIAL_EDGE_DENSITY

                    new_grid.initialize_edges(edge_init_type)

                    # Log edge density settings after init
                    logger.debug(f"GlobalSettings.Simulation.INITIAL_EDGE_DENSITY: {GlobalSettings.Simulation.INITIAL_EDGE_DENSITY}")
                    if 'connect_probability' in self.controller.rule.params:
                        logger.debug(f"Rule connect_probability after init: {self.controller.rule.params['connect_probability']}")
                    else:
                        logger.debug("Rule connect_probability not set after init")

                    # Calculate and log edge statistics
                    total_nodes = np.prod(self.dimensions)
                    active_nodes = np.sum(new_grid.grid_array > 0)
                    max_neighbors = new_grid.max_neighbors
                    max_possible_edges = active_nodes * max_neighbors / 2
                    actual_edges = len(new_grid.get_edges())
                    edge_ratio = actual_edges / max_possible_edges if max_possible_edges > 0 else 0.0

                    logger.debug(f"Total nodes: {total_nodes}, Active nodes: {active_nodes}")
                    logger.debug(f"Max possible edges: {max_possible_edges}, Actual edges: {actual_edges}, Edge ratio: {edge_ratio}")

                    # Clear highlighted edges and nodes
                    self.highlighted_nodes.clear()
                    self.highlighted_edges.clear()

                    # Update label and restore view *after* the grid is updated
                    current_size = GlobalSettings.Simulation.get_current_grid_size()
                    # --- MODIFIED: Access grid_size_label via ControlPanelUI ---
                    if hasattr(self, 'control_panel_ui') and self.control_panel_ui and hasattr(self.control_panel_ui, 'widgets') and 'grid_size_label' in self.control_panel_ui.widgets and isinstance(self.control_panel_ui.widgets['grid_size_label'], tk.Label):
                        self.control_panel_ui.widgets['grid_size_label'].config(text=f"Size: {current_size}")
                    # ---
                    self._enable_controls()

                    # CRITICAL FIX: Update the grid visualizer with the new grid
                    if hasattr(self, 'grid_visualizer') and self.grid_visualizer:
                        if self.grid is not None:
                            self.grid_visualizer.set_grid(self.grid)
                        logger.debug("Updated grid visualizer with new grid")

                        # CRITICAL: Trigger a full redraw
                        self.grid_visualizer.update_visualization_state()
                        logger.debug("Triggered full redraw after rule change")

                    # Restore simulation state
                    if was_running:
                        self.running = True

                    logger.info(f"Changed {self.controller.dimension_type.name} grid size to: {new_size}")

                else:
                    logger.error("Cannot create new grid because rule is None")
                    return

        except ValueError as e:
            logger.error(f"Invalid grid size value: {e}")
            messagebox.showerror("Error", f"Invalid grid size value: {e}")
        except Exception as e:
            logger.error(f"Error changing grid size: {e}")
            messagebox.showerror("Error", f"Failed to change grid size: {e}")
        finally:
            if hasattr(self, '_is_resizing'):
                self._is_resizing = False  # Clear flag
            if hasattr(self, '_debounce_timer'):
                self._debounce_timer = None # Clear the timer

    def _disable_controls(self):
        """Disable control widgets during updates"""
        for widget in self.widgets.values():
            if isinstance(widget, (tk.Button, tk.Scale, tk.OptionMenu, tk.Checkbutton, tk.Entry)):
                widget.config(state=tk.DISABLED)

    def _enable_controls(self):
        """Enable control widgets after updates"""
        for widget in self.widgets.values():
            if isinstance(widget, (tk.Button, tk.Scale, tk.OptionMenu, tk.Checkbutton, tk.Entry)):
                widget.config(state=tk.NORMAL)

    def _on_spacing_change(self, value_str: str):
        """Handle node spacing slider change, adjusting axis limits correctly.
           (Round 15: Remove forced render)"""
        log_prefix = "_on_spacing_change (R15 Render Fix): " # Updated round
        try:
            # --- ADDED: Check initialization/preset flag ---
            if hasattr(self, '_is_initializing_or_applying_preset') and self._is_initializing_or_applying_preset:
                logger.debug(f"{log_prefix}Skipping spacing change because flag is set.")
                # Update setting but don't redraw
                try:
                    spacing = float(value_str)
                    GlobalSettings.Visualization.set_node_spacing(spacing)
                except ValueError: pass # Ignore invalid values during init
                return
            # --- END ADDED ---

            spacing = float(value_str)
            GlobalSettings.Visualization.set_node_spacing(spacing)
            current_spacing = GlobalSettings.Visualization.NODE_SPACING

            logger.info(f"{log_prefix}Node spacing changed to: {current_spacing:.2f}")

            if not (hasattr(self, 'coord_system') and self.coord_system):
                logger.error(f"{log_prefix}Coordinate system not initialized, cannot update spacing.")
                return

            self.coord_system.update_parameters(node_spacing=current_spacing)

            # --- REMOVED: Manual limit update - let fit_view handle it ---
            # x_min, x_max = self.ax.get_xlim()
            # y_min, y_max = self.ax.get_ylim()
            # # This scaling logic was likely incorrect anyway
            # new_x_min = x_min * self.coord_system.scale_factor / 90.0 # Old scale factor?
            # new_x_max = x_max * self.coord_system.scale_factor / 90.0
            # new_y_min = y_min * self.coord_system.scale_factor / 90.0
            # new_y_max = y_max * self.coord_system.scale_factor / 90.0
            # self.ax.set_xlim(new_x_min, new_x_max)
            # self.ax.set_ylim(new_y_min, new_y_max)
            # ---

            # Invalidate blit cache and schedule a standard redraw
            if self.grid_visualizer and hasattr(self.grid_visualizer, 'blitting_manager'):
                self.grid_visualizer.blitting_manager.invalidate_cache()
            # --- REMOVED: _safe_plot_update(force=True) ---
            self._safe_plot_update() # Schedule standard update

        except ValueError as e:
            logger.error(f"{log_prefix}Invalid node spacing value: {e}")
            messagebox.showerror("Error", f"Invalid node spacing value: {e}", parent=self.root)
        except Exception as e:
            logger.error(f"{log_prefix}Error changing node spacing: {e}")
            messagebox.showerror("Error", f"Failed to change node spacing: {e}", parent=self.root)

    def _on_node_size_change(self, value_str: str):
        """Handle node size slider change, clamping NODE_SIZE and adjusting spacing if needed."""
        log_prefix = "_on_node_size_change: "
        try:
            node_size_multiplier = float(value_str)
            logger.info(f"{log_prefix}Attempting to set node size multiplier to: {node_size_multiplier:.3f}")

            if not hasattr(self, 'coord_system') or not self.coord_system:
                logger.error(f"{log_prefix}CoordinateSystem not initialized, cannot calculate dynamic max node size.")
                GlobalSettings.Visualization.NODE_SIZE = node_size_multiplier # Still set even if clamping fails
                return

            # --- Calculate Maximum Allowed Node Size based on current spacing ---
            max_allowed_size = GlobalSettings.Visualization.calculate_max_node_size_for_spacing(GlobalSettings.Visualization.NODE_SPACING)
            # Clamp the input node size to the calculated maximum
            clamped_node_size = min(node_size_multiplier, max_allowed_size)

            # --- Apply Clamped Value ---
            GlobalSettings.Visualization.NODE_SIZE = clamped_node_size # Set the clamped value

            # Update slider position if it was clamped
            if abs(clamped_node_size - node_size_multiplier) > 1e-4:
                node_size_scale_widget = self.control_panel_ui.widgets.get('node_size_scale') if self.control_panel_ui else None
                if isinstance(node_size_scale_widget, tk.Scale):
                    logger.debug(f"{log_prefix}Updating slider position to clamped value: {clamped_node_size:.3f}")
                    node_size_scale_widget.set(clamped_node_size)

            # Invalidate blit cache and force redraw
            if hasattr(self, 'grid_visualizer') and self.grid_visualizer:
                self.grid_visualizer.blitting_manager.invalidate_cache()
                self._safe_plot_update(force=True) # Correct call within SimulationGUI
            else:
                logger.warning(f"{log_prefix}GridVisualizer not available, cannot redraw.")

        except ValueError as e:
            logger.error(f"{log_prefix}Invalid node size value: {e}")
            messagebox.showerror("Error", f"Invalid node size value: {e}", parent=self.root)
        except Exception as e:
            logger.error(f"{log_prefix}Error handling node size change: {e}")
            logger.error(traceback.format_exc())

    def _on_node_density_change(self, value_str: str):
        """
        Handle node density slider change. Adds/removes active nodes randomly
        to approach the target density without full re-initialization.
        Clears queues on modification.
        (Round 50: Add initialization checks)
        """
        log_prefix = "_on_node_density_change (R50 Init Check): " # Updated round
        logger.info(f"{log_prefix}Callback triggered with value '{value_str}'.")

        # --- Skip if initializing/applying preset ---
        if hasattr(self, '_is_initializing_or_applying_preset') and self._is_initializing_or_applying_preset:
            logger.debug(f"{log_prefix}Skipping density change because init/preset flag is set.")
            try: # Still update global setting if possible
                density = float(value_str)
                if 0.0 <= density <= 1.0: GlobalSettings.Simulation.INITIAL_NODE_DENSITY = density
            except ValueError: pass
            return
        # ---

        # --- ADDED: Check if grid and previous arrays are ready ---
        if self.grid is None or self.grid.grid_array is None or \
           (self.controller and self.controller.rule and self.controller.rule.needs_neighbor_degrees and self.grid.previous_degree_array is None) or \
           (self.controller and self.controller.rule and self.controller.rule.needs_neighbor_active_counts and self.grid.previous_active_neighbor_array is None):
            logger.warning(f"{log_prefix}Grid or necessary previous state arrays not initialized. Cannot perform incremental update. Use Reset first.")
            # Optionally show a message to the user
            # messagebox.showinfo("Info", "Grid state not fully initialized. Please Reset the simulation before adjusting density.", parent=self.root)
            # Revert slider to current global setting
            node_density_scale_widget = self.control_panel_ui.widgets.get('node_density_scale') if self.control_panel_ui else None
            if isinstance(node_density_scale_widget, tk.Scale): node_density_scale_widget.set(GlobalSettings.Simulation.INITIAL_NODE_DENSITY)
            return
        # --- END ADDED CHECK ---

        # --- Pause simulation ---
        was_running = self.running
        self._pause_computation(reason="Change Node Density")
        original_blitting = self.grid_visualizer.blitting_manager.enabled if hasattr(self, 'grid_visualizer') and self.grid_visualizer else GlobalSettings.ENABLE_BLITTING
        if hasattr(self, 'grid_visualizer') and self.grid_visualizer: self.grid_visualizer.blitting_manager.set_enabled(False)
        # ---

        try:
            target_density = float(value_str)
            if not (0.0 <= target_density <= 1.0):
                raise ValueError("Density must be between 0.0 and 1.0")

            logger.info(f"{log_prefix}Adjusting node density towards {target_density:.3f}.")
            self._clear_lasso_selection() # Clear selection before modifying grid

            total_nodes = self.grid.total_nodes
            logger.debug(f"{log_prefix}Grid state BEFORE density change: {np.sum(self.grid.grid_array.ravel() > 1e-6)} active nodes.")
            current_active_indices = np.where(self.grid.grid_array.ravel() > 1e-6)[0]
            current_active_count = len(current_active_indices)
            target_active_count = int(round(total_nodes * target_density))
            delta_nodes = target_active_count - current_active_count

            logger.debug(f"{log_prefix}Total={total_nodes}, CurrentActive={current_active_count}, TargetActive={target_active_count}, Delta={delta_nodes}")

            modified = False
            if delta_nodes != 0:
                self._push_grid_state_to_undo(f"Adjust Node Density to {target_density:.3f}")
                if delta_nodes > 0: # Add nodes
                    inactive_indices = np.where(self.grid.grid_array.ravel() <= 1e-6)[0]
                    logger.debug(f"{log_prefix}Attempting to add {delta_nodes} nodes. Found {len(inactive_indices)} inactive nodes.")
                    if len(inactive_indices) < delta_nodes:
                        logger.warning(f"{log_prefix}Not enough inactive nodes ({len(inactive_indices)}) to add {delta_nodes}. Adding as many as possible.")
                        nodes_to_add_indices = inactive_indices
                    else:
                        nodes_to_add_indices = np.random.choice(inactive_indices, size=delta_nodes, replace=False)

                    if nodes_to_add_indices.size > 0:
                        logger.info(f"{log_prefix}Adding {len(nodes_to_add_indices)} nodes.")
                        activate_state = 1.0
                        if self.controller and self.controller.rule:
                            rule = self.controller.rule; node_type = getattr(rule, 'node_state_type', StateType.BINARY); min_node = getattr(rule, 'min_node_state', 0.0); max_node = getattr(rule, 'max_node_state', 1.0); initial_cont = rule.get_param('initial_continuous_node_state', 0.1)
                            if node_type == StateType.INTEGER: activate_state = min_node + 1
                            elif node_type == StateType.REAL: activate_state = max(initial_cont, min_node + 1e-6)
                            activate_state = np.clip(activate_state, min_node, max_node)
                        self.grid.grid_array.ravel()[nodes_to_add_indices] = activate_state
                        modified = True
                    else:
                        logger.debug(f"{log_prefix}No inactive nodes available to add.")
                        self._pop_undo_if_match(f"Adjust Node Density to {target_density:.3f}") # Pop if no change

                else: # Remove nodes (delta_nodes < 0)
                    nodes_to_remove_count = abs(delta_nodes)
                    logger.debug(f"{log_prefix}Attempting to remove {nodes_to_remove_count} nodes. Found {len(current_active_indices)} active nodes.")
                    if len(current_active_indices) < nodes_to_remove_count:
                        logger.warning(f"{log_prefix}Not enough active nodes ({len(current_active_indices)}) to remove {nodes_to_remove_count}. Removing all active.")
                        nodes_to_remove_indices = current_active_indices
                    else:
                        nodes_to_remove_indices = np.random.choice(current_active_indices, size=nodes_to_remove_count, replace=False)

                    if nodes_to_remove_indices.size > 0:
                        logger.info(f"{log_prefix}Removing {len(nodes_to_remove_indices)} nodes.")
                        deactivate_state = 0.0
                        if self.controller and self.controller.rule: deactivate_state = getattr(self.controller.rule, 'min_node_state', 0.0)
                        self.grid.grid_array.ravel()[nodes_to_remove_indices] = deactivate_state
                        modified = True
                    else:
                        logger.debug(f"{log_prefix}No active nodes available to remove.")
                        self._pop_undo_if_match(f"Adjust Node Density to {target_density:.3f}") # Pop if no change

            if modified:
                # Update grid state dependents
                self.grid.update_active_nodes()
                self.grid.previous_active_nodes_set = self.grid.active_nodes.copy()
                self.grid.populate_spatial_hash() # Repopulate hash
                self._calculate_initial_previous_arrays() # Recalculate previous arrays
                logger.info(f"{log_prefix}Grid state updated. Active nodes: {len(self.grid.active_nodes)}")
                # --- Clear queues and force redraw ---
                self._clear_computation_and_render_queues()
                self._force_initial_render()
                # ---
                # --- Update Initial Conditions display ---
                self._programmatic_change = True
                try: self.initial_conditions_var.set("Custom (Density Modified)")
                finally: self.root.after(10, self._clear_programmatic_change_flag)
                self._update_initial_conditions_selector()
                # ---
                self._set_active_preset(None) # Clear active preset
            else:
                logger.debug(f"{log_prefix}No nodes added or removed.")

        except ValueError as e:
            logger.error(f"{log_prefix}Invalid node density value: {value_str} ({e})")
            messagebox.showerror("Error", f"Invalid node density value: {value_str}", parent=self.root)
            node_density_scale_widget = self.control_panel_ui.widgets.get('node_density_scale') if self.control_panel_ui else None
            if isinstance(node_density_scale_widget, tk.Scale): node_density_scale_widget.set(GlobalSettings.Simulation.INITIAL_NODE_DENSITY)
        except Exception as e:
            logger.error(f"{log_prefix}Error changing node density: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Error", f"Failed to change node density: {e}", parent=self.root)
            node_density_scale_widget = self.control_panel_ui.widgets.get('node_density_scale') if self.control_panel_ui else None
            if isinstance(node_density_scale_widget, tk.Scale): node_density_scale_widget.set(GlobalSettings.Simulation.INITIAL_NODE_DENSITY)
        finally:
            if hasattr(self, 'grid_visualizer') and self.grid_visualizer: self.grid_visualizer.blitting_manager.set_enabled(original_blitting)
            # Resume computation if it was running
            if was_running: self._resume_computation(reason="Change Node Density Complete")
            logger.debug(f"{log_prefix}Exiting callback.")

    def _on_edge_density_change(self, value_str: str):
        """
        Handle edge density slider change. Adds/removes edges randomly between
        currently active nodes to approach the target density.
        Clears queues on modification.
        (Round 50: Add initialization checks)
        """
        log_prefix = "_on_edge_density_change (R50 Init Check): " # Updated round
        logger.info(f"{log_prefix}Callback triggered with value '{value_str}'.")

        # --- Skip if initializing/applying preset ---
        if hasattr(self, '_is_initializing_or_applying_preset') and self._is_initializing_or_applying_preset:
            logger.debug(f"{log_prefix}Skipping density change because flag is set.")
            try: # Still update global setting if possible
                density = float(value_str)
                if 0.0 <= density <= 1.0: GlobalSettings.Simulation.INITIAL_EDGE_DENSITY = density
                if self.controller and self.controller.rule:
                    self.controller.rule.update_parameter('connect_probability', density)
            except ValueError: pass
            return
        # ---

        # --- ADDED: Check if grid and previous arrays are ready ---
        # Edge density adjustment primarily needs the grid and edge data itself,
        # but recalculating previous arrays requires them to exist.
        if self.grid is None or self.grid.grid_array is None or \
           (self.controller and self.controller.rule and self.controller.rule.needs_neighbor_degrees and self.grid.previous_degree_array is None) or \
           (self.controller and self.controller.rule and self.controller.rule.needs_neighbor_active_counts and self.grid.previous_active_neighbor_array is None):
            logger.warning(f"{log_prefix}Grid or necessary previous state arrays not initialized. Cannot perform incremental update. Use Reset first.")
            # Revert slider to current global setting
            edge_density_scale_widget = self.control_panel_ui.widgets.get('edge_density_scale') if self.control_panel_ui else None
            if isinstance(edge_density_scale_widget, tk.Scale): edge_density_scale_widget.set(GlobalSettings.Simulation.INITIAL_EDGE_DENSITY)
            return
        # --- END ADDED CHECK ---

        # --- Pause simulation ---
        was_running = self.running
        self._pause_computation(reason="Change Edge Density")
        original_blitting = self.grid_visualizer.blitting_manager.enabled if hasattr(self, 'grid_visualizer') and self.grid_visualizer else GlobalSettings.ENABLE_BLITTING
        if hasattr(self, 'grid_visualizer') and self.grid_visualizer: self.grid_visualizer.blitting_manager.set_enabled(False)
        # ---

        try:
            target_density = float(value_str)
            if not (0.0 <= target_density <= 1.0):
                raise ValueError("Density must be between 0.0 and 1.0")

            if self.grid is None or self.controller is None or self.controller.rule is None:
                logger.error(f"{log_prefix}Grid, Controller, or Rule not initialized.")
                return

            # --- Check if rule supports edges ---
            edge_init_type = self.controller.rule.get_param('edge_initialization', 'NONE')
            if edge_init_type == 'NONE':
                logger.warning(f"{log_prefix}Rule '{self.controller.rule.name}' does not support edges (edge_initialization=NONE). Slider has no effect.")
                return
            # ---

            logger.info(f"{log_prefix}Adjusting edge density towards {target_density:.3f}.")
            self._clear_lasso_selection()

            # --- Calculate Target vs Current Edges ---
            active_indices = np.where(self.grid.grid_array.ravel() > 1e-6)[0]
            num_active_nodes = len(active_indices)
            current_edges_set = self.grid.edges.copy() # Work with a copy
            current_edge_count = len(current_edges_set)

            max_possible_edges_now = 0
            if num_active_nodes >= 2:
                max_possible_edges_now = num_active_nodes * self.grid.max_neighbors // 2
                max_possible_edges_now = max(1, max_possible_edges_now) # Avoid division by zero later

            target_edge_count = int(round(max_possible_edges_now * target_density))
            delta_edges = target_edge_count - current_edge_count

            logger.debug(f"{log_prefix}ActiveNodes={num_active_nodes}, MaxPossibleEdges={max_possible_edges_now}, CurrentEdges={current_edge_count}, TargetEdges={target_edge_count}, Delta={delta_edges}")

            modified = False
            if delta_edges != 0:
                self._push_grid_state_to_undo(f"Adjust Edge Density to {target_density:.3f}")
                if delta_edges > 0: # Add Edges
                    logger.info(f"{log_prefix}Adding {delta_edges} edges.")
                    potential_new_edges = set()
                    for node1_idx in active_indices:
                        neighbors = self.grid.get_neighbors(node1_idx, self.grid.coord_system)
                        for node2_idx in neighbors:
                            if node2_idx > node1_idx and node2_idx in active_indices:
                                node1_coords = tuple(_unravel_index(node1_idx, self.grid.dimensions))
                                node2_coords = tuple(_unravel_index(node2_idx, self.grid.dimensions))
                                edge_tuple = self.grid._ordered_edge(node1_coords, node2_coords)
                                if edge_tuple not in current_edges_set:
                                    potential_new_edges.add(edge_tuple)
                    logger.debug(f"{log_prefix}Found {len(potential_new_edges)} potential new edges to add.")

                    edges_to_add_count = min(delta_edges, len(potential_new_edges))
                    if edges_to_add_count > 0:
                        edges_to_add_list = random.sample(list(potential_new_edges), edges_to_add_count)
                        for edge_coords in edges_to_add_list:
                            n1c, n2c = edge_coords
                            idx1 = _ravel_multi_index(np.array(n1c), self.grid.dimensions)
                            idx2 = _ravel_multi_index(np.array(n2c), self.grid.dimensions)
                            self.grid.add_edge(idx1, idx2, edge_state=1.0) # Add binary edge for simplicity
                        modified = True
                        logger.info(f"{log_prefix}Added {edges_to_add_count} edges.")
                    else:
                        logger.debug(f"{log_prefix}No potential new edges found to add.")
                        self._pop_undo_if_match(f"Adjust Edge Density to {target_density:.3f}")

                else: # Remove Edges (delta_edges < 0)
                    edges_to_remove_count = abs(delta_edges)
                    logger.info(f"{log_prefix}Removing {edges_to_remove_count} edges.")
                    logger.debug(f"{log_prefix}Found {len(current_edges_set)} existing edges to remove from.")
                    if len(current_edges_set) < edges_to_remove_count:
                        logger.warning(f"{log_prefix}Not enough edges ({len(current_edges_set)}) to remove {edges_to_remove_count}. Removing all.")
                        edges_to_remove_list = list(current_edges_set)
                    else:
                        edges_to_remove_list = random.sample(list(current_edges_set), edges_to_remove_count)

                    if edges_to_remove_list:
                        for edge_coords in edges_to_remove_list:
                            n1c, n2c = edge_coords
                            idx1 = _ravel_multi_index(np.array(n1c), self.grid.dimensions)
                            idx2 = _ravel_multi_index(np.array(n2c), self.grid.dimensions)
                            self.grid.remove_edge(idx1, idx2)
                        modified = True
                        logger.info(f"{log_prefix}Removed {len(edges_to_remove_list)} edges.")
                    else:
                        logger.debug(f"{log_prefix}No edges available to remove.")
                        self._pop_undo_if_match(f"Adjust Edge Density to {target_density:.3f}")

            if modified:
                # Update grid state dependents (only need to recalc degrees/neighbors)
                self._calculate_initial_previous_arrays() # Recalculate previous arrays
                logger.info(f"{log_prefix}Grid edges updated. Edge count: {len(self.grid.edges)}")
                # --- Clear queues and force redraw ---
                self._clear_computation_and_render_queues()
                self._force_initial_render()
                # ---
                # --- Update Initial Conditions display ---
                self._programmatic_change = True
                try: self.initial_conditions_var.set("Custom (Density Modified)")
                finally: self.root.after(10, self._clear_programmatic_change_flag)
                self._update_initial_conditions_selector()
                # ---
                self._set_active_preset(None) # Clear active preset
            else:
                logger.debug(f"{log_prefix}No edges added or removed.")

        except ValueError as e:
            logger.error(f"{log_prefix}Invalid edge density value: {value_str} ({e})")
            messagebox.showerror("Error", f"Invalid edge density value: {value_str}", parent=self.root)
            edge_density_scale_widget = self.control_panel_ui.widgets.get('edge_density_scale') if self.control_panel_ui else None
            if isinstance(edge_density_scale_widget, tk.Scale): edge_density_scale_widget.set(GlobalSettings.Simulation.INITIAL_EDGE_DENSITY)
        except Exception as e:
            logger.error(f"{log_prefix}Error changing edge density: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Error", f"Failed to change edge density: {e}", parent=self.root)
            edge_density_scale_widget = self.control_panel_ui.widgets.get('edge_density_scale') if self.control_panel_ui else None
            if isinstance(edge_density_scale_widget, tk.Scale): edge_density_scale_widget.set(GlobalSettings.Simulation.INITIAL_EDGE_DENSITY)
        finally:
            if hasattr(self, 'grid_visualizer') and self.grid_visualizer: self.grid_visualizer.blitting_manager.set_enabled(original_blitting)
            # Resume computation if it was running
            if was_running: self._resume_computation(reason="Change Edge Density Complete")
            logger.debug(f"{log_prefix}Exiting callback.")

    def _on_highlight_toggle(self):
        """Handle highlight toggle checkbox change by updating the shared parameter
           for the preparation thread and invalidating the blit cache.
           Does NOT force an immediate redraw.
           (Round 20: Update prep thread params)
           (Round 21/24: Remove forced redraw, only update prep state & invalidate blit)"""
        log_prefix = "_on_highlight_toggle (R24 Non-Blocking): " # Updated round
        try:
            if not hasattr(self, 'highlight_var'):
                logger.error(f"{log_prefix}highlight_var missing.")
                return

            highlight_state = self.highlight_var.get()
            logger.info(f"{log_prefix}Highlight toggle changed to: {highlight_state}")

            # --- Update prep thread params under lock ---
            with self._prep_params_lock: # Ensure lock is used
                self._prep_visualization_params['highlight_on'] = highlight_state
            logger.debug(f"{log_prefix}Updated prep thread highlight_on parameter to {highlight_state}.")
            # ---

            # --- Invalidate Blit Cache ---
            if hasattr(self, 'grid_visualizer') and self.grid_visualizer:
                self.grid_visualizer.blitting_manager.invalidate_cache()
                logger.debug(f"{log_prefix}Invalidated blitting cache due to highlight toggle.")
            else:
                logger.warning(f"{log_prefix}GridVisualizer not initialized, cannot invalidate blit cache.")
            # ---

        except Exception as e:
            logger.error(f"{log_prefix}Error toggling highlights: {e}")
            logger.error(traceback.format_exc())

    def _on_bg_color_change(self, value: str):
        """Handle background color change"""
        try:
            GlobalSettings.Colors.BACKGROUND = value
            self.root.configure(bg=value)
            if self.main_frame is not None:
                self.main_frame.configure(bg=value)
            else:
                logger.error("main_frame is not initialized. Cannot configure background color.")
            if self.viz_frame is not None:
                self.viz_frame.configure(bg=value)
            if self.main_frame is not None:
                self.fig.set_facecolor(value)
            if hasattr(self, 'ax') and self.ax is not None:
                self.ax.set_facecolor(value)
            # Trigger a full redraw
            if self.grid_visualizer is not None:
                self.grid_visualizer.update_visualization_state(background_color=value)
            logger.info(f"Background color changed to: {value}")
        except Exception as e:
            logger.error(f"Error changing background color: {e}")
                    
    def _on_node_color_change(self, value: str):
        """Handle node color change"""
        try:
            GlobalSettings.Colors.NODE_ACTIVE = value
            # Trigger a full redraw with the new color
            if self.grid_visualizer is not None:
                self.grid_visualizer.update_visualization_state(node_color=value)
            logger.info(f"Node color changed to: {value}")
        except Exception as e:
            logger.error(f"Error changing node color: {e}")

    def _on_new_node_color_change(self, value: str):
        """Handle new node color change"""
        try:
            GlobalSettings.Colors.NODE_EDGE_NEW = value
            # Trigger a full redraw with the new color
            if self.grid_visualizer is not None:
                self.grid_visualizer.update_visualization_state(new_node_color=value)
            logger.info(f"New node color changed to: {value}")
        except Exception as e:
            logger.error(f"Error changing new node color: {e}")

    def _on_default_edge_color_change(self, value: str):
        """Handle default edge color change"""
        try:
            GlobalSettings.Colors.NODE_EDGE_OLD = value
            # Trigger a full redraw with the new color
            if self.grid_visualizer is not None:
                self.grid_visualizer.update_visualization_state(default_edge_color=value)
            logger.info(f"Default edge color changed to: {value}")
        except Exception as e:
            logger.error(f"Error changing default edge color: {e}")

    def _on_new_edge_color_change(self, value: str):
        """Handle new edge color change"""
        try:
            GlobalSettings.Colors.NODE_EDGE_NEW = value
            # Trigger a full redraw with the new color
            if self.grid_visualizer is not None:
                self.grid_visualizer.update_visualization_state(new_edge_color=value)
            logger.info(f"New edge color changed to: {value}")
        except Exception as e:
            logger.error(f"Error changing new edge color: {e}")
            
    def _on_speed_change(self, value: str):
        """Handle speed slider change"""
        try:
            speed = float(value)
            # Convert speed (0-1000) to delay (1000-10ms)
            self.step_delay = int(1000 - (speed * 0.99)) +1 # Gives range 1000ms to 10ms
            logger.info(f"Speed changed to {speed}, delay set to {self.step_delay}")
        except ValueError:
            logger.error("Invalid speed value")
                
    def _get_view_center_grid_coords(self):
        """Gets the center of the current view in *grid* coordinates."""
        if self.grid is None or self.grid_visualizer is None:
            return (0, 0) if self.controller.dimension_type == Dimension.TWO_D else (0, 0, 0)

        # Get current view limits in display coordinates
        x_min, x_max = self.ax.get_xlim()
        y_min, y_max = self.ax.get_ylim()
        center_x_display = (x_min + x_max) / 2
        center_y_display = (y_min + y_max) / 2

        if self.controller.dimension_type == Dimension.THREE_D:
            z_min, z_max = self.ax.get_zlim()  # type: ignore
            center_z_display = (z_min + z_max) / 2
            # Convert display center to grid center
            center_grid = self.grid_visualizer.coord_system.display_to_grid((center_x_display, center_y_display, center_z_display))
        else:
            # Convert display center to grid center
            center_grid = self.grid_visualizer.coord_system.display_to_grid((center_x_display, center_y_display))
        return center_grid # Always return a tuple

    def _find_nearest_node_to_center(self):
        """Find the node nearest to the center of the current view (in display coordinates)."""
        if self.grid is None or self.grid_visualizer is None:
            return None

        # Get current view limits in display coordinates
        x_min, x_max = self.ax.get_xlim()
        y_min, y_max = self.ax.get_ylim()
        center_x_display = (x_min + x_max) / 2
        center_y_display = (y_min + y_max) / 2

        min_dist_sq = float('inf')
        nearest_node_idx = None

        # Iterate through *active* nodes and find the closest one
        for node_idx in self.grid.get_node_positions():
            if self.grid.grid_array.ravel()[node_idx] > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD:
                # Get display coordinates of the node
                display_coords = self.grid_visualizer.coord_system.index_to_display(node_idx)

                # Calculate squared distance to center
                dist_sq = (display_coords[0] - center_x_display)**2 + (display_coords[1] - center_y_display)**2
                if self.grid.dimension_type == Dimension.THREE_D:
                    dist_sq += (display_coords[2] - (self.ax.get_zlim()[0] + self.ax.get_zlim()[1]) / 2)**2  # type: ignore

                # Update if closer
                if dist_sq < min_dist_sq:
                    min_dist_sq = dist_sq
                    nearest_node_idx = node_idx

        return nearest_node_idx

    def _calculate_initial_previous_arrays(self):
        """Calculates and sets the initial previous_degree_array and
           previous_active_neighbor_array based on the current grid state.
           (Round 4: New helper method)"""
        log_prefix = "SimulationGUI._calculate_initial_previous_arrays: "
        if self.grid is None or self.controller is None or self.controller.rule is None:
            logger.error(f"{log_prefix}Cannot calculate: Grid, Controller, or Rule is None.")
            return

        try:
            logger.debug(f"{log_prefix}Calculating initial previous arrays...")
            initial_grid_array_flat = self.grid.grid_array.ravel()
            initial_edge_set = self.grid.edges.copy()
            initial_degree_array = np.zeros(self.grid.total_nodes, dtype=np.int32)
            initial_active_neighbor_array = np.zeros(self.grid.total_nodes, dtype=np.int32)
            activity_threshold = 1e-6

            # Calculate initial degrees
            if self.controller.rule.needs_neighbor_degrees:
                for edge_coords in initial_edge_set:
                    try:
                        node1_coords, node2_coords = edge_coords
                        idx1 = _ravel_multi_index(np.array(node1_coords), self.grid.dimensions)
                        idx2 = _ravel_multi_index(np.array(node2_coords), self.grid.dimensions)
                        if 0 <= idx1 < self.grid.total_nodes: initial_degree_array[idx1] += 1
                        if 0 <= idx2 < self.grid.total_nodes: initial_degree_array[idx2] += 1
                    except Exception as degree_calc_err:
                        logger.error(f"{log_prefix}Error processing edge {edge_coords} for initial degree calculation: {degree_calc_err}")
                self.grid.previous_degree_array = initial_degree_array
                logger.debug(f"{log_prefix}Set initial previous_degree_array (Sum: {np.sum(initial_degree_array)}).")
            else:
                self.grid.previous_degree_array = None

            # Calculate initial active neighbors
            if self.controller.rule.needs_neighbor_active_counts:
                for node_idx in range(self.grid.total_nodes):
                    count = 0
                    neighbors_indices = self.grid.get_neighbors(node_idx, self.grid.coord_system)
                    for neighbor_idx in neighbors_indices:
                        if neighbor_idx != -1 and 0 <= neighbor_idx < initial_grid_array_flat.size and initial_grid_array_flat[neighbor_idx] > activity_threshold:
                            count += 1
                    initial_active_neighbor_array[node_idx] = count
                self.grid.previous_active_neighbor_array = initial_active_neighbor_array
                logger.debug(f"{log_prefix}Set initial previous_active_neighbor_array (Sum: {np.sum(initial_active_neighbor_array)}).")
            else:
                self.grid.previous_active_neighbor_array = None

        except Exception as e_prev:
            logger.error(f"{log_prefix}Error calculating initial previous state arrays: {e_prev}")
            self.grid.previous_degree_array = np.zeros(self.grid.total_nodes, dtype=np.int32) # Fallback
            self.grid.previous_active_neighbor_array = np.zeros(self.grid.total_nodes, dtype=np.int32) # Fallback
    
    def _on_initial_conditions_change(self, condition_name: str):
        """
        Handle initial conditions selection change. Updates rule parameter,
        stops simulation, clears grid, applies selected condition via Manager,
        and forces redraw.
        (Round 19: Apply condition directly via Manager)
        (Round 4: Trigger full reset and apply selected condition)
        """
        log_prefix = f"_on_initial_conditions_change (R19 Direct Apply): " # Updated round
        logger.info(f"{log_prefix}Callback triggered with condition_name='{condition_name}'")

        # --- Programmatic Change Check ---
        if self._programmatic_change:
            logger.debug(f"{log_prefix}Skipping callback because _programmatic_change flag is set.")
            return
        # ---

        # --- Check if selection is valid ---
        if not condition_name or condition_name == "(None)":
            logger.warning(f"{log_prefix}Invalid condition selected: '{condition_name}'. No action taken.")
            # Optionally revert the dropdown variable if needed
            # if self.controller and self.controller.rule:
            #     self.initial_conditions_var.set(self.controller.rule.get_param('initial_conditions', "Random"))
            return
        # ---

        # --- Stop Simulation ---
        if not self._stop_computation_threads(reason=f"Change Initial Condition to {condition_name}"):
            logger.error(f"{log_prefix}Aborted: Failed to stop computation threads cleanly.")
            # Revert dropdown if stop failed
            if self.controller and self.controller.rule: self.initial_conditions_var.set(self.controller.rule.get_param('initial_conditions', "Random"))
            return
        if hasattr(self, '_stop_event') and self._stop_event: self._stop_event.clear()
        # ---

        original_blitting = self.grid_visualizer.blitting_manager.enabled if hasattr(self, 'grid_visualizer') and self.grid_visualizer else GlobalSettings.ENABLE_BLITTING
        if hasattr(self, 'grid_visualizer') and self.grid_visualizer: self.grid_visualizer.blitting_manager.set_enabled(False)
        logger.info(f"\n{'='*25} Changing Initial Condition: {condition_name} {'='*25}")
        try:
            logger.info(f"{log_prefix}Changing initial conditions to: {condition_name}")
            self._clear_lasso_selection()
            self._push_grid_state_to_undo(f"Set Initial Condition: {condition_name}")

            # --- Update Rule Parameter ---
            rule_param_updated = False
            if self.controller and self.controller.rule:
                if self.controller.rule.update_parameter('initial_conditions', condition_name):
                    logger.debug(f"{log_prefix}Updated rule's initial_conditions parameter to: {condition_name}")
                    rule_param_updated = True
                else: logger.warning(f"{log_prefix}Failed to update rule's initial_conditions parameter to: {condition_name}")
            else: logger.error(f"{log_prefix}Rule is not set. Cannot update initial conditions parameter."); return
            # ---

            # --- Reset Grid and Apply Selected Condition ---
            # Reset state but keep generation counter (optional, could reset gen too)
            self._reset_simulation_state_and_visualization(clear_grid_content=True, initialize_grid_content=False, reset_generation_counter=True)
            logger.debug(f"{log_prefix}Simulation state reset.")

            # --- MODIFIED: Apply the selected condition directly using the Manager ---
            manager = InitialConditionManager.get_instance()
            logger.info(f"{log_prefix}Calling InitialConditionManager.apply('{condition_name}', grid_id={id(self.grid)})")
            if self.grid is not None:
                manager.apply(condition_name, self.grid) # Use the selected name
            else:
                logger.error(f"Cannot apply initial condition '{condition_name}' because self.grid is None.")
            if self.grid is not None:
                logger.info(f"{log_prefix}Applied condition '{condition_name}'. Active nodes: {len(self.grid.active_nodes)}")
            else:
                logger.warning(f"{log_prefix}Cannot log active nodes because self.grid is None.")
            # --- END MODIFIED ---

            # Calculate initial previous arrays AFTER applying condition
            self._calculate_initial_previous_arrays() # Call helper

            # --- Final Updates ---
            if self.grid is not None:
                self.grid.populate_spatial_hash()
            else:
                logger.error("Cannot call populate_spatial_hash because self.grid is None.")
            self._force_initial_render()
            self._set_active_preset(None) # Clear active preset
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui: self.control_panel_ui.update_button_states()
            logger.info(f"{log_prefix}Applied initial condition '{condition_name}' successfully.")

        except InterruptedError:
            logger.warning(f"{log_prefix}Initial condition application '{condition_name}' was cancelled.")
        except Exception as e:
            logger.error(f"{log_prefix}Error changing initial conditions: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Error", f"Failed to change initial conditions: {e}")
            if self.controller and self.controller.rule: self.initial_conditions_var.set(self.controller.rule.get_param('initial_conditions', "Random"))
        finally:
            if hasattr(self, 'grid_visualizer') and self.grid_visualizer: self.grid_visualizer.blitting_manager.set_enabled(original_blitting)
            self.running = False; self.paused = False; self._fixed_steps_running = False; self._stopped = False # Set stopped=False after change
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui: self.control_panel_ui.update_button_states()
            self._initialization_complete = True
            logger.debug(f"{log_prefix}Set _initialization_complete = True in finally block.")

    def _update_initial_conditions_selector(self):
        """Update the initial conditions selector options, preserving special values like 'Pattern' or 'Shape: ...' if currently set.
           (Round 46: Preserve current value during update)"""

        # --- Access widget via control_panel_ui ---
        if not hasattr(self, 'control_panel_ui') or not self.control_panel_ui:
            logger.error("ControlPanelUI not initialized, cannot update initial conditions selector.")
            return
        initial_conditions_selector = self.control_panel_ui.widgets.get('initial_conditions_selector')
        # ---

        if not isinstance(initial_conditions_selector, tk.OptionMenu):
            logger.error("Initial conditions selector widget not found or invalid type.")
            return

        log_prefix = "SimulationGUI._update_initial_conditions_selector (R46 Preserve): " # Updated round
        # --- Store the value BEFORE rebuilding ---
        value_before_update = self.initial_conditions_var.get()
        logger.debug(f"{log_prefix}Updating dropdown. Value BEFORE update: '{value_before_update}'")
        # ---

        try:
            manager = InitialConditionManager.get_instance()
            standard_condition_names = manager.get_all_names() # Get standard names

            # --- Determine the final list of options to display ---
            display_names = list(standard_condition_names)
            # --- Check if the value before update is special ---
            is_special_value = (value_before_update == "Pattern" or value_before_update.startswith("Shape: "))

            # Add the current value to the display list if it's not standard
            if value_before_update not in display_names:
                # Try inserting after "Random" if possible
                try:
                    random_index = display_names.index("Random")
                    display_names.insert(random_index + 1, value_before_update)
                except ValueError:
                    display_names.insert(0, value_before_update) # Insert at beginning if "Random" not found
                logger.debug(f"{log_prefix}Added current value '{value_before_update}' to display options.")
            # ---

            if not display_names: display_names = ["(None)"] # Fallback

            menu = initial_conditions_selector['menu']
            if menu is None:
                logger.error(f"{log_prefix}Initial conditions selector menu not found.")
                return
            if not menu.winfo_exists():
                 logger.warning(f"{log_prefix}Initial conditions selector menu widget destroyed.")
                 return

            # --- Rebuild Menu ---
            menu.delete(0, 'end')
            for name in display_names:
                # Command still uses the main variable's value at the time of selection
                menu.add_command(label=name, command=functools.partial(self._on_initial_conditions_change, name))

            # --- Set Variable Value (Protected by Flag) ---
            # Determine the final target value: Use the value *before* the update if it's valid in the new display list.
            target_value = value_before_update
            if target_value not in display_names:
                # If the original value is somehow invalid even after adding it, default to first
                logger.warning(f"{log_prefix}Original value '{target_value}' still not in final options {display_names}. Resetting var to '{display_names[0]}'.")
                target_value = display_names[0] if display_names else ""

            logger.debug(f"{log_prefix}Attempting to set initial_conditions_var to '{target_value}'. Current _programmatic_change: {self._programmatic_change}")
            # The flag should be set by the caller (e.g., apply_grid_preset) before this method is called
            # if the change is programmatic.
            self.initial_conditions_var.set(target_value)
            logger.debug(f"{log_prefix}Successfully set initial_conditions_var to '{target_value}'.")

            logger.debug(f"{log_prefix}Initial conditions selector updated. Final selected value: {self.initial_conditions_var.get()}")

        except Exception as e:
            logger.error(f"{log_prefix}Error updating initial conditions selector: {e}")
            logger.error(traceback.format_exc())

    def _on_rule_type_change(self, rule_type: str):
        """Handle rule type (category) change and update instance selector."""

        try:
            logger.debug(f"Rule type changed to: {rule_type}")

            # --- MODIFIED: More Robust Widget Access ---
            if not hasattr(self, 'control_panel_ui') or not self.control_panel_ui:
                logger.error("ControlPanelUI not initialized, cannot update rule instance selector.")
                return
            if not hasattr(self.control_panel_ui, 'widgets'):
                 logger.error("ControlPanelUI widgets dictionary not initialized.")
                 return

            rule_instance_selector = self.control_panel_ui.widgets.get('rule_instance_selector')
            if not isinstance(rule_instance_selector, tk.OptionMenu):
                logger.error(f"Rule instance selector widget not found or invalid type in ControlPanelUI. Found: {type(rule_instance_selector)}")
                # Log available widgets for debugging
                logger.debug(f"Available widgets in ControlPanelUI: {list(self.control_panel_ui.widgets.keys())}")
                return
            # --- END MODIFIED ---

            # Get available rule names for this type from RuleLibraryManager
            available_rule_names = sorted(list(dict.fromkeys(RuleLibrary.get_rules_in_category(rule_type)))) # Deduplicate and sort
            logger.debug(f"Available rules for category '{rule_type}': {available_rule_names}")

            # Get the menu widget associated with the instance selector
            menu = rule_instance_selector['menu']
            if menu is None:
                logger.error("Rule instance selector menu not found.")
                return

            # Clear existing options
            menu.delete(0, 'end')

            # Add new options
            new_selection = ""
            if available_rule_names:
                new_selection = available_rule_names[0] # Default to first rule NAME
                for rule_name in available_rule_names: # Iterate through NAMES
                    # Use functools.partial to correctly bind the rule_name
                    menu.add_command(label=rule_name,
                                    command=functools.partial(self._on_rule_instance_change, rule_name))
            else:
                # Add a disabled placeholder if no rules are in the category
                menu.add_command(label=f"(No {rule_type})", state="disabled") # More specific placeholder

            # Set the variable to the new selection (first rule name or placeholder)
            self.rule_instance_var.set(new_selection if available_rule_names else f"(No {rule_type})")
            logger.debug(f"Set rule_instance_var to: '{self.rule_instance_var.get()}'")

            # --- Explicitly trigger rule change ONLY if a valid rule is selected ---
            if new_selection:
                 logger.debug(f"Explicitly calling set_rule for '{new_selection}'")
                 self.set_rule(new_selection) # Call set_rule directly
            else:
                 logger.warning(f"No rules found in category/favorites '{rule_type}', cannot select a default instance.")
                 # Clear the grid or show a message? For now, do nothing, leaving the previous rule active.

        except KeyError as e:
             logger.error(f"Error accessing widget key during rule type change: {e}")
             messagebox.showerror("Error", f"Internal error updating rule list: Missing widget key.")
        except Exception as e:
            logger.error(f"Error in _on_rule_type_change: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Error", f"Failed to change rule type: {e}")

    def _on_rule_instance_change(self, rule_name: str):
        """Handle rule instance selection change, preventing reload during programmatic changes."""


        log_prefix = f"SimulationGUI._on_rule_instance_change(Rule='{rule_name}'): "
        logger.debug(f"{log_prefix}ENTRY.")

        # --- ADDED: Check programmatic change flag ---
        if self._programmatic_change:
            logger.debug(f"{log_prefix}Skipping rule change because _programmatic_change flag is set.")
            # Optionally clear the flag here if this is the intended end of the programmatic change
            # self._programmatic_change = False
            return
        # --- END ADDED ---

        try:
            logger.debug(f"{log_prefix}Rule instance changed to: {rule_name}")

            # Check if the selected rule is the same as the current rule
            # --- MODIFIED: Check against controller.rule_name ---
            if self.controller.rule and rule_name == self.controller.rule_name:
                logger.debug(f"{log_prefix}Selected rule is the same as current rule, skipping change.")
                return
            # --- END MODIFIED ---

            # Set the rule using the set_rule method, passing the NAME
            if not self.set_rule(rule_name): # Pass the selected NAME
                logger.error(f"{log_prefix}Failed to set rule: {rule_name}")
                # Optionally, revert the dropdown to the previous selection
                if self.controller.rule:
                    self.rule_instance_var.set(self.controller.rule.name)
            else:
                # Rule change successful, update selected name tracker
                self._selected_rule_name = rule_name

        except Exception as e:
            logger.error(f"{log_prefix}Error changing rule instance: {e}")
            messagebox.showerror("Error", f"Failed to change rule instance: {e}")
            # Revert dropdown on error
            if self.controller.rule:
                self.rule_instance_var.set(self.controller.rule.name)
        finally:
            logger.debug(f"{log_prefix}EXIT.")

    def _update_rule_instance_selector(self):
        """Update the rule instance selector with available rules based on the selected category,
           prioritizing the currently active rule."""
        try:
            # --- MODIFIED: Access widget via control_panel_ui ---
            if not hasattr(self, 'control_panel_ui') or not self.control_panel_ui:
                logger.error("ControlPanelUI not initialized, cannot update rule instance selector.")
                return
            rule_instance_selector = self.control_panel_ui.widgets.get('rule_instance_selector')
            # --- END MODIFIED ---

            if not isinstance(rule_instance_selector, tk.OptionMenu):
                logger.error("Rule instance selector widget not found or invalid type in ControlPanelUI.")
                return

            # Get the current rule type/category
            current_rule_category = self.rule_type_var.get()
            logger.debug(f"_update_rule_instance_selector: Updating for category '{current_rule_category}'")

            # Get available rule NAMES for this type from RuleLibraryManager
            available_rule_names = sorted(list(dict.fromkeys(RuleLibrary.get_rules_in_category(current_rule_category)))) # Deduplicate and sort
            logger.debug(f"  Available rule names: {available_rule_names}")

            # Get the menu widget associated with the instance selector
            menu = rule_instance_selector['menu']
            if menu is None:
                logger.error("Rule instance selector menu not found.")
                return

            # Clear existing options
            menu.delete(0, 'end')

            # Add new options
            if available_rule_names:
                for rule_name in available_rule_names: # Iterate through sorted NAMES
                    # Use functools.partial to correctly bind the rule_name
                    menu.add_command(label=rule_name,
                                    command=functools.partial(self._on_rule_instance_change, rule_name))
            else:
                # Add a disabled placeholder if no rules are in the category
                menu.add_command(label="(No rules)", state="disabled")

            # --- Determine the value to set in the dropdown ---
            target_selection = ""
            if available_rule_names:
                # Prioritize the controller's current rule if it's in the list
                if self.controller and self.controller.rule and self.controller.rule_name in available_rule_names:
                    target_selection = self.controller.rule_name
                    logger.debug(f"  Setting selector to controller's current rule: '{target_selection}'")
                else:
                    # Otherwise, default to the first rule in the list
                    target_selection = available_rule_names[0]
                    logger.debug(f"  Controller's rule not in list or unavailable, defaulting to first rule: '{target_selection}'")
            else:
                target_selection = "(No rules)"
                logger.debug("  No rules available in this category.")

            # --- Set the variable WITHOUT triggering the callback temporarily ---
            logger.debug(f"  Attempting to set rule_instance_var to: '{target_selection}'")
            self._programmatic_change = True # Prevent callback loop
            try:
                self.rule_instance_var.set(target_selection)
                # Update internal tracker
                self._selected_rule_name = target_selection if target_selection != "(No rules)" else ""
            except Exception as set_err:
                 logger.error(f"  Error setting rule_instance_var: {set_err}")
            finally:
                 # Schedule clearing the flag slightly later to ensure Tkinter processes the set first
                 self.root.after(10, self._clear_programmatic_change_flag)
            # ---

            logger.info(f"Rule instance selector updated. Selected rule: {self.rule_instance_var.get()}")

        except KeyError as e:
             logger.error(f"Error accessing widget key during rule instance update: {e}")
             messagebox.showerror("Error", f"Internal error updating rule list: Missing widget key.")
        except Exception as e:
            logger.error(f"Error updating rule instance selector: {e}")
            logger.error(traceback.format_exc())

    def _add_additional_edges(self):
        """Add additional edges to match the initial render"""
        try:
            # Get the current number of edges
            if self.controller.grid is not None:
                current_edges = set(self.controller.grid.get_edges())
            current_edge_count = len(current_edges)

            # Calculate the target number of edges based on the density
            if self.controller.grid is not None:
                active_nodes = np.sum(self.controller.grid.grid_array > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD)
                max_neighbors = self.controller.grid.max_neighbors  # Access directly from the Grid
                max_possible_edges = active_nodes * max_neighbors / 2  # Divide by 2 because edges are bidirectional
                target_edge_count = int(max_possible_edges * GlobalSettings.Simulation.INITIAL_EDGE_DENSITY)

            logger.debug(f"Current edge count: {current_edge_count}, Target edge count: {target_edge_count}")

            # If we need more edges, add them
            if current_edge_count < target_edge_count:
                # Get all active nodes
                if self.controller.grid is not None:
                  active_indices = np.where(self.controller.grid.grid_array.ravel() > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD)[0]

                # Get all possible edges
                possible_edges = []
                for node_i in active_indices:
                    # Access neighbor_indices directly
                    if self.controller.grid is not None:
                        neighbors = self.controller.grid.get_neighbors(node_i, self.controller.grid.coord_system) # Use get_neighbors
                        active_neighbors = [n for n in neighbors if n >= 0 and self.controller.grid.grid_array.ravel()[n] > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD]
                        for j in active_neighbors:
                            edge = self.controller.grid._ordered_edge(node_i, j) # Use helper
                            if edge not in current_edges:
                                possible_edges.append(edge)

                # Shuffle the possible edges
                np.random.shuffle(possible_edges)

                # Add edges until we reach the target
                edges_to_add = min(len(possible_edges), target_edge_count - current_edge_count)
                for i in range(edges_to_add):
                    node1, node2 = possible_edges[i]
                    if self.controller.grid is not None:
                        self.controller.grid.add_edge(node1, node2)

                logger.debug(f"Added {edges_to_add} additional edges")

        except Exception as e:
            logger.error(f"Error adding additional edges: {e}")

    def _on_neighborhood_change(self, neighborhood_str: str):
        """Handle neighborhood type change"""

        log_prefix = "SimulationGUI._on_neighborhood_change: "
        logger.info(f"\n{'='*25} Changing Neighborhood: {neighborhood_str} {'='*25}")
        self._is_transitioning = True
        if not self._stop_computation_threads(reason=f"Change Neighborhood to {neighborhood_str}"):
            logger.error(f"{log_prefix}Aborted: Failed to stop computation threads cleanly.")
            self._is_transitioning = False
            return
        # --- ADDED: Clear stop event after successful stop ---
        if hasattr(self, '_stop_event') and self._stop_event:
            self._stop_event.clear()
            logger.debug("Cleared stop event after stopping threads.")
        # ---

        original_blitting = self.grid_visualizer.blitting_manager.enabled if hasattr(self, 'grid_visualizer') and self.grid_visualizer else GlobalSettings.ENABLE_BLITTING
        if hasattr(self, 'grid_visualizer') and self.grid_visualizer: self.grid_visualizer.blitting_manager.set_enabled(False)
        try:
            # [ Rest of the method remains the same as Round 22... ]
            new_neighborhood_type = NeighborhoodType[neighborhood_str]
            if self.controller.rule:
                rule_neigh = self.controller.rule.PARAMETER_METADATA.get('neighborhood_type', {}).get('allowed_values')
                if rule_neigh and 'ANY' not in rule_neigh and neighborhood_str not in rule_neigh:
                    messagebox.showerror("Incompatible Neighborhood", f"The current rule '{self.controller.rule.name}' is not compatible with {neighborhood_str}.", parent=self.root)
                    self.neighborhood_var.set(self.neighborhood_type.name); self._is_transitioning = False; return
            if new_neighborhood_type != self.neighborhood_type:
                self.neighborhood_type = new_neighborhood_type
                self.controller.neighborhood_type = self.neighborhood_type
                logger.info(f"{log_prefix}Neighborhood type updated to {self.neighborhood_type.name}.")
                if self.grid is not None and self.coord_system is not None:
                    self.grid.reinitialize(
                        self.dimensions, self.neighborhood_type, self.dimension_type,
                        self.coord_system, gui=self, rule=self.controller.rule, unique_id=self._unique_id
                    )
                    self.grid.setup_shared_memory(); self.controller.grid = self.grid
                    logger.info(f"{log_prefix}Grid reinitialized.")
                else: logger.error(f"{log_prefix}Grid or CoordinateSystem is not initialized."); self._is_transitioning = False; return
                self.reset_simulation()
                logger.info(f"{log_prefix}Neighborhood changed to: {neighborhood_str}")
            else:
                logger.debug(f"{log_prefix}Neighborhood type unchanged.")

        except KeyError:
            logger.error(f"{log_prefix}Invalid neighborhood type string: {neighborhood_str}")
            messagebox.showerror("Error", f"Invalid neighborhood type: {neighborhood_str}")
            self.neighborhood_var.set(self.neighborhood_type.name) # Revert
        except Exception as e:
            logger.error(f"{log_prefix}Error changing neighborhood type: {e}")
            messagebox.showerror("Error", f"Failed to change neighborhood type: {e}")
            self.neighborhood_var.set(self.neighborhood_type.name) # Revert
        finally:
            if hasattr(self, 'grid_visualizer') and self.grid_visualizer: self.grid_visualizer.blitting_manager.set_enabled(original_blitting)
            self.running = False; self.paused = False; self._fixed_steps_running = False
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui: self.control_panel_ui.update_button_states()
            self._is_transitioning = False
            self._initialization_complete = True
            logger.debug(f"{log_prefix}Set _initialization_complete = True in finally block.")

    def _check_stabilization(self):
        """Check if simulation has stabilized, with added logging."""
        # --- ADDED: Check if stability detection is enabled ---
        if not hasattr(self, 'stability_detection_var') or not self.stability_detection_var.get():
            logger.debug("_check_stabilization: Stability detection disabled, skipping check.")
            return False # Return False as it's not stable (or detection is off)
        # ---

        if self.generation > GlobalSettings.Simulation.MIN_GENERATIONS:
            # --- ADDED: Log entry into stability check ---
            logger.debug(f"--- _check_stabilization: Generation {self.generation} ---")

            # --- Get current state ---
            current_nodes_for_stability = set()
            current_edges_for_stability = set()
            try:
                if self.grid is not None:
                    grid_array = self.grid.grid_array
                    visible_mask = grid_array > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD
                    if self.dimension_type == Dimension.TWO_D:
                        for i, j in np.ndindex(self.dimensions):
                            if visible_mask[i, j]: current_nodes_for_stability.add((i, j))
                    elif self.dimension_type == Dimension.THREE_D:
                        for i, j, k in np.ndindex(self.dimensions):
                            if visible_mask[i, j, k]: current_nodes_for_stability.add((i, j, k))
                    current_edges_for_stability = set(self.grid.edges) # Get edges directly
                    logger.debug(f"  Current State: Nodes={len(current_nodes_for_stability)}, Edges={len(current_edges_for_stability)}")
                    if len(current_nodes_for_stability) < 20: logger.debug(f"    Current Nodes: {current_nodes_for_stability}")
                    if len(current_edges_for_stability) < 20: logger.debug(f"    Current Edges: {current_edges_for_stability}")
                else:
                    logger.error("  Grid is None during stability check!")
                    return False
            except Exception as state_err:
                 logger.error(f"  Error extracting current state for stability: {state_err}\n{traceback.format_exc()}")
                 return False
            # ---

            current_state_tuple = (frozenset(current_nodes_for_stability), frozenset(current_edges_for_stability))

            # Initialize history if needed
            if not hasattr(self, 'state_history'):
                self.state_history = []
            self.state_history.append(current_state_tuple)
            if len(self.state_history) > 10:
                self.state_history = self.state_history[-10:]

            # --- Perform Stability Checks with Logging ---
            is_stable = False
            stability_message = ""

            # Static Stability (State repeats from previous step)
            if len(self.state_history) >= 2:
                prev_nodes, prev_edges = self.state_history[-2]
                logger.debug(f"  Checking Static Stability vs Step {self.generation - 1}:")
                logger.debug(f"    Prev State: Nodes={len(prev_nodes)}, Edges={len(prev_edges)}")
                if len(prev_nodes) < 20: logger.debug(f"      Prev Nodes: {prev_nodes}")
                if len(prev_edges) < 20: logger.debug(f"      Prev Edges: {prev_edges}")

                nodes_match = current_nodes_for_stability == prev_nodes
                edges_match = current_edges_for_stability == prev_edges
                logger.debug(f"    Nodes Match: {nodes_match}, Edges Match: {edges_match}")

                if nodes_match and edges_match:
                    is_stable = True
                    stability_message = "Static stability detected - simulation has reached a stable state."
                    logger.info(f"  STATIC STABILITY DETECTED at generation {self.generation}")

            # Period-2 Oscillation
            if not is_stable and len(self.state_history) >= 3: # Need at least 3 states to check period 2
                state_minus_2_nodes, state_minus_2_edges = self.state_history[-3]
                logger.debug(f"  Checking Period-2 Stability vs Step {self.generation - 2}:")
                logger.debug(f"    State[-3]: Nodes={len(state_minus_2_nodes)}, Edges={len(state_minus_2_edges)}")

                nodes_match = current_nodes_for_stability == state_minus_2_nodes
                edges_match = current_edges_for_stability == state_minus_2_edges
                logger.debug(f"    Nodes Match: {nodes_match}, Edges Match: {edges_match}")

                if nodes_match and edges_match:
                    is_stable = True
                    stability_message = "Period-2 oscillation detected - simulation has reached a stable oscillation."
                    logger.info(f"  PERIOD-2 STABILITY DETECTED at generation {self.generation}")

            # Period-3 Oscillation (Add more if needed)
            if not is_stable and len(self.state_history) >= 4: # Need at least 4 states
                state_minus_3_nodes, state_minus_3_edges = self.state_history[-4]
                logger.debug(f"  Checking Period-3 Stability vs Step {self.generation - 3}:")
                logger.debug(f"    State[-4]: Nodes={len(state_minus_3_nodes)}, Edges={len(state_minus_3_edges)}")

                nodes_match = current_nodes_for_stability == state_minus_3_nodes
                edges_match = current_edges_for_stability == state_minus_3_edges
                logger.debug(f"    Nodes Match: {nodes_match}, Edges Match: {edges_match}")

                if nodes_match and edges_match:
                    is_stable = True
                    stability_message = "Period-3 oscillation detected - simulation has reached a stable oscillation."
                    logger.info(f"  PERIOD-3 STABILITY DETECTED at generation {self.generation}")

            # --- Handle Stability ---
            if is_stable:
                logger.info(f"--- STABILITY CONFIRMED: {stability_message} ---")
                self.running = False # Stop the simulation loop flag
                # Schedule GUI updates on the main thread
                self.root.after(0, lambda msg=stability_message: (
                    messagebox.showinfo("Simulation Complete", msg),
                    setattr(self, 'generation', 0),
                    setattr(self, 'step_count', 0)
                ))

                return True # Indicate stability detected
            else:
                logger.debug("  No stability detected.")

        else:
             logger.debug(f"  Generation {self.generation} <= Min Generations {GlobalSettings.Simulation.MIN_GENERATIONS}, skipping stability check.")

        return False # Indicate stability not detected

    def toggle_stability_detection(self):
        """Toggle stability detection on/off"""
        if hasattr(self, 'controller') and self.controller:
            # Update both the GUI's auto_stabilize and the controller's auto_stabilize
            self.auto_stabilize = self.stability_detection_var.get()
            self.controller.auto_stabilize = self.stability_detection_var.get()
            logger.info(f"Stability detection {'enabled' if self.auto_stabilize else 'disabled'}")

    # TODO: New method to integrate
    def _on_toggle_analytics_enabled(self):
        """Callback when the 'Enable Analytics' checkbox is toggled."""
        is_enabled = self.analytics_enabled_var.get()
        logger.info(f"Analytics collection toggled {'ON' if is_enabled else 'OFF'}.")
        # The actual check happens in the controller before pushing data.
        # Update the state in the AnalyticsWindow if it's open
        if hasattr(self, 'analytics_window') and self.analytics_window and self.analytics_window.winfo_exists():
            # --- ADDED: Check if _update_control_states exists before calling ---
            if hasattr(self.analytics_window, '_update_control_states') and callable(self.analytics_window._update_control_states):
                self.analytics_window._update_control_states()
            else:
                logger.warning("AnalyticsWindow does not have the _update_control_states method.")
            # ---

    # TODO: New method to integrate
    def _open_analytics_window(self):
        """Opens the Analytics window."""
        log_prefix = "SimulationGUI._open_analytics_window: "
        logger.debug(f"{log_prefix}Attempting to open Analytics Window.")

        # Check if controller and analytics manager exist
        if not hasattr(self, 'controller') or not self.controller:
            logger.error(f"{log_prefix}Controller not initialized.")
            messagebox.showerror("Error", "Controller not ready.", parent=self.root)
            return
        if not hasattr(self.controller, 'analytics_manager') or not self.controller.analytics_manager:
            logger.error(f"{log_prefix}AnalyticsManager not initialized.")
            messagebox.showerror("Error", "Analytics system not ready.", parent=self.root)
            return

        # Check if window already exists
        if hasattr(self, 'analytics_window') and self.analytics_window and self.analytics_window.winfo_exists():
            logger.debug(f"{log_prefix}Analytics window already exists, lifting.")
            self.analytics_window.lift()
            return

        try:
            logger.debug(f"{log_prefix}Creating new AnalyticsWindow instance.")
            # Import locally to avoid circular dependency at module level if AnalyticsWindow is in analytics.py
            from .analytics import AnalyticsWindow # Assuming it's in analytics.py
            # --- MODIFIED: Assign to the correctly typed attribute ---
            self.analytics_window = AnalyticsWindow(self, self.controller.analytics_manager)
            # ---
            logger.info(f"{log_prefix}Analytics window created and displayed.")
        except ImportError:
             logger.error(f"{log_prefix}Could not import AnalyticsWindow. Ensure analytics.py exists.")
             messagebox.showerror("Error", "Could not load the Analytics Window component.", parent=self.root)
             self.analytics_window = None # Ensure it's None on import error
        except Exception as e:
            logger.error(f"{log_prefix}Error creating Analytics window: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Error", f"Failed to open Analytics window: {e}", parent=self.root)
            self.analytics_window = None # Ensure it's None on other errors

    def _update_statistics(self):
        """Update simulation statistics"""
        if self.grid is not None and self.grid.grid_array is not None:
            active_cells = np.sum(self.grid.grid_array > 0)
        else:
            active_cells = 0
        total_cells = np.prod(self.dimensions)

        try:
            # Calculate edge_density using a list comprehension and filtering out None values
            edge_densities = []
            for idx in range(total_cells):
                # Create a NeighborhoodData object for the current node
                if self.controller.grid is not None:
                    neighborhood = self.controller.grid.create_neighborhood_data(idx)
                    # Call get_metric on the RULE, passing the NeighborhoodData object
                    metric_value = self.controller.rule.get_metric('edge_density', neighborhood)
                    if metric_value is not None:  # Only append if we got a valid value
                        edge_densities.append(metric_value)

            # Calculate the mean only if we have valid values
            edge_density = float(np.mean(edge_densities)) if edge_densities else 0.0

        except Exception as e:
            logger.error(f"Error calculating edge density: {e}")
            edge_density = 0.0  # Handle cases where edge density might be undefined

        performance_stats = self.perf_logger.get_stats() # Now correctly accesses the instance attribute

        self.stats.update(
            generation=self.generation,
            active_ratio=active_cells / total_cells,
            edge_density=edge_density,
            # Add individual performance metrics instead of the whole dictionary
            simulation_avg_time=performance_stats.get('step', {}).get('avg', 0.0),
            grid_avg_time=self.controller.grid.get_performance_stats().get('grid_stats', {}).get('avg_update_time', 0.0) if self.controller.grid else 0.0,
            rule_avg_time=self.controller.rule.get_performance_stats().get('avg_compute_time', 0.0)
        )

    def step_simulation(self):
        """Perform one step of simulation using the controller.
           (Round 42: Correctly call controller.step instead of grid.update_grid_parallel)"""
        try:
            log_prefix = "step_simulation (R42 Fix): " # Updated round
            logger.debug(f"{log_prefix}Initiating simulation step via controller.")

            # Store pre-update state for verification
            pre_active = 0
            pre_edges = 0
            if self.grid and self.grid.grid_array is not None:
                pre_active = np.sum(self.grid.grid_array > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD) # Use threshold
                pre_edges = len(self.grid.edges) # Use grid.edges
            logger.debug(f"{log_prefix}Pre-step state - Active nodes: {pre_active}, Edges: {pre_edges}")

            # Verify controller exists
            if not hasattr(self, 'controller') or self.controller is None:
                logger.error(f"{log_prefix}Controller not initialized")
                raise RuntimeError("Controller not initialized")

            # --- MODIFIED: Call controller.step() ---
            logger.debug(f"{log_prefix}Calling self.controller.step()")
            snapshot = self.controller.step() # Call the controller's step method
            # --- END MODIFIED ---

            # Check if the controller step was successful (returned a snapshot)
            if snapshot is None:
                logger.error(f"{log_prefix}Controller step failed (returned None). Stopping simulation.")
                self.running = False
                if hasattr(self, 'control_panel_ui') and self.control_panel_ui is not None:
                    self.control_panel_ui.update_button_states()
                return # Stop processing this step
            logger.debug(f"{log_prefix}Controller step completed successfully (Gen: {snapshot.get('generation', 'N/A')}).")

            # Verify post-update state (using the grid updated by the controller)
            post_active = 0
            post_edges = 0
            if self.grid and self.grid.grid_array is not None:
                post_active = np.sum(self.grid.grid_array > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD) # Use threshold
                post_edges = len(self.grid.edges) # Use grid.edges
            logger.debug(f"{log_prefix}Post-step state - Active nodes: {post_active}, Edges: {post_edges}")

            if post_active == pre_active and post_edges == pre_edges:
                logger.warning(f"{log_prefix}Grid state unchanged after step - possible update failure or stable state")

            # --- Update generation counter FROM SNAPSHOT ---
            # Controller already incremented its generation, use the value from snapshot
            self.generation = snapshot.get('generation', self.generation) # Use snapshot gen
            self.step_count = self.generation # Keep synced
            if hasattr(self.controller, 'generation'):
                 # Ensure controller's generation is also synced if snapshot was somehow old (unlikely)
                 self.controller.generation = self.generation
            # ---

            # Update statistics
            self._update_statistics()

            # Check for stabilization if enabled
            if self.auto_stabilize:
                self._check_stabilization()

            # Periodically cleanup ghost edges (controller step might not do this)
            if self.grid:
                self.grid.cleanup_ghost_edges()

            logger.debug(f"{log_prefix}Simulation step processing complete.")

        except Exception as e:
            logger.error(f"{log_prefix}Error in simulation step: {e}\nTraceback:\n{traceback.format_exc()}")
            # Ensure simulation stops on error
            self.running = False
            self.paused = False
            self._stopped = True
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                self.control_panel_ui.update_button_states()
            raise # Re-raise after logging and stopping

    def handle_step_button(self):
        """Handle step button press with interruption support"""
        try:
            # Reset any interruption requests
            self.controller.interrupt_requested = False
            self._stop_requested = False

            # It's *always* okay to step, regardless of self.running or self.paused
            self.step_simulation_logic(logger=logging.getLogger(__name__))  # Pass the logger argument

            # Force plot update
            self._safe_plot_update()

        except Exception as e:
            logger.error(f"Error in step button handler: {e}")
            logger.error(traceback.format_exc())
            # Consider whether to set self.running = False here, depending on desired behavior
            messagebox.showerror("Error", "An error occurred during the simulation step.")
        
    def setup_animation(self):
        """Initialize the animation"""
        logger.debug("Starting animation setup")
        
        try:            
            # Update the canvas
            logger.debug("Updating canvas")
            if self.canvas is not None:
                self.canvas.draw()
            
            logger.debug("Animation setup completed")
        except Exception as e:
            logger.error(f"Error in animation setup: {str(e)}")
            raise

    def toggle_simulation(self):
        """Start/Pause/Resume/Stop simulation, handling different states including fixed steps.
           On Start: Sets flags immediately, checks _is_stopping flag, calls _force_initial_render,
           then delays thread/loop start. Creates a NEW stop event.
           Resets controller interrupt flag and stop requested flag. Preserves generation counter.
           Logs both rule type and name in banner.
           (Round 12: Add rule type to banner log)
           """
        log_prefix = f"toggle_simulation (R12 Rule Type Log): " # Updated round
        try:
            action = "Unknown"
            current_gen_display = self.generation
            # --- MODIFIED: Get both rule type and name ---
            rule_name = "N/A"; rule_type_name = "N/A"
            if self.controller and self.controller.rule:
                rule_name = self.controller.rule.name
                rule_type_name = self.controller.rule.__class__.__name__
            # ---
            banner_width = 60

            with self._update_lock: # Protect state changes
                if self.running and not self.paused:
                    # --- PAUSE ---
                    action = "Pausing"
                    # --- MODIFIED: Include type and name ---
                    banner_text = f" {action} Simulation (Gen: {current_gen_display}, Rule: {rule_type_name} - '{rule_name}') "
                    # ---
                    logger.info(f"\n{'=' * banner_width}\n{banner_text:=^{banner_width}}\n{'=' * banner_width}") # BANNER
                    self.paused = True
                    self._stopped = False
                    if hasattr(self, 'computation_pause_flag'): self.computation_pause_flag.clear(); logger.debug("Cleared computation_pause_flag (signaling pause).")
                    else: logger.warning("computation_pause_flag not found, cannot signal pause.")
                    logger.debug(f"{log_prefix}Clearing communication and render queues on PAUSE.")
                    if hasattr(self, 'communication_queue'):
                        qsize_before = self.communication_queue.qsize()
                        while not self.communication_queue.empty():
                            try: self.communication_queue.get_nowait()
                            except queue.Empty: break
                        qsize_after = self.communication_queue.qsize()
                        logger.info(f"{log_prefix}Communication queue cleared (was {qsize_before}, now {qsize_after}).")
                    if hasattr(self, 'render_data_queue'):
                        qsize_before = self.render_data_queue.qsize()
                        while not self.render_data_queue.empty():
                            try: self.render_data_queue.get_nowait()
                            except queue.Empty: break
                        qsize_after = self.render_data_queue.qsize()
                        logger.info(f"{log_prefix}Render data queue cleared (was {qsize_before}, now {qsize_after}).")
                    self._latest_grid_snapshot = None
                    self._last_prepared_snapshot_for_highlight = None
                    logger.debug(f"{log_prefix}Set snapshot trackers to None on PAUSE.")
                    self._last_render_completion_time = 0.0
                    logger.debug(f"{log_prefix}Reset _last_render_completion_time on PAUSE.")
                    if hasattr(self, 'control_panel_ui') and self.control_panel_ui and hasattr(self.control_panel_ui, 'widgets'):
                        buffer_label = self.control_panel_ui.widgets.get('buffering_status_label')
                        if isinstance(buffer_label, tk.Label): buffer_label.config(text="")

                elif self.running and self.paused:
                    # --- RESUME ---
                    action = "Resuming"
                    # --- MODIFIED: Include type and name ---
                    banner_text = f" {action} Simulation (Gen: {current_gen_display}, Rule: {rule_type_name} - '{rule_name}') "
                    # ---
                    logger.info(f"\n{'=' * banner_width}\n{banner_text:=^{banner_width}}\n{'=' * banner_width}") # BANNER
                    self.paused = False
                    self._stopped = False
                    self._last_render_completion_time = time.time()
                    logger.debug(f"{log_prefix}Reset _last_render_completion_time on RESUME.")
                    if hasattr(self, 'computation_pause_flag'): self.computation_pause_flag.set(); logger.debug("Set computation_pause_flag (signaling resume).")
                    else: logger.warning("computation_pause_flag not found, cannot signal resume.")
                    if not getattr(self, '_fixed_steps_running', False):
                        if hasattr(self, 'root') and self.root.winfo_exists():
                            if not hasattr(self, '_render_timer_after_id') or not self._render_timer_after_id:
                                logger.info("Resume (Continuous): Scheduling render timer loop (was not scheduled).")
                                self._render_timer_after_id = self.root.after(1, self._render_timer_loop)
                            else:
                                logger.debug("Resume (Continuous): Render timer loop likely already scheduled.")
                        else:
                            logger.warning("Resume (Continuous): Root window destroyed, cannot schedule render loop.")
                    else: logger.info("Resume (Fixed Steps): Fixed steps thread will continue.")
                    if hasattr(self, 'control_panel_ui') and self.control_panel_ui and hasattr(self.control_panel_ui, 'widgets'):
                        buffer_label = self.control_panel_ui.widgets.get('buffering_status_label')
                        if isinstance(buffer_label, tk.Label): buffer_label.config(text="")

                elif not self.running: # Includes stopped or initial state
                    # --- START ---
                    if hasattr(self, '_is_stopping') and self._is_stopping:
                        logger.warning(f"{log_prefix}Cannot start simulation, stop sequence is still in progress.")
                        messagebox.showwarning("Busy", "Cannot start simulation while the previous stop is finalizing. Please wait a moment.", parent=self.root)
                        return

                    if hasattr(self, '_is_shutting_down') and self._is_shutting_down:
                        logger.warning(f"{log_prefix}Cannot start simulation, shutdown sequence is in progress.")
                        messagebox.showwarning("Busy", "Cannot start simulation while the previous stop is finalizing. Please wait a moment.", parent=self.root)
                        return

                    logger.debug(f"{log_prefix}START: Flags BEFORE set: running={self.running}, paused={self.paused}, _stopped={self._stopped}")
                    self.running = True; self.paused = False; self._stopped = False
                    self._stop_requested = False
                    logger.info(f"{log_prefix}START: Flags set IMMEDIATELY: running={self.running}, paused={self.paused}, _stopped={self._stopped}, _stop_requested={self._stop_requested}")

                    self._grid_undo_stack.clear(); self._grid_redo_stack.clear()
                    logger.info(f"{log_prefix}Cleared undo/redo stacks on simulation start.")
                    self._stop_event = threading.Event()
                    logger.info(f"{log_prefix}Created NEW stop_event object (ID: {id(self._stop_event)}). Initial state: is_set={self._stop_event.is_set()}")

                    if hasattr(self.controller, 'interrupt_requested'): self.controller.interrupt_requested = False; logger.info(f"{log_prefix}Reset controller.interrupt_requested flag.")
                    else: logger.warning(f"{log_prefix}Controller has no 'interrupt_requested' attribute to reset.")

                    logger.info(f"{log_prefix}Controller generation PRESERVED (Current: {self.controller.generation if hasattr(self.controller, 'generation') else 'N/A'}).")

                    self._last_render_completion_time = time.time()
                    self.last_avg_fps = 0.0; self.fps_history.clear(); self.fps_display_var.set("Avg FPS: N/A")
                    logger.debug(f"{log_prefix}Reset FPS tracking variables on START.")

                    logger.info(f"{log_prefix}Forcing process pool recreation on START.")
                    if not self.controller._initialize_process_pool(force_recreate=True):
                        logger.error("  Failed to initialize process pool on start. Aborting start.")
                        self.running = False; self._stopped = True; return

                    # [ Calculate initial previous arrays - Unchanged ]
                    if self.grid and self.controller and self.controller.rule and \
                       (self.controller.rule.needs_neighbor_degrees or self.controller.rule.needs_neighbor_active_counts):
                        logger.info(f"{log_prefix}Calculating initial previous degree/active neighbor arrays for Gen {self.generation}...")
                        try:
                            initial_grid_array_flat = self.grid.grid_array.ravel()
                            initial_edge_set = self.grid.edges.copy()
                            initial_degree_array = np.zeros(self.grid.total_nodes, dtype=np.int32)
                            initial_active_neighbor_array = np.zeros(self.grid.total_nodes, dtype=np.int32)
                            activity_threshold = 1e-6
                            if self.controller.rule.needs_neighbor_degrees:
                                for edge_coords in initial_edge_set:
                                    try:
                                        node1_coords, node2_coords = edge_coords
                                        idx1 = _ravel_multi_index(np.array(node1_coords), self.grid.dimensions)
                                        idx2 = _ravel_multi_index(np.array(node2_coords), self.grid.dimensions)
                                        if 0 <= idx1 < self.grid.total_nodes: initial_degree_array[idx1] += 1
                                        if 0 <= idx2 < self.grid.total_nodes: initial_degree_array[idx2] += 1
                                    except Exception as degree_calc_err: logger.error(f"{log_prefix}Error processing edge {edge_coords} for initial degree calculation: {degree_calc_err}")
                                self.grid.previous_degree_array = initial_degree_array
                                logger.info(f"{log_prefix}Set initial previous_degree_array (Sum: {np.sum(initial_degree_array)}).")
                            else: self.grid.previous_degree_array = None
                            if self.controller.rule.needs_neighbor_active_counts:
                                for node_idx in range(self.grid.total_nodes):
                                    count = 0
                                    neighbors_indices = self.grid.get_neighbors(node_idx, self.grid.coord_system)
                                    for neighbor_idx in neighbors_indices:
                                        if neighbor_idx != -1 and 0 <= neighbor_idx < initial_grid_array_flat.size and initial_grid_array_flat[neighbor_idx] > activity_threshold: count += 1
                                    initial_active_neighbor_array[node_idx] = count
                                self.grid.previous_active_neighbor_array = initial_active_neighbor_array
                                logger.info(f"{log_prefix}Set initial previous_active_neighbor_array (Sum: {np.sum(initial_active_neighbor_array)}).")
                            else: self.grid.previous_active_neighbor_array = None
                        except Exception as e_prev_init: logger.error(f"{log_prefix}Error calculating initial previous state arrays on start: {e_prev_init}"); self.grid.previous_degree_array = np.zeros(self.grid.total_nodes, dtype=np.int32); self.grid.previous_active_neighbor_array = np.zeros(self.grid.total_nodes, dtype=np.int32)
                    else: logger.debug(f"{log_prefix}Skipping initial previous array calculation (grid/rule missing or not needed).")

                    # --- Force Initial Render BEFORE starting threads ---
                    logger.info(f"{log_prefix}Calling _force_initial_render on START.")
                    self._force_initial_render()
                    # ---

                    # --- Schedule Thread/Loop Start AFTER Initial Render ---
                    logger.info(f"{log_prefix}Scheduling start of threads and render loop.")
                    if hasattr(self, 'root') and self.root and self.root.winfo_exists():
                        self.root.after(10, self._start_simulation_threads_and_render_loop)
                    else:
                        logger.warning(f"{log_prefix}Root window not available, cannot schedule thread/loop start.")
                        self._start_simulation_threads_and_render_loop()
                    # ---

                    # --- Set Buffering Message ---
                    run_continuously_flag = self.run_continuously.get()
                    if run_continuously_flag:
                        action = "Starting Continuous"
                        # --- MODIFIED: Include type and name ---
                        banner_text = f" {action} Simulation (Gen: {self.generation}, Rule: {rule_type_name} - '{rule_name}') "
                        # ---
                        logger.info(f"\n{'=' * banner_width}\n{banner_text:=^{banner_width}}\n{'=' * banner_width}")
                        if hasattr(self, 'control_panel_ui') and self.control_panel_ui and hasattr(self.control_panel_ui, 'widgets'):
                            buffer_label = self.control_panel_ui.widgets.get('buffering_status_label')
                            if isinstance(buffer_label, tk.Label): buffer_label.config(text="Buffering Frames...")
                            else: logger.warning(f"{log_prefix}Buffering status label not found or invalid.")
                        else: logger.warning(f"{log_prefix}ControlPanelUI not available, cannot set buffering status.")
                    else: # Fixed steps
                        try: num_steps = int(self.num_steps_var.get()); assert num_steps > 0
                        except (ValueError, AssertionError): messagebox.showerror("Invalid Input", "Please enter a positive whole number for the number of steps.", parent=self.root); self.running = False; self._stopped = True; return
                        action = f"Starting Fixed ({num_steps} steps)"
                        # --- MODIFIED: Include type and name ---
                        banner_text = f" {action} Simulation (Gen: {self.generation}, Rule: {rule_type_name} - '{rule_name}') "
                        # ---
                        logger.info(f"\n{'=' * banner_width}\n{banner_text:=^{banner_width}}\n{'=' * banner_width}")
                        if hasattr(self, 'control_panel_ui') and self.control_panel_ui and hasattr(self.control_panel_ui, 'widgets'):
                            buffer_label = self.control_panel_ui.widgets.get('buffering_status_label')
                            if isinstance(buffer_label, tk.Label): buffer_label.config(text="")
                    # ---

            # Update button states AFTER changing state
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                self.control_panel_ui.update_button_states()

        except Exception as e:
            logger.error(f"Error in toggle_simulation ({action}): {e}")
            logger.error(traceback.format_exc())
            self.running = False; self.paused = False; self._stop_requested = True; self._fixed_steps_running = False; self._stopped = True
            if hasattr(self, '_stop_event') and self._stop_event: self._stop_event.set()
            if hasattr(self, 'computation_running_flag'): self.computation_running_flag.clear()
            if hasattr(self, 'computation_pause_flag'): self.computation_pause_flag.set()
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui: self.control_panel_ui.update_button_states()
            
    def _start_simulation_threads_and_render_loop(self):
        """
        Helper to start computation/prep threads and rendering loop after initial render.
        Uses the CURRENT stop event created by the START logic.
        (Round 64: Use existing stop event)
        (Round 37: Start new _render_timer_loop)
        (Round 40: Log ID and state of stop event being passed)
        """
        log_prefix = "_start_simulation_threads_and_render_loop (R40 Log Event): " # Updated round
        logger.info(f"{log_prefix}Starting threads and render loop.")

        # --- Use the CURRENT stop event ---
        if not hasattr(self, '_stop_event') or not self._stop_event:
            logger.error(f"{log_prefix}Cannot start threads: _stop_event is missing or None!")
            return
        current_stop_event = self._stop_event
        # --- ADDED: Log ID and state ---
        logger.info(f"{log_prefix}Using current stop_event object (ID: {id(current_stop_event)}, is_set={current_stop_event.is_set()}).")
        # ---

        # --- Start Computation Thread ---
        run_continuously_flag = self.run_continuously.get()
        if run_continuously_flag:
            if self.computation_thread is None or not self.computation_thread.is_alive():
                logger.info("  Starting new computation thread for continuous run.")
                if hasattr(self, 'computation_running_flag'): self.computation_running_flag.set()
                if hasattr(self, 'computation_pause_flag'): self.computation_pause_flag.set()
                # --- Pass the CURRENT stop event ---
                self.computation_thread = threading.Thread(target=self._computation_loop, args=(current_stop_event,), daemon=True, name="ComputationThread")
                # ---
                self.computation_thread.start()
            else:
                logger.info("  Computation thread already running, signaling flags.")
                if hasattr(self, 'computation_running_flag'): self.computation_running_flag.set()
                if hasattr(self, 'computation_pause_flag'): self.computation_pause_flag.set()
        else: # Fixed steps
            try:
                num_steps = int(self.num_steps_var.get()); assert num_steps > 0
                if self.fixed_steps_thread is None or not self.fixed_steps_thread.is_alive():
                    logger.info(f"  Starting new fixed steps thread for {num_steps} steps.")
                    if hasattr(self, 'computation_running_flag'): self.computation_running_flag.set()
                    if hasattr(self, 'computation_pause_flag'): self.computation_pause_flag.set()
                    self._fixed_steps_running = True # Set flag before starting thread
                    # --- Pass the CURRENT stop event ---
                    self.fixed_steps_thread = threading.Thread(target=self._run_fixed_steps, args=(num_steps, current_stop_event,), daemon=True, name="FixedStepsThread")
                    # ---
                    self.fixed_steps_thread.start()
                else:
                    logger.warning("  Fixed steps thread already running?")
            except (ValueError, AssertionError):
                logger.error(f"{log_prefix}Invalid number of steps '{self.num_steps_var.get()}' when starting fixed steps thread.")
                self.running = False; self._stopped = True # Stop if invalid steps
                if hasattr(self, 'control_panel_ui') and self.control_panel_ui: self.control_panel_ui.update_button_states()
                return
        # ---

        # --- Start Preparation Thread ---
        self._start_preparation_thread() # This should also use the current stop event implicitly if needed
        # ---

        # --- Schedule NEW Rendering Loop ---
        logger.info("  Scheduling first rendering TIMER loop step.")
        if not hasattr(self, '_render_delay_ms'): self._setup_rendering_loop()
        if hasattr(self, '_render_timer_after_id') and self._render_timer_after_id:
            try: self.root.after_cancel(self._render_timer_after_id) # Cancel previous if any
            except: pass
        # --- Schedule the NEW timer loop ---
        self._render_timer_after_id = self.root.after(1, self._render_timer_loop)
        logger.debug(f"{log_prefix}Scheduled first _render_timer_loop (after_id: {self._render_timer_after_id}).")
        # ---

    def _clear_computation_and_render_queues(self):
        """
        Safely clears the communication and render queues and resets snapshot trackers.
        Should be called AFTER pausing computation and BEFORE resuming when the grid
        state has been modified by user interaction.
        (Round 11: New method)
        """
        log_prefix = "_clear_computation_and_render_queues: "
        logger.info(f"{log_prefix}Clearing queues and snapshot trackers.")

        # Clear Communication Queue
        if hasattr(self, 'communication_queue'):
            qsize_before = self.communication_queue.qsize()
            while not self.communication_queue.empty():
                try: self.communication_queue.get_nowait()
                except queue.Empty: break
                except Exception as e: logger.warning(f"{log_prefix}Error clearing communication_queue item: {e}"); break # Stop on error
            qsize_after = self.communication_queue.qsize()
            logger.debug(f"{log_prefix}Communication queue cleared (was {qsize_before}, now {qsize_after}).")
        else:
            logger.warning(f"{log_prefix}Communication queue not found.")

        # Clear Render Data Queue
        if hasattr(self, 'render_data_queue'):
            qsize_before = self.render_data_queue.qsize()
            while not self.render_data_queue.empty():
                try: self.render_data_queue.get_nowait()
                except queue.Empty: break
                except Exception as e: logger.warning(f"{log_prefix}Error clearing render_data_queue item: {e}"); break # Stop on error
            qsize_after = self.render_data_queue.qsize()
            logger.debug(f"{log_prefix}Render data queue cleared (was {qsize_before}, now {qsize_after}).")
        else:
            logger.warning(f"{log_prefix}Render data queue not found.")

        # Reset snapshot trackers
        self._latest_grid_snapshot = None
        self._last_prepared_snapshot_for_highlight = None
        # Keep _last_rendered_snapshot as is, it represents what's on screen

        logger.info(f"{log_prefix}Queues cleared and snapshot trackers reset.")

    def _execute_single_step(self):
        """Executes a single simulation step, typically called by step_button_clicked."""
        try:
            logger.debug("Executing single step.")
            # Reset any interruption requests specifically for this step
            self.controller.interrupt_requested = False
            self._stop_requested = False # Ensure stop request is false for a single step
            # --- ADDED: Explicitly reset drawing/schedule flags before step ---
            self._is_drawing = False
            self._update_scheduled = False
            logger.debug("Explicitly reset _is_drawing and _update_scheduled flags for single step")
            # ---

            # CRITICAL FIX: Use a thread for the single step to avoid blocking GUI
            def single_step_thread():
                with self._update_lock:
                    step_success = self.controller.step() # Call controller step
                    if step_success and self.canvas is not None:
                        # Schedule plot update on the main thread
                        # --- MODIFIED: Use the wrapper to manage the schedule flag ---
                        if not self._update_scheduled:
                            self._update_scheduled = True
                            self.root.after(0, self._safe_plot_update_wrapper)
                        # ---
                    elif not step_success:
                         logger.error("Single step execution failed in controller.")
                         self.root.after(0, lambda: messagebox.showerror("Error", "Simulation step failed."))

            threading.Thread(target=single_step_thread, daemon=True).start()
            logger.debug("Single step thread started.")

        except Exception as e:
            logger.error(f"Error executing single step: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Error", "An error occurred during the simulation step.")

    @timer_decorator
    def _computation_loop(self, stop_event: threading.Event):
        """
        The main loop for the background computation thread.
        Computes steps, puts snapshot onto communication_queue.
        Respects throttling via downstream blocking. Checks stop_event frequently.
        (Round 1: Queue Management Refactor - Put snapshot on communication_queue, remove throttling)
        """
        thread_name = threading.current_thread().name
        main_logger = logging.getLogger(__name__)
        rendering_logger = logging.getLogger("RenderingPipeline")
        log_prefix = f"CompThread ({thread_name} R1 Queue Refactor): " # Updated round

        wait_check_interval = 0.03
        gc_interval = 100
        steps_since_last_gc = 0

        if not hasattr(self, 'communication_queue'): main_logger.error(f"{log_prefix}Communication queue not initialized! Exiting."); return
        if not hasattr(self, 'render_data_queue'): main_logger.error(f"{log_prefix}Render data queue not initialized! Exiting."); return
        main_logger.info(f"--- Computation Thread ({thread_name}) Started --- Received stop_event (ID: {id(stop_event)}, is_set={stop_event.is_set()})")
        main_logger.info(f"{log_prefix}Using communication_queue ID: {id(self.communication_queue)}, render_data_queue ID: {id(self.render_data_queue)}")

        try:
            while True: # Loop indefinitely until stop_event is set
                throttle_wait_time = 0.0
                step_duration = 0.0
                loop_start_time = time.time()
                snapshot = None # Initialize snapshot for this iteration

                try:
                    # --- Check stop_event FIRST ---
                    logger.debug(f"{log_prefix}Loop Start: Checking stop_event (ID: {id(stop_event)}, is_set={stop_event.is_set()})")
                    if stop_event.is_set():
                        main_logger.info(f"{log_prefix}Stop event detected at start of loop. Exiting.")
                        break
                    # ---

                    # --- Pause/Stop Logic ---
                    is_paused = hasattr(self, 'computation_pause_flag') and not self.computation_pause_flag.is_set()
                    is_stopped = hasattr(self, '_stopped') and self._stopped
                    if is_paused or is_stopped:
                        state_reason = "STOPPED" if is_stopped else "PAUSED"
                        main_logger.debug(f"{log_prefix}{state_reason}. Waiting...")
                        while (not self.computation_pause_flag.is_set() or self._stopped) and not stop_event.is_set(): time.sleep(wait_check_interval)
                        if stop_event.is_set(): main_logger.info(f"{log_prefix}Stop signal received while {state_reason}. Exiting loop."); break
                        main_logger.debug(f"{log_prefix}Resumed/Started."); continue
                    # ---

                    # --- Queue Size Logging (Informational Only) ---
                    comm_qsize = self.communication_queue.qsize()
                    render_qsize = self.render_data_queue.qsize()
                    rendering_logger.debug(f"{log_prefix}Queue Sizes: Comm={comm_qsize}, Render={render_qsize}")
                    # ---

                    # --- REMOVED: Manual Throttling based on communication_queue size ---
                    # The prep thread blocking on render_data_queue.put() will implicitly throttle this loop.
                    # ---

                    # --- Final Check Before Computation ---
                    is_paused = hasattr(self, 'computation_pause_flag') and not self.computation_pause_flag.is_set(); is_stopped = hasattr(self, '_stopped') and self._stopped
                    if stop_event.is_set() or is_paused or is_stopped: log_reason = "Stop event set" if stop_event.is_set() else "Paused" if is_paused else "Stopped"; main_logger.info(f"{log_prefix}Condition met ({log_reason}) right before controller.step(). Skipping step."); continue
                    # ---

                    # --- Perform one computation step ---
                    step_start_time = time.time()
                    current_gen = self.controller.generation if self.controller else -1
                    rule = self.controller.rule if self.controller else None
                    rule_name = rule.name if rule else "N/A"
                    rendering_logger.debug(f"{log_prefix}Starting Step {current_gen} (Rule: {rule_name})")
                    main_logger_level_name = logging.getLevelName(main_logger.getEffectiveLevel())
                    main_logger.debug(f"{log_prefix}VERIFY Main Logger Level BEFORE step_simulation_logic: {main_logger_level_name}")

                    snapshot = self.step_simulation_logic(main_logger) # Get snapshot or None

                    step_duration = time.time() - step_start_time
                    if hasattr(self, 'step_duration_history'): self.step_duration_history.append(step_duration)
                    if snapshot is None: main_logger.error(f"{log_prefix}step_simulation_logic returned None. Stopping."); break # Stop if step failed
                    snapshot_gen = snapshot.get('generation', -1) # Get generation from returned snapshot
                    rendering_logger.debug(f"{log_prefix}Step {snapshot_gen-1} computed in {step_duration:.4f}s")
                    # ---

                    # --- Check stop_event BEFORE putting on queue ---
                    if stop_event.is_set():
                        main_logger.info(f"{log_prefix}Stop event detected AFTER step computation but BEFORE queue put. Discarding snapshot for Gen {snapshot_gen-1}.")
                        break # Exit loop without putting on queue
                    # ---

                    # --- Put snapshot onto communication_queue ---
                    try:
                        # Package snapshot for the prep thread
                        # Highlights are calculated in prep thread now, so don't need them here
                        queue_item = {
                            "snapshot": snapshot,
                            # "nodes_to_highlight": set(), # Prep thread will calculate
                            # "edges_to_highlight": set()  # Prep thread will calculate
                        }
                        # Put onto the (large/unbounded) communication queue
                        self.communication_queue.put(queue_item, block=True, timeout=1.0) # Use block=True
                        rendering_logger.debug(f"{log_prefix}Put snapshot for gen {snapshot_gen} onto communication_queue (qsize={self.communication_queue.qsize()}).")
                    except queue.Full:
                        # This should ideally not happen often with a large queue, but handle it
                        logger.warning(f"{log_prefix}Communication queue full! Discarding snapshot for gen {snapshot_gen}.")
                    except Exception as q_err:
                        logger.error(f"{log_prefix}Error putting snapshot on communication_queue: {q_err}")
                        self.running = False # Stop on queue error
                        if hasattr(self, 'root') and self.control_panel_ui is not None and hasattr(self.control_panel_ui, 'update_button_states'):
                            self.root.after(0, self.control_panel_ui.update_button_states)
                        break # Exit loop
                    # ---

                    rendering_logger.debug(f"{log_prefix}Step {current_gen} Complete")

                    # [ Periodic Garbage Collection - Unchanged ]
                    steps_since_last_gc += 1
                    if steps_since_last_gc >= gc_interval: gc.collect(); main_logger.debug(f"{log_prefix}Performed periodic GC."); steps_since_last_gc = 0

                except Exception as e:
                    main_logger.error(f"--- Computation Thread ({thread_name}) Error in main loop: {e} ---")
                    main_logger.error(traceback.format_exc())
                    if hasattr(self, 'computation_running_flag'): self.computation_running_flag.clear()
                    try: self.communication_queue.put(None, block=False) # Signal error
                    except: pass
                    break # Exit loop on error
                finally:
                    loop_duration = time.time() - loop_start_time
                    rendering_logger.debug(f"{log_prefix}Iteration took {loop_duration:.4f}s (Step: {step_duration:.4f}s, Throttle Wait: {throttle_wait_time:.4f}s)")

            # --- Loop finished (either by stop_event or error) ---
            main_logger.info(f"--- Computation Thread ({thread_name}) Exiting WHILE loop (Stop Event Set: {stop_event.is_set()}) ---")

        finally:
            main_logger.info(f"{log_prefix}Pool shutdown will be handled by controller cleanup.")
            main_logger.info(f"--- Computation Thread ({thread_name}) Fully Exiting _computation_loop ---")

    def _open_shape_editor_and_export_rle(self):
        """Opens the editor (if not open) and triggers the export RLE dialog."""
        self._open_shape_editor_window()
        if hasattr(self, 'shape_editor_window') and self.shape_editor_window and self.shape_editor_window.winfo_exists():
            self.shape_editor_window._export_library_as_rle_dialog()

    def _open_shape_editor_window(self):
        """Opens the Shape Library & Editor window."""
        # Check if already open
        if hasattr(self, 'shape_editor_window') and self.shape_editor_window and self.shape_editor_window.winfo_exists():
            self.shape_editor_window.lift()
            logger.info("Shape editor window already open, bringing to front.")
            return

        try:
            manager = ShapeLibraryManager.get_instance(self.app_paths) # Ensure manager is initialized with paths
            self.shape_editor_window = ShapeLibraryEditorWindow(self, manager)
            logger.info("Opened Shape Library & Editor window.")
        except Exception as e:
            logger.error(f"Error opening shape editor window: {e}")
            messagebox.showerror("Error", f"Could not open Shape Editor: {e}", parent=self.root)

    def _open_shape_editor_and_load(self):
        """Opens the editor (if not open) and triggers the load file dialog."""
        self._open_shape_editor_window()
        if hasattr(self, 'shape_editor_window') and self.shape_editor_window and self.shape_editor_window.winfo_exists():
            self.shape_editor_window._load_library_file()

    def _open_shape_editor_and_save(self):
        """Opens the editor (if not open) and triggers the save file dialog."""
        self._open_shape_editor_window()
        if hasattr(self, 'shape_editor_window') and self.shape_editor_window and self.shape_editor_window.winfo_exists():
            self.shape_editor_window._save_library_file()

    def _select_all_nodes(self):
        """Selects all currently active nodes on the grid."""
        logger.info("Selecting all active nodes.")
        if self.grid is None: return

        active_indices = np.where(self.grid.grid_array.ravel() > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD)[0]
        selected_coords = set()
        for idx in active_indices:
            try:
                selected_coords.add(tuple(_unravel_index(idx, self.grid.dimensions)))
            except IndexError:
                logger.warning(f"Select All: Index {idx} out of bounds for grid dimensions {self.grid.dimensions}")

        self.current_selection['nodes'] = selected_coords
        self.current_selection['edges'] = set() # Clear edge selection
        logger.info(f"Selected {len(selected_coords)} active nodes.")

        # Update editor buttons
        self._update_editor_buttons_if_open()
        # Force redraw to show selection highlight
        self._safe_plot_update(force=True)

    def _add_nodes_within_selection(self):
        """Placeholder for adding nodes within the current selection bounds."""
        logger.info("Add Nodes Within Selection clicked (Not Implemented Yet).")
        messagebox.showinfo("Not Implemented", "Adding nodes within selection is not yet implemented.", parent=self.root)

    def _cut_selection(self):
        """Copies the selection to the clipboard and then erases the selected nodes.
           (Round 11 Fix: Don't clear clipboard on successful cut)
           (Round 10: Pause simulation before action)"""
        log_prefix = "_cut_selection (R11 Fix, R10 Pause): " # Updated round
        logger.info(f"{log_prefix}Attempting to cut selection.")

        # --- ADDED: Pause simulation ---
        self._request_pause_for_interaction("Cut Selection")
        # ---

        if not self.current_selection.get('nodes'):
            messagebox.showwarning("Nothing Selected", "Select nodes using Lasso first.", parent=self.root)
            return
        if self.grid is None: return

        # 1. Copy the selection first
        self._copy_selection() # This stores data in self._clipboard

        # 2. Check if copy was successful (clipboard has data)
        if hasattr(self, '_clipboard') and self._clipboard:
            logger.debug(f"{log_prefix}Copy successful, proceeding to erase selection for cut.")
            # 3. Erase the selected nodes (use the ViewManager helper)
            if hasattr(self, 'view_manager') and self.view_manager:
                self._push_grid_state_to_undo("Cut Selection (Erase)") # Specific undo action
                if self.view_manager._erase_selected_nodes():
                    logger.info(f"{log_prefix}Selection successfully cut (copied and erased).")
                    # --- DO NOT CLEAR CLIPBOARD ON SUCCESS ---
                    # self._clipboard = None # REMOVED
                    # ---
                    # Redraw is handled by _erase_selected_nodes
                else:
                    logger.error(f"{log_prefix}Failed to erase nodes after copying for cut operation.")
                    if self._grid_undo_stack and self._grid_undo_stack[-1].get('action') == "Cut Selection (Erase)":
                        self._grid_undo_stack.pop()
                    messagebox.showerror("Error", "Failed to erase selection after copying.", parent=self.root)
                    self._clipboard = None # Clear clipboard ONLY if erase failed
            else:
                logger.error(f"{log_prefix}ViewManager not available, cannot erase selection for cut.")
                self._clipboard = None # Clear clipboard if erase failed
        else:
            logger.error(f"{log_prefix}Copy operation failed, cannot complete cut.")
            messagebox.showerror("Error", "Failed to copy selection, cut operation cancelled.", parent=self.root)
            self._clipboard = None # Clear clipboard if copy failed

    def _copy_selection(self):
        """Copies the selected nodes/edges to an internal clipboard."""
        logger.info("Attempting to copy selection.")
        if not self.current_selection.get('nodes'):
            messagebox.showwarning("Nothing Selected", "Select nodes using Lasso first.", parent=self.root)
            return
        if self.grid is None: return

        try:
            selected_node_coords_abs = self.current_selection['nodes']
            active_coords_abs = list(selected_node_coords_abs)
            if not active_coords_abs: return

            dims = len(active_coords_abs[0])
            min_coords = list(active_coords_abs[0])
            for coord in active_coords_abs[1:]:
                for d in range(dims): min_coords[d] = min(min_coords[d], coord[d])
            origin_offset = tuple(min_coords)

            relative_coords = [tuple(c - mc for c, mc in zip(abs_coord, origin_offset)) for abs_coord in active_coords_abs]
            abs_to_rel_map = dict(zip(active_coords_abs, relative_coords))

            node_states_rel: Dict[Tuple[int, ...], float] = {}
            for abs_coord in active_coords_abs:
                rel_coord = abs_to_rel_map.get(abs_coord)
                if rel_coord is not None:
                    try: node_states_rel[rel_coord] = float(self.grid.grid_array[abs_coord])
                    except: pass

            relative_edges_list: List[Tuple[Tuple[int, ...], Tuple[int, ...]]] = []
            edge_states_rel: Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float] = {}
            active_coords_abs_set = set(active_coords_abs)
            for edge_abs, state in self.grid.edge_states.items():
                node1_abs, node2_abs = edge_abs
                if node1_abs in active_coords_abs_set and node2_abs in active_coords_abs_set:
                    rel_node1 = abs_to_rel_map.get(node1_abs); rel_node2 = abs_to_rel_map.get(node2_abs)
                    if rel_node1 is not None and rel_node2 is not None:
                        ordered_rel_edge_tuple = (rel_node1, rel_node2) if rel_node1 < rel_node2 else (rel_node2, rel_node1)
                        if ordered_rel_edge_tuple not in edge_states_rel:
                            relative_edges_list.append(ordered_rel_edge_tuple)
                            edge_states_rel[ordered_rel_edge_tuple] = float(state)

            # Store copied data in a temporary attribute (clipboard)
            self._clipboard = {
                "relative_coords": relative_coords,
                "node_states": node_states_rel,
                "relative_edges": relative_edges_list,
                "edge_states": edge_states_rel,
                "connectivity": "explicit" if relative_edges_list else "none"
            }
            logger.info(f"Copied {len(relative_coords)} nodes and {len(relative_edges_list)} edges to clipboard.")
            self._update_editor_buttons_if_open() # Use the corrected helper method

        except Exception as e:
            logger.error(f"Error copying selection: {e}")
            messagebox.showerror("Error", f"Failed to copy selection: {e}", parent=self.root)
            self._clipboard = None
            self._update_editor_buttons_if_open() # Use the corrected helper method

    def _paste_selection(self, origin_coords: Tuple[int, ...]):
        """Pastes the clipboard content at the specified origin, checking overlap first.
           Clears queues after successful direct paste.
           (Round 11: Clear queues after successful direct paste)"""
        log_prefix = "_paste_selection (R11 Queue Clear): " # Updated round
        logger.info(f"{log_prefix}Attempting to paste selection at {origin_coords}.")
        if not hasattr(self, '_clipboard') or not self._clipboard:
            messagebox.showwarning("Empty Clipboard", "Nothing to paste. Copy or Cut a selection first.", parent=self.root)
            return
        if self.grid is None or self.grid.shape_placer is None:
            logger.error("Grid or ShapePlacer not available for paste.")
            return

        try:
            # Create a temporary ShapeDefinition from clipboard data
            clipboard_data = self._clipboard
            temp_shape_def = ShapeDefinition(
                name="PastedShape", # Temporary name
                category="Clipboard",
                relative_coords=clipboard_data["relative_coords"],
                node_states=clipboard_data["node_states"],
                relative_edges=clipboard_data["relative_edges"],
                edge_states=clipboard_data["edge_states"],
                connectivity=clipboard_data["connectivity"]
            )

            # --- Check if paste fits ---
            min_rel, max_rel = temp_shape_def.get_bounding_box()
            shape_size = tuple(mx - mn + 1 for mn, mx in zip(min_rel, max_rel))
            required_dims = tuple(o + s for o, s in zip(origin_coords, shape_size))
            fits = all(req <= grid_dim for req, grid_dim in zip(required_dims, self.grid.dimensions))

            resize_info = None
            if not fits:
                logger.info("Pasted shape does not fit current grid. Prompting user to resize.")
                grid_is_empty = not np.any(self.grid.grid_array > 1e-6)
                dialog = ResizePromptDialog(self.root, required_dims, self.grid.dimensions, grid_is_empty)
                resize_info = dialog.result
                if resize_info is None or resize_info.get("action") != "resize":
                    logger.info("User cancelled resize or paste.")
                    return
            # ---

            # --- Placement Logic ---
            if resize_info:
                logger.info(f"{log_prefix}Triggering resize to {resize_info['dimensions']} before pasting.")
                # Resize handles its own queue clearing and redraw
                self._apply_new_grid_size(
                    target_dimensions=resize_info['dimensions'],
                    clear_or_copy=resize_info['clear_action'],
                    shape_to_place_after=temp_shape_def,
                    origin_to_place_after=origin_coords
                )
            else:
                logger.info(f"{log_prefix}Pasting clipboard content at grid origin {origin_coords}")

                # --- Overlap Check BEFORE placing ---
                overlaps = False
                for rel_coord in temp_shape_def.get_relative_coordinates():
                    abs_coord = tuple(o + r for o, r in zip(origin_coords, rel_coord))
                    if self.grid.is_valid_coord(abs_coord):
                        try:
                            if self.grid.grid_array[abs_coord] > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD:
                                overlaps = True; break
                        except IndexError: pass

                proceed_paste = True
                if overlaps:
                    logger.warning("Paste overlaps existing active cells.")
                    overlap_dialog = OverlapPromptDialog(self.root, "Pasted Shape")
                    action = overlap_dialog.result
                    if action == "cancel": proceed_paste = False
                    elif action == "find_clear_spot": # Changed from find_spot
                        logger.info("User chose to find clear spot for paste.")
                        new_origin = self._find_empty_spot_for_shape(temp_shape_def, origin_coords)
                        if new_origin:
                            origin_coords = new_origin # Update origin if spot found
                            logger.info(f"Found clear spot for paste at: {origin_coords}")
                        else:
                            proceed_paste = False
                            logger.warning("Could not find clear spot for paste.")
                            messagebox.showinfo("Paste Failed", "Could not find a clear spot nearby.", parent=self.root)
                    # "overwrite" means proceed_paste remains True
                # ---

                if proceed_paste:
                    self._push_grid_state_to_undo("Paste Selection")
                    placed_indices = self.grid.shape_placer.place_shape_definition(temp_shape_def, origin_coords)
                    if placed_indices is not None:
                        # --- ADDED: Clear queues after successful direct paste ---
                        self._clear_computation_and_render_queues()
                        # ---
                        self._safe_plot_update() # Use non-forced update here
                        logger.debug("Paste finished, queues cleared, visualization updated.")
                    else:
                        logger.warning("Paste seemed allowed but place_shape_definition returned None.")
                        if self._grid_undo_stack and self._grid_undo_stack[-1].get('action') == "Paste Selection":
                            self._grid_undo_stack.pop()
                else:
                    logger.info("Paste cancelled by user during overlap prompt or find spot.")

        except Exception as e:
            logger.error(f"Error pasting selection: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Error", f"Failed to paste selection: {e}", parent=self.root)

    def _clear_selection_after_action(self):
        """Clears the current selection in the GUI."""
        # --- MODIFIED: Access current_selection via self.gui ---
        if self.current_selection.get('nodes'): # Check if self.gui exists
            logger.debug("Clearing selection after tool action.")
            self.current_selection['nodes'] = set()
            self.current_selection['edges'] = set()
            # Update editor buttons
            self._update_editor_buttons_if_open() # Use the corrected helper method

    def _find_empty_spot_for_shape(self, shape_def: ShapeDefinition, initial_origin: Tuple[int, ...]) -> Optional[Tuple[int, ...]]:
        """
        Performs a spiral search outwards from the initial origin to find
        an empty spot large enough for the shape's bounding box.

        Returns:
            The coordinates of the top-left corner of the found empty spot,
            or None if no suitable spot is found within a reasonable search radius.
        """
        if self.grid is None: return None
        logger.debug(f"Searching for empty spot for '{getattr(shape_def, 'name', type(shape_def).__name__)}' starting near {initial_origin}")

        min_rel, max_rel = shape_def.get_bounding_box()
        shape_size = tuple(mx - mn + 1 for mn, mx in zip(min_rel, max_rel))
        dims = len(self.grid.dimensions)

        # --- Check Function: Checks if a given origin is valid AND clear ---
        def is_spot_valid_and_clear(origin_to_check: Tuple[int, ...]) -> bool:
            # 1. Check if origin itself is valid
            if self.grid is None or not self.grid.is_valid_coord(origin_to_check):
                return False
            # 2. Check if the entire shape fits and doesn't overlap active cells
            for rel_coord in shape_def.get_relative_coordinates():
                 if len(rel_coord) != len(origin_to_check): continue # Dimension mismatch
                 abs_coord = tuple(o + r for o, r in zip(origin_to_check, rel_coord))
                 if not self.grid.is_valid_coord(abs_coord):
                     return False # Shape goes out of bounds
                 try:
                     if self.grid.grid_array[abs_coord] > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD:
                         return False # Overlaps an active cell
                 except IndexError:
                     return False # Should not happen if is_valid_coord passed, but safety check
            return True # No overlaps found for any shape cell
        # ---

        # --- Spiral Search Logic (2D/3D) ---
        # Start at the initial origin
        q: queue.Queue[Tuple[int,...]] = queue.Queue()
        q.put(initial_origin)
        visited: Set[Tuple[int,...]] = {initial_origin}
        max_search_steps = 5000 # Limit search iterations

        search_count = 0
        while not q.empty() and search_count < max_search_steps:
            search_count += 1
            current_origin = q.get()

            # Check if this spot is clear
            if is_spot_valid_and_clear(current_origin):
                logger.info(f"Found empty spot at {current_origin} after {search_count} checks.")
                return current_origin

            # Add neighbors to the queue (spiral outwards)
            # Define offsets based on dimensions
            if dims == 2:
                offsets = [(0, 1), (1, 0), (0, -1), (-1, 0), (1, 1), (1, -1), (-1, -1), (-1, 1)] # Moore neighborhood for search
            else: # 3D
                offsets = list(itertools.product([-1, 0, 1], repeat=3))
                offsets.remove((0, 0, 0)) # Moore 3D

            for offset in offsets:
                next_origin_list = list(current_origin)
                valid_offset = True
                if len(offset) != dims: continue # Skip if offset dim mismatch
                for d in range(dims):
                    next_origin_list[d] += offset[d]
                next_origin = tuple(next_origin_list)

                # Check if neighbor is valid grid coord and not visited
                if self.grid.is_valid_coord(next_origin) and next_origin not in visited:
                    visited.add(next_origin)
                    q.put(next_origin)

        logger.warning(f"Could not find empty spot within {max_search_steps} steps for shape '{getattr(shape_def, 'name', type(shape_def).__name__)}'.")
        return None

    def _place_shape_definition_from_editor(self):
        """Gets selected shape, calculates center, checks 'Add Edges' checkbox, and places it."""
        log_prefix = "_place_shape_definition_from_editor: "
        # --- ADDED: Log entry and pause state ---
        logger.info(f"{log_prefix}Initiating placement from editor. Paused={self.paused}")
        # ---

        if not hasattr(self, 'shape_editor_window') or not self.shape_editor_window or not self.shape_editor_window.winfo_exists():
            logger.warning("Shape editor window not open.")
            return
        if self.grid is None or self.grid.shape_placer is None:
            logger.error("Grid or ShapePlacer not available.")
            messagebox.showerror("Error", "Grid not ready for shape placement.", parent=self.root)
            return

        selected_shape_def = self.shape_editor_window.selected_shape_def
        if not selected_shape_def:
            logger.warning("No shape selected in the editor.")
            messagebox.showwarning("No Selection", "Please select a shape from the library first.", parent=self.shape_editor_window)
            return

        add_default_edges = False
        if hasattr(self.shape_editor_window, 'add_edges_on_place_var'):
            add_default_edges = self.shape_editor_window.add_edges_on_place_var.get()
            logger.debug(f"Add Default Edges checkbox state: {add_default_edges}")
        else:
            logger.warning("Could not find add_edges_on_place_var in editor window.")

        try:
            center_coords_float = self._get_view_center_grid_coords()
            center_coords_int = tuple(int(round(c)) for c in center_coords_float)
            min_rel, max_rel = selected_shape_def.get_bounding_box()
            shape_center_offset = tuple((mn + mx) / 2 for mn, mx in zip(min_rel, max_rel))
            origin = tuple(int(round(center - offset)) for center, offset in zip(center_coords_int, shape_center_offset))

            logger.info(f"Placing shape '{selected_shape_def.name}' centered near grid coords {center_coords_int} (calculated origin: {origin})")

            # --- REMOVED Pause/Resume ---
            # self._pause_computation(reason="Place Shape from Editor")
            placed_indices = None # Initialize
            try:
                # --- Overlap Check (using place_shape_definition's internal logic) ---
                # place_shape_definition now handles overlap prompting and returns None if cancelled
                self._push_grid_state_to_undo(f"Place Shape '{selected_shape_def.name}' (Editor)")
                placed_indices = self.grid.shape_placer.place_shape_definition(selected_shape_def, origin)

                if placed_indices is not None:
                    if add_default_edges:
                        logger.info("Add Default Edges checked, adding edges based on shape connectivity.")
                        connectivity_to_use = selected_shape_def.connectivity
                        if connectivity_to_use != "explicit" and connectivity_to_use != "none":
                            self.grid.shape_placer.add_default_edges(placed_indices, connectivity_to_use)
                        elif connectivity_to_use == "explicit":
                             logger.debug("Shape uses explicit edges, not adding default edges.")
                        else: # connectivity == "none"
                             logger.debug("Shape connectivity is 'none', not adding default edges.")
                    # Force redraw only if placement wasn't cancelled
                    self._safe_plot_update(force=True)
                    logger.debug("Shape placement attempt finished, visualization updated.")
                else:
                    logger.warning("Placement cancelled or failed in place_shape_definition.")
                    # Pop the potentially incorrect undo state
                    if self._grid_undo_stack and self._grid_undo_stack[-1]['action'].startswith("Place Shape"):
                        self._grid_undo_stack.pop()
            finally:
                # self._resume_computation(reason="Place Shape from Editor Complete") # REMOVED
                pass # No resume needed
            # --- END REMOVED Pause/Resume ---

        except Exception as e:
            logger.error(f"Error placing shape definition: {e}")
            logger.error(traceback.format_exc())
            messagebox.showerror("Error", f"Failed to place shape: {e}", parent=self.shape_editor_window)

    def _add_default_edges_to_selection(self):
        """Adds default edges ('full' connectivity) to the currently selected nodes."""
        logger.info("Attempting to add default edges to selection.")
        if not hasattr(self, 'current_selection') or not self.current_selection.get('nodes'):
            messagebox.showwarning("No Selection", "Lasso select some nodes first.", parent=self.shape_editor_window)
            return
        if self.grid is None or self.grid.shape_placer is None:
            logger.error("Grid or ShapePlacer not available.")
            return

        selected_node_coords = self.current_selection['nodes']
        # Convert coords to indices
        selected_indices = set()
        for coords in selected_node_coords:
            if self.grid.is_valid_coord(coords):
                selected_indices.add(_ravel_multi_index(np.array(coords), self.grid.dimensions))
            else:
                logger.warning(f"Skipping invalid coordinate in selection: {coords}")

        if not selected_indices:
            logger.warning("No valid node indices in selection.")
            return

        try:
            # Use 'full' connectivity for this action
            self.grid.shape_placer.add_default_edges(selected_indices, "full")
            self._safe_plot_update(force=True) # Update view
            logger.info(f"Added default 'full' edges to {len(selected_indices)} selected nodes.")
        except Exception as e:
            logger.error(f"Error adding default edges to selection: {e}")
            messagebox.showerror("Error", f"Failed to add edges: {e}", parent=self.shape_editor_window)

    def _remove_edges_from_selection(self):
        """Removes all edges connecting any two nodes within the current selection."""
        logger.info("Attempting to remove edges from selection.")
        if not hasattr(self, 'current_selection') or not self.current_selection.get('nodes'):
            messagebox.showwarning("No Selection", "Lasso select some nodes first.", parent=self.shape_editor_window)
            return
        if self.grid is None:
            logger.error("Grid not available.")
            return

        selected_node_coords_set = self.current_selection['nodes']
        edges_to_remove = set()
        removed_count = 0

        # Iterate through a copy of the grid's edges
        for edge_coords in list(self.grid.edges):
            node1_coords, node2_coords = edge_coords
            # Check if BOTH endpoints are in the selected set
            if node1_coords in selected_node_coords_set and node2_coords in selected_node_coords_set:
                edges_to_remove.add(edge_coords)

        if not edges_to_remove:
            logger.info("No internal edges found within the selection to remove.")
            return

        # Remove the identified edges
        try:
            for edge_coords in edges_to_remove:
                node1_coords, node2_coords = edge_coords
                idx1 = _ravel_multi_index(np.array(node1_coords), self.grid.dimensions)
                idx2 = _ravel_multi_index(np.array(node2_coords), self.grid.dimensions)
                self.grid.remove_edge(idx1, idx2)
                removed_count += 1

            self._safe_plot_update(force=True) # Update view
            logger.info(f"Removed {removed_count} internal edges from selection.")
        except Exception as e:
            logger.error(f"Error removing edges from selection: {e}")
            messagebox.showerror("Error", f"Failed to remove edges: {e}", parent=self.shape_editor_window)

    def _save_grid_as_new_shape(self):
        """Saves the currently active nodes/edges and their states as a new shape definition.
           (Round 17 Fix: Use SaveShapeDialog modal, pass rule name)"""
        log_prefix = "_save_grid_as_new_shape (R17 Modal Fix): " # Updated round
        logger.info(f"{log_prefix}Attempting to save grid as new shape.")
        if self.grid is None:
            messagebox.showerror("Error", "Grid is not initialized.", parent=self.root)
            return

        # 1. Get Active Nodes (using visibility threshold)
        active_indices = np.where(self.grid.grid_array.ravel() > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD)[0]
        if active_indices.size == 0:
            messagebox.showwarning("Empty Grid", "No active nodes found to save as a shape.", parent=self.root)
            return

        active_coords_abs = [tuple(_unravel_index(idx, self.grid.dimensions)) for idx in active_indices]

        # 2. Calculate Relative Coordinates and Origin Offset
        if not active_coords_abs: return
        dims = len(active_coords_abs[0])
        min_coords = list(active_coords_abs[0])
        for coord in active_coords_abs[1:]:
            for d in range(dims):
                min_coords[d] = min(min_coords[d], coord[d])
        origin_offset = tuple(min_coords)

        relative_coords = [tuple(c - mc for c, mc in zip(abs_coord, origin_offset)) for abs_coord in active_coords_abs]
        abs_to_rel_map = dict(zip(active_coords_abs, relative_coords))

        # Capture Node States
        node_states_rel: Dict[Tuple[int, ...], float] = {}
        for abs_coord in active_coords_abs:
            rel_coord = abs_to_rel_map.get(abs_coord)
            if rel_coord is not None:
                try:
                    node_states_rel[rel_coord] = float(self.grid.grid_array[abs_coord])
                except IndexError: logger.warning(f"{log_prefix}IndexError getting state for {abs_coord} while saving shape.")
                except Exception as e: logger.error(f"{log_prefix}Error getting state for {abs_coord}: {e}")

        # Capture Edges and Edge States within the shape
        relative_edges_list: List[Tuple[Tuple[int, ...], Tuple[int, ...]]] = []
        edge_states_rel: Dict[Tuple[Tuple[int, ...], Tuple[int, ...]], float] = {}
        active_coords_abs_set = set(active_coords_abs)

        for edge_abs, state in self.grid.edge_states.items():
            node1_abs, node2_abs = edge_abs
            if node1_abs in active_coords_abs_set and node2_abs in active_coords_abs_set:
                rel_node1 = abs_to_rel_map.get(node1_abs)
                rel_node2 = abs_to_rel_map.get(node2_abs)
                if rel_node1 is not None and rel_node2 is not None:
                    if rel_node1 < rel_node2:
                        ordered_rel_edge_tuple = (rel_node1, rel_node2)
                    else:
                        ordered_rel_edge_tuple = (rel_node2, rel_node1)
                    if ordered_rel_edge_tuple not in edge_states_rel:
                        relative_edges_list.append(ordered_rel_edge_tuple)
                        edge_states_rel[ordered_rel_edge_tuple] = float(state)

        # --- MODIFIED: Prompt using SaveShapeDialog, pass rule name ---
        shape_manager = ShapeLibraryManager.get_instance()
        existing_names = shape_manager.get_shape_names()
        current_rule_name = self.controller.rule.name if self.controller and self.controller.rule else None
        dialog = SaveShapeDialog(self.root, shape_manager, initial_name="New Shape from Grid", existing_names=existing_names, current_rule_name=current_rule_name)
        dialog_result = dialog.result

        if dialog_result is None: # User cancelled
            logger.info(f"{log_prefix}User cancelled saving shape.")
            return

        shape_name = dialog_result["name"]
        category = dialog_result["category"]
        description = dialog_result["description"]
        tags = dialog_result["tags"]
        connectivity = "explicit" if relative_edges_list else "none"
        # --- END MODIFIED ---

        # 4. Create ShapeDefinition with states
        shape_def = ShapeDefinition(
            name=shape_name,
            category=category,
            description=description,
            relative_coords=relative_coords,
            connectivity=connectivity,
            tags=tags,
            author="User",
            relative_edges=relative_edges_list if relative_edges_list else None,
            node_states=node_states_rel if node_states_rel else None,
            edge_states=edge_states_rel if edge_states_rel else None,
            intended_rule=self.rule.name if self.rule else None
            # 'rules' field will be empty by default
        )

        # 5. Save using Manager
        try:
            manager = ShapeLibraryManager.get_instance()
            if manager.add_shape(shape_def):
                messagebox.showinfo("Success", f"Shape '{shape_name}' saved successfully.", parent=self.root)
                if hasattr(self, 'shape_editor_window') and self.shape_editor_window and self.shape_editor_window.winfo_exists():
                    self.shape_editor_window._populate_treeview()
                    self.shape_editor_window._select_shape_in_tree(shape_name) # Select new shape
            else:
                 messagebox.showerror("Error", f"Failed to save shape '{shape_name}'.", parent=self.root)
        except Exception as e:
            logger.error(f"Error saving shape: {e}")
            messagebox.showerror("Error", f"Failed to save shape: {e}", parent=self.root)

    def _clear_clipboard(self):
        """Clears the internal clipboard."""
        logger.info("Clearing clipboard.")
        self._clipboard = None
        # Update relevant UI elements (e.g., Paste button state)
        self._update_editor_buttons_if_open() # Use the corrected helper method
        # No redraw needed unless Paste button state is shown elsewhere

    def _check_queue(self): # Renamed back
        """Check the result queue for grid snapshots and schedule plot update."""
        error_occurred = False
        new_snapshot_received = False
        snapshot_generation = -1
        grid_snapshot_for_logging = None
        num_chunks_used = 0

        try:
            items_processed = 0
            while not self.result_queue.empty():
                items_processed += 1
                try:
                    item = self.result_queue.get_nowait()
                    if isinstance(item, dict) and 'grid_array' in item:
                        self._latest_grid_snapshot = item
                        grid_snapshot_for_logging = item
                        new_snapshot_received = True
                        snapshot_generation = item.get('generation', -1)
                        num_chunks_used = item.get('num_chunks', 0)
                    else:
                        logger.warning(f"    Unexpected item in queue: {type(item)}")
                except Empty: break
                except Exception as get_err: logger.error(f"  Error getting item from queue: {get_err}"); error_occurred = True; break

            if new_snapshot_received and not self._update_scheduled:
                self._update_scheduled = True
                self.root.after(0, self._safe_plot_update_wrapper)

            # --- Periodic Summary Log to File ---
            reporting_enabled = self.periodic_reporting_var.get()

            if reporting_enabled and new_snapshot_received and snapshot_generation >= 0:
                try:
                    interval_str = self.reporting_interval_var.get()
                    log_interval = int(interval_str) if interval_str.isdigit() else LogSettings.Performance.REPORTING_INTERVAL
                    log_interval = max(LogSettings.Performance.MIN_REPORTING_INTERVAL, min(log_interval, LogSettings.Performance.MAX_REPORTING_INTERVAL))

                    if snapshot_generation % log_interval == 0:
                        logger_periodic = logging.getLogger("periodic_report")

                        # --- ADDED: Log self.perf_logger ID before get_average ---
                        logger.debug(f"_check_queue: Accessing self.perf_logger (ID: {id(self.perf_logger)}) for AvgStep.")
                        # ---
                        avg_step_time = self.perf_logger.get_average('update_grid_parallel_total_time') * 1000 # ms

                        # --- Gather other info ---
                        rule_name = self.controller.rule.name if self.controller and self.controller.rule else "N/A"
                        dims = tuple(self.dimensions); neigh_type = self.neighborhood_type.name
                        total_nodes = np.prod(dims)
                        step_num = snapshot_generation; parallel_enabled = GlobalSettings.USE_PARALLEL_PROCESSING
                        active_nodes = np.sum(grid_snapshot_for_logging['grid_array'] > 1e-6) if grid_snapshot_for_logging and 'grid_array' in grid_snapshot_for_logging else 0
                        active_ratio = active_nodes / total_nodes if total_nodes > 0 else 0.0
                        edge_count = len(grid_snapshot_for_logging['edges']) if grid_snapshot_for_logging and 'edges' in grid_snapshot_for_logging else 0
                        process = psutil.Process(os.getpid()); mem_usage_mb = process.memory_info().rss / (1024 * 1024)
                        # --- MODIFIED: Get dynamic chunk size from grid ---
                        dynamic_chunk_size = self.grid._calculated_chunk_size if self.grid and hasattr(self.grid, '_calculated_chunk_size') else 'N/A'
                        # ---
                        actual_chunks = num_chunks_used
                        num_processes_setting = GlobalSettings.Simulation.NUM_PROCESSES
                        workers_actual = 1; pool_type_str = "None"; pool_instance_id = "N/A"
                        if hasattr(self.controller, 'process_pool') and self.controller.process_pool:
                            pool_instance = self.controller.process_pool; pool_instance_id = id(pool_instance)
                            if isinstance(pool_instance, ProcessPoolExecutor): workers_actual = num_processes_setting; pool_type_str = "ProcessPool"
                            elif isinstance(pool_instance, ThreadPoolExecutor): workers_actual = 1; pool_type_str = "ThreadPool"
                        cache_hits = self.grid._cache_hits if self.grid else 0; cache_misses = self.grid._cache_misses if self.grid else 0
                        cache_hit_rate = cache_hits / (cache_hits + cache_misses) if (cache_hits + cache_misses) > 0 else 0.0
                        step_delay_ms = self.step_delay

                        summary_msg = (
                            f"Gen:{step_num}; Rule:{rule_name}; Dim:{dims}; Neigh:{neigh_type}; "
                            f"Nodes:{total_nodes}; Active:{active_nodes}({active_ratio:.1%}); Edges:{edge_count}; "
                            f"Mem:{mem_usage_mb:.1f}MB; Parallel:{parallel_enabled}; PoolType:{pool_type_str}; WorkersSet:{num_processes_setting}; WorkersActual:{workers_actual}; "
                            f"ChunkUsed:{dynamic_chunk_size}; ChunksUsed:{actual_chunks}; AvgStep:{avg_step_time:.2f}ms; " # Updated log
                            f"CacheHits:{cache_hits}; CacheMisses:{cache_misses} (Rate:{cache_hit_rate:.1%}); StepDelay:{step_delay_ms}ms"
                        )
                        logger_periodic.info(summary_msg)
                except Exception as log_err:
                    logger.warning(f"Error generating/logging performance summary: {log_err}")
            # --- END MODIFIED ---

        except Exception as e:
            logger.error(f"Error checking result queue: {e}")
            logger.error(traceback.format_exc())
            error_occurred = True

        # Schedule next check if running
        if self.running:
            delay_ms = 33
            if error_occurred: delay_ms = 100; logger.warning(f"Scheduling next _check_queue with increased delay ({delay_ms}ms) due to error.")
            if hasattr(self, 'root') and self.root.winfo_exists(): self.root.after(delay_ms, self._check_queue)
            else: logger.warning("Root window destroyed, cannot schedule next _check_queue.")

    def _run_simulation_step(self):
        """Run a single simulation step and schedule the next one"""
        try:
            if not self.running or self.paused:
                logger.info("Simulation paused or stopped")
                return

            logger.info("Starting simulation step...")

            # Add a flag to track if we're in the middle of a step
            if not hasattr(self, '_is_stepping'):
                self._is_stepping = False

            # If we're already stepping, skip this step
            if self._is_stepping:
                logger.debug("Already stepping, skipping")
                # Schedule next step
                self.root.after(int(self.step_delay), self._run_simulation_step)
                return

            self._is_stepping = True

            try:
                # Perform step logic using the encapsulated method
                self.step_simulation_logic(logger=logging.getLogger(__name__))

                # Update step counter
                self.step_count = self.controller.generation
                if self.step_label is not None:
                    self.step_label.config(text=f"Step: {self.step_count}")

            finally:
                # Always reset the stepping flag
                self._is_stepping = False

            # Schedule next step if still running
            if self.running and not self.paused and not self.controller.interrupt_requested:
                logger.debug("Scheduling next step")
                self.root.after(int(self.step_delay), self._run_simulation_step)
                logger.info("Next update scheduled")

        except Exception as e:
            logger.error(f"Error in simulation step: {e}")
            logger.error(traceback.format_exc())
            self.running = False
            # Use widgets dictionary instead of direct attribute access
            if 'start_button' in self.widgets and isinstance(self.widgets['start_button'], tk.Button):
                self.widgets['start_button'].config(text="Start")
                        
    @log_errors
    def change_rule(self, rule_name: str, new_params: Optional[Dict[str, Any]] = None):
        """Change the current rule"""
        try:
            # Load rule data and create new rule instance
            try:
                rule_data = RuleLibraryManager.get_rule(rule_name)
            except ValueError as e:
                logger.error(f"Error loading rule {rule_name}: {e}")
                return False

            # Create metadata for the rule
            metadata_dict = {k: v for k, v in rule_data.items() if k != 'params'}
            metadata_dict['neighborhood_type'] = self.neighborhood_type
            metadata = RuleMetadata(**metadata_dict)

            # Create new rule instance
            try:
                new_rule = RuleLibrary.create_rule(rule_name, metadata) # Get instance
            except ValueError as e:
                logger.error(f"Error creating rule {rule_name}: {e}")
                return False

            # Get parameters from rule data
            params = rule_data.get('params', {})
            if not params:
                logger.warning(f"No parameters found for rule {rule_name} in library")
                params = {} # Initialize params to empty dict if not found in rule data

            # Deep copy parameters here
            new_rule.params = copy.deepcopy(params) # Deep copy params
            logger.debug(f"New rule parameters after deep copy: {new_rule.params}")

            # Change rule in controller
            self.controller.set_rule(new_rule) # Pass the INSTANCE

            # Reset simulation with new rule
            self.reset_simulation()

            #Update plot limits based on magnification
            self._update_plot_limits()

            logger.info(f"Changed to rule: {rule_name}")
        except Exception as e:
            logger.error(f"Error changing rule: {str(e)}")

    @log_errors
    def _update_simulation(self):
        """Internal method to update simulation state"""
        try:
            while self.running and not self.paused:
                # Check if interruption was requested
                if self.controller.interrupt_requested:
                    self.running = False
                    self.start_button.config(text="Start")
                    logger.info("Simulation loop interrupted")
                    return

                if self.step_count < GlobalSettings.Simulation.NUM_STEPS:
                    self.step_simulation()
                    # Schedule next update with delay
                    self.root.after(int(self.step_delay), self._update_simulation)
                else:
                    self.running = False
                    self.start_button.config(text="Start")
                    logger.debug("Simulation run completed")
                    break

        except Exception as e:
            logger.error(f"Error in simulation update loop: {e}")
            self.running = False
            self.start_button.config(text="Start")
            raise

    def _cleanup_event_loop(self):
        """Clean up event loop properly"""
        try:
            if hasattr(self, 'event_loop') and self.event_loop is not None:
                # First check if we're in the event loop thread
                current_thread = threading.current_thread()
                is_event_loop_thread = (
                    hasattr(self, 'loop_thread') and
                    current_thread == self.loop_thread
                )

                if self.event_loop.is_running():
                    if is_event_loop_thread:
                        # If we're in the event loop thread, just stop it
                        self.event_loop.stop()
                    else:
                        # If we're in a different thread, use call_soon_threadsafe
                        self.event_loop.call_soon_threadsafe(self.event_loop.stop)

                        # Wait for the event loop to stop
                        if hasattr(self, 'loop_thread') and self.loop_thread is not None and self.loop_thread.is_alive():
                            self.loop_thread.join(timeout=1.0)
                            logger.info("Event loop thread joined")

                    # Don't close the event loop - just let it be garbage collected
                    # This avoids the "Cannot close a running event loop" error
                    self.event_loop = None

                    logger.info("Event loop cleanup completed")

        except Exception as e:
            logger.error(f"Error cleaning up event loop: {e}")
                                        
    def _setup_event_loop(self):
        """Setup event loop with proper logging configuration, ensuring single loop"""
        try:
            if not hasattr(self, 'event_loop') or self.event_loop is None:
                # Create event loop in the main thread only if it doesn't exist
                self.event_loop = asyncio.new_event_loop()
                asyncio.set_event_loop(self.event_loop)
                
                # Start the event loop in a separate thread
                def run_event_loop():
                    # Use existing logger
                    global logger
                    logger.info("Starting event loop thread")
                    asyncio.set_event_loop(self.event_loop)
                    try:
                        if self.event_loop is not None:
                            self.event_loop.run_forever()
                    except Exception as e:
                        logger.error(f"Error in event loop thread: {e}")
                    finally:
                        logger.info("Event loop thread finished")
                            
                    self.loop_thread = threading.Thread(target=run_event_loop, daemon=True)
                    self.loop_thread.start()
                    logger.info("Event loop thread started")
                
            else:
                logger.info("Event loop already running, reusing existing loop")
                
        except Exception as e:
            logger.error(f"Error setting up event loop: {e}")
            raise

    def _on_render_queue_size_change(self, value_str: str):
        """Callback for the Render Queue Size slider.
           Updates the global setting. The actual queue size takes effect on reset.
           (Round 2: Simplified for Queue Management Refactor)"""
        # --- Get separate logger ---
        rendering_logger = logging.getLogger("RenderingPipeline")
        # ---
        log_prefix = "_on_render_queue_size_change (R2 Simplified): " # Updated round
        try:
            new_render_size = int(float(value_str)) # Convert slider value to int
            if new_render_size < 1: new_render_size = 1; self.render_queue_size_var.set(new_render_size)

            # Update Render Queue setting if it changed
            if new_render_size != GlobalSettings.Simulation.RENDER_QUEUE_SIZE:
                GlobalSettings.Simulation.RENDER_QUEUE_SIZE = new_render_size
                # --- Log render queue change to rendering_logger ---
                rendering_logger.info(f"{log_prefix}Render Queue Size setting changed to: {new_render_size}. (Effective on next simulation start/reset)")
                # ---
            else:
                rendering_logger.debug(f"{log_prefix}Render Queue Size unchanged ({new_render_size}).") # Use rendering_logger

        except ValueError:
            logger.error(f"{log_prefix}Invalid value from Render Queue Size slider: {value_str}") # Use main logger
            # Reset variable to the current global setting if conversion fails
            self.render_queue_size_var.set(GlobalSettings.Simulation.RENDER_QUEUE_SIZE)
        except Exception as e:
            logger.error(f"{log_prefix}Error handling slider change: {e}") # Use main logger
            # Reset variable on other errors
            self.render_queue_size_var.set(GlobalSettings.Simulation.RENDER_QUEUE_SIZE)

    def _validate_num_steps(self, value):
        """Validate the number of steps entry"""
        if value == "":
            return True  # Allow empty string
        try:
            num = int(value)
            if num > 0:
                return True
            else:
                return False
        except ValueError:
            return False

    def _on_run_continuously_change(self):
        """Handle run continuously checkbox change"""
        self._update_num_steps_entry_state()

    def _update_num_steps_entry_state(self):
        """Update the state of the num_steps_entry based on run_continuously."""
        if 'num_steps_entry' in self.widgets and isinstance(self.widgets['num_steps_entry'], tk.Entry):  # Check existence and type
            if self.run_continuously.get():
                self.widgets['num_steps_entry'].config(state=tk.DISABLED)
                logger.debug("Disabled num_steps_entry because run_continuously is True")
            else:
                self.widgets['num_steps_entry'].config(state=tk.NORMAL)
                logger.debug("Enabled num_steps_entry because run_continuously is False")
                
    def _setup_keyboard_events(self):
        """Setup keyboard events for panning and zooming"""
        try:
            # Bind arrow keys for panning
            self.root.bind("<Up>", lambda event: self.view_manager.pan(0, 1) if hasattr(self, 'view_manager') and self.view_manager else None)
            self.root.bind("<Down>", lambda event: self.view_manager.pan(0, -1) if hasattr(self, 'view_manager') and self.view_manager else None)
            self.root.bind("<Left>", lambda event: self.view_manager.pan(1, 0) if hasattr(self, 'view_manager') and self.view_manager else None)
            self.root.bind("<Right>", lambda event: self.view_manager.pan(-1, 0) if hasattr(self, 'view_manager') and self.view_manager else None)

            # Bind shift + arrow keys for zooming
            self.root.bind("<Shift-Up>", lambda event: self.grid_visualizer.zoom(1.1) if self.grid_visualizer else None)
            self.root.bind("<Shift-Down>", lambda event: self.grid_visualizer.zoom(0.9) if self.grid_visualizer else None)

            # ADD THIS: Bind 'c' key to toggle control panel
            self.root.bind("c", lambda event: self.toggle_control_panel())
            self.root.bind("C", lambda event: self.toggle_control_panel()) # Also bind capital C

            logger.info("Keyboard events setup completed")
        except Exception as e:
            logger.error(f"Error setting up keyboard events: {e}")

    def zoom_in(self):
        """Zoom in to the visualization."""
        log_prefix = "SimulationGUI.zoom_in: "
        if hasattr(self, 'view_manager') and self.view_manager:
            factor = 0.8
            new_zoom_factor = self.view_manager.zoom(factor) # ViewManager handles axes limits and GUI state
            logger.debug(f"{log_prefix}Zoomed in with factor: {factor}. New internal zoom: {new_zoom_factor:.3f}")
            # --- ADDED: Update prep thread params ---
            with self._prep_params_lock:
                self._prep_visualization_params['zoom_factor'] = new_zoom_factor
            logger.debug(f"{log_prefix}Updated prep thread zoom factor.")
            # Optionally clear render queue to apply zoom faster
            # while not self.render_data_queue.empty(): try: self.render_data_queue.get_nowait() except queue.Empty: break
            # ---
        else:
            logger.warning(f"{log_prefix}ViewManager not initialized, cannot zoom in")

    def zoom_out(self):
        """Zoom out from the visualization."""
        log_prefix = "SimulationGUI.zoom_out: "
        if hasattr(self, 'view_manager') and self.view_manager:
            factor = 1.25
            new_zoom_factor = self.view_manager.zoom(factor) # ViewManager handles axes limits and GUI state
            logger.debug(f"{log_prefix}Zoomed out with factor: {factor}. New internal zoom: {new_zoom_factor:.3f}")
            # --- ADDED: Update prep thread params ---
            with self._prep_params_lock:
                self._prep_visualization_params['zoom_factor'] = new_zoom_factor
            logger.debug(f"{log_prefix}Updated prep thread zoom factor.")
            # Optionally clear render queue to apply zoom faster
            # while not self.render_data_queue.empty(): try: self.render_data_queue.get_nowait() except queue.Empty: break
            # ---
        else:
            logger.warning(f"{log_prefix}ViewManager not initialized, cannot zoom out")

    def reset_view(self):
        """Reset the view to the default."""
        self._reset_view_state()
        self.notify_observers()  # Notify to trigger redraw
                                                                               
    def update(self, subject):
        """Handle updates from the observed subject (Grid or Controller)"""
        # --- MODIFIED: Only log, do not call _safe_plot_update ---
        logger.debug(f"SimulationGUI received update from: {type(subject).__name__}")
        if self.grid is not None:
            logger.debug(f"  Grid ID in SimulationGUI.update: {self.grid._unique_id}")
        else:
            logger.debug("  Grid is None in SimulationGUI.update")
        # self._safe_plot_update() # REMOVED CALL
        # --- END MODIFIED SECTION ---

    def _reset_drawing_flag(self):
        """Resets the _is_drawing flag."""
        self._is_drawing = False
        logger.debug("_reset_drawing_flag: Reset _is_drawing=False")

    @timer_decorator
    def _safe_plot_update_wrapper(self, grid_snapshot: Optional[Dict[str, Any]] = None):
        """Wrapper function to call _safe_plot_update, pass snapshot, calculate/pass highlights, and reset the schedule flag.
           (Round 20: Remove grid_snapshot from _safe_plot_update call)"""

        log_prefix = "_safe_plot_update_wrapper (R20 Fix): " # Updated round
        try:
            if grid_snapshot is None:
                logger.warning(f"{log_prefix}Called without snapshot, using latest.")
                grid_snapshot = getattr(self, '_latest_grid_snapshot', None)

            if grid_snapshot:
                gen = grid_snapshot.get('generation', 'N/A')
                logger.debug(f"{log_prefix}Processing snapshot for Gen {gen}.")

                # --- Calculate highlights here, comparing snapshot to last rendered ---
                nodes_to_highlight = set()
                edges_to_highlight = set()
                highlight_on = self.highlight_var.get() if hasattr(self, 'highlight_var') else True

                if self._last_rendered_snapshot is None:
                    logger.debug(f"{log_prefix}First render (Gen {gen}), no highlights calculated.")
                elif highlight_on:
                    try:
                        # Extract current state
                        current_nodes_coords = set()
                        current_edges_coords = set()
                        grid_array_snap = grid_snapshot.get('grid_array')
                        edges_snap = grid_snapshot.get('edges')
                        if grid_array_snap is not None and edges_snap is not None:
                            grid_dims = grid_array_snap.shape
                            visible_mask = grid_array_snap > 1e-6
                            visible_indices = np.where(visible_mask.ravel())[0]
                            for idx in visible_indices:
                                current_nodes_coords.add(tuple(_unravel_index(idx, grid_dims)))
                            current_edges_coords = edges_snap
                        else: logger.warning(f"{log_prefix}Snapshot missing data for highlight calc.")

                        # Extract previous state
                        nodes_before_render = set()
                        edges_before_render = set()
                        grid_array_prev = self._last_rendered_snapshot.get('grid_array')
                        edges_prev = self._last_rendered_snapshot.get('edges')
                        if grid_array_prev is not None and edges_prev is not None:
                            grid_dims_prev = grid_array_prev.shape
                            visible_mask_prev = grid_array_prev > 1e-6
                            visible_indices_prev = np.where(visible_mask_prev.ravel())[0]
                            for idx in visible_indices_prev:
                                nodes_before_render.add(tuple(_unravel_index(idx, grid_dims_prev)))
                            edges_before_render = edges_prev
                        else: logger.warning(f"{log_prefix}Last rendered snapshot missing data for highlight calc.")

                        # Calculate ADDED nodes/edges
                        nodes_to_highlight = current_nodes_coords - nodes_before_render
                        edges_to_highlight = current_edges_coords - edges_before_render
                        logger.info(f"{log_prefix}HIGHLIGHTS CALCULATED (Gen {gen}): AddedNodes={len(nodes_to_highlight)}, AddedEdges={len(edges_to_highlight)}")

                    except Exception as diff_err:
                        logger.error(f"{log_prefix}Error calculating highlights in wrapper: {diff_err}")
                        nodes_to_highlight = set() # Ensure empty on error
                        edges_to_highlight = set()
                else: # Highlight off
                    logger.debug(f"{log_prefix}Highlighting disabled, ensuring highlight sets are empty.")
                    nodes_to_highlight = set() # Explicitly clear sets if highlight_on is False
                    edges_to_highlight = set()
                # ---

                # Call the actual update function, passing snapshot and potentially empty highlight sets
                logger.debug(f"{log_prefix}Calling _safe_plot_update for Gen {gen} with {len(nodes_to_highlight)} node highlights, {len(edges_to_highlight)} edge highlights.")
                # --- MODIFIED: Removed grid_snapshot argument ---
                self._safe_plot_update(
                    nodes_to_highlight=nodes_to_highlight, # Pass calculated or empty set
                    edges_to_highlight=edges_to_highlight  # Pass calculated or empty set
                    # force=False # Default is False
                )
                # ---
                # --- Update last rendered snapshot AFTER successful render ---
                self._last_rendered_snapshot = grid_snapshot.copy()
                logger.debug(f"{log_prefix}Updated _last_rendered_snapshot in wrapper for Gen {gen}.")
                # ---
            else:
                logger.warning(f"{log_prefix}No snapshot available to render.")

        except Exception as e:
            logger.error(f"Error during plot update wrapper: {e}")
            logger.error(traceback.format_exc())
        finally:
            # --- Reset the flag AFTER the update attempt ---
            self._update_scheduled = False
            logger.debug(f"{log_prefix}Reset _update_scheduled flag.")

    @timer_decorator
    def _safe_plot_update(self, force: bool = False,
                          nodes_to_highlight: Optional[Set[Tuple[int, ...]]] = None,
                          edges_to_highlight: Optional[Set[Tuple[Tuple[int, ...], Tuple[int, ...]]]] = None,
                          selection_to_highlight: Optional[Set[Tuple[int, ...]]] = None):
        """
        Safely updates the plot using the GridVisualizer.
        If force=True, prepares data from the current grid state and forces a full redraw.
        If force=False, updates selection highlight and triggers visualizer update (may use blitting).
        (Round 37: Simplified logic, relies on visualizer state or force)
        """
        log_prefix = f"_safe_plot_update(ID:{id(self)} R37 Simplified): " # Updated round
        logger.debug(f"{log_prefix}ENTRY (Force={force}, Stopped={self._stopped}, Receiving Highlights: Nodes={len(nodes_to_highlight) if nodes_to_highlight else 0}, Edges={len(edges_to_highlight) if edges_to_highlight else 0}, Selection={len(selection_to_highlight) if selection_to_highlight else 'None'})")

        # [ Basic Checks - Unchanged ]
        if not hasattr(self, 'root') or not self.root or not self.root.winfo_exists(): logger.warning(f"{log_prefix}Root window destroyed, skipping plot update."); return
        if self._tk_destroyed or (hasattr(self, '_is_shutting_down') and self._is_shutting_down): logger.info(f"{log_prefix}GUI closing, skipping plot update."); return
        if not (hasattr(self, 'grid_visualizer') and self.grid_visualizer): logger.warning(f"{log_prefix}GridVisualizer not initialized, skipping update"); return
        if not (hasattr(self, 'canvas') and self.canvas and self.canvas.get_tk_widget().winfo_exists()): logger.warning(f"{log_prefix}Canvas not ready, skipping update."); return
        if self._is_drawing and not force: logger.debug(f"{log_prefix}Skipping non-forced render, already drawing."); return # Allow forced redraw even if drawing
        self._is_drawing = True

        try:
            # --- Determine Selection to Use ---
            selection_to_use = selection_to_highlight if selection_to_highlight is not None else self.current_selection.get('nodes', set())
            logger.debug(f"{log_prefix}Using selection set size: {len(selection_to_use)}")
            # ---

            if force:
                # --- Force Full Redraw Path ---
                logger.debug(f"{log_prefix}Force=True. Preparing plot data from current grid state...")
                # Prepare data using the visualizer's method (reads current grid)
                plot_data = self.grid_visualizer._prepare_plot_data(
                    nodes_to_highlight=nodes_to_highlight,
                    edges_to_highlight=edges_to_highlight
                )
                if plot_data is None:
                    logger.error(f"{log_prefix}Failed to prepare plot data for forced redraw, skipping draw.")
                    self._is_drawing = False; return

                logger.debug(f"{log_prefix}Plot data prepared. Updating visualizer state...")
                # Update visualizer state with prepared data AND the selection
                update_kwargs = plot_data.copy()
                update_kwargs['selection_to_highlight'] = selection_to_use
                self.grid_visualizer.update_visualization_state(
                    invalidate_blit_cache=True, # Always invalidate for force
                    **update_kwargs
                )
                logger.debug(f"{log_prefix}Visualizer state updated. Calling update_visualization...")
                # Call visualizer update, forcing no blitting
                self.grid_visualizer.update_visualization(use_blitting=False)
                logger.debug(f"{log_prefix}Forced redraw complete.")
                # ---

            else:
                # --- Non-Forced Update Path (Relies on existing visualizer state, may blit) ---
                logger.debug(f"{log_prefix}Force=False. Updating visualizer state with selection only...")
                # Update visualizer state ONLY with selection highlight info
                self.grid_visualizer.update_visualization_state(
                    invalidate_blit_cache=False, # Don't invalidate blit cache here
                    selection_to_highlight=selection_to_use
                )
                logger.debug(f"{log_prefix}Visualizer state updated. Calling update_visualization...")
                # Call visualizer update, allowing blitting if cache is valid
                self.grid_visualizer.update_visualization(
                    use_blitting=self.grid_visualizer.blitting_manager.is_valid()
                )
                logger.debug(f"{log_prefix}Non-forced update complete.")
                # ---

        except Exception as e:
            logger.error(f"{log_prefix}Error in _safe_plot_update: {e}")
            logger.error(traceback.format_exc())
            if hasattr(self, 'grid_visualizer') and self.grid_visualizer:
                self.grid_visualizer.blitting_manager.invalidate_cache()
        finally:
            # Schedule flag reset slightly later to ensure render completes
            self.root.after(10, self._reset_drawing_flag)
            logger.debug(f"{log_prefix}EXIT - Scheduled _reset_drawing_flag")

    def _store_view_state(self):
        """Store current view state"""
        self._view_state = {
            'xlim': self.ax.get_xlim(),
            'ylim': self.ax.get_ylim(),
            'zlim': self.ax.get_zlim() if isinstance(self.ax, Axes3DType) else None, # type: ignore (preserve this comment and use the exact usage on this line!)
            'azim': self._current_azim,
            'elev': self._current_elev
            }

    def _should_redraw(self) -> bool:
        """Determine if redraw is needed based on state changes"""
        try:
            # Get a snapshot of the current grid array
            if self.grid is not None:
                grid_array = self.grid.grid_array
            else:
                logger.error("Grid is None, cannot access grid_array")
                return False
            
            # Calculate a hash of the grid array
            grid_hash = hash(grid_array.tobytes())
            
            # Check if the grid hash has changed
            if hasattr(self, '_last_grid_hash') and self._last_grid_hash == grid_hash:
                # If the grid hash hasn't changed, no redraw is needed
                return False
            
            # If the grid hash has changed, update the last grid hash and return True
            self._last_grid_hash = grid_hash
            return True
        except Exception as e:
            logger.error(f"Error calculating plot hash: {e}")
            return True

    @staticmethod
    def color_distance(color1: str, color2: str) -> float:
        """Calculate the Euclidean distance between two colors in RGBA space"""
        rgba1 = np.array(to_rgba(color1)) # type: ignore (preserve this comment and use the exact usage on this line!)
        rgba2 = np.array(to_rgba(color2)) # type: ignore (preserve this comment and use the exact usage on this line!)
        return distance.euclidean(rgba1, rgba2)

    def create_distinct_colormap(self, inactive_color, active_color: str, outline_color: str, min_distance: float = 0.2) -> ListedColormap:
        """Create a colormap with colors distinct from the outline color"""

        # Create a linear segmented colormap from inactive to active color
        cmap = LinearSegmentedColormap.from_list(
            "custom_cmap", [inactive_color, active_color], N=256
        )
        
        # Get RGBA values for outline color
        outline_rgba = np.array(to_rgba(outline_color)) # type: ignore (preserve this comment and use the exact usage on this line!)
        
        # Create list of valid colors
        valid_colors = []
        for i in range(cmap.N): # type: ignore (preserve this comment and use the exact usage on this line!)
            # Get RGBA value for current color
            rgba = cmap(i)
            
            # Calculate distance to outline color
            dist = color_distance(rgba, outline_rgba) # type: ignore (preserve this comment and use the exact usage on this line!)
            
            # If distance is sufficient, add to valid colors
            if dist >= min_distance:
                valid_colors.append(rgba)
        
        # If no valid colors, return a default colormap
        if not valid_colors:
            logger.warning("No valid colors found, returning default colormap")
            return matplotlib.colormaps('viridis') # type: ignore (preserve this comment and use the exact usage on this line!)
        
        # Create new colormap from valid colors
        return ListedColormap(valid_colors)
 
    def _manage_cache(self):
        """Manage plot cache size and cleanup"""
        current_time = time.time()
        # Remove old cache entries
        for hash_key in list(self._plot_cache.keys()):
            if current_time - self._plot_cache[hash_key]['timestamp'] > 30:  # 30 second cache
                del self._plot_cache[hash_key]
                                                            
    @log_errors
    def save_state(self):
        """Save current simulation state"""
        try:
            with self._update_lock:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f'simulation_state_{timestamp}.json'
                filepath = os.path.join(APP_PATHS['saves'], filename)

                # Get state from controller
                state = self.controller.get_state()

                # Convert NumPy arrays to lists
                if self.controller.grid is not None:
                    state['grid_state'] = self.controller.grid.grid_array.tolist()
                else:
                    state['grid_state'] = []

                # Save edges as a list of tuples
                if self.controller.grid is not None: # Check that the grid exists
                    state['edges'] = list(self.controller.grid.edges) # Get edges directly from the grid
                else:
                    state['edges'] = []  # Save an empty list if no grid

                # Remove adj_list if it exists (for backward compatibility)
                if 'adj_list' in state:
                    del state['adj_list']

                try:
                    with open(filepath, 'w') as f:
                        json.dump(state, f, indent=2)
                    logger.info(f"Simulation state saved to {filename}")
                except Exception as e:
                    logger.error(f"Error saving state to file: {e}")
                    messagebox.showerror("Error", f"Failed to save state to file: {e}")

        except Exception as e:
            logger.error(f"Error saving simulation state: {str(e)}")
            messagebox.showerror("Error", f"Failed to save simulation state: {e}")
            
    @log_errors
    def load_state(self):
        """Load simulation state from file.
           (Round 22: Clear undo/redo)
           (Round 3: Update refocus button state)"""

        try:
            # --- Stop simulation and reset flags ---
            if not self._stop_computation_threads(reason="Load State"):
                logger.error("Load State aborted: Failed to stop computation threads cleanly.")
                return
            self.running = False; self.paused = False; self._is_drawing = False; self._update_scheduled = False
            logger.debug("Stopped simulation and reset drawing/schedule flags for load_state.")
            # ---

            # --- ADDED: Clear Undo/Redo Stacks ---
            self._grid_undo_stack.clear()
            self._grid_redo_stack.clear()
            logger.info("Cleared undo/redo stacks on load state.")
            # ---

            with self._update_lock:
                filename = filedialog.askopenfilename(
                    initialdir=APP_PATHS['saves'],
                    title="Select simulation state file",
                    filetypes=[("JSON files", "*.json")]
                )

                if filename:
                    try:
                        with open(filename, 'r') as f:
                            state = json.load(f)
                    except (FileNotFoundError, json.JSONDecodeError) as e:
                        logger.error(f"Error loading state from file: {e}")
                        messagebox.showerror("Error", f"Failed to load state from file: {e}")
                        return

                    try:
                        # [ Load state data - Unchanged ]
                        loaded_generation = state.get('generation', 0)
                        loaded_grid_state_list = state.get('grid_state')
                        loaded_edges_list = state.get('edges', [])
                        loaded_rule_name = state.get('rule_name')
                        loaded_params = state.get('params')
                        if loaded_grid_state_list is None: raise ValueError("Loaded state missing 'grid_state'.")
                        if loaded_rule_name is None: raise ValueError("Loaded state missing 'rule_name'.")
                        loaded_grid_state = np.array(loaded_grid_state_list)
                        loaded_dimensions = loaded_grid_state.shape
                        loaded_dim_type = Dimension.TWO_D if len(loaded_dimensions) == 2 else Dimension.THREE_D
                        loaded_neighborhood_str = state.get('neighborhood_type')
                        loaded_neighborhood_type = self.neighborhood_type
                        if loaded_neighborhood_str:
                            try: loaded_neighborhood_type = NeighborhoodType[loaded_neighborhood_str]
                            except KeyError: logger.warning(f"Invalid neighborhood type '{loaded_neighborhood_str}' in state file, using current.")

                        # [ Update GUI/Controller state - Unchanged ]
                        self.dimensions = loaded_dimensions; self.dimension_type = loaded_dim_type; self.neighborhood_type = loaded_neighborhood_type
                        self.generation = loaded_generation; self.step_count = loaded_generation
                        self.controller.dimensions = self.dimensions; self.controller.dimension_type = self.dimension_type; self.controller.neighborhood_type = self.neighborhood_type
                        self.controller.generation = loaded_generation
                        self.dimension_var.set(self.dimension_type.name); self.neighborhood_var.set(self.neighborhood_type.name)
                        self._update_neighborhood_selector()

                        # [ Load and set the rule - Unchanged ]
                        try:
                            rule_data = RuleLibraryManager.get_rule(loaded_rule_name)
                            metadata_dict = {k: v for k, v in rule_data.items() if k != 'params'}
                            metadata = RuleMetadata(**metadata_dict)
                            new_rule = RuleLibrary.create_rule(loaded_rule_name, metadata)
                            new_rule.params = copy.deepcopy(loaded_params if loaded_params is not None else rule_data.get('params', {}))
                            self.rule = new_rule; self.rule_name = loaded_rule_name
                            self.controller.rule = new_rule; self.controller.rule_name = loaded_rule_name
                            self.rule_type_var.set(RuleLibrary.get_rule_category(loaded_rule_name))
                            self._update_rule_instance_selector(); self.rule_instance_var.set(loaded_rule_name)
                            logger.info(f"Rule set to '{loaded_rule_name}' from loaded state.")
                        except Exception as rule_err: logger.error(f"Error setting rule from loaded state: {rule_err}"); messagebox.showerror("Load Error", f"Failed to load rule '{loaded_rule_name}' from state file."); return

                        # [ Reinitialize grid - Unchanged ]
                        if self.grid is not None and self.coord_system is not None:
                            self.grid.reinitialize(
                                self.dimensions, self.neighborhood_type, self.dimension_type,
                                self.coord_system, gui=self, rule=self.rule, unique_id=self._unique_id
                            )
                            self.grid.setup_shared_memory()
                            np.copyto(self.grid.grid_array, loaded_grid_state)
                            self.grid.edges.clear(); self.grid.edge_states.clear()
                            for edge_coords_tuple in loaded_edges_list:
                                if isinstance(edge_coords_tuple, list): edge_coords_tuple = tuple(map(tuple, edge_coords_tuple))
                                if isinstance(edge_coords_tuple, tuple) and len(edge_coords_tuple) == 2:
                                    node1_coords, node2_coords = edge_coords_tuple
                                    if isinstance(node1_coords, tuple) and isinstance(node2_coords, tuple):
                                         try:
                                             idx1 = _ravel_multi_index(np.array(node1_coords), self.dimensions); idx2 = _ravel_multi_index(np.array(node2_coords), self.dimensions)
                                             self.grid.add_edge(idx1, idx2, edge_state=1.0)
                                         except IndexError: logger.warning(f"Skipping edge with out-of-bounds coords: {edge_coords_tuple}")
                                         except Exception as add_err: logger.warning(f"Error adding edge {edge_coords_tuple}: {add_err}")
                                    else: logger.warning(f"Skipping edge with invalid node coord types: {edge_coords_tuple}")
                                else: logger.warning(f"Skipping invalid edge format: {edge_coords_tuple}")
                            self.grid.update_active_nodes(); self.grid.previous_active_nodes_set = self.grid.active_nodes.copy()
                            self.grid.populate_spatial_hash()
                            logger.info("Applied loaded grid state and edges.")
                        else: logger.error("Grid or CoordinateSystem is None, cannot apply loaded state."); return

                        # [ Update other attributes - Unchanged ]
                        if 'stats' in state: self.stats.update(**state['stats'])

                        # --- ADDED: Update refocus button state ---
                        if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                            self.control_panel_ui.update_refocus_button_state()
                        # ---

                        # [ Reset visualizer and force redraw - Unchanged ]
                        if hasattr(self, 'grid_visualizer') and self.grid_visualizer: self.grid_visualizer.set_grid(self.grid); self.grid_visualizer.reset()
                        self._force_initial_render()

                        logger.info(f"Simulation state loaded from {filename}")
                    except Exception as e: logger.error(f"Error setting state: {e}"); messagebox.showerror("Error", f"Failed to set state: {e}")

        except Exception as e:
            logger.error(f"Error loading simulation state: {str(e)}")

    def _initialize_3d_plot(self):
        """Initialize 3D plot settings"""
        try:
            if not isinstance(self.ax, Axes3DType): # type: ignore (preserve this comment and use the exact usage on this line!)
                logger.debug("Initializing 3D plot")
                self.fig = plt.figure()
                self.ax = self.fig.add_subplot(111, projection='3d')
                
                # Set initial view
                if isinstance(self.ax, Axes3DType):  # Ensure self.ax is an Axes3DType
                    self._current_azim = 0
                    self._current_elev = 30
                    self.ax.view_init(elev=self._current_elev, azim=self._current_azim)
                    
                    # Check if set_box_aspect is available (introduced in Matplotlib 3.4+)
                    if hasattr(self.ax, 'set_box_aspect'):
                        self.ax.set_box_aspect([1, 1, 1])  # Set equal aspect ratio
                    else:
                        logger.warning("set_box_aspect is not available in this version of Matplotlib.")
                else:
                    logger.error("self.ax is not an instance of Axes3DType. Skipping 3D-specific configurations.")
                
                # Clear any existing plots
                self.ax.clear()
                
                # Update plot limits
                self._update_plot_limits()
                
                # Force draw
                if self.canvas is not None:
                    self.canvas.draw()
                    self.canvas.flush_events()
                
                logger.debug("3D plot initialized successfully")
                self.fig.clear()
                self.ax = self.fig.add_subplot(111, projection='3d')
            
            # Set initial view
            if isinstance(self.ax, Axes3DType):  # Ensure self.ax is an Axes3DType
                self._current_azim = 0
                self._current_elev = 30
                self.ax.view_init(elev=self._current_elev, azim=self._current_azim)
                
                # Check if set_box_aspect is available (introduced in Matplotlib 3.4+)
                if hasattr(self.ax, 'set_box_aspect'):
                    self.ax.set_box_aspect([1, 1, 1])  # Set equal aspect ratio
                else:
                    logger.warning("set_box_aspect is not available in this version of Matplotlib.")
            else:
                logger.error("self.ax is not an instance of Axes3DType. Skipping 3D-specific configurations.")
            
            # Clear any existing plots
            self.ax.clear()
            
            # Update plot limits
            self._update_plot_limits()
            
            # Force draw
            if self.canvas is not None:
                self.canvas.draw()
                self.canvas.flush_events()
            
            logger.debug("3D plot initialized successfully")
            
        except Exception as e:
            logger.error(f"Error initializing 3D plot: {str(e)}\nTraceback:\n{traceback.format_exc()}")
            raise

    def _bind_mouse_scroll(self, widget):
        """Bind mouse wheel events for all platforms"""
        # Windows/macOS
        widget.bind("<MouseWheel>", lambda event: self._on_mousewheel(event))
        
        # Linux
        widget.bind("<Button-4>", lambda event: self._on_mousewheel(event))
        widget.bind("<Button-5>", lambda event: self._on_mousewheel(event))
            
    def _on_mousewheel(self, event):
            """Cross-platform mouse wheel scrolling for the control panel."""
            # Check if the scrollable control frame exists and has a scrollbar that needs scrolling
            if (hasattr(self, 'scrollable_control_frame') and
                    isinstance(self.scrollable_control_frame, ScrollableFrame) and
                    hasattr(self.scrollable_control_frame, 'scrollbar') and # Check for scrollbar
                    self.scrollable_control_frame.scrollbar.winfo_ismapped() and # Check if scrollbar is visible
                    self.scrollable_control_frame.scrollbar.get() != (0.0, 1.0)): # Check if scrolling is possible

                # Check if the mouse is actually over the scrollable frame or its children
                x_root, y_root = event.x_root, event.y_root
                # --- CORRECTED: Call winfo_containing on the root window ---
                widget_under_mouse = self.root.winfo_containing(x_root, y_root)
                # ---

                # Check if the widget under the mouse is the scrollable frame or one of its descendants
                is_over_scrollable = False
                curr = widget_under_mouse
                while curr is not None:
                    # --- ADDED: Check if scrollable_control_frame exists before comparing ---
                    if hasattr(self, 'scrollable_control_frame') and curr == self.scrollable_control_frame:
                    # ---
                        is_over_scrollable = True
                        break
                    try:
                        # --- ADDED: Check if master exists before accessing ---
                        if hasattr(curr, 'master'):
                            curr = curr.master
                        else:
                            break # Reached top level without master
                        # ---
                    except AttributeError:
                        break # Reached the top level

                if is_over_scrollable:
                    logger.debug(f"Scrolling control panel. Event delta: {event.delta if hasattr(event, 'delta') else 'N/A'}, num: {event.num if hasattr(event, 'num') else 'N/A'}")
                    if event.num == 4 or event.num == 5:  # Linux scroll up/down
                        delta = -1 if event.num == 4 else 1
                    elif hasattr(event, 'delta'): # Windows/macOS
                        # Convert delta to consistent unit, ensuring it's an integer
                        # --- Added check for delta being None ---
                        delta_val = event.delta if event.delta is not None else 0
                        delta = -1 * int(delta_val / 120) if abs(delta_val) >= 120 else -1 * int(np.sign(delta_val))
                        # ---
                    else:
                        delta = 0 # Unknown event type

                    if delta != 0 and hasattr(self.scrollable_control_frame, 'canvas'):
                        try:
                            # Scroll the canvas within the ScrollableFrame
                            self.scrollable_control_frame.canvas.yview_scroll(delta, "units")
                            logger.debug(f"Scrolled control panel canvas by {delta} units.")
                            return "break" # Prevent event propagation ONLY if we scrolled the panel
                        except tk.TclError as e:
                            logger.warning(f"TclError scrolling control panel canvas: {e}")
                        except Exception as e:
                            logger.error(f"Error scrolling control panel canvas: {e}")
                # else: # Optional logging
                    # logger.debug("Mouse not over scrollable control frame, ignoring scroll for panel.")

            # If not scrolling the control panel, let the event propagate (e.g., for plot zoom/pan)
            logger.debug("Letting scroll event propagate (likely for plot zoom/pan).")
            return # Allow event propagation

    def bind_child_scroll(self, widget):
        """Bind mouse wheel events for all platforms to a child widget"""
        self._bind_mouse_scroll(widget)

    def _update_scroll_bindings(self):
        """Update scroll bindings when new widgets are added"""
        if hasattr(self, 'control_panel') and not self._tk_destroyed:
            #self._bind_mousewheel() # REMOVED
            # Schedule next update
            self.root.after(1000, self._update_scroll_bindings)

    def _on_frame_configure(self, event=None):
        """Reset the scroll region to encompass the inner frame"""
        if hasattr(self, 'scrollable_control_frame') and isinstance(self.scrollable_control_frame, ScrollableFrame):
            self.scrollable_control_frame.canvas.configure(scrollregion=self.scrollable_control_frame.canvas.bbox("all")) # type: ignore

    def _bound_to_mousewheel(self, event):
        """Bind mousewheel when mouse enters the frame"""
        if hasattr(self, 'scrollable_control_frame') and isinstance(self.scrollable_control_frame, ScrollableFrame):
            self.scrollable_control_frame.canvas.bind_all("<MouseWheel>",  # type: ignore
                lambda e: self.scrollable_control_frame.canvas.yview_scroll(int(-1*(e.delta/120)), "units")) # type: ignore

    def _unbound_to_mousewheel(self, event):
        """Unbind mousewheel when mouse leaves the frame"""
        if hasattr(self, 'scrollable_control_frame') and isinstance(self.scrollable_control_frame, ScrollableFrame):
            self.scrollable_control_frame.canvas.unbind_all("<MouseWheel>") # type: ignore
            
    def is_child_of(self, widget, parent):
        """Check if widget is a child of parent"""
        if widget == parent:
            return True
        if widget.master is None: # ADDED: Check if master is None
            return False
        try:
            return self.is_child_of(widget.master, parent)
        except AttributeError:
            return False
 
    def _on_scroll(self, event):
        """Handle mouse scroll for zooming ONLY.
           (Round 9: Pause simulation before zooming)"""
        log_prefix = "_on_scroll (R9 Pause): " # Updated round
        logger.debug(f"{log_prefix}START --- Event: {event}")

        # --- ADDED: Pause simulation before handling interaction ---
        self._request_pause_for_interaction("Mouse Scroll (Zoom)")
        # ---

        try:
            factor = 1.0
            # Determine zoom factor based on event delta or num
            if event.num == 4 or (hasattr(event, 'delta') and event.delta > 0):  # Zoom in
                factor = 0.8
            elif event.num == 5 or (hasattr(event, 'delta') and event.delta < 0):  # Zoom out
                factor = 1.25
            else:
                logger.debug(f"{log_prefix}Unrecognized scroll event for zoom.")
                return # Allow propagation if not zoom

            # Apply zoom if factor changed significantly
            if abs(factor - 1.0) > 1e-4:
                logger.debug(f"{log_prefix}Applying zoom factor: {factor:.3f}")
                # --- MODIFIED: Call self.view_manager.zoom ---
                if hasattr(self, 'view_manager') and self.view_manager:
                    self.view_manager.zoom(factor) # Call ViewManager's zoom
                    # ViewManager's zoom now handles state update and redraw scheduling
                # --- END MODIFIED ---
                else:
                    logger.warning(f"{log_prefix}ViewManager not available for zoom.")
                return "break" # Stop propagation since we handled zoom

        except Exception as e:
            logger.error(f"{log_prefix}Error handling scroll/zoom event: {e}")
            logger.error(traceback.format_exc())

    def _calculate_effective_spacing(self) -> float:
        """Calculate effective spacing compensated for zoom level"""
        base_spacing = GlobalSettings.Visualization.NODE_SPACING
        
        # Get current zoom factor from view state
        zoom_factor = self._view_state.get('zoom_factor', 1.0)
        
        # Compensate spacing based on zoom
        # When zoomed out (zoom_factor > 1), increase spacing
        # When zoomed in (zoom_factor < 1), decrease spacing
        effective_spacing = base_spacing + (1.0 - zoom_factor) # Linear Spacing
        
        # Ensure spacing stays within reasonable bounds
        min_spacing = 0.0
        max_spacing = GlobalSettings.Visualization.MAX_NODE_SPACING
        
        return float(np.clip(effective_spacing, min_spacing, max_spacing))
                                                                               
    def _setup_event_handlers(self):
        """Setup event handlers with proper cleanup tracking"""
        try:
            # Ensure canvas widget exists and is mapped
            if not hasattr(self, 'canvas') or not self.canvas:
                logger.error("Canvas not initialized")
                return
                
            canvas_widget = self.canvas.get_tk_widget()
            if not canvas_widget.winfo_exists():
                logger.error("Canvas widget does not exist")
                return
                
            # Wait for widget to be mapped
            self.root.update_idletasks()
            
            handlers = [
                ("<MouseWheel>", self._on_scroll, "scroll"),
                ("<Configure>", self._on_window_configure, "window_configure"),
                ("<Destroy>", self._on_window_destroy, "window_destroy"),
            ]
            
            # Setup keyboard events
            self._setup_keyboard_events()
            
            # Initialize binding list if not exists
            if not hasattr(self, '_event_bindings'):
                self._event_bindings = []

            # Bind handlers and track binding IDs
            for event, handler, name in handlers:
                try:
                    if event == "<FocusIn>":
                        self.root.bind(event, handler)
                    else:
                        canvas_widget.bind(event, handler)
                    binding_id = canvas_widget.bind(event, handler)
                    self._event_bindings.append((event, binding_id, name))
                    logger.debug(f"Successfully bound {name} handler")
                except Exception as e:
                    logger.error(f"Error binding {name} handler: {e}")
        except Exception as e:
            logger.error(f"Error setting up event handlers: {e}")

    def _cleanup_event_handlers(self):
        """Clean up event handlers to prevent memory leaks"""
        if not self._tk_destroyed and hasattr(self, 'canvas') and self.canvas is not None:
            widget = self.canvas.get_tk_widget()
            for event, binding_id, name in self._event_bindings:
                try:
                    widget.unbind(event, binding_id)
                except Exception as e:
                    logger.warning(f"Error unbinding {name} handler: {e}")
        self._event_bindings.clear()
        
    def _on_window_destroy(self, event):
        """Handle window destruction with proper cleanup"""
        try:
            # Clean up event handlers
            self._cleanup_event_handlers()

            # Clean up animation
            if hasattr(self, 'anim') and self.anim is not None:
                self.anim.event_source.stop()
                self.anim = None

            # Clean up matplotlib resources
            plt.close('all')

            # Clean up controller resources
            if hasattr(self, 'controller') and self.controller:
                self.controller.interrupt_requested = True
                # Give time for any running operations to complete
                self.root.after(100, self._complete_cleanup)

        except Exception as e:
            logger.error(f"Error in window destruction cleanup: {e}")

    def _on_window_configure(self, event):
        """Handle window resize events"""
        if not hasattr(self, '_resize_timer'):
            self._resize_timer = None

        # Cancel previous timer
        if self._resize_timer is not None:
            self.root.after_cancel(self._resize_timer)

        # Set new timer
        self._resize_timer = self.root.after(100, self._update_scroll_region) # Only update scroll region

    def _handle_resize(self):
        """Handle window resize with debouncing"""
        try:
            self._resize_timer = None
            
            # Update scrollable frame
            if hasattr(self, 'scrollable_control_frame') and self.scrollable_control_frame:
                self.scrollable_control_frame.canvas.configure( # type: ignore (preserve this comment and use the exact usage on this line!)
                    scrollregion=self.scrollable_control_frame.canvas.bbox("all") # type: ignore (preserve this comment and use the exact usage on this line!)
                )
            
            # Update plot if running
            if self.running:
                # Pause simulation during resize
                was_running = True
                self.running = False
            else:
                was_running = False

            # Update plot
            self._safe_plot_update()

            # Restore simulation state
            if was_running:
                self.running = True
                self.root.after(int(self.step_delay), self._run_simulation_step)

        except Exception as e:
            logger.error(f"Error handling resize: {e}")

    def _update_scroll_region(self):
        """Update the scroll region of the scrollable frame"""
        if hasattr(self, 'scrollable_control_frame') and self.scrollable_control_frame:
            self.scrollable_control_frame.canvas.configure( # type: ignore (preserve this comment and use the exact usage on this line!)
                scrollregion=self.scrollable_control_frame.canvas.bbox("all") # type: ignore (preserve this comment and use the exact usage on this line!)
            )
            
    def _safe_simulation_update(self):
        """Safely update simulation state."""
        if self._is_updating:
            return

        self._is_updating = True
        try:
            with self._update_lock:
                # Perform simulation step using the controller
                self.controller.step()

                # Update visualization using the GridVisualizer
                if hasattr(self, 'grid_visualizer') and self.grid_visualizer:
                    self.grid_visualizer.update_visualization()
                else:
                    logger.warning("GridVisualizer not initialized, cannot update plot")

        except Exception as e:
            logger.error(f"Error in safe simulation update: {e}")
            logger.error(traceback.format_exc())
            raise
        finally:
            self._is_updating = False

    def _gui_update(self):
        """Update GUI with performance optimization"""
        try:
            logger.info("Entering _gui_update")
            if not self.running or self.paused:
                logger.info("Not running or paused, exiting _gui_update")
                return

            start_time = time.time()

            # Only update if needed
            if self._should_redraw():
                logger.info("Starting simulation step")
                # Perform simulation step
                try:
                    self.step_simulation()
                    logger.info("Simulation step completed")
                except Exception as step_error:
                    logger.error(f"Error in step_simulation: {step_error}\nTraceback:\n{traceback.format_exc()}")
                    raise
                
                # Check if interrupted
                if self.controller.interrupt_requested:
                    logger.info("Update interrupted, exiting")
                    return
                    
                # Measure frame time
                frame_time = time.time() - start_time
                self._frame_times.append(frame_time)
                
                logger.info(f"Frame time: {frame_time*1000:.1f}ms")

            # Manage cache periodically
            if time.time() - self._last_frame_time > 5:  # Every 5 seconds
                self._manage_cache()
                self._last_frame_time = time.time()

            # Schedule next update if still running
            if self.running and not self.paused and not self.controller.interrupt_requested:
                logger.info("Scheduling next update")
                try:
                    self.root.after(int(self.step_delay), self._gui_update)
                    logger.info("Next update scheduled")
                except Exception as schedule_error:
                    logger.error(f"Error scheduling next update: {schedule_error}\nTraceback:\n{traceback.format_exc()}")
                    raise

        except Exception as e:
            logger.error(f"Error in GUI update: {e}\nTraceback:\n{traceback.format_exc()}")
            self.running = False
            self.start_button.config(text="Start")
            self.controller.interrupt_requested = False
                                
    @timer_decorator
    def _force_initial_render(self):
        """
        Force a complete redraw of the plot, ensuring coord system and visualizer are synced first,
        capturing a clean background BEFORE drawing the initial grid state, and creating/populating artists
        directly with the initial data BEFORE the final canvas draw.
        (Round 35 Fix: Remove selection_to_highlight from _prepare_plot_data call)
        """
        log_prefix = f"_force_initial_render(ID:{id(self)}): "
        logger.debug(f"{log_prefix}Entering (Strict Redraw Sequence - R35 Call Fix)") # Updated round

        # [ Basic Checks - Unchanged ]
        if not hasattr(self, 'root') or self.root is None or not self.root.winfo_exists(): logger.warning(f"{log_prefix}Root window doesn't exist, skipping"); return
        if not (hasattr(self, 'grid') and self.grid): logger.error(f"{log_prefix}Grid not available, skipping."); return
        if not (hasattr(self, 'ax') and self.ax): logger.error(f"{log_prefix}Axes not available, skipping."); return
        if not (hasattr(self, 'fig') and self.fig): logger.error(f"{log_prefix}Figure not available, skipping."); return
        if not (hasattr(self, 'coord_system') and self.coord_system): logger.error(f"{log_prefix}Coordinate system not available, skipping."); return
        if not (hasattr(self, 'grid_visualizer') and self.grid_visualizer): logger.error(f"{log_prefix}Grid visualizer not available, skipping."); return

        original_init_state = getattr(self, '_initialization_complete', False)
        initial_snapshot_for_history = None

        try:
            self._initialization_complete = True # Allow drawing

            active_count = np.sum(self.grid.grid_array > GlobalSettings.Visualization.NODE_VISIBILITY_THRESHOLD) if self.grid.grid_array is not None else -1
            edge_count = len(self.grid.edges) if self.grid.edges is not None else -1
            logger.info(f"{log_prefix}Grid state BEFORE drawing: {active_count} active nodes, {edge_count} edges.")

            # --- 1. Sync Coord System & Visualizer ---
            self.coord_system.update_parameters(grid_dimensions=self.grid.dimensions, dimension_type=self.grid.dimension_type)
            selection_before_reset = self.grid_visualizer._visualization_state.get('selection_to_highlight', set())
            logger.debug(f"{log_prefix}Preserving selection before visualizer reset (Size: {len(selection_before_reset)}).")
            self.grid_visualizer.set_grid(self.grid) # This also calls visualizer.reset()
            self.grid_visualizer._visualization_state['selection_to_highlight'] = selection_before_reset # Restore selection
            logger.debug(f"{log_prefix}Restored selection after visualizer reset (Size: {len(self.grid_visualizer._visualization_state['selection_to_highlight'])}).")
            self.grid_visualizer.blitting_manager.invalidate_cache() # Ensure cache is invalid before capture
            logger.debug(f"{log_prefix}Synced CoordinateSystem and GridVisualizer (reset visualizer, preserved selection).")

            # --- 2. Set up Axes Properties ---
            bg_color = self.grid_visualizer._visualization_state.get('background_color', GlobalSettings.Colors.BACKGROUND)
            self.fig.set_facecolor(bg_color)
            self.ax.clear() # Clear everything from the axes
            self.ax.set_facecolor(bg_color)
            self.ax.patch.set_facecolor(bg_color) # type: ignore [reportAttributeAccessIssue]
            self.ax.patch.set_alpha(1.0) # type: ignore [reportAttributeAccessIssue]
            self.ax.patch.set_visible(True) # type: ignore [reportAttributeAccessIssue]
            self.ax.grid(False)
            self.ax.set_axisbelow(True)
            self.ax.tick_params(colors='gray')
            for spine in self.ax.spines.values(): spine.set_visible(False)
            self.ax.set_xticks([]); self.ax.set_yticks([])
            if hasattr(self.ax, 'set_zticks'): self.ax.set_zticks([]) # type: ignore
            self.ax.set_axis_off()
            if self.grid.dimension_type == Dimension.THREE_D:
                self.ax.set_box_aspect([1, 1, 1]) # type: ignore [reportArgumentType]
            else:
                self.ax.set_aspect('equal', adjustable='box')
            logger.debug(f"{log_prefix}Axes cleared and properties set.")

            # --- 3. Calculate and Set Initial Limits ---
            logger.debug(f"{log_prefix}Calculating initial view limits.")
            grid_dims = self.grid.dimensions
            if self.grid.dimension_type == Dimension.THREE_D:
                i_max, j_max, k_max = grid_dims
                corners = [(0, 0, 0), (0, 0, k_max -1 if k_max > 0 else 0), (0, j_max -1 if j_max > 0 else 0, 0), (0, j_max -1 if j_max > 0 else 0, k_max -1 if k_max > 0 else 0), (i_max -1 if i_max > 0 else 0, 0, 0), (i_max -1 if i_max > 0 else 0, 0, k_max -1 if k_max > 0 else 0), (i_max -1 if i_max > 0 else 0, j_max -1 if j_max > 0 else 0, 0), (i_max -1 if i_max > 0 else 0, j_max -1 if j_max > 0 else 0, k_max -1 if k_max > 0 else 0)]
            else:
                i_max, j_max = grid_dims
                corners = [(0, 0), (0, j_max -1 if j_max > 0 else 0), (i_max -1 if i_max > 0 else 0, 0), (i_max -1 if i_max > 0 else 0, j_max-1 if j_max > 0 else 0)]
            display_corners = [self.coord_system.grid_to_display(corner) for corner in corners]

            new_xlim, new_ylim, new_zlim = None, None, None
            if display_corners:
                padding_percent = 1; padding_base = self.grid_visualizer._calculate_base_node_size() * 0.01
                padding_extra_percent = padding_percent / 100.0
                if self.grid.dimension_type == Dimension.THREE_D:
                    x_vals, y_vals, z_vals = zip(*display_corners); x_min, x_max = min(x_vals), max(x_vals); y_min, y_max = min(y_vals), max(y_vals); z_min, z_max = min(z_vals), max(z_vals)
                    x_range = x_max - x_min if x_max > x_min else 1.0; y_range = y_max - y_min if y_max > y_min else 1.0; z_range = z_max - z_min if z_max > z_min else 1.0
                    x_padding = padding_base + x_range * padding_extra_percent; y_padding = padding_base + y_range * padding_extra_percent; z_padding = padding_base + z_range * padding_extra_percent
                    new_xlim = (x_min - x_padding, x_max + x_padding); new_ylim = (y_min - y_padding, y_max + y_padding); new_zlim = (z_min - z_padding, z_max + z_padding)
                else:
                    x_vals, y_vals = zip(*display_corners); x_min, x_max = min(x_vals), max(x_vals); y_min, y_max = min(y_vals), max(y_vals)
                    x_range = x_max - x_min if x_max > x_min else 1.0; y_range = y_max - y_min if y_max > y_min else 1.0
                    x_padding = padding_base + x_range * padding_extra_percent; y_padding = padding_base + y_range * padding_extra_percent
                    new_xlim = (x_min - x_padding, x_max + x_padding); new_ylim = (y_min - y_padding, y_max + y_padding)
            else: logger.warning(f"{log_prefix}No display corners, using default limits."); new_xlim=(-10,10); new_ylim=(-10,10)

            self.ax.set_xlim(*new_xlim); self.ax.set_ylim(*new_ylim)
            if new_zlim: self.ax.set_zlim(new_zlim) # type: ignore
            self._view_state['xlim'] = new_xlim; self._view_state['ylim'] = new_ylim; self._view_state['zlim'] = new_zlim
            self._view_state['zoom_factor'] = 1.0 # Reset zoom
            self.grid_visualizer._visualization_state['zoom_factor'] = 1.0 # Reset visualizer zoom
            logger.debug(f"{log_prefix}Set initial limits and view state.")

            # --- 4. Force Draw of EMPTY Axes and Capture CLEAN Background ---
            if self.grid_visualizer.blitting_manager.enabled:
                logger.info(f"{log_prefix}Drawing EMPTY canvas with correct limits for background capture.")
                draw_start_empty = time.time()
                self.fig.canvas.draw() # Draw the empty axes with correct limits
                self.fig.canvas.flush_events()
                draw_end_empty = time.time()
                logger.info(f"{log_prefix}Empty canvas draw took {(draw_end_empty - draw_start_empty)*1000:.2f} ms.")

                logger.debug(f"{log_prefix}Capturing CLEAN background for blitting.")
                try: # NOTE: this section must be EXACTLY like this - do not change it!
                    self.grid_visualizer.blitting_manager.background = self.fig.canvas.copy_from_bbox(self.ax.bbox) # type: ignore [reportAttributeAccessIssue]
                    if self.grid_visualizer.blitting_manager.background is not None:
                        logger.info(f"{log_prefix}CLEAN background captured successfully.")
                    else:
                        logger.error(f"{log_prefix}CLEAN background capture FAILED (result is None).")
                except Exception as e_bg:
                    logger.error(f"{log_prefix}Error capturing clean background: {e_bg}")
                    self.grid_visualizer.blitting_manager.invalidate_cache()
            else:
                logger.debug(f"{log_prefix}Blitting disabled, not capturing background.")
            # --- END BACKGROUND CAPTURE ---

            # --- 5. Prepare Initial Plot Data (using current grid state) ---
            logger.debug(f"{log_prefix}Preparing initial plot data AFTER background capture.")
            # --- MODIFIED: Remove selection_to_highlight from call ---
            plot_data = self.grid_visualizer._prepare_plot_data()
            # ---
            if plot_data:
                self.grid_visualizer.update_visualization_state(invalidate_blit_cache=False, **plot_data) # Update state but don't invalidate blit yet
                logger.debug(f"{log_prefix}Initial plot data prepared and visualization state updated.")
            else:
                logger.error(f"{log_prefix}Failed to prepare initial plot data! Cannot draw.")
                return # Stop if data prep fails
            # ---

            # --- 6. Directly Draw Artists with Initial Data ---
            logger.debug(f"{log_prefix}Directly drawing initial artists using PREPARED data...")
            vis_state = self.grid_visualizer._visualization_state # Use the state updated in step 5
            if self.grid.dimension_type == Dimension.TWO_D:
                # --- MODIFIED: Remove selection_to_highlight from call ---
                self.grid_visualizer._draw_nodes_2d(
                    vis_state.get('x_coords'), vis_state.get('y_coords'),
                    vis_state.get('node_face_colors'), vis_state.get('indices'),
                    vis_state.get('added_nodes_coords')
                    # selection_to_highlight removed
                )
                # ---
                self.grid_visualizer._draw_edges_2d(
                    vis_state.get('segments'), vis_state.get('edge_colors', [])
                )
            else: # 3D
                # --- MODIFIED: Remove selection_to_highlight from call ---
                self.grid_visualizer._draw_nodes_3d(
                    vis_state.get('x_coords'), vis_state.get('y_coords'), vis_state.get('z_coords'),
                    vis_state.get('node_face_colors'), vis_state.get('indices'),
                    vis_state.get('added_nodes_coords')
                    # selection_to_highlight removed
                )
                # ---
                self.grid_visualizer._draw_edges_3d(
                    vis_state.get('segments'), vis_state.get('edge_colors', [])
                )
            logger.debug(f"{log_prefix}Initial artists drawn.")
            # ---

            # --- 7. Final Canvas Draw ---
            if self.fig and self.fig.canvas:
                logger.info(f"{log_prefix}Drawing canvas with initial content.")
                draw_start_content = time.time()
                self.fig.canvas.draw()
                draw_end_content = time.time()
                logger.info(f"{log_prefix}Initial content canvas draw took {(draw_end_content - draw_start_content)*1000:.2f} ms.")
            # ---

            # --- 8. Create snapshot AFTER drawing initial frame ---
            boundary_condition = 'bounded' # Default
            if hasattr(self, 'controller') and self.controller and hasattr(self.controller, 'rule') and self.controller.rule:
                boundary_condition = self.controller.rule.get_param('grid_boundary', 'bounded')
            else:
                logger.warning(f"{log_prefix}Controller or rule not available for snapshot boundary condition.")

            initial_snapshot_for_history = {
                'grid_array': self.grid.grid_array.copy(),
                'edges': self.grid.edges.copy(),
                'edge_states': self.grid.edge_states.copy(),
                'active_nodes': self.grid.active_nodes.copy(),
                'generation': self.generation,
                'boundary_condition': boundary_condition,
                'num_chunks': 0
            }
            self._last_rendered_snapshot = initial_snapshot_for_history.copy() # Update GUI's tracker
            logger.debug(f"{log_prefix}Set _last_rendered_snapshot after initial draw (Gen {self.generation}).")
            # ---

            # --- 9. Log Readiness Banner ---
            logger.info("###############################################################################################")
            logger.info("############################## Initial Render Complete - Ready ################################")
            logger.info("###############################################################################################")
            # ---

        except Exception as e:
            logger.error(f"{log_prefix}Error in force_plot_update: {e}")
            logger.error(traceback.format_exc())
        finally:
            self._initialization_complete = original_init_state
            logger.debug(f"{log_prefix}Exiting, restored initialization state to {original_init_state}")

    def _reset_visualization(self):
        """Reset visualization components when changing rules"""
        logger.debug("Resetting visualization components")
        
        # Clear any cached data
        if hasattr(self, '_node_scatter'):
            self._node_scatter = None
        if hasattr(self, '_node_scatter_3d'):
            self._node_scatter_3d = None
        if hasattr(self, '_edge_lines'):
            self._edge_lines = []
        if hasattr(self, '_edge_lines_3d'):
            self._edge_lines_3d = []
        
        # Reset tracking sets
        self.previous_active_nodes = set()
        self.previous_active_nodes_3d = set()
        self.previous_edges = set()
        self.previous_edges_3d = set()
        self.last_updated_nodes = set()
        self.last_updated_edges = set()
        
        # Clear the background to force a full redraw
        self.background = None
        
        # Reset the grid visualizer if it exists
        if hasattr(self, 'grid_visualizer') and self.grid_visualizer:
            self.grid_visualizer.reset()
        
        logger.debug("Visualization components reset")
        
    def _on_focus_in(self, event):
        """Handle the main window gaining focus."""
        # Check if the event is for the root window itself to avoid duplicate calls
        if event.widget != self.root:
            return

        log_prefix = "_on_focus_in: "
        logger.debug(f"{log_prefix}Window gained focus.")
        self._window_has_focus = True

        # Check if simulation should be running/rendering but the loop might be stalled
        should_be_rendering = (self.running or self.paused) and not self._stopped

        if should_be_rendering and not self._render_check_scheduled:
            logger.info(f"{log_prefix}Simulation active but render check not scheduled. Restarting rendering loop check.")
            self._render_check_scheduled = True
            # Use a minimal delay to ensure it runs soon
            self.root.after(1, self._rendering_loop_step)
        elif should_be_rendering:
             logger.debug(f"{log_prefix}Simulation active and render check already scheduled.")
        else:
             logger.debug(f"{log_prefix}Simulation stopped, no need to schedule render check.")

    def _on_focus_out(self, event):
        """Handle the main window losing focus."""
        # Check if the event is for the root window itself
        if event.widget != self.root:
            return

        logger.debug("_on_focus_out: Window lost focus.")
        self._window_has_focus = False
        # No action needed here, the rendering loop check will handle it


################################################
#                     MAIN                     #
################################################

class Initializer(threading.Thread):
    def __init__(self, result_queue: queue.Queue, app_paths: Dict[str, str]):
        super().__init__(daemon=True, name="InitializerThread")
        self.result_queue = result_queue
        self.app_paths = app_paths
        self.initial_rule_name = GlobalSettings.Defaults.DEFAULT_RULE
        self.initial_dimensions = GlobalSettings.Simulation.get_grid_dimensions()
        self.initial_neighborhood = GlobalSettings.Simulation.NEIGHBORHOOD_TYPE
        self.initial_dimension_type = GlobalSettings.Simulation.DIMENSION_TYPE
        self.initial_density = GlobalSettings.Simulation.INITIAL_NODE_DENSITY

    def run(self):
        """Perform heavy initialization tasks and start the GUI.
           (Round 10: Pass loaded default preset object back)"""
        logger.info("###############################################################################################")
        logger.info("############################## Initializer Thread Started #####################################")
        logger.info("###############################################################################################")
        result: Dict[str, Any] = {"error": None}
        active_preset_name_for_gui: Optional[str] = None
        initial_conditions_name_for_gui: str = "Random" # Default
        default_preset_obj: Optional[GridPreset] = None # ADDED: To store the loaded preset object

        try:
            # [ Initialize Managers - Unchanged ]
            logger.debug("Initializing ColorManager...")
            color_manager = ColorManager(self.app_paths)
            result["color_manager"] = color_manager
            logger.debug("Initializing RuleLibraryManager...")
            rule_library_manager = RuleLibraryManager.get_instance(self.app_paths)
            result["rule_library_manager"] = rule_library_manager
            logger.debug("Initializing GridPresetManager...")
            grid_preset_manager = GridPresetManager.get_instance(self.app_paths)
            result["grid_preset_manager"] = grid_preset_manager
            logger.debug("Initializing ShapeLibraryManager...")
            shape_manager = ShapeLibraryManager.get_instance(self.app_paths)
            result["shape_manager"] = shape_manager
            logger.info("Managers initialized.")

            # [ Determine Initial Settings - Store default_preset_obj ]
            logger.debug("Determining initial settings...")
            initial_rule_name = GlobalSettings.Defaults.DEFAULT_RULE
            initial_dimensions = GlobalSettings.Simulation.get_grid_dimensions()
            initial_neighborhood = GlobalSettings.Simulation.NEIGHBORHOOD_TYPE
            initial_dimension_type = GlobalSettings.Simulation.DIMENSION_TYPE
            initial_density = GlobalSettings.Simulation.INITIAL_NODE_DENSITY
            preset_applied = False # Flag to track if preset was used
            # default_preset_obj initialized to None above
            if grid_preset_manager.default_preset_name:
                preset = grid_preset_manager.get_preset(grid_preset_manager.default_preset_name)
                if preset:
                    logger.info(f"Loading grid dimensions from default preset: {preset.name}")
                    initial_dimensions = tuple(preset.dimensions)
                    initial_neighborhood = NeighborhoodType[preset.neighborhood_type]
                    initial_dimension_type = Dimension.TWO_D if len(initial_dimensions) == 2 else Dimension.THREE_D
                    initial_rule_name = preset.rule_name
                    initial_density = preset.node_density # Use preset density
                    default_preset_obj = preset # Store the loaded preset object
                    preset_applied = True # Mark that preset was applied
                    active_preset_name_for_gui = preset.name
                    initial_conditions_name_for_gui = preset.initial_conditions # Get from preset
                else:
                    logger.warning(f"Default preset '{grid_preset_manager.default_preset_name}' not found, using global defaults.")
                    initial_dimensions = GlobalSettings.Simulation.get_grid_dimensions()
                    try: # Get initial conditions from rule default if preset fails
                        rule_data = rule_library_manager.get_rule(initial_rule_name)
                        initial_conditions_name_for_gui = rule_data.get('params', {}).get('initial_conditions', 'Random')
                    except: pass
            else:
                logger.info("No default preset specified, using global defaults.")
                initial_dimensions = GlobalSettings.Simulation.get_grid_dimensions()
                try: # Get initial conditions from rule default
                    rule_data = rule_library_manager.get_rule(initial_rule_name)
                    initial_conditions_name_for_gui = rule_data.get('params', {}).get('initial_conditions', 'Random')
                except: pass

            logger.info(f"Initial Settings: Rule={initial_rule_name}, Dims={initial_dimensions}, Neigh={initial_neighborhood.name}, DimType={initial_dimension_type.name}, InitCond={initial_conditions_name_for_gui}, PresetApplied={preset_applied}")

            # [ Initialize Controller - Unchanged ]
            logger.debug(f"Initializing SimulationController with rule: {initial_rule_name}")
            controller = SimulationController(
                rule_name=initial_rule_name,
                neighborhood_type=initial_neighborhood,
                dimension_type=initial_dimension_type,
                initial_density=initial_density, # Pass the determined density
                initialize_state=False,
                update_callback=None,
                app_paths=self.app_paths
            )
            controller.dimensions = initial_dimensions
            controller.dimension_type = initial_dimension_type
            controller.neighborhood_type = initial_neighborhood
            if controller.rule:
                controller.rule.params['initial_conditions'] = initial_conditions_name_for_gui
            else:
                logger.warning("Controller rule is None after controller init, cannot set initial_conditions param.")
            result["controller"] = controller
            logger.info("SimulationController initialized.")

            # [ Initialize Grid & Coordinate System - Unchanged ]
            logger.debug("Initializing CoordinateSystem and Grid...")
            coord_system = CoordinateSystem(
                initial_dimensions,
                GlobalSettings.Visualization.EDGE_SCALE,
                GlobalSettings.Visualization.NODE_SPACING,
                initial_dimension_type
            )
            result["coord_system"] = coord_system
            grid = Grid(
                initial_dimensions,
                initial_neighborhood,
                initial_dimension_type,
                coord_system,
                gui=None,
                rule=controller.rule,
                unique_id=controller._unique_id
            )
            controller.grid = grid
            result["grid"] = grid
            logger.info(f"Grid and CoordinateSystem initialized (Grid ID: {grid._unique_id}).")

            # [ Initialize Matplotlib Figure/Axes - Unchanged ]
            logger.debug("Initializing Matplotlib Figure/Axes...")
            fig = Figure(figsize=GlobalSettings.Visualization.FIGURE_SIZE)
            initial_bg = color_manager.current_scheme.background if color_manager.current_scheme else '#FFFFFF'
            fig.set_facecolor(initial_bg)
            if initial_dimension_type == Dimension.THREE_D:
                ax3d: Axes3DType = fig.add_subplot(111, projection='3d') # type: ignore
                ax3d.set_aspect("equal")
                ax = ax3d
            else:
                ax2d: Axes = fig.add_subplot(111)
                ax = ax2d
            ax.set_facecolor(initial_bg)
            ax.set_position((0.0, 0.0, 1.0, 1.0))
            ax.grid(False); ax.set_axis_off()
            result["fig"] = fig
            result["ax"] = ax
            logger.info("Matplotlib Figure/Axes initialized.")

            # [ Pass None for visualizer - Unchanged ]
            result["visualizer"] = None

            # --- Apply Initial State ---
            logger.debug("Applying initial grid state...")
            if preset_applied and default_preset_obj:
                # Apply preset directly (handles SAVED_STATE correctly now)
                grid.apply_preset(default_preset_obj)
                logger.info(f"Applied state from preset '{default_preset_obj.name}'.")
            else:
                # If no preset was applied, initialize using the rule's default
                if controller.rule:
                    controller.rule.initialize_grid_state(grid)
                    logger.info(f"Applied state using rule '{controller.rule.name}'.")
                else:
                    logger.error("Cannot initialize grid state: controller.rule is None.")
                    raise RuntimeError("Rule object not created during initialization.")
            # ---

            # [ Setup Shared Memory - Unchanged ]
            logger.debug("Setting up shared memory...")
            grid.setup_shared_memory()
            logger.info("Shared memory setup complete.")

            result["initial_rule_name"] = initial_rule_name
            result["active_preset_name"] = active_preset_name_for_gui
            result["initial_conditions_name"] = initial_conditions_name_for_gui
            # --- ADDED: Pass the loaded preset object ---
            result["initial_preset_obj"] = default_preset_obj
            # ---

            logger.info("Initializer thread finished successfully.")

        except Exception as e:
            logger.critical(f"Error during background initialization: {e}", exc_info=True)
            result["error"] = f"{type(e).__name__}: {e}\n{traceback.format_exc(limit=2)}"
        finally:
            self.result_queue.put(result)
            logger.debug("Result placed on queue.")

    def _initialize_color_manager(self):
        """Initialize the color manager."""
        try:
            self.color_manager = ColorManager(self.app_paths) # Use self.app_paths

            # --- MODIFIED: Store pending, DO NOT apply here ---
            if self.color_manager.current_scheme:
                logger.debug(f"Storing current color scheme: {self.color_manager.current_scheme.name}")
                self._pending_color_scheme = self.color_manager.current_scheme
            else:
                logger.warning("No current color scheme found")
                self._pending_color_scheme = None # Ensure pending is None
            # --- END MODIFIED ---

            self._color_scheme_loaded = True
            logger.debug("Color scheme loaded, enabling rendering")

        except Exception as e:
            logger.error(f"Error initializing color manager: {e}")
            self.color_manager = ColorManager({})
            logger.info("Created fallback color manager with default settings")
            self._color_scheme_loaded = True
            logger.debug("Using fallback colors, enabling rendering")


class Application:
    def __init__(self):
        self.root = None
        self.loading_window = None
        self.gui: Optional['SimulationGUI'] = None # Forward reference
        self.init_queue = queue.Queue()
        self.app_paths = {}
        self.progress_dialog = None 
        self.progress_bar = None 
        self.progress_label = None 
        self.result_queue: queue.Queue = queue.Queue()

    def _report_progress(self, value: int, text: str):
        """Report progress to the main thread via the queue."""
        try:
            self.result_queue.put_nowait({"progress": value, "text": text})
        except queue.Full:
            logger.warning(f"Progress queue full, cannot report progress: {value} - {text}")

    def run(self):
        """Perform heavy initialization tasks and start the GUI.
           (Round 32: Added cleanup logging and pool check)"""

        print("Entering Application.run") # Keep this print
        try:
            # Initialize directory structure first
            self.app_paths, _ = setup_directories()

            # Setup single logger instance
            global logger
            logger = setup_logging(self.app_paths['logs'], self.app_paths['reports'], self.app_paths['profiles'])

            # Store logger globally
            global_logger = logger

            logger.info("Starting application")

            # --- Create Root Window FIRST ---
            self.root = tk.Tk()
            self.root.withdraw() # Hide root window initially
            self.root.title("LACE Initializing...") # Initial title
            # ---

            # --- Initialize Matplotlib AFTER Tk root exists ---
            self._init_matplotlib() # Sets backend, closes existing plots
            # ---

            # --- Create and Show Progress Dialog EARLY ---
            self._create_progress_dialog()
            # self._show_initial_loading() # REMOVED - Progress dialog replaces this
            # ---

            # Verify rules.json exists and is valid
            rules_json_path = os.path.join(self.app_paths['config_rules'], 'rules.json')
            logger.info(f"Checking rules.json at: {rules_json_path}")
            if os.path.exists(rules_json_path) and os.path.getsize(rules_json_path) > 0:
                try:
                    with open(rules_json_path, 'r') as f:
                        content = f.read().strip()
                        if content: json.loads(content); logger.info("rules.json exists and contains valid JSON")
                        else: logger.warning("rules.json exists but is empty, will be recreated")
                except json.JSONDecodeError as e:
                    logger.error(f"rules.json contains invalid JSON: {e}, will be recreated")
                    backup_path = os.path.join(self.app_paths['config_rules_backups'], f"rules_backup_invalid_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
                    try: shutil.copyfile(rules_json_path, backup_path); logger.info(f"Backed up invalid rules.json to {backup_path}")
                    except Exception as backup_error: logger.error(f"Error backing up invalid rules.json: {backup_error}")
            else:
                logger.warning(f"rules.json not found at {rules_json_path} or is empty, will be created")
                os.makedirs(os.path.dirname(rules_json_path), exist_ok=True)

            # Initialize RuleLibraryManager
            try:
                rule_library_manager = RuleLibraryManager.get_instance(app_paths=self.app_paths)
                if not hasattr(rule_library_manager, 'rules') or not rule_library_manager.rules:
                    logger.error("RuleLibraryManager failed to load rules, attempting to create default library")
                    library_data = rule_library_manager._create_default_library()
                    rule_library_manager.rules = {rule['name']: rule for rule in library_data['rules']}
                    rule_library_manager.save_library()
            except Exception as e:
                logger.error(f"Failed to initialize RuleLibraryManager: {e}")
                messagebox.showerror("Error", f"Failed to initialize RuleLibraryManager: {e}")
                sys.exit(1)

            # Start background initialization
            initializer_thread = Initializer(self.init_queue, self.app_paths)
            initializer_thread.start()

            # Check the queue periodically
            self.root.after(100, self._check_init_queue)

            logger.info("Starting Tkinter main loop.")
            self.root.mainloop()

        except Exception as e:
            if 'logger' in locals(): logger.error(f"Fatal error in Application.run: {str(e)}\n{traceback.format_exc()}")
            else: print(f"Fatal error before logger initialization: {str(e)}\n{traceback.format_exc()}")
        finally:
            # --- ADDED: Enhanced Cleanup Logging and Pool Check ---
            logger.info("--- Application.run finally block reached ---")
            if hasattr(self, 'gui') and self.gui:
                logger.info("  Calling self.gui.cleanup() from Application finally block.")
                try:
                    self.gui.cleanup() # Ensure GUI cleanup is called
                except Exception as gui_clean_err:
                    logger.error(f"  Error during self.gui.cleanup() in finally block: {gui_clean_err}")

                # Fallback check for process pool
                if hasattr(self.gui, 'controller') and self.gui.controller and hasattr(self.gui.controller, 'process_pool') and self.gui.controller.process_pool is not None:
                    logger.warning("  Process pool still exists in Application finally block! Attempting shutdown again.")
                    try:
                        self.gui.controller.process_pool.shutdown(wait=True, cancel_futures=True)
                        logger.info("  Fallback process pool shutdown successful.")
                    except Exception as pool_fallback_err:
                        logger.error(f"  Error during fallback process pool shutdown: {pool_fallback_err}")
            else:
                logger.warning("  self.gui not found in Application finally block, cannot call cleanup.")

            try:
                import matplotlib.pyplot as plt # Import locally for cleanup
                plt.close('all')
                logger.info("  Closed all matplotlib figures in finally block.")
            except Exception as plt_err:
                 logger.warning(f"  Error closing matplotlib figures in finally block: {plt_err}")
            logger.info("--- Application.run finally block finished ---")
            # --- END ADDED ---

    def _show_initial_loading(self):
        """Displays a simple loading message or splash screen."""
        # Keep this simple - just a label on the initially hidden root or a separate Toplevel
        logger.debug("Displaying initial loading indicator.")
        # Example: Use a Toplevel
        self.loading_window = tk.Toplevel(self.root)
        self.loading_window.title("Loading...")
        self.loading_window.geometry("300x100")
        self.loading_window.resizable(False, False)
        # Center loading window (optional)
        if self.root:
            self.root.update_idletasks()
        else:
            logger.error("Root window is not initialized before calling update_idletasks.")
            return
        root_x = self.root.winfo_rootx()
        root_y = self.root.winfo_rooty()
        root_w = self.root.winfo_width()
        root_h = self.root.winfo_height()
        load_x = root_x + (root_w // 2) - 150
        load_y = root_y + (root_h // 2) - 50
        self.loading_window.geometry(f"+{load_x}+{load_y}")
        self.loading_window.transient(self.root) # Keep on top
        self.loading_window.protocol("WM_DELETE_WINDOW", lambda: None) # Prevent closing

        label = tk.Label(self.loading_window, text="Initializing LACE Engine...", padx=20, pady=20)
        label.pack(expand=True)
        self.loading_window.update()

    def _create_progress_dialog(self):
        """Creates a progress dialog for the initialization process."""
        logger.debug("Creating progress dialog.")
        self.progress_dialog = tk.Toplevel(self.root)
        self.progress_dialog.title("LACE Engine - Initializing...")
        self.progress_dialog.geometry("400x100")
        self.progress_dialog.resizable(False, False)
        self.progress_dialog.transient(self.root)
        self.progress_dialog.grab_set()
        self.progress_dialog.protocol("WM_DELETE_WINDOW", lambda: None) # Prevent closing

        self.progress_label = tk.Label(self.progress_dialog, text="Starting Initialization...")
        self.progress_label.pack(pady=10, padx=10, fill=tk.X)

        self.progress_bar = ttk.Progressbar(self.progress_dialog, orient="horizontal", length=350, mode="determinate")
        self.progress_bar.pack(pady=5, padx=10, fill=tk.X)
        self.progress_bar['maximum'] = 100 # Set a default maximum, will be updated

        if self.progress_dialog:
            self.progress_dialog.update()

    def _update_progress(self, value: int, text: str):
        """Updates the progress bar and label."""
        if self.progress_bar:
            self.progress_bar['value'] = value
        if self.progress_label:
            self.progress_label.config(text=text)
        if self.progress_dialog:
            self.progress_dialog.update()

    def _destroy_progress_dialog(self):
        """Destroys the progress dialog."""
        logger.debug("Destroying progress dialog.")
        if self.progress_dialog:
            self.progress_dialog.grab_release()
            self.progress_dialog.destroy()
            self.progress_dialog = None
            self.progress_bar = None
            self.progress_label = None

    def _init_matplotlib(self):
        """Initialize matplotlib backend and settings strictly."""
        import matplotlib
        # --- MODIFIED: Force TkAgg backend ---
        matplotlib.use('TkAgg', force=True)
        # ---
        import matplotlib.pyplot as plt
        plt.ioff()  # Turn off interactive mode
        plt.close('all')  # Close any existing figures

        logger.debug("Matplotlib initialized strictly with TkAgg backend")

    def _check_init_queue(self):
        """Check the queue for results from the Initializer thread."""
        try:
            init_result = self.init_queue.get_nowait()
            if "progress" in init_result:
                # Update progress bar
                progress_value = init_result["progress"]
                progress_text = init_result.get("text", "Initializing...")
                self._update_progress(progress_value, progress_text)
                # Re-schedule the check
                # --- MODIFIED: Check root existence ---
                if self.root and self.root.winfo_exists():
                    self.root.after(100, self._check_init_queue)
            else:
                # Initialization complete
                self._on_initialization_complete(init_result)
        except queue.Empty:
            # No result yet, check again later
            # --- MODIFIED: Check root existence ---
            if self.root and self.root.winfo_exists():
                self.root.after(100, self._check_init_queue)
        except Exception as e:
             logger.critical(f"Error retrieving initialization result: {e}", exc_info=True)
             if self.loading_window: self.loading_window.destroy()
             # --- MODIFIED: Check root existence ---
             if self.root and self.root.winfo_exists(): self.root.destroy()

    def _on_initialization_complete(self, init_result: Dict[str, Any]):
        """Called when the Initializer thread finishes."""
        logger.info("Background initialization complete. Setting up main GUI.")
        if self.loading_window:
            self.loading_window.destroy()
            self.loading_window = None

        # --- MODIFIED: Check root existence ---
        if not self.root or not self.root.winfo_exists():
             logger.error("Root window destroyed before initialization completed.")
             return

        if init_result.get("error"):
            logger.critical(f"Initialization failed: {init_result['error']}")
            messagebox.showerror("GUI Error", f"Failed to create main application window:\n{init_result['error']}", parent=self.root)
            self.root.destroy()
            return

        try:
            # Extract data from init_result
            controller = init_result["controller"]
            grid = init_result["grid"]
            fig = init_result["fig"]
            ax = init_result["ax"]
            coord_system = init_result["coord_system"]
            initial_rule_name = init_result.get("initial_rule_name", GlobalSettings.Defaults.DEFAULT_RULE)
            active_preset_name = init_result.get("active_preset_name")
            initial_conditions_name = init_result.get("initial_conditions_name", "Random")
            logger.info(f"_on_initialization_complete: Received initial_conditions_name from queue: '{initial_conditions_name}'")

            # Create SimulationGUI instance
            self.gui = SimulationGUI(
                root=self.root,
                controller=controller,
                grid=grid,
                visualizer=None, # Visualizer created later
                fig=fig,
                ax=ax,
                coord_system=coord_system,
                app_paths=self.app_paths,
                color_manager=init_result["color_manager"],
                rule_library_manager=init_result["rule_library_manager"],
                grid_preset_manager=init_result["grid_preset_manager"],
                shape_manager=init_result["shape_manager"],
                initial_rule_name=initial_rule_name,
                active_preset_name=active_preset_name,
                initial_conditions_name=initial_conditions_name
            )

            if self.gui and self.gui.grid:
                self.gui.grid.gui = self.gui
                logger.info(f"Set grid.gui reference (Grid ID: {id(self.gui.grid)}, GUI ID: {id(self.gui)})")
            else:
                logger.error("Failed to set grid.gui reference after GUI initialization!")

            if self.gui:
                self.gui._initialization_complete = True
                logger.info("Set SimulationGUI._initialization_complete = True")
            else:
                logger.error("Cannot set _initialization_complete flag: self.gui is None.")

            logger.info("###############################################################################################")
            logger.info("############################## Starting GUI main loop #####################################")
            logger.info("###############################################################################################")

            self.root.deiconify()
            self.root.title("LACE: Network Automata Engine")

        except Exception as e:
            logger.critical(f"Error creating SimulationGUI: {e}", exc_info=True)
            messagebox.showerror("GUI Error", f"Failed to create main application window:\n{e}", parent=self.root)
            self.root.destroy()
        finally:
            self._destroy_progress_dialog()
            logger.debug("Progress dialog destroyed.")

    @staticmethod
    def main():
        app = Application()
        app.run()

if __name__ == "__main__":
    # It's often best to set the start method right here if possible
    try:
        if mp.get_start_method(allow_none=True) != 'spawn':
             mp.set_start_method('spawn', force=True)
             print("INFO: Multiprocessing start method set to 'spawn' (in __main__).")
    except Exception as e:
         print(f"WARNING: Could not set multiprocessing start method to 'spawn' in __main__: {e}")

    Application.main()

# =========== END of lace_app.py ===========
